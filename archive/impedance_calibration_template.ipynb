{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "1. Network Preperation\n",
    "1. Import Matched Trace Data\n",
    "2. Specify Calibration Parameters\n",
    "    - Link Impedance Function\n",
    "    - Turn Impedance Function\n",
    "    - Objective Function\n",
    "        - Exact Overlap\n",
    "        - Buffer Overlap (in progress)\n",
    "        - Frechet Distance (in progress)\n",
    "3. Run Calibration (in progress)\n",
    "4. Export Results to Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "from network.src import modeling_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "network_fp = Path(config['project_directory']) / \"Map_Matching\"\n",
    "traces_fp = Path(config['project_directory']) / \"CycleAtlanta\"\n",
    "export_fp = Path(config['project_directory']) / \"Calibration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pyproj is pointing to a postgis installation?\n",
    "# import pyproj\n",
    "# #pyproj.datadir.get_data_dir()\n",
    "# #https://pyproj4.github.io/pyproj/stable/api/datadir.html#pyproj.datadir.get_data_dir\n",
    "# #https://stackoverflow.com/questions/69630630/on-fresh-conda-installation-of-pyproj-pyproj-unable-to-set-database-path-pypr\n",
    "# proj_dir = r'C:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\Library\\share\\proj'\n",
    "# pyproj.datadir.set_data_dir(proj_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (fp / 'chosen.pkl').open('rb') as fh:\n",
    "    links,turns,turn_G = pickle.load(fh)\n",
    "del turn_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G = modeling_turns.make_turn_graph(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalculate length and add to network\n",
    "fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\"\n",
    "edges = gpd.read_file(fp/'networks/elevation_added.gpkg',layer=\"links\")\n",
    "edges.to_crs('epsg:2240',inplace=True)\n",
    "geo_dict = dict(zip(edges['linkid'],edges['geometry']))\n",
    "length_dict = dict(zip(edges['linkid'],edges.length))\n",
    "del edges\n",
    "\n",
    "links['length_ft'] = links['linkid'].map(length_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shouldnt need this anymore\n",
    "# multi_edges = df_edges.loc[df_edges[['source','target']].duplicated(keep=False),['source','target']]\n",
    "# src = turns.merge(multi_edges,left_on=['source_A','source_B'],right_on=['source','target']).index.tolist()\n",
    "# trgt = turns.merge(multi_edges,left_on=['target_A','target_B'],right_on=['source','target']).index.tolist()\n",
    "# multi_edges = list(set(src + trgt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format variables (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['high_traffic_stress'] = links['highway'] == 'primary'\n",
    "# df_edges['bike_facility_type'].value_counts()\n",
    "# df_edges['high_traffic_stress'] = df_edges['bike_facility_type'].isna() & (df_edges['highway'].map(levels) > 4 | df_edges['speed limit'] > 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format turn variables (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns['left'] = turns['turn_type'] == 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Link Impedance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have position of beta next to name of variable\n",
    "betas_links = {\n",
    "    0 : 'ascent_grade',\n",
    "    1 : 'high_traffic_stress',\n",
    "}\n",
    "\n",
    "betas_turns = {\n",
    "    2 : 'signalized',\n",
    "    3 : 'unsignalized',\n",
    "    4 : 'left',\n",
    "}\n",
    "\n",
    "'''\n",
    "Currently works with binary and numeric variables. Categoricals will have to be\n",
    "cast into a different format for now.\n",
    "\n",
    "Link impedance is weighted by the length of the link, turns are just the impedance associated\n",
    "'''\n",
    "\n",
    "#customize this function to change impedance formula\n",
    "#TODO streamline process of trying out new impedance functions\n",
    "def link_impedance_function(betas,beta_links,links):\n",
    "    #prevent mutating the original links gdf\n",
    "    links = links.copy()\n",
    "    \n",
    "    links['attr_multiplier'] = 0\n",
    "\n",
    "    for key, item in beta_links.items():\n",
    "        links['attr_multiplier'] = links['attr_multiplier'] + (betas[key] * links[item])\n",
    "\n",
    "    links['link_cost'] = links['length_ft'] * (1 + links['attr_multiplier'])\n",
    "    \n",
    "    return links\n",
    "\n",
    "def turn_impedance_function(betas,beta_turns,turns):\n",
    "    #use beta coefficient to calculate turn cost\n",
    "    base_turn_cost = 30 # from Lowry et al 2016 DOI: http://dx.doi.org/10.1016/j.tra.2016.02.003\n",
    "    # turn_costs = {\n",
    "    #     'left': betas[1] * base_turn_cost,\n",
    "    #     'right': betas[1] * base_turn_cost,\n",
    "    #     'straight': betas[1] * base_turn_cost\n",
    "    # }\n",
    "    #turns['turn_cost'] = turns['turn_type'].map(turn_costs)\n",
    "\n",
    "    turns = turns.copy()\n",
    "\n",
    "    turns['turn_cost'] = 0\n",
    "\n",
    "    for key, item in beta_turns.items():\n",
    "        turns['turn_cost'] = turns['turn_cost'] + (betas[key] * turns[item])\n",
    "\n",
    "    turns['turn_cost'] = turns['turn_cost'].astype(float)\n",
    "\n",
    "    return turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test impedance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [3,4,20,20,50]\n",
    "\n",
    "#round betas to nearest hundreths\n",
    "betas = np.round(betas,2)\n",
    "\n",
    "# #prevent negative link weights\n",
    "# if (betas < 0).any():\n",
    "#     val = 0\n",
    "#     return val\n",
    "\n",
    "#use provided link impedance function and update edge costs\n",
    "links = link_impedance_function(betas, betas_links, links)\n",
    "cost_dict = dict(zip(links['linkid'],links['link_cost']))\n",
    "turns['source_link_cost'] = turns['source_linkid'].map(cost_dict)\n",
    "turns['target_link_cost'] = turns['target_linkid'].map(cost_dict)\n",
    "\n",
    "#use provided turn impedance function and update turn costs\n",
    "turns = turn_impedance_function(betas, betas_turns, turns)\n",
    "\n",
    "#cacluate new total cost and round to tenth place\n",
    "turns['total_cost'] = (turns['source_link_cost'] + turns['target_link_cost'] + turns['turn_cost']).round(1)\n",
    "\n",
    "#round the rest too\n",
    "turns['source_link_cost'] = turns['source_link_cost'].round(1)\n",
    "turns['target_link_cost'] = turns['target_link_cost'].round(1)\n",
    "turns['turn_cost'] = turns['turn_cost'].round(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['source_linkid','source_reverse_link','target_linkid','target_reverse_link','total_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G.get_edge_data(u=(2,False),v=(0,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [betas,betas_links,betas_turns,link_impedance_function,turn_impedance_function,links,turns,turn_G]\n",
    "stochastic_optimization.impedance_update(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G.get_edge_data(u=(2,False),v=(0,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G.get_edge_data(u=(2,False),v=(0,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_edge_costs = {((row[0],row[1]),(row[2],row[3])):row[4] for row in turns[cols].itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(turn_G,values=updated_edge_costs,name='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Matched Trace Data\n",
    "Dictionary Containing Origins and Destinations, Matches, Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export for impedance calibration\n",
    "with (Path('D:/matched_traces')/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    match_results = pickle.load(fh)\n",
    "# with (Path('D:/matched_traces')/'ready4calibration.pkl').open('rb') as fh:\n",
    "#     matched_traces = pickle.load(fh)\n",
    "\n",
    "#retrieve all ods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import trips table and knock out excessiely long trips, primarily exercise trips etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into s training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_key(dictionary):\n",
    "    random_key =  random.choice(list(dictionary.keys()))\n",
    "    #recursion?\n",
    "    if isinstance(dictionary.get(random_key),str):\n",
    "        random_key = get_random_key(dictionary)\n",
    "    return random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_keys = set([get_random_key(match_results) for x in range(0,100)])\n",
    "match_results = {key:item for key, item in match_results.items() if key in random_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods = stochastic_optimization.match_results_to_ods(match_results)\n",
    "\n",
    "# objective_function = stochastic_optimization.exact_overlap\n",
    "# objective_function_args = {'length_dict':length_dict,'standardize':True}\n",
    "\n",
    "objective_function = stochastic_optimization.buffer_overlap\n",
    "objective_function_args = {'geo_dict':geo_dict,'buffer_ft':50,'standardize':True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vals = stochastic_optimization.impedance_calibration(ods,match_results,\n",
    "                                  betas,betas_links,betas_turns,\n",
    "                                  link_impedance_function,\n",
    "                                  turn_impedance_function,\n",
    "                                  links,turns,turn_G,\n",
    "                                  objective_function,\n",
    "                                  **objective_function_args\n",
    "                                  )\n",
    "test_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods = [(key,item['start_node'],item['end_node']) for key, item in match_results.items()]\n",
    "ods = pd.DataFrame(ods,columns=['tripid','start_node','end_node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplify ods for shortest path calculations\n",
    "ods0 = [tuple(row) for row in ods[['start_node','end_node']].drop_duplicates().to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = 68168815\n",
    "# d = 7502147722\n",
    "# turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns,turn_G,[o],[d])\n",
    "# length, edge_list = nx.single_source_dijkstra(turn_G,source=o,target=d,weight='weight')\n",
    "# turn_G = modeling_turns.remove_virtual_links_new(turn_G,virtual_starts,virtual_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate Dijkstra's shortest paths for a single source\n",
    "def impedance_path(turns,turn_G,o,d):\n",
    "    #NOTE: without these it'll throw a 'the result is ambiguous error'\n",
    "    o = int(o)\n",
    "    d = int(d)\n",
    "    \n",
    "    turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns,turn_G,[o],[d])\n",
    "    length, edge_list = nx.single_source_dijkstra(turn_G,source=o,target=d,weight='weight')\n",
    "    edge_list = edge_list[1:-1] #chop off the virtual nodes added\n",
    "    turn_G = modeling_turns.remove_virtual_links_new(turn_G,virtual_starts,virtual_ends)\n",
    "    return {'length':np.round(length,1), 'edge_list':edge_list}\n",
    "\n",
    "results_dict = {(start_node,end_node):impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in ods0}\n",
    "# #takes 11 minutes for 3000 trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Random Trip for Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ods.sample(1).squeeze()\n",
    "tripid = row['tripid']\n",
    "start_node = row['start_node']\n",
    "end_node = row['end_node']\n",
    "print(tripid,start_node,end_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize random trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in match_results[tripid]['matched_edges'].to_numpy()]\n",
    "shortest = [tuple(row) for row in match_results[tripid]['shortest_edges'].to_numpy()]\n",
    "#retrieve modeled path linkids\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "chosen_lines = gpd.GeoSeries(chosen_geo,crs='epsg:2240')\n",
    "shortest_lines = gpd.GeoSeries(shortest_geo,crs='epsg:2240')\n",
    "modeled_lines = gpd.GeoSeries(modeled_geo,crs='epsg:2240')\n",
    "\n",
    "stochastic_optimization.visualize_three_no_legend(chosen_lines,shortest_lines,modeled_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function\n",
    "This function calculates the success of a modeled trip when compared against the matched one. There are several available but only one can be used in the impedance calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 Exact Overlap\n",
    "This objective function looks at whether the edges taken in the modeled trip matches the ones taken in the matched trip.\n",
    "\n",
    "Two ways to calculate:\n",
    "- By trip and then average (weight equally on short and long trips)\n",
    "- Total intersected length divided by total chosen length (longer trips have more weight but perhaps a more complete picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in match_results[tripid]['matched_edges'].to_numpy()]\n",
    "#retrieve modeled path linkids\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get lengths (non-directional)\n",
    "chosen_length = np.sum([length_dict[linkid[0]] for linkid in chosen])\n",
    "modeled_length = np.sum([length_dict[linkid[0]] for linkid in modeled_edges])\n",
    "\n",
    "#convert to sets\n",
    "chosen = set(chosen)\n",
    "modeled_edges = set(modeled_edges)\n",
    "\n",
    "#find intersection of sets\n",
    "shared = list(set.intersection(chosen,modeled_edges))\n",
    "\n",
    "#find intersection length\n",
    "intersection_length = np.sum([length_dict[linkid[0]] for linkid in shared])\n",
    "\n",
    "#here we can have an if condition that determines which method to do\n",
    "\n",
    "# calculate exact overlap (chosen length will never be greater than modeled length)\n",
    "exact_overlap = intersection_length / chosen_length\n",
    "exact_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Buffer Overlap\n",
    "Having the modeled trip have to match the chosen trip exactly might be unrealistic since our impedance function isn't able to account for everything. Instead it may be better to see if the impedance function is generally producing results that are similar to the chosen ones. In this objective function, both the chosen and modeled routes are buffered and intersected. This intersection is divided by the union of the two buffered geometries to get a percentage. The more overlap between the two, the closer to one this intersection will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set buffer dist\n",
    "buffer_ft = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in match_results[tripid]['matched_edges'].to_numpy()]\n",
    "#shortest = [tuple(row) for row in match_results[linkid]['shortest_edges'].to_numpy()]\n",
    "#retrieve modeled path linkids\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "#shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "#turn into linestring and then buffer\n",
    "chosen_geo = MultiLineString(chosen_geo).buffer(buffer_ft)\n",
    "modeled_geo = MultiLineString(modeled_geo).buffer(buffer_ft)\n",
    "\n",
    "chosen_area = chosen_geo.area\n",
    "modeled_area = modeled_geo.area\n",
    "intersection_area = chosen_geo.intersection(modeled_geo).area\n",
    "\n",
    "# intersected area divided by the non overlapping area\n",
    "# close to one the better\n",
    "buffer_overlap = intersection_area / (chosen_area+modeled_area-intersection_area)\n",
    "buffer_overlap\n",
    "\n",
    "#take the median?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Frechet Distance\n",
    "This third method uses Frechet Distanct which can be used as a measure of similarity between two curves. With this method, link direction is also accounted for. The higher the frechet distance, the less similar the results. We should probably divide this number by the length of the chosen/modeled route to standardize it somewhat accross trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_ft = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve tuples of the format (linkid:int,reverse_link:boolean)\n",
    "chosen = [tuple(row) for row in match_results[tripid]['matched_edges'].to_numpy()]\n",
    "#shortest = [tuple(row) for row in match_results[linkid]['shortest_edges'].to_numpy()]\n",
    "modeled = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#retrieve coordinates, revesing coordinate sequence if neccessary\n",
    "def retrieve_coordinates(link,geo_dict):\n",
    "    line = np.array(geo_dict[link[0]].coords)\n",
    "    if link[1] == True:\n",
    "        line = line[::-1]\n",
    "    return line\n",
    "\n",
    "chosen_geo = [retrieve_coordinates(link,geo_dict) for link in chosen]\n",
    "modeled_geo = [retrieve_coordinates(link,geo_dict) for link in modeled]\n",
    "\n",
    "#turn to a single line\n",
    "chosen_geo = LineString(np.vstack(chosen_geo))\n",
    "modeled_geo = LineString(np.vstack(modeled_geo))\n",
    "\n",
    "#simplify with rdp\n",
    "chosen_coords = np.array(chosen_geo.simplify(rdp_ft).coords)\n",
    "modeled_coords = np.array(modeled_geo.simplify(rdp_ft).coords)\n",
    "\n",
    "#find frechet distance\n",
    "frechet_distance = similaritymeasures.frechet_dist(chosen_coords,modeled_coords)\n",
    "frechet_distance\n",
    "\n",
    "#can minimize total frechet distance or an average value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization (in progress)\n",
    "For comparing results? Come back to this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns\n",
    "\n",
    "test['percent_detour'] = (((test['length_ft']-test['shortest_length_ft'])/test['shortest_length_ft'])*100).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trip_and_user = pd.read_pickle(export_fp/'trip_and_user.pkl')\n",
    "\n",
    "test_merge = test.merge(trip_and_user,on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = test.loc[test['overlap']<0.2,'tripid'].sample(1).item()\n",
    "tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['starttime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium.plugins import MarkerCluster, PolyLineTextPath\n",
    "from folium.map import FeatureGroup\n",
    "def visualize(test_merge,tripid):\n",
    "\n",
    "\n",
    "     gdf = test_merge.copy()\n",
    "\n",
    "     gdf.set_geometry(\"geometry\",inplace=True)\n",
    "     gdf.set_crs(\"epsg:2240\",inplace=True)\n",
    "\n",
    "     # Your GeoDataFrames\n",
    "     chosen_path = gdf.loc[gdf['tripid']==tripid,['tripid','geometry']]\n",
    "     shortest_path = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_geo']].set_geometry('shortest_geo').set_crs(gdf.crs)\n",
    "     intersection = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_intersect_geo']].set_geometry('shortest_intersect_geo').set_crs(gdf.crs)\n",
    "     modeled_path = gdf.loc[gdf['tripid']==tripid,['tripid','geometry_modeled']].set_geometry('geometry_modeled').set_crs(gdf.crs)\n",
    "\n",
    "     #start point\n",
    "     start_N = gdf.loc[gdf['tripid']==tripid,'start'].item()\n",
    "     start_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==start_N,'geometry'].item()\n",
    "\n",
    "     #end point\n",
    "     end_N = gdf.loc[gdf['tripid']==tripid,'end'].item()\n",
    "     end_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==end_N,'geometry'].item()\n",
    "\n",
    "     # reproject\n",
    "     x_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.x\n",
    "     y_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.y\n",
    "\n",
    "     # Create a Folium map centered around the mean of the GPS points\n",
    "     center = [y_mean,x_mean-.04]\n",
    "     mymap = folium.Map(location=center, zoom_start=13)\n",
    "\n",
    "     # Convert GeoDataFrames to GeoJSON\n",
    "     chosen_path_geojson = chosen_path.to_crs(epsg='4326').to_json()\n",
    "     shortest_path_geojson = shortest_path.to_crs(epsg='4326').to_json()\n",
    "     intersection_geojson = intersection.to_crs(epsg='4326').to_json()\n",
    "     modeled_path_geojson = modeled_path.to_crs(epsg='4326').to_json()\n",
    "\n",
    "     # Create FeatureGroups for each GeoDataFrame\n",
    "     chosen_path_fg = FeatureGroup(name='Chosen Path')\n",
    "     shortest_path_fg = FeatureGroup(name='Shortest Path')\n",
    "     intersection_fg = FeatureGroup(name='Buffer Intersection',show=False)\n",
    "     modeled_path_fg = FeatureGroup(name='Modeled Path')\n",
    "\n",
    "     # Add GeoJSON data to FeatureGroups\n",
    "     folium.GeoJson(chosen_path_geojson, name='Chosen Path',\n",
    "                    style_function=lambda x: {'color': '#fc8d62', 'weight': 12}).add_to(chosen_path_fg)\n",
    "     folium.GeoJson(shortest_path_geojson, name='Shortest Path',\n",
    "                    style_function=lambda x: {'color': '#66c2a5', 'weight': 8}).add_to(shortest_path_fg)\n",
    "     folium.GeoJson(intersection_geojson, name='Buffer Intersection',\n",
    "                    style_function=lambda x: {'color':\"gray\",'fillColor':\"#ffff00\",\"fillOpacity\": 0.75}).add_to(intersection_fg)\n",
    "     folium.GeoJson(modeled_path_geojson, name='Modeled Path',\n",
    "                    style_function=lambda x: {'color': '#8da0cb','weight': 8}).add_to(modeled_path_fg)\n",
    "\n",
    "     # Add FeatureGroups to the map\n",
    "     chosen_path_fg.add_to(mymap)\n",
    "     shortest_path_fg.add_to(mymap)\n",
    "     intersection_fg.add_to(mymap)\n",
    "     modeled_path_fg.add_to(mymap)\n",
    "\n",
    "     # Add start and end points with play and stop buttons\n",
    "     start_icon = folium.Icon(color='green',icon='play',prefix='fa')\n",
    "     end_icon = folium.Icon(color='red',icon='stop',prefix='fa')\n",
    "     folium.Marker(location=[start_pt.y, start_pt.x],icon=start_icon).add_to(mymap)\n",
    "     folium.Marker(location=[end_pt.y, end_pt.x],icon=end_icon).add_to(mymap)\n",
    "\n",
    "     # Add layer control to toggle layers on/off\n",
    "     folium.LayerControl().add_to(mymap)\n",
    "\n",
    "     #retrive overlap\n",
    "     # exact_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_exact_overlap_prop'].item()\n",
    "     # buffer_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_buffer_overlap'].item()\n",
    "     row = gdf.loc[gdf['tripid']==tripid].squeeze()\n",
    "\n",
    "     # Add legend with statistics\n",
    "     #TODO what happened to duration\n",
    "     legend_html = f'''\n",
    "          <div style=\"position: fixed; \n",
    "                    bottom: 5px; left: 5px; width: 300px; height: 400px; \n",
    "                    border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                    background-color: white;\n",
    "                    opacity: 0.9;\">\n",
    "          &nbsp; <b>Trip ID: {tripid}, User ID: {row['userid']}</b> <br>\n",
    "          &nbsp; <b> Date: {row['starttime']} </b> <br>\n",
    "          &nbsp; Start Point &nbsp; <i class=\"fa fa-play\" style=\"color:green\"></i>,\n",
    "          End Point &nbsp; <i class=\"fa fa-stop\" style=\"color:red\"></i> <br>\n",
    "          \n",
    "          &nbsp; Chosen Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #fc8d62; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Shortest Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #66c2a5; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Modeled Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #8da0cb; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Buffer Overlap &nbsp; <div style=\"width: 20px; height: 10px; background-color: #ffff00; display: inline-block;\"></div> <br>\n",
    "\n",
    "          &nbsp; Percent Detour: {row['percent_detour']:.0f}% <br>\n",
    "          &nbsp; Shortest Path Overlap: {row['shortest_buffer_overlap']*100:.0f}% <br>\n",
    "          &nbsp; Modeled Path Overlap: {row['overlap']*100:.0f}% <br>\n",
    "          &nbsp; Trip Type: {row['trip_type']} <br>\n",
    "          &nbsp; Length (mi): {row['length_ft']/5280:.0f} <br>\n",
    "          &nbsp; Age: {row['age']} <br>\n",
    "          &nbsp; Gender: {row['gender']} <br>\n",
    "          &nbsp; Income: {row['income']} <br>\n",
    "          &nbsp; Ethnicity: {row['ethnicity']} <br>\n",
    "          &nbsp; Cycling Frequency: {row['cyclingfreq']} <br>\n",
    "          &nbsp; Rider History: {row['rider_history']} <br>\n",
    "          &nbsp; Rider Type: {row['rider_type']} <br><br>\n",
    "\n",
    "          </div>\n",
    "          '''\n",
    "     mymap.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "     # Save the map to an HTML file or display it in a Jupyter notebook\n",
    "     #mymap.save('map.html')\n",
    "     # mymap.save('/path/to/save/map.html')  # Use an absolute path if needed\n",
    "     return mymap  # Uncomment if you are using Jupyter notebook\n",
    "\n",
    "     #TODO add in the legend with trip info and then we're golden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Calibration Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excess Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get geometry from edges\n",
    "modeled_edges = links.set_index(['source','target']).loc[edge_list]\n",
    "\n",
    "# modeled_edges = links.merge(linkids.loc[edge_list],on=['linkid','reverse_link'],how='inner')\n",
    "# modeled_edges = gpd.GeoDataFrame(modeled_edges,geometry='geometry')\n",
    "\n",
    "shortest_paths[(source,target)] = {\n",
    "        'edges': set(modeled_edges['linkid'].tolist()),\n",
    "        'geometry':MultiLineString(modeled_edges['geometry'].tolist()),#modeled_edges.dissolve()['geometry'].item(),\n",
    "        'length':MultiLineString(modeled_edges['geometry'].tolist()).length\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn shortest paths dict to dataframe\n",
    "shortest_paths = pd.DataFrame.from_dict(shortest_paths,orient='index')\n",
    "shortest_paths.reset_index(inplace=True)\n",
    "shortest_paths.columns = ['start','end','linkids','geometry','length']\n",
    "#shortest_paths[['start','end']] = shortest_paths['index'].apply(lambda x: pd.Series(x))\n",
    "#shortest_paths.drop(columns=['index'],inplace=True)\n",
    "\n",
    "#add modeled paths to matched_traces dataframe\n",
    "merged = matched_traces.merge(shortest_paths,on=['start','end'],suffixes=(None,'_modeled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_overlap(modeled_linkids,chosen_linkids):\n",
    "\n",
    "    \n",
    "    \n",
    "    sum_all = merged['length'].sum() * 5280\n",
    "    all_overlap = 0\n",
    "\n",
    "    for idx, row in merged.iterrows():\n",
    "        #find shared edges\n",
    "        chosen_and_shortest = row['linkids_modeled'] & row['linkids']\n",
    "        #get the lengths of those links\n",
    "        overlap_length = links.set_index('linkid').loc[list(chosen_and_shortest)]['length_ft'].sum()\n",
    "        #overlap_length = np.sum([link_lengths.get(link_tup,'error') for link_tup in chosen_and_shortest])\n",
    "        all_overlap += overlap_length\n",
    "\n",
    "    #calculate objective function value\n",
    "    val = all_overlap / sum_all\n",
    "    print('Exact overlap percent is:',np.round(val*100,1),'%')\n",
    "\n",
    "\n",
    "\n",
    "if exact:\n",
    "    \n",
    "\n",
    "#calculate approximate overlap (new approach)\n",
    "else:\n",
    "    #buffer and dissolve generated route and matched route\n",
    "    buffer_ft = 500\n",
    "\n",
    "    merged.set_geometry('geometry',inplace=True)\n",
    "    merged['buffered_geometry'] = merged.buffer(buffer_ft)\n",
    "    merged.set_geometry('buffered_geometry',inplace=True)\n",
    "    merged['area'] = merged.area\n",
    "\n",
    "    merged.set_geometry('geometry_modeled',inplace=True)\n",
    "    merged['buffered_geometry_modeled'] = merged.buffer(buffer_ft)\n",
    "    merged.set_geometry('buffered_geometry_modeled',inplace=True)\n",
    "    merged['area_modeled'] = merged.area\n",
    "\n",
    "    #for each row find intersection between buffered features\n",
    "    merged['intersection'] = merged.apply(lambda row: row['buffered_geometry'].intersection(row['buffered_geometry_modeled']), axis=1)\n",
    "\n",
    "    # merged['intersection'] = merged.apply(\n",
    "    #     lambda row: shapely.intersection(row['buffered_geometry'],row['buffered_geometry_modeled']))\n",
    "    merged.set_geometry('intersection',inplace=True)\n",
    "    merged['intersection_area'] = merged.area\n",
    "\n",
    "    #find the overlap with the total area (not including intersections)\n",
    "    #if the modeled/chosen links are different, then overlap decreases\n",
    "    #punishes cirquitious modeled routes that utilize every link in the chosen one but include extraneous ones\n",
    "    merged['overlap'] = merged['intersection_area'] / (merged['area_modeled'] + merged['area'] - merged['intersection_area'])\n",
    "\n",
    "    #find average overlap (using median to reduce impact of outliers?)\n",
    "    val = merged['overlap'].median()\n",
    "    print('Median overlap percent is:',np.round(val*100,1),'%')\n",
    "\n",
    "if follow_up:\n",
    "    return merged\n",
    "\n",
    "return -val#, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [2,3,4,5,6]\n",
    "#link_impedance_function(betas,beta_links,df_edges)\n",
    "#(turn_impedance_function(betas,beta_turns,turns)['turn_cost'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'beta_links': beta_links,\n",
    "    'beta_turns': beta_turns,\n",
    "    'links': df_edges,\n",
    "    'pseudo_links': turns,\n",
    "    'turn_G': turn_G,\n",
    "    'matched_traces': matched_traces,\n",
    "    'link_impedance_function': link_impedance_function,\n",
    "    'turn_impedance_function': turn_impedance_function,\n",
    "    'exact': False,\n",
    "    'follow_up': False\n",
    "}\n",
    "args = tuple(v for k, v in kwargs.items())\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [[0, 5] for _ in range(0, 5)]\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "# args = (df_edges,turns,turn_G,matched_traces,False)\n",
    "x = minimize(stochastic_optimization.objective_function, bounds, args=args, method='pso', options={'maxiter':5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60} hours')\n",
    "#results[segment_filepath] = (x.x,x.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impedance Function 2\n",
    "- Link Specific:\n",
    "    - Average Grade (%grade)\n",
    "    - Vehicle Seperation from OSM/ARC Inventory (1 = None, 2 = Bike Lane, 3 = MUP/Curb protected bike lanes)\n",
    "    - Number of lanes from HERE ()\n",
    "- Turn Specific\n",
    "    - Unsignalized left/straight across roads with higher than tertiary classification (0 or 1)\n",
    "    - Signalized intersection left/straight (0 or 1)\n",
    "\n",
    "## Applying Link Costs\n",
    "---\n",
    "Dict keys must correspond to column names in links GeoDataFrame. Multiple dicts can be passed to turns the impacts of changing impedances. The links cost function is of this format:\n",
    "$$ C_e = \\frac{l_e*60^2}{s*5280} * (1-\\sum \\beta_i x_{i,e}) $$\n",
    "\n",
    "where:\n",
    "- $e$ is an edge/link in network graph $G$ with V vertices/nodes and E edges/links\n",
    "- $l_e$ is the length of the link in feet\n",
    "- $\\beta$ is the impedance coefficient for attribute $i$\n",
    "- $X_{i,e}$ is the value of attribute $i$ for link $e$\n",
    "- $s$ is the assumed average speed of the cyclist in mph\n",
    "\n",
    "Notes:\n",
    "- Negative attributes **decrease** impedance  \n",
    "- Positive attributes **increase** impedance\n",
    "- **Negative link costs are not allowed**\n",
    "- Time to traverse a link has already been calculated in the prepare_network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% prepare link dataframe\n",
    "# links['bike'] = links['bl'] + links['pbl'] + links['mu']\n",
    "# links['bike'] = links['bike'] >= 1\n",
    "\n",
    "# cost_columns = ['linkid','bike','length_ft']#,'up-grade','down-grade','length_ft']\n",
    "# df_edges = df_edges.merge(links[cost_columns],on='linkid')\n",
    "\n",
    "# # df_edges['grade'] = np.nan\n",
    "# # df_edges.loc[df_edges['reverse_link'],'grade'] = df_edges['down-grade']\n",
    "# # df_edges.loc[~df_edges['reverse_link'],'grade'] = df_edges['up-grade']\n",
    "# # #ignore downs\n",
    "# # df_edges.loc[df_edges['grade']<0,'grade'] = 0\n",
    "# # df_edges.drop(columns=['up-grade','down-grade','bearing'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fix set\n",
    "# import ast\n",
    "# matched_traces['linkids'] = matched_traces['linkids'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop loops\n",
    "matched_traces = matched_traces.loc[matched_traces['start']!=matched_traces['end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (fp / 'impedance_calibration.pkl').open('rb') as fh:\n",
    "#     (df_edges,turns,turn_G) = pickle.load(fh)\n",
    "args = (df_edges,turns,turn_G,matched_traces,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = 68294161\n",
    "# target = 2400730083\n",
    "\n",
    "# turn_G, virtual_edges = modeling_turns.add_virtual_links(turns,turn_G,source,[target])   \n",
    "\n",
    "# virtual_edges\n",
    "\n",
    "# turn_G.out_edges(target)\n",
    "# #turn_G.in_edges((5416154182, 2400730083))\n",
    "\n",
    "# list(turn_G.in_edges(target))[0]\n",
    "\n",
    "# test = nx.ego_graph(turn_G,source,4)\n",
    "# test.edges()\n",
    "\n",
    "# import networkx as nx\n",
    "# test_target = (5318092552,5416166514)\n",
    "\n",
    "# length, node_list = nx.single_source_dijkstra(turn_G,source,test_target,weight='weight')\n",
    "# node_list\n",
    "\n",
    "# turn_G = modeling_turns.remove_virtual_edges(turn_G,virtual_edges)\n",
    "\n",
    "# import stochastic_optimization\n",
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "# reload(modeling_turns)\n",
    "\n",
    "# betas = [1.14593853, 0.60739776]\n",
    "# val, merged = stochastic_optimization.objective_function(betas,*args)\n",
    "\n",
    "# merged[1].set_geometry('geometry_modeled').set_crs('epsg:2240').explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to re-create routes using the coefficients so we can do vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "betas = np.array([0.09231109, 2.35131751])\n",
    "args = (df_edges,turns,turn_G,matched_traces,False,True)\n",
    "test = stochastic_optimization.objective_function(betas,*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tripid = 891#30000\n",
    "tripid = 7257#9806#891\n",
    "mymap = visualize(test_merge,tripid)\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linkid, start_node, end_node in tqdm(ods.itertuples(index=False),total=ods.shape[0]):\n",
    "#     turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns,turn_G,[start_node],[end_node])\n",
    "#     length, edge_list = nx.single_source_dijkstra(turn_G,source=start_node,target=end_node,weight='weight')\n",
    "#     turn_G = modeling_turns.remove_virtual_links_new(turn_G,virtual_starts,virtual_ends)\n",
    "# #takes \n",
    "# import networkx as nx\n",
    "# import concurrent.futures\n",
    "\n",
    "# results_dict = {}\n",
    "\n",
    "# # Define a function to calculate Dijkstra's shortest paths for a single source\n",
    "# def impedance_path(turns, turn_G, tripid, o, d):\n",
    "#     turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns, turn_G, [o], [d])\n",
    "#     length, edge_list = nx.single_source_dijkstra(turn_G, source=o, target=d, weight='weight')\n",
    "#     turn_G = modeling_turns.remove_virtual_links_new(turn_G, virtual_starts, virtual_ends)\n",
    "#     return tripid, {'length': length, 'edge_list': edge_list}\n",
    "\n",
    "# # Define the number of concurrent workers based on your system's capability\n",
    "# # You may need to experiment to find the optimal number\n",
    "# num_workers = 4  # For example\n",
    "\n",
    "# # Initialize ThreadPoolExecutor or ProcessPoolExecutor\n",
    "# with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     # Submit the tasks for each origin destination pair\n",
    "#     futures = [executor.submit(impedance_path, turns, turn_G, tripid, origin, destination) \n",
    "#                for tripid, origin, destination in ods.itertuples(index=False)]\n",
    "\n",
    "#     # Wait for all tasks to complete\n",
    "#     concurrent.futures.wait(futures)\n",
    "\n",
    "#     # Retrieve results\n",
    "#     for future in futures:\n",
    "#         tripid, result_dict = future.result()\n",
    "#         results_dict[tripid] = result_dict\n",
    "# import concurrent.futures\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# results_dict = {}\n",
    "\n",
    "# # Define a function to calculate Dijkstra's shortest paths for a single source\n",
    "# def impedance_path(turns, turn_G, tripid, o, d):\n",
    "#     turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns, turn_G, [o], [d])\n",
    "#     length, edge_list = nx.single_source_dijkstra(turn_G, source=o, target=d, weight='weight')\n",
    "#     turn_G = modeling_turns.remove_virtual_links_new(turn_G, virtual_starts, virtual_ends)\n",
    "#     results_dict[tripid] = {'length': length, 'edge_list': edge_list}\n",
    "#     #return tripid, {'length': length, 'edge_list': edge_list}\n",
    "\n",
    "\n",
    "# # Define the number of concurrent workers based on your system's capability\n",
    "# # You may need to experiment to find the optimal number\n",
    "# num_workers = 20  # For example\n",
    "\n",
    "# # Initialize ThreadPoolExecutor or ProcessPoolExecutor\n",
    "# with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     # Submit the tasks for each origin destination pair\n",
    "#     futures = [executor.submit(impedance_path, turns, turn_G, tripid, origin, destination) \n",
    "#                for tripid, origin, destination in ods.itertuples(index=False)]\n",
    "    \n",
    "#     # Wrap the futures with tqdm to create a progress bar\n",
    "#     with tqdm(total=len(futures)) as pbar:\n",
    "#         for future in futures:\n",
    "#             future.add_done_callback(lambda p: pbar.update())\n",
    "\n",
    "#     # # Retrieve results\n",
    "#     # for future in futures:\n",
    "#     #     tripid, result_dict = future.result()\n",
    "#     #     results_dict[tripid] = result_dict\n",
    "\n",
    "\n",
    "# # Assuming you have a graph called G and a list of origins and destinations\n",
    "# # Define your graph G and the list of origins and destinations here\n",
    "# results_dict = {}\n",
    "\n",
    "# # Define a function to calculate Dijkstra's shortest paths for a single source\n",
    "# def impedance_path(turns,turn_G,tripid,o,d,results_dict):\n",
    "#     turn_G, virtual_starts, virtual_ends = modeling_turns.add_virtual_links_new(turns,turn_G,[o],[d])\n",
    "#     length, edge_list = nx.single_source_dijkstra(turn_G,source=o,target=d,weight='weight')\n",
    "#     turn_G = modeling_turns.remove_virtual_links_new(turn_G,virtual_starts,virtual_ends)\n",
    "#     return length, edge_list\n",
    "\n",
    "# # Define the number of concurrent workers based on your system's capability\n",
    "# # You may need to experiment to find the optimal number\n",
    "# num_workers = 4  # For example\n",
    "\n",
    "# # Initialize ThreadPoolExecutor or ProcessPoolExecutor\n",
    "# with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     # Submit the tasks for each origin destination pair\n",
    "#     futures = [executor.submit(impedance_path,[turns,turn_G,tripid,origin,destination,results_dict]) for tripid, origin, destination, in ods.itertuples(index=False)]\n",
    "\n",
    "#     # Wait for all tasks to complete\n",
    "#     concurrent.futures.wait(futures)\n",
    "\n",
    "#     # Retrieve results\n",
    "#     results = [future.result() for future in futures]\n",
    "\n",
    "# # Process the results as needed\n",
    "# for result in results:\n",
    "#     # Do something with the result\n",
    "#     print(result)\n",
    "\n",
    "#Os = list(set([item['start_node'] for key, item in match_results.items()]))\n",
    "#Ds = list(set([item['end_node'] for key, item in match_results.items()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
