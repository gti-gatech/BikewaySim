{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting CycleAtlanta Users/Trips\n",
    "This module is for performing k-means clustering using detour rate and/or speed on\n",
    "cycleatlanta users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keurfonluu.github.io/stochopy/api/optimize.html\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "fp = Path.home() / \"Documents/GitHub/Impedance-Calibration\"\n",
    "\n",
    "#import matched traces\n",
    "export_fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot/gps_traces'\n",
    "\n",
    "with (export_fp/'test_matches.pkl').open('rb') as fh:\n",
    "    trips_df = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add these earlier in the process\n",
    "trips_df['detour_pct'] = ((trips_df['length_ft'] - trips_df['shortest_length_ft']) * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp = Path.home() / 'Documents/ridership_data/CycleAtlantaClean/9-10-16 Trip Lines and Data/raw data'\n",
    "\n",
    "#%% import trip info\n",
    "trip = pd.read_csv(data_fp/\"trip.csv\", header = None)\n",
    "col_names = ['tripid','userid','trip_type','description','starttime','endtime','notsure']\n",
    "trip.columns = col_names\n",
    "trip.drop(columns=['notsure'],inplace=True)\n",
    "\n",
    "#not sure what to do with the notes yet\n",
    "#note = pd.read_csv(data_fp/'note.csv',header=None)\n",
    "\n",
    "# import user info and filter columns\n",
    "user = pd.read_csv(data_fp/\"user.csv\", header=None)\n",
    "user_col = ['userid','created_date','device','email','age','gender','income','ethnicity','homeZIP','schoolZip','workZip','cyclingfreq','rider_history','rider_type','app_version']\n",
    "user.columns = user_col\n",
    "user.drop(columns=['device','app_version','app_version','email'], inplace=True)\n",
    "\n",
    "# merge trip and users\n",
    "#join the user information with trip information\n",
    "trip_and_user = pd.merge(trip,user,on='userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mapping dictionary\n",
    "user_data_definitions = json.load(open(fp/'user_data_definition.json'))\n",
    "for col in set(trip_and_user.columns.tolist()) & set(user_data_definitions.keys()):\n",
    "    trip_and_user[col] = trip_and_user[col].astype(str)\n",
    "    trip_and_user[col] = trip_and_user[col].map(user_data_definitions[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NAs\n",
    "trip_and_user.replace(-1,np.nan,inplace=True)\n",
    "trip_and_user.replace('-1',np.nan,inplace=True)\n",
    "trip_and_user.replace('no data',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_and_user.loc[4,'schoolZip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_and_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_and_user.to_pickle(export_fp/'trip_and_user.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge to trips_df\n",
    "trips_df = trips_df.merge(trip_and_user,on='tripid')\n",
    "trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop trips more than five miles\n",
    "less_than_five_miles = trips_df['length_ft']<(5*5280)\n",
    "print(less_than_five_miles.sum())\n",
    "trips_df = trips_df[less_than_five_miles]\n",
    "\n",
    "#for now, throw out trips mentioning group rides and those with detour rate above 100 (twice the distance)\n",
    "removal_words = ['critical mass','mobile social','dikov ride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def export_segments(column_name,categorical,trips_df,values_to_exclude,user_data_definitions):\n",
    "    if categorical:\n",
    "        trips_df[column_name] = trips_df[column_name].astype(str)\n",
    "        trips_df[column_name] = trips_df[column_name].map(user_data_definitions[column_name])\n",
    "\n",
    "    for value in trips_df[column_name].dropna().unique():\n",
    "        if value in values_to_exclude:\n",
    "            continue\n",
    "        to_sample = trips_df[trips_df[column_name]==value]\n",
    "        \n",
    "        try:\n",
    "            sample = to_sample.sample(200)\n",
    "            sample.to_csv(fp/f'segments/{column_name}-{value}.csv',index=False)\n",
    "        except:\n",
    "            print(value,'did not have enough values')\n",
    "            continue\n",
    "\n",
    "    #trips_df.drop(columns=[column_name+'temp'],inplace=True)\n",
    "    \n",
    "export_segments('gender',True,trips_df,['no data'],user_data_definitions)\n",
    "export_segments('ethnicity',True,trips_df,['no data'],user_data_definitions)\n",
    "export_segments('age',True,trips_df,['no data'],user_data_definitions)\n",
    "export_segments('income',True,trips_df,['no data'],user_data_definitions)\n",
    "export_segments('trip_type',False,trips_df,['no data'],user_data_definitions)\n",
    "export_segments('rider_type',False,trips_df,['no data'],user_data_definitions)\n",
    "\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "Variables:\n",
    "trip distance\n",
    "detour %\n",
    "dist to: work, home, school\n",
    "\n",
    "aim for 3-4 clusters\n",
    "\n",
    "on longer trips people are more likely to detour, for short trips directness prefereed?\n",
    "casual riders are travelling shorter distances and may be more avoidant of certain roads\n",
    "\n",
    "\n",
    "some of the really high detour trip are still loops\n",
    "valid but need to have better detection for pauses\n",
    "\n",
    "\n",
    "most of the data is just winding up in one cluster, so i need to think harder about what i am clustering/grouping on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#cluster using trip distance and detour %\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(figsize =(10, 5))\n",
    "bins = np.array([x for x in range(0, 300, 5)])\n",
    "axis.hist(trips_df['detour_rate'], bins = bins)\n",
    "plt.xlabel('Percent Detour')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Calculate the median\n",
    "median_value = np.median(trips_df['detour_rate'])\n",
    "\n",
    "# Draw a vertical line at the median\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=2, label=f'Median = {median_value}')\n",
    "\n",
    "# Label the vertical line\n",
    "#plt.text(median_value + 10, 20, f'Median = {median_value}', rotation=90, color='red')\n",
    "\n",
    "# Displaying the graph\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "#turn to array\n",
    "X = np.asarray(trips_df[['detour_rate','chosen_length_ft']])\n",
    "\n",
    "# do clustering\n",
    "kmeans = KMeans(n_clusters=3).fit(X)\n",
    "\n",
    "trips_df['cluster_label'] = kmeans.labels_\n",
    "results = pd.DataFrame(kmeans.cluster_centers_, columns = ['detour_rate','chosen_length_ft'])\n",
    "print(results)\n",
    "\n",
    "# for cluster_label in trips_df['cluster_label'].dropna().unique():\n",
    "#     to_sample = trips_df[trips_df['cluster_label']==cluster_label]\n",
    "#     sample = to_sample.sample(50)\n",
    "#     sample.to_csv(fp/f'segments/cluster_{cluster_label}.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "#cluter using euclidean distance to work/home/school too\n",
    "\n",
    "\n",
    "'''\n",
    "come back to, right now most of the data is just in one cluster\n",
    "\n",
    "K-prototypes (accepts both numerical and catagorical)\n",
    "\n",
    "Trip purpose\n",
    "ethnicity\n",
    "gender\n",
    "income\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
