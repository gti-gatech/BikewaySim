{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prepare\n",
    "This notebook prepares the final routing network.\n",
    "\n",
    "1. Import the desired routing network\n",
    "1. Add attributes\n",
    "1. Add reconciled attributes\n",
    "1. Add signals\n",
    "1. Add elevation\n",
    "\n",
    "Then the network will be turned into a directed network graph complete with an edge list representing the directed edges and another one representing turns. Some attribute values are reversed to account for direction (e.g., elevation, signals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import src.modeling_turns as modeling_turns\n",
    "import src.add_attributes as add_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from previous notebooks and merge them. Merge here so updates can be done at each step without having to repeat everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_filepath = Path.home() / \"Documents/BikewaySimData/Projects/gdot/networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered data\n",
    "links = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_links')\n",
    "nodes = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add osm data\n",
    "links = add_attributes.add_osm_attr(links,network_filepath / 'osm_attr.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['osm_A', 'osm_B', 'osm_linkid', 'osmid', 'link_type', 'name', 'highway',\n",
       "       'oneway', 'bearing', 'bridge', 'tunnel', 'bl', 'pbl', 'mu', 'speed_mph',\n",
       "       'lanes', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconciled data\n",
    "reconciled = gpd.read_file(network_filepath/'reconciled.gpkg',layer='links',ignore_geometry=True)\n",
    "#[col for col in reconciled.columns if col not in links.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['osm_linkid','speedlimit_range_mph','lanes_per_direction']\n",
    "links = links.merge(reconciled[cols_to_keep],on='osm_linkid',how='left')\n",
    "del reconciled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename\n",
    "links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "nodes.rename(columns={'osm_N':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signals added\n",
    "links_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='links',ignore_geometry=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>signalid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67358015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67358019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67358022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67358027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67358031</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133027</th>\n",
       "      <td>11718012146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133028</th>\n",
       "      <td>11718012147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133029</th>\n",
       "      <td>11718404908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133030</th>\n",
       "      <td>11718404910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133031</th>\n",
       "      <td>11718404911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133032 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  N  signalid\n",
       "0          67358015       NaN\n",
       "1          67358019       NaN\n",
       "2          67358022       NaN\n",
       "3          67358027       NaN\n",
       "4          67358031       NaN\n",
       "...             ...       ...\n",
       "133027  11718012146       NaN\n",
       "133028  11718012147       NaN\n",
       "133029  11718404908       NaN\n",
       "133030  11718404910       NaN\n",
       "133031  11718404911       NaN\n",
       "\n",
       "[133032 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='nodes',ignore_geometry=True)\n",
    "nodes_w_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change linkid to osm_linkid later\n",
    "cols_to_keep = ['linkid','signal_A','signal_B']\n",
    "links = links.merge(links_w_signals[cols_to_keep],on='linkid',how='left')\n",
    "##del nodes_w_signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elevation added\n",
    "links_w_elevation = gpd.read_file(network_filepath/'elevation_added.gpkg',ignore_geometry=True)\n",
    "links_w_elevation.columns\n",
    "links_w_elevation.rename(columns={\n",
    "    'a_s_c_e_n_t___m':'ascent_m',\n",
    "    'd_e_s_c_e_n_t___m':'descent_m',\n",
    "    'a_s_c_e_n_t___g_r_a_d_e':'ascent_grade',\n",
    "    'd_e_s_c_e_n_t___g_r_a_d_e':'descent_grade',\n",
    "}, inplace =True)\n",
    "cols_to_keep = ['linkid','ascent_m','descent_m','ascent_grade','descent_grade','(0,2]_descent',\n",
    "       '(2,4]_descent', '(4,6]_descent', '(6,10]_descent', '(10,15]_descent',\n",
    "       '(15,inf]_descent', '(0,2]_ascent', '(2,4]_ascent', '(4,6]_ascent',\n",
    "       '(6,10]_ascent', '(10,15]_ascent', '(15,inf]_ascent']\n",
    "links = links.merge(links_w_elevation[cols_to_keep],on='linkid')\n",
    "del links_w_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['osm_A', 'osm_B', 'osm_linkid', 'osmid', 'link_type', 'name', 'highway',\n",
       "       'oneway', 'bearing', 'bridge', 'tunnel', 'bl', 'pbl', 'mu', 'speed_mph',\n",
       "       'lanes', 'geometry', 'speedlimit_range_mph', 'lanes_per_direction',\n",
       "       'linkid_x', 'signal_A', 'signal_B', 'linkid_y', 'ascent_m', 'descent_m',\n",
       "       'ascent_grade', 'descent_grade', '(0,2]_descent', '(2,4]_descent',\n",
       "       '(4,6]_descent', '(6,10]_descent', '(10,15]_descent',\n",
       "       '(15,inf]_descent', '(0,2]_ascent', '(2,4]_ascent', '(4,6]_ascent',\n",
       "       '(6,10]_ascent', '(10,15]_ascent', '(15,inf]_ascent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\"\n",
    "edges = gpd.read_file(fp/'networks/elevation_added.gpkg',layer=\"links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use geometry one last time\n",
    "edges['length_ft'] = edges.length\n",
    "\n",
    "#turn bridge and tunnel to boolean values\n",
    "edges['tunnel'] = edges['tunnel'].notna()\n",
    "edges['bridge'] = edges['bridge'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn bike facil into one column\n",
    "edges['bike_facility_type'] = np.nan\n",
    "edges.loc[(edges['mu'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'shared-use path'\n",
    "edges.loc[(edges['pbl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'protected bike lane'\n",
    "edges.loc[(edges['bl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'bike lane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(edges,'A','B','linkid','oneway',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add desired attributes from links to df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_edges = df_edges.merge(edges[['linkid','geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = ['linkid', 'osmid', 'link_type', 'name', 'oneway','length_ft']\n",
    "\n",
    "#anything that's an instance or would be better as a count value (but not a turn)\n",
    "event_cols = ['bridge','tunnel']\n",
    "\n",
    "#anything that's for the duration of the entire link and has categories\n",
    "category_cols = ['link_type','highway','speedlimit_range_mph',\n",
    "               'lanes_per_direction','bike_facility_type']\n",
    "\n",
    "#reverse in tuple form (these need to be flipped if going the other direction)\n",
    "rev_columns = [('ascent_m','descent_m'),\n",
    "               ('ascent_grade','descent_grade'),\n",
    "               ('(0,2]_ascent','(0,2]_descent'),\n",
    "               ('(2,4]_ascent','(2,4]_descent'),\n",
    "               ('(4,6]_ascent','(4,6]_descent'),\n",
    "               ('(6,10]_ascent','(6,10]_descent'),\n",
    "               ('(10,15]_ascent','(10,15]_descent'),\n",
    "               ('(15,inf]_ascent','(15,inf]_descent')]\n",
    "\n",
    "from itertools import chain\n",
    "keep_cols = basic_cols + event_cols + category_cols + list(chain(*rev_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrs = ['linkid', 'osmid', 'link_type', 'name', 'highway',\n",
    "#        'bridge', 'tunnel', 'bl', 'pbl', 'mu','speedlimit_range_mph',\n",
    "#        'lanes_per_direction', 'up_grade', 'down_grade', 'length_ft',\n",
    "#        'vehicle_separation','geometry']\n",
    "df_edges = df_edges.merge(edges[keep_cols],on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with grade\n",
    "Need to flip sign of grade for reverse links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_up_down_tuples(lst):\n",
    "#     result = []\n",
    "#     current_tuple = []\n",
    "\n",
    "#     for item in lst:\n",
    "#         if 'ascent' in item or 'descent' in item:\n",
    "#             current_tuple.append(item)\n",
    "#             if len(current_tuple) == 2:\n",
    "#                 result.append(tuple(current_tuple))\n",
    "#                 current_tuple = []\n",
    "\n",
    "#     return result\n",
    "\n",
    "# rev_columns = ['ascent_m','descent_m','ascent_grade','descent_grade',\n",
    "#                '(0,2]_down', '(2,4]_down', '(4,6]_down',\n",
    "#                '(6,10]_down', '(10,15]_down','(15,inf]_down',\n",
    "#                '(0,2]_up', '(2,4]_up', '(4,6]_up', '(6,10]_up',\n",
    "#                '(10,15]_up', '(15,inf]_up'\n",
    "#                ]\n",
    "\n",
    "# combined_tuples = combine_up_down_tuples(rev_columns)\n",
    "\n",
    "for elev_columns in rev_columns:\n",
    "    df_edges[elev_columns[0]] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "    #drop the down version?\n",
    "    df_edges.drop(columns=elev_columns[1],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turns and Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add additional attributes needed for processing\n",
    "source_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "target_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "source_links.columns = 'source_' + source_links.columns\n",
    "target_links.columns = 'target_' + target_links.columns\n",
    "pseudo_df = pseudo_df.merge(source_links,on='source_linkid',how='left')\n",
    "pseudo_df = pseudo_df.merge(target_links,on='target_linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Restrictions\n",
    "Two types in OSM (represented as OSM relations):\n",
    "- No (blank) turns\n",
    "- Only this turn allowed\n",
    "\n",
    "For chosen we don't need to consider turn restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn_restrictions = pd.read_csv(fp.parent/'osm_turn_restrictions.csv')\n",
    "# pseudo_df = pseudo_df.merge(turn_restrictions,left_on=['source_osmid','target_osmid'],right_on=['from_way_id','to_way_id'],how='left')\n",
    "# road_cond = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# no_restr = pseudo_df['type'] == 'no'\n",
    "# only_restr = pseudo_df['type'] == 'only'\n",
    "\n",
    "# #add a remove column\n",
    "# pseudo_df['remove'] = False\n",
    "\n",
    "# #remove the no turns\n",
    "# pseudo_df.loc[road_cond & no_restr,'remove'] = True\n",
    "\n",
    "# #for only, find all instances road_cond + from source and set to True\n",
    "# sources = set(turn_restrictions.loc[turn_restrictions['type']=='only','from_way_id'].tolist())\n",
    "# pseudo_df.loc[road_cond & pseudo_df['source_osmid'].isin(sources) & pseudo_df['type'].isna(),'remove'] = True\n",
    "\n",
    "# #Remove these turns and drop the added columns\n",
    "# print((pseudo_df['remove']==True).sum(),'turns removed')\n",
    "# pseudo_df = pseudo_df[pseudo_df['remove']==False]\n",
    "# pseudo_df.drop(columns=['relation_id', 'restriction', 'from_way_id',\n",
    "#        'to_way_id', 'type', 'remove'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with signals\n",
    "Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "- For the source link, use signal_B if reverse == False else signal_A\n",
    "- For the target link, use signal_A if reverse == False else signal_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pseudo_df[['source_linkid','source_reverse_link']].merge(edges,left_on='source_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "target = pseudo_df[['target_linkid','target_reverse_link']].merge(edges,left_on='target_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_B'], target['signal_A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying signalized/unsignalized turns\n",
    "- Only look at roads for now\n",
    "- Filter to left/right turns per source linkid per direction\n",
    "- Take the highest road classification and assign it as the cross street road classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "highway_order = {\n",
    "    'trunk': 0,\n",
    "    'trunk_link': 1,\n",
    "    'primary': 2,\n",
    "    'primary_link': 3,\n",
    "    'secondary': 4,\n",
    "    'secondary_link': 5,\n",
    "    'tertiary': 6,\n",
    "    'tertiary_link': 7,\n",
    "    'unclassified': 8,\n",
    "    'residential': 9\n",
    "}\n",
    "highway_order = pd.Series(highway_order)\n",
    "highway_order = highway_order.reset_index()\n",
    "highway_order.columns = ['highway','order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add highway ranking based on the above\n",
    "pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove straight and uturn\n",
    "cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "#only road to road for now\n",
    "cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "#use groupby to find the max target_highway order\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "cross_streets.name = 'cross_street'\n",
    "\n",
    "#add to main df\n",
    "pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "#change numbers back to normal\n",
    "pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Add OSM crossing into this logic\n",
    "    - Signals\n",
    "        - Wait on this until we have the route attributes code done\n",
    "        - Add crossings in signalization\n",
    "        - Majority of crossings are nodes not ways\n",
    "        - Cycleway crossings typically dealt the same way\n",
    "        - If meeting nodes are both crossings and within the traffic signal buffer, they're signalized crossings\n",
    "            - Or if both connecting links are crossings/connect to the road etc\n",
    "        - Way attributes\n",
    "            - Footway = crossing\n",
    "            - Highway = footway\n",
    "        - Node attributes\n",
    "            - Crossing = * (traffic signals/marked/etc)\n",
    "            - Highway = crossing\n",
    "        - Link attributes\n",
    "            - Some links are labeled as crossings but this is not as consistent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_street = pseudo_df['cross_street_order'] <= 5\n",
    "\n",
    "#signalized\n",
    "pseudo_df.loc[signalized & both_road,'signalized'] = True\n",
    "pseudo_df.loc[pseudo_df['signalized'].isna(),'signalized'] = False\n",
    "# pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "# pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "pseudo_df.loc[-signalized & both_road & cross_street,'unsignalized'] = True\n",
    "pseudo_df.loc[pseudo_df['unsignalized'].isna(),'unsignalized'] = False\n",
    "\n",
    "#clean up\n",
    "rem =  ['source_osmid', 'source_link_type', 'source_name',\n",
    "       'source_highway', 'target_osmid', 'target_link_type', 'target_name',\n",
    "       'target_highway', 'source_signal', 'target_signal',\n",
    "       'target_highway_order', 'source_highway_order', 'cross_street',\n",
    "       'cross_street_order']\n",
    "pseudo_df.drop(columns=rem,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for impedance calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_edges = gpd.GeoDataFrame(df_edges,crs='epsg:2240')\n",
    "df_edges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (fp.parent / 'chosen.pkl').open('wb') as fh:\n",
    "    export = (df_edges,pseudo_df,pseudo_G)\n",
    "    pickle.dump(export,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add geometry to examine results in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add geo\n",
    "link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "#check results (may need a smaller road network to test on)\n",
    "pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
