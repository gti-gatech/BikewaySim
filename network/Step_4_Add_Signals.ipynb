{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Traffic Signals to Network\n",
    "In this case we already have a traffic signal inventory from the Georgia Department of Transportation, but code for downloading existing traffic signal data from OpenStreetMap (OSM) is also included. This code also retrieves crossings from OSM.\n",
    "\n",
    "First, we'll find signals in the GDOT data that are not covered in the OSM data. Then we'll take these intersect the them with OSM nodes. Using the reference ID columns on the OSM links, these signals can be added to the links. A turn dataframe is then constructed with all of the links that contain at least one signal.\n",
    "\n",
    "Once this happens, the link street name will be cross-referenced to validate the match.\n",
    "\n",
    "- If signals are both road links, check the road name on each to see if it matches the GDOT name\n",
    "- If non-road link just set it to null for now. Some of these may be crosswalks at the intersection, but they could also be walkways further away from the intersection.\n",
    "\n",
    "This final result should be QAQC'd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import conflation_tools, modeling_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['network_fp']/'networks.gpkg',layer='osm_links')\n",
    "nodes = gpd.read_file(config['network_fp']/'networks.gpkg',layer='osm_nodes')\n",
    "#add attributes back\n",
    "raw = gpd.read_file(config['osmdwnld_fp']/f\"osm.gpkg\",layer=\"raw\",ignore_geometry=True)\n",
    "links = pd.merge(links,raw[['osmid','highway','name']],how='left',on='osmid')\n",
    "del raw\n",
    "#create a name col for checking against the GDOT names\n",
    "links['name0'] = links['name'].apply(lambda x: conflation_tools.contract_suffix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buffer function\n",
    "def buffer_signals(signal_gdf,buffer_ft):\n",
    "    '''\n",
    "    Use to create a copy of a gdf and buffer the point geometry\n",
    "    '''\n",
    "    signal_gdf = signal_gdf.copy()\n",
    "    signal_gdf.geometry = signal_gdf.buffer(buffer_ft)\n",
    "    return signal_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSM Signals\n",
    "No need to conflate, already embedded in the OSM network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_signals = gpd.read_file(config['osmdwnld_fp']/f\"osm.gpkg\",layer='highway_nodes')\n",
    "osm_signals = osm_signals[osm_signals['highway']=='traffic_signals']\n",
    "osm_signals.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "osm_signal_ids = set(osm_signals['osmid'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalized_links = links[(links['osm_A'].isin(osm_signal_ids)) | (links['osm_B'].isin(osm_signal_ids))]\n",
    "\n",
    "## Create turn graph dataframe\n",
    "_, turns_df = modeling_turns.create_pseudo_dual_graph(signalized_links,'osm_A','osm_B','osm_linkid','oneway')\n",
    "\n",
    "#add signals ids back in\n",
    "turns_df['signalized'] = turns_df['source_B'].isin(osm_signal_ids)\n",
    "\n",
    "#drop unsignalized turn movements\n",
    "turns_df = turns_df[turns_df['signalized']==True]\n",
    "\n",
    "#export\n",
    "turns_df.to_pickle(config['network_fp']/'osm_signals.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDOT Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read gdot signals\n",
    "keep = ['signalID','mainStreetName','sideStreetName','geometry']\n",
    "gdot_signals = gpd.read_file(config['gdot_signals_fp'],mask=gpd.read_file(config['studyarea_fp'])).to_crs(links.crs)[keep]\n",
    "gdot_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName']\n",
    "gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName'] \n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'\\(.*?\\)', '', x)) # remove anything in parenthesis #TODO instead put / / instead so it can be sperated out\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'\\(.*?\\)', '', x)) # remove anything in parenthesis\n",
    "gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: x.replace('MLK','martin luther king'))#re.sub(r'MLK', 'martin luther king', x)) # change mlk to full version\n",
    "gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: x.replace('MLK','martin luther king'))#re.sub(r'MLK', 'martin luther king', x)) # change mlk to full version\n",
    "gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: x.replace('RDA','ralph david abernathy'))#re.sub(r'RDA', 'ralph david abernathy', x)) # change mlk to full version\n",
    "gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: x.replace('RDA','ralph david abernathy'))# re.sub(r'RDA', 'ralph david abernathy', x)) # change mlk to full version\n",
    "gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'[()]', '/', x)) # remove anything in parenthesis\n",
    "gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'[()]', '/', x)) # remove anything in parenthesis\n",
    "mainStreetName = gdot_signals['mainStreetName0'].apply(lambda x: x.split('/'))\n",
    "sideStreetName = gdot_signals['sideStreetName0'].apply(lambda x: x.split('/'))\n",
    "gdot_signals['gdot_names'] = mainStreetName + sideStreetName\n",
    "gdot_signals['gdot_names'] = gdot_signals['gdot_names'].apply(lambda x: [y for y in x if len(y.replace(' ','')) > 0])\n",
    "gdot_signals['gdot_names'] = gdot_signals['gdot_names'].apply(lambda list_of_names: [conflation_tools.contract_suffix(name) for name in list_of_names])\n",
    "gdot_signals.sample(20)\n",
    "\n",
    "# #some specific regex for the gdot dataset\n",
    "# import re \n",
    "\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: x.lower())\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'sr \\d+', '', x)) # remove the state routes\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'us \\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'ga \\d+', '', x)) # remove the ga routes\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'i-\\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'phb \\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub(r'\\(.*?\\)', '', x)) # remove anything in parenthesis\n",
    "# # gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub('/', ' ', x)) # replace / with space\n",
    "# gdot_signals['mainStreetName0'] = gdot_signals['mainStreetName0'].apply(lambda x: re.sub('ramp', ' ', x)) # remove ramps from name\n",
    "\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: x.lower())\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'sr \\d+', '', x)) # remove the state routes\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'us \\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'ga \\d+', '', x)) # remove the ga routes\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'i-\\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'phb \\d+', '', x)) # remove the us routes\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub(r'\\(.*?\\)', '', x)) # remove anything in parenthesis\n",
    "# # gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub('/', ' ', x)) # replace / with space\n",
    "# gdot_signals['sideStreetName0'] = gdot_signals['sideStreetName0'].apply(lambda x: re.sub('ramp', ' ', x)) # remove ramps from name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Difference\n",
    "Find GDOT signals that are not already covered by OSM. Maybe ask an undergrad to add these into OSM later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdot_signals.shape[0],'GDOT signals and',osm_signals.shape[0],'OSM signals')\n",
    "buffer_ft = 100 #selecting 100 ft based on city block sizes and that's about where the number of gdot signals not represented by osm signals drops\n",
    "buffered_osm_signals = buffer_signals(osm_signals,buffer_ft)\n",
    "difference = gdot_signals.overlay(buffered_osm_signals,how='difference')\n",
    "difference = difference[difference.drop(columns=['gdot_names']).duplicated()==False]\n",
    "print('Around',difference.shape[0],'GDOT traffic signals not in OSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add these new GDOT signals into the OSM network\n",
    "Set a buffer for each signal and find all candidate nodes associated\n",
    "- Filter OSM nodes to only consider links with a node with a degree higher than 2 and that's labelled as a road\n",
    "- Buffer and intersect the GDOT signals with the filtered OSM nodes\n",
    "- Check the road names for links attached to a candidate node\n",
    "\n",
    "\n",
    "we set a buffer distance around each signal to find all candidate nodes associated with the traffic signal.\n",
    "- Then, we remove links that are unlikely to be signalized intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#only consider road nodes (if there's a service road that connects to a signalized intersection this should still count them)\n",
    "only_roads = links[links['link_type'].isin(['road'])].copy()\n",
    "road_nodes = pd.Series(Counter(only_roads['osm_A'].tolist()+only_roads['osm_B'].tolist()))\n",
    "road_nodes = set(road_nodes[road_nodes>2].index.tolist()) # and remove matches where degree is 2 or less\n",
    "road_nodes = nodes[nodes['osm_N'].isin(road_nodes)]\n",
    "\n",
    "buffer_ft = 100\n",
    "gdot_buffered = buffer_signals(difference,buffer_ft)\n",
    "candidate_signals = gpd.overlay(road_nodes,gdot_buffered,how=\"intersection\")\n",
    "# candidate_signals.explore()\n",
    "\n",
    "# subset the links\n",
    "candidate_signals0 = set(candidate_signals['osm_N'].tolist())\n",
    "candidate_links = links[links['osm_A'].isin(candidate_signals0) | links['osm_B'].isin(candidate_signals0)].copy()\n",
    "candidate_links = candidate_links[candidate_links['link_type']=='road']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the candidate nodes info to the candidate links so that we can check street name\n",
    "from importlib import reload\n",
    "reload(conflation_tools)\n",
    "A = candidate_links.merge(candidate_signals,left_on='osm_A',right_on='osm_N')\n",
    "name_check = A.apply(lambda row: any([conflation_tools.name_check(row['name0'],name,.6) for name in row['gdot_names']]), axis = 1)\n",
    "# A[name_check==False].sample(30)\n",
    "A = A[name_check]\n",
    "A = set(A['osm_linkid'].tolist())\n",
    "\n",
    "B = candidate_links.merge(candidate_signals,left_on='osm_B',right_on='osm_N')\n",
    "name_check = B.apply(lambda row: any([conflation_tools.name_check(row['name0'],name,.6) for name in row['gdot_names']]), axis = 1)\n",
    "# main_check = B.apply(lambda row: conflation_tools.name_check(row['name'],row['mainStreetName']),axis=1)\n",
    "# side_check = B.apply(lambda row: conflation_tools.name_check(row['name'],row['sideStreetName']),axis=1)\n",
    "B = B[name_check]\n",
    "B = set(B['osm_linkid'].tolist())\n",
    "\n",
    "candidate_links = links[links['osm_linkid'].isin(set.union(A,B))]\n",
    "# candidate_links.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, turns_df = modeling_turns.create_pseudo_dual_graph(candidate_links,'osm_A','osm_B','osm_linkid','oneway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add signals ids back in\n",
    "turns_df['signalized'] = turns_df['source_B'].isin(candidate_signals0)\n",
    "turns_df = turns_df[turns_df['signalized'] == True]\n",
    "\n",
    "# turns_df.drop(columns=['source','target'],inplace=True)\n",
    "\n",
    "turns_df.to_pickle(config['network_fp']/'gdot_signals.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAQC\n",
    "None of the data overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osm = pd.read_parquet(config['network_fp']/'osm_signals.parquet')\n",
    "# gdot = pd.read_parquet(config['network_fp']/'gdot_signals.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osm.signalized.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdot.signalized.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gdot.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "# osm.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "\n",
    "# gdot = gdot[['signalized','source_B']]\n",
    "# gdot.columns = ['osm','osm_N']\n",
    "# osm = osm[['signalized','source_B']]\n",
    "# osm.columns = ['gdot','osm_N']\n",
    "# node_geo = dict(zip(nodes['osm_N'],nodes.geometry))\n",
    "# test = pd.merge(gdot,osm,left_index=True,right_index=True)\n",
    "# test\n",
    "\n",
    "# test[test['osm'].notna() & test['gdot'].notna()]\n",
    "# test['geometry'] = test['source_B'].map(node_geo)\n",
    "# test = gpd.GeoDataFrame(test,crs=config['projected_crs_epsg'])\n",
    "# test\n",
    "# test.explore()\n",
    "# tcandidate_signals = candidate_signals[candidate_signals['osm_N'].isin(road_nodes)]\n",
    "# test_dict = dict(zip(candidate_signals['osm_N'],candidate_signals['signalID']))\n",
    "\n",
    "# links['signal_A'] = links['osm_A'].map(test_dict)\n",
    "# links['signal_B'] = links['osm_B'].map(test_dict)\n",
    "# candidate_signals_links = links[(links['signal_A'] != links['signal_B']) & (links['signal_A'].notna() | links['signal_B'].notna()) & (links['link_type']=='road')]\n",
    "# #candidate_signals_links.explore()\n",
    "# candidate_signals_links.columns\n",
    "# _, turns_df = modeling_turns.create_pseudo_dual_graph(signalized_links,'osm_A','osm_B','osm_linkid','oneway')\n",
    "# _, turns_df = modeling_turns.create_pseudo_dual_graph(signalized_links,'osm_A','osm_B','osm_linkid','oneway')\n",
    "# #add signals ids back in\n",
    "# test_dict = dict(zip(candidate_signals['osm_N'],candidate_signals['signalID']))\n",
    "\n",
    "# turns_df['source_signal_A'] = turns_df['source_A'].map(test_dict)\n",
    "# turns_df['source_signal_B'] = turns_df['source_B'].map(test_dict)\n",
    "# turns_df['target_signal_A'] = turns_df['target_A'].map(test_dict)\n",
    "# turns_df['target_signal_B'] = turns_df['target_B'].map(test_dict)\n",
    "# #assign the source signal and target signal parts based on the link directions\n",
    "# import numpy as np\n",
    "# turns_df['source_signal'] = np.where(turns_df['source_reverse_link'], turns_df['source_signal_A'], turns_df['source_signal_B'])\n",
    "# turns_df['target_signal'] = np.where(turns_df['target_reverse_link']==False, turns_df['source_signal_B'], turns_df['source_signal_A'])\n",
    "# turns_df.drop(columns=['source_signal_A','source_signal_B','target_signal_A','target_signal_B'],inplace=True)\n",
    "# #add signals ids back in\n",
    "# test_dict = dict(zip(candidate_signals['osm_N'],candidate_signals['signalID']))\n",
    "\n",
    "# turns_df['source_signal_A'] = turns_df['source_A'].map(test_dict)\n",
    "# turns_df['source_signal_B'] = turns_df['source_B'].map(test_dict)\n",
    "# turns_df['target_signal_A'] = turns_df['target_A'].map(test_dict)\n",
    "# turns_df['target_signal_B'] = turns_df['target_B'].map(test_dict)\n",
    "# #assign the source signal and target signal parts based on the link directions\n",
    "# import numpy as np\n",
    "# turns_df['source_signal'] = np.where(turns_df['source_reverse_link'], turns_df['source_signal_A'], turns_df['source_signal_B'])\n",
    "# turns_df['target_signal'] = np.where(turns_df['target_reverse_link']==False, turns_df['source_signal_B'], turns_df['source_signal_A'])\n",
    "# turns_df.drop(columns=['source_signal_A','source_signal_B','target_signal_A','target_signal_B'],inplace=True)\n",
    "# #add name and the signal cross street names back\n",
    "# name_dict = dict(zip(links['osm_linkid'],links['name']))\n",
    "\n",
    "# turns_df['source_name'] = turns_df['source_linkid'].map(name_dict)\n",
    "# turns_df['target_name'] = turns_df['target_linkid'].map(name_dict)\n",
    "# candidate_signals\n",
    "# candidate_signals_links = links[(links['signal_A'] == links['signal_B']) & (links['link_type']=='road')]\n",
    "# #add name\n",
    "# pd.merge(candidate_signals_links,candidate_signals.drop(columns=['geometry']),on='')\n",
    "# A = pd.merge(links[['osm_A']],candidate_signals.drop(columns=['geometry']),left_on='osm_A',right_on='osm_N',how='left')\n",
    "# # A.drop(columns=['osm_A','osm_N'],inplace=True)\n",
    "# # A.columns = A.columns + '_A'\n",
    "\n",
    "# B = pd.merge(links[['osm_B']],candidate_signals.drop(columns=['mainStreetName','sideStreetName','geometry']),left_on='osm_B',right_on='osm_N',how='left')\n",
    "# # B.drop(columns=['osm_B','osm_N'],inplace=True)\n",
    "# # B.rename(columns={'signalID':'signalID_B'},inplace=True)\n",
    "\n",
    "# links[['osm_A']]\n",
    "\n",
    "# B.shape[0]\n",
    "# A.shape[0] \n",
    "\n",
    "# test = pd.concat([links,A,B],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "# candidate_signals\n",
    "\n",
    "# intersect = {key:item for key, item in intersect.items() if key in road_nodes}\n",
    "\n",
    "# signals['buffered_geo'] = signals.buffer(buffer_ft)\n",
    "# signals.set_geometry('buffered_geo',inplace=True)\n",
    "# #signals.explore()\n",
    "# ## Next, we intersect these bufferred signals with the street nodes\n",
    "# intersect = gpd.overlay(nodes,signals,how='intersection')\n",
    "# intersect.head()\n",
    "# # intersect = intersect[['N','signalID']]#,'mainStreetName','sideStreetName']]\n",
    "# # intersect = dict(zip(intersect['N'],intersect['signalID']))\n",
    "# ## First identify public road intersections \n",
    "# Most signals should only be at the intersection of public roads (and maybe some major parking lot/service road entrances), knowing this subset to only look at public roads and then calculate the degree of the road nodes. Remove signal id matches for links with degree of 2 or less.\n",
    "# links['link_type'].unique()\n",
    "# only_roads = links['link_type'].isin(['road','service'])\n",
    "# road_nodes = links['A'].append(links['B']).value_counts()\n",
    "# #remove matches where degree is 2 or less\n",
    "# road_nodes = road_nodes[road_nodes>2].index.tolist()\n",
    "# intersect = {key:item for key, item in intersect.items() if key in road_nodes}\n",
    "\n",
    "# only_roads = links['link_type']=='road'\n",
    "# road_nodes = links['A'].append(links['B']).value_counts()\n",
    "# #remove matches where degree is 2 or less\n",
    "# road_nodes = road_nodes[road_nodes>2].index.tolist()\n",
    "# intersect = {key:item for key, item in intersect.items() if key in road_nodes}\n",
    "# ### With that done, we assign the signal ID to the node and add it as an attribute in links\n",
    "# links['signal_A'] = links['A'].map(intersect)\n",
    "# links['signal_B'] = links['B'].map(intersect)\n",
    "# nodes['signalid'] = nodes['N'].map(intersect)\n",
    "# Drop null values\n",
    "# links = links[~links[['signal_A','signal_B']].isna().all(axis=1)]\n",
    "# nodes = nodes[~nodes['N'].isna()]\n",
    "# ## In the Export Network notebook, we'll process this data further\n",
    "# links.to_file(network_fp/'signals_added.gpkg',layer='links')\n",
    "# nodes.to_file(network_fp/'signals_added.gpkg',layer='nodes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
