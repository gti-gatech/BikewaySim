{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation Cleaning\n",
    "---\n",
    "This notebook smooths out the sampled elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, mapping\n",
    "from shapely.ops import Point\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import elevation_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import network\n",
    "links = gpd.read_file(config['network_fp'] / f\"osm.gpkg\",layer='raw')\n",
    "\n",
    "#reproject network to DEM crs\n",
    "with (config['network_fp']/'dem_crs.txt').open('r') as fh:\n",
    "    dem_crs = fh.read()\n",
    "links.to_crs(dem_crs,inplace=True)\n",
    "\n",
    "# import sampled elevation data\n",
    "with (config['network_fp']/'elevation.pkl').open('rb') as fh:\n",
    "    interpolated_points_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove links if no elevation data found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some below zero elevations near the airport\n",
    "error = []\n",
    "for linkid, item in interpolated_points_dict.items():\n",
    "    if (item['elevations'] < 0).any():\n",
    "        error.append(linkid)\n",
    "print(len(error),'links with below zero elevations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop links with below zero elevations\n",
    "interpolated_points_dict = {key:item for key,item in interpolated_points_dict.items() if key not in error}\n",
    "links = links[links['osmid'].isin(interpolated_points_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_elev = np.max(np.array([item['elevations'].max() for key, item in interpolated_points_dict.items()]))\n",
    "min_elev = np.min(np.array([item['elevations'].min() for key, item in interpolated_points_dict.items()]))\n",
    "print('Max Elevation:',max_elev,'m','Min Elevation:',min_elev,'m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Examples\n",
    "---\n",
    "Examine some specific links to see what their grade profile looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 79424672\n",
    "# grade_threshold = 10\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 42106698\n",
    "# grade_threshold = 20\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 26800206\n",
    "# grade_threshold = 20\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_points_dict[linkid] = elevation_tools.point_knockout(interpolated_points_dict[linkid],8)\n",
    "# interpolated_points_dict[linkid]['elevations']\n",
    "# linkid = 26800206\n",
    "# grade_threshold = 8\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)\n",
    "# x = interpolated_points_dict[linkid]['distances']\n",
    "# y = interpolated_points_dict[linkid]['elevations']\n",
    "# test = elevation_tools.elevation_stats(x,y,80)\n",
    "# test.keys()\n",
    "# test['descent_grade']\n",
    "# test['bad_ascent_grades']\n",
    "# test['bad_descent_grades']\n",
    "# test['distance_deltas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Local road that I know has steep grades: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 340365816\n",
    "# grade_threshold = 15\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True,lidar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Northside Drive as \"tertiary\" road with a small segment above 15% -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 352003174\n",
    "# grade_threshold = 15\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True,lidar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Unpaved trail -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 1087991070\n",
    "# grade_threshold = 30\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BeltLine -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 226119768\n",
    "# grade_threshold = 15\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 741964053\n",
    "# grade_threshold = 30\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Circular golf course loop -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 1087991070\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid = 569529892\n",
    "# grade_threshold = 4\n",
    "# elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,config['maptilerapikey'],one_off=True,lidar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace dem elevation values with lidar where available (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, item in interpolated_points_dict.items():\n",
    "#     if 'lidar' in item.keys():\n",
    "#         lidar_elev = item['lidar']\n",
    "#         dem_elev = item['elevations']\n",
    "#         new_elev = [a if not np.isnan(a) else b for a, b in zip(lidar_elev,dem_elev)]\n",
    "#         interpolated_points_dict[key]['elevations'] = np.array(new_elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Knockout\n",
    "- Calculate segment grades (rise/10m or rise/length if link length was less than 10m)\n",
    "- Define a segment grade threshold by OSM highway type (e.g., motorway, local, secondary, etc.)\n",
    "    - Highways/Interstates > 8%\n",
    "    - Most local roads > 15%\n",
    "    - Few local roads > 25%\n",
    "- Knockout elevations where the associated grade changes exceeds the threshold\n",
    "- Repeat until no grade changes are above the set threshold\n",
    "    - If threshold is too low this will remove too many points\n",
    "    - Just start and end will be used \n",
    "- Spline fit on the remaining data for the interpolation step\n",
    "\n",
    "How it differs from Hongyu's Method:\n",
    "- Find first grade change (ascent or descent) exceeding threshold\n",
    "- Search 30m, 100m, or 150m after and find the last opposite grade change exceeding threshold\n",
    "- Remove first to last point\n",
    "- Infill with the spline fit\n",
    "- Our segments are too short for this but this approach could be explored in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Grade Thresholds\n",
    "Don't set too high of a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_thresholds = {\n",
    "    'tunnel': 8,\n",
    "    'bridge': 8,\n",
    "    'roads': 8,\n",
    "    'local': 20,\n",
    "    'bikeped': 20,\n",
    "    'everything_else': 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the label field\n",
    "links['label'] = None\n",
    "\n",
    "#tunnel\n",
    "links.loc[links['tunnel'].notna() & links['label'].isna(),'label'] = 'tunnel'\n",
    "\n",
    "#bridge\n",
    "links.loc[links['bridge'].notna() & links['label'].isna(),'label'] = 'bridge'\n",
    "\n",
    "#motorway/major arterials\n",
    "motorway = ['motorway','motorway_link',\n",
    "            'trunk', 'trunk_link',\n",
    "            'primary','primary_link',\n",
    "            'secondary','secondary_link',\n",
    "            'raceway', 'proposed','tertiary','tertiary_link','service', 'unclassified','living_street']\n",
    "links.loc[links['highway'].isin(motorway) & links['label'].isna(),'label'] = 'roads'\n",
    "\n",
    "#local/service roads\n",
    "local = ['residential']\n",
    "links.loc[links['highway'].isin(local) & links['label'].isna(),'label'] = 'local'\n",
    "\n",
    "#pedestrian paths/steps may not follow grade thresholds\n",
    "bikeped = ['path','footway','pedestrian','cycleway']\n",
    "links.loc[links['highway'].isin(bikeped) & links['label'].isna(),'label'] = 'bikeped'\n",
    "\n",
    "#label everything else as exclude or place a high value\n",
    "links.loc[links['label'].isna(),'label'] = 'everything_else'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(elevation_tools)\n",
    "for label, grade_threshold in grade_thresholds.items():\n",
    "    #identify links with grades exceeding the threshold\n",
    "    labelled_links = links.loc[links['label']==label,'osmid'].tolist()\n",
    "    exceeds = elevation_tools.exceeds_threshold(labelled_links,interpolated_points_dict,grade_threshold)\n",
    "    print(len(exceeds),'/',len(interpolated_points_dict),label,'links exceed the threshold')\n",
    "    #for the links that exceed the threshold, do point knockout\n",
    "    for linkid in tqdm(exceeds):\n",
    "        item = interpolated_points_dict.get(linkid,0)\n",
    "        item = elevation_tools.point_knockout(item,grade_threshold)\n",
    "        interpolated_points_dict[linkid] = item\n",
    "check = [key for key, item in interpolated_points_dict.items() if np.isnan(item['elevations']).any()]\n",
    "print(len(check),'links had at least one point knocked out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "linkid = random.choice(check)\n",
    "print(linkid)\n",
    "print(interpolated_points_dict[linkid]['elevations'])\n",
    "grade_threshold = 10\n",
    "elevation_tools.visualize(links,dem_crs,interpolated_points_dict,[linkid],grade_threshold,None,one_off=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export into QGIS to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = {linkid:elevation_tools.simple_elevation_stats(item['distances'],item['elevations']) for linkid, item in interpolated_points_dict.items()}\n",
    "export = pd.DataFrame.from_dict(export,orient='index')\n",
    "\n",
    "df = pd.merge(links,export,left_on='osmid',right_index=True)\n",
    "df['ascent_ft'] = df['ascent_m'] * 3.28084\n",
    "df['descent_ft'] = df['descent_m'] * 3.28084\n",
    "\n",
    "df['max_grade'] = np.max(np.abs(df[['ascent_grade_%','descent_grade_%']].values),axis=1)\n",
    "gdf = gpd.GeoDataFrame(df,crs=dem_crs)\n",
    "gdf.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "gdf.to_file(Path.home()/'Downloads/scratch.gpkg',layer='raw_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[(gdf['ascent_m']>100) | (gdf['descent_m']>100)].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[gdf['max_grade']>20].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spline Fit\n",
    "For all the links, fit a spline for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spline fit\n",
    "#TODO this step could be more advanced\n",
    "import numpy as np\n",
    "from scipy.interpolate import splrep, splev, BSpline\n",
    "\n",
    "too_short = [ ]\n",
    "\n",
    "for key, item in tqdm(interpolated_points_dict.items()):\n",
    "    df = pd.DataFrame({'distance':item['distances'],'elevation':item['elevations']})\n",
    "\n",
    "    #remove na values\n",
    "    df = df[df.notna().all(axis=1)]\n",
    "\n",
    "    #in this case, just do linear interpolation between the two values\n",
    "    if df.shape[0] <= 3:\n",
    "        too_short.append(key)\n",
    "        continue\n",
    "\n",
    "    #fit a spline\n",
    "    spline = splrep(df['distance'], df['elevation'], s=0.5)\n",
    "\n",
    "    #add spline to dict\n",
    "    interpolated_points_dict[key]['spline'] = spline\n",
    "\n",
    "    #TODO add this feature\n",
    "    #get smoothed elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(too_short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_points_dict[too_short[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links[links['osmid'].isin(too_short)].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['network_fp'] / \"spline_fit_elevation.pkl\").open('wb') as fh:\n",
    "    pickle.dump(interpolated_points_dict,fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikewaysim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
