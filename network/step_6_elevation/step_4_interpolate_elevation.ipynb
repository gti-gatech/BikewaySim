{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate elevation data from the spline fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import nearest_points, LineString, Point\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from scipy.interpolate import splrep, splev, BSpline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import elevation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for storing the interpolated points with sampled elevation data\n",
    "import pickle\n",
    "with (config['network_fp']/'spline_fit_elevation.pkl').open('rb') as fh:\n",
    "    interpolated_points_dict = pickle.load(fh)\n",
    "\n",
    "links = gpd.read_file(config['network_fp']/'osm.gpkg',layer='edges')[['linkid','osmid','start_dist','end_dist','geometry']]\n",
    "links['start_dist'] = (links['start_dist'] / 3.28084).round(2) # convert to meters\n",
    "links['end_dist'] = (links['end_dist'] / 3.28084).round(2)\n",
    "\n",
    "#cross reference\n",
    "links = links[links['osmid'].isin(interpolated_points_dict.keys())]\n",
    "\n",
    "#reproject network to DEM crs\n",
    "with (config['network_fp']/'dem_crs.txt').open('r') as fh:\n",
    "    dem_crs = fh.read()\n",
    "links.to_crs(dem_crs,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine some spline fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_key = random.choice([x for x in interpolated_points_dict.keys() if interpolated_points_dict[x].get('spline')])\n",
    "test = interpolated_points_dict[random_key]\n",
    "\n",
    "distance = test['distances']\n",
    "elevation = test['elevations']\n",
    "distance0 = np.array(list(range(0,distance[-1]+1,1)))\n",
    "# smoothed_elevations = splev(distance,test['spline']) TODO this has a dimension mismatch\n",
    "smoothed_elevations = np.interp(distance0, distance, elevation)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the elevation profile\n",
    "ax.plot(distance, elevation, label='Elevation profile')\n",
    "ax.plot(distance0, smoothed_elevations, label='Smoothed Elevations')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Distance (m)')\n",
    "ax.set_ylabel('Elevation (m)')\n",
    "\n",
    "# Ensure no vertical exaggeration by setting equal scale\n",
    "# Here, the aspect ratio is based on the maximum range of the data\n",
    "aspect_ratio = (max(distance) - min(distance)) / (max(elevation) - min(elevation))\n",
    "ax.set_aspect(aspect_ratio)\n",
    "\n",
    "# Add a grid and legend\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# elevation_tools.elevation_stats(distance,elevation,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO fix this part so i can compare the network line to the original line\n",
    "# #select a link and try it\n",
    "# linkid = 637636161\n",
    "# link = links[links['osmid']==linkid].iloc[[0],:]\n",
    "\n",
    "# #get osm line\n",
    "# line = raw_links.loc[linkid,'geometry']#interpolated_points_dict[linkid]['geometry']\n",
    "# line = np.array(line.coords)\n",
    "\n",
    "# #get geo of start and end\n",
    "# #or just use the included line to reduce memory?\n",
    "# pointA = nodes[nodes['osm_N']==link['osm_A'].item()]\n",
    "# pointB = nodes[nodes['osm_N']==link['osm_B'].item()]\n",
    "# print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the coordinates of two additional points\n",
    "# point1 = (pointA.geometry.item().x,pointA.geometry.item().y)\n",
    "# point2 = (pointB.geometry.item().x,pointB.geometry.item().y)\n",
    "# print(point1,point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the GeoDataFrame and the additional points\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # plot the full link\n",
    "# ax.plot(line[:,0],line[:,1], color='gray', label='full osm')\n",
    "\n",
    "# link.plot(ax=ax, color='blue', label='osm segemnt')\n",
    "# ax.plot(point1[0], point1[1], marker='o', color='red', markersize=10, label='Point 1')\n",
    "# ax.plot(point2[0], point2[1], marker='o', color='green', markersize=10, label='Point 2')\n",
    "\n",
    "# # Add labels to the additional points\n",
    "# #ax.text(point1[0], point1[1], 'Point 1', fontsize=12, ha='right')\n",
    "# #ax.text(point2[0], point2[1], 'Point 2', fontsize=12, ha='right')\n",
    "\n",
    "# # Add legend and labels\n",
    "# ax.legend()\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "# ax.set_title('GeoDataFrame with Additional Points')\n",
    "\n",
    "# # Manually set limits to create a square aspect ratio\n",
    "# min_x, max_x = ax.get_xlim()\n",
    "# min_y, max_y = ax.get_ylim()\n",
    "# width = max(max_x - min_x, max_y - min_y)\n",
    "# center_x = (min_x + max_x) / 2\n",
    "# center_y = (min_y + max_y) / 2\n",
    "# ax.set_xlim(center_x - width / 2, center_x + width / 2)\n",
    "# ax.set_ylim(center_y - width / 2, center_y + width / 2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point1_geo = Point(point1)\n",
    "# point2_geo = Point(point2)\n",
    "# line_geo = LineString(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distance of the shapepoint on each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely import line_locate_point, equals_exact\n",
    "\n",
    "# point1_dist = line_locate_point(LineString(line),Point(point1))\n",
    "# point2_dist = line_locate_point(LineString(line),Point(point2))\n",
    "\n",
    "# #scenario 1: last point intersects with early point on a line (line loops into itself)\n",
    "# #so trim off the points before point 1\n",
    "# if point1_dist >= point2_dist:\n",
    "#     for first_i, point in enumerate(line):\n",
    "#         if equals_exact(Point(point),Point(point1),tolerance=1):\n",
    "#             break\n",
    "#     new_line = line[first_i+1:]\n",
    "#     point2_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "\n",
    "# #scenario 2: first point intersect with last point on a line\n",
    "# #so trim off the point at the end of the line\n",
    "# if point1_dist >= point2_dist:\n",
    "#     new_line = line[0:-1]\n",
    "#     point1_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "#     point2_dist = line_locate_point(LineString(line),Point(point1))\n",
    "    \n",
    "# if point1_dist >= point2_dist:\n",
    "#     print('error')\n",
    "# else:\n",
    "#     print(np.round(point1_dist),np.round(point2_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate distance on line\n",
    "For each network link, use the pre-calculated start_dist and end_dist to interpolate elevation data from the fitted spline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "test = []\n",
    "for idx, row in tqdm(links.iterrows(),total=links.shape[0]):\n",
    "    osmid = row['osmid']\n",
    "    start_dist = row['start_dist']\n",
    "    end_dist = row['end_dist']\n",
    "    segment_length = row['geometry'].length # no need to convert to meters here\n",
    "\n",
    "    if start_dist > end_dist:\n",
    "        continue\n",
    "\n",
    "    #get osm distances and elevation\n",
    "    item = interpolated_points_dict.get(osmid,False)\n",
    "    if isinstance(item,bool):\n",
    "        print('no record for',idx)\n",
    "        continue\n",
    "    \n",
    "    #get the max osm_dist\n",
    "    osm_dist = item['distances'][-1]\n",
    "\n",
    "    #retrieve the fitted spline if it exists\n",
    "    spline = item.get('spline',0)\n",
    "\n",
    "    if isinstance(spline,int):\n",
    "        # in these cases a spline wasn't fit to the data because there were\n",
    "        # only three data points so just assign it the same data as the osm way\n",
    "        xs = item['distances']\n",
    "        ys = item['elevations']\n",
    "        if np.isnan(ys).any():\n",
    "            continue\n",
    "        result[row['linkid']] = {'distances':xs,'elevations':ys}\n",
    "        continue\n",
    "\n",
    "    # normal case\n",
    "    if start_dist < end_dist:\n",
    "        #if the end dist is past the osm dist, use the osm dist\n",
    "        #this can happen if there's a rounding error\n",
    "        if end_dist > osm_dist:\n",
    "            end_dist = osm_dist\n",
    "        \n",
    "        # if the segment is less than 10 m, just use the first and last point for grade estimation\n",
    "        if segment_length < 10:\n",
    "            xs = [start_dist,end_dist]\n",
    "            ys = splev(xs,spline)\n",
    "        else:\n",
    "            #get x values from start_dist to end_dist every 10 m\n",
    "            xs = []\n",
    "            while start_dist < end_dist:\n",
    "                xs.append(start_dist)\n",
    "                start_dist += 10\n",
    "        \n",
    "        xs = np.array(xs)\n",
    "        # ys = splev(xs,spline)\n",
    "        #NOTE I was getting a spline fit that was giving ludicrous numbers when interpolating\n",
    "        #TODO fix the spline interpolation\n",
    "        # until I can fix that, using piecewise linear interpolation\n",
    "        ys = np.interp(xs, item['distances'], item['elevations'])\n",
    "        #normalize xs so that it goes from 0 to end for the elevation stats function\n",
    "        xs = xs - xs[0]\n",
    "        result[row['linkid']] = {'distances':np.array(xs),'elevations':ys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create link level elevation statistics\n",
    "---\n",
    "This is not at all an exhaustive method for aggregating elevation information. Feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export into QGIS to examine\n",
    "export = {linkid:elevation_tools.simple_elevation_stats(item['distances'],item['elevations']) for linkid, item in result.items()}\n",
    "export = pd.DataFrame.from_dict(export,orient='index')\n",
    "\n",
    "df = pd.merge(links,export,left_on='linkid',right_index=True)\n",
    "df['ascent_ft'] = (df['ascent_m'] * 3.28084).round(0)\n",
    "df['descent_ft'] = (df['descent_m'] * 3.28084).round(0)\n",
    "df['max_elev'] = np.max(np.abs(df[['ascent_ft','descent_ft']].values),axis=1)\n",
    "df['max_grade'] = np.max(np.abs(df[['ascent_grade_%','descent_grade_%']].values),axis=1)\n",
    "df['descent_ft'] = df['descent_ft'].abs()\n",
    "df['descent_grade_%'] = df['descent_grade_%'].abs()\n",
    "gdf = gpd.GeoDataFrame(df,crs=dem_crs)\n",
    "gdf.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "print(gdf['max_grade'].isna().sum(),'nan grades')\n",
    "#remove nan grades, we'll fill them in the next one\n",
    "gdf = gdf[gdf['max_grade'].notna()]\n",
    "\n",
    "#fill in any nan values\n",
    "\n",
    "# turn into 3 categories [< 4, 4-6, > 6]\n",
    "bins = [0,4,6,np.inf]\n",
    "labels = ['[0,4)','[4,6)','[6,inf)']\n",
    "gdf['ascent_grade_cat'] = pd.cut(gdf['ascent_grade_%'],bins=bins,labels=labels,include_lowest=True).astype(str)\n",
    "gdf['descent_grade_cat'] = pd.cut(gdf['descent_grade_%'],bins=bins,labels=labels,include_lowest=True).astype(str)\n",
    "gdf['max_grade_cat'] = pd.cut(gdf['max_grade'],bins=bins,labels=labels,include_lowest=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gpd.read_file(config['network_fp']/'networks.gpkg',layer='osm_links',ignore_geometry=True)[['linkid','link_type']]\n",
    "x = x.set_index('linkid')['link_type'].to_dict()\n",
    "gdf['link_type'] = gdf['linkid'].map(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(config['network_fp']/'elevation.gpkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikewaysim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
