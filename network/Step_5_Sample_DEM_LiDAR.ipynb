{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Adding Elevation Data from USGS DEM to OSM\n",
    "---\n",
    "Method based on [Liu et al. 2018](https://doi.org/10.1016/j.trc.2018.05.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, mapping\n",
    "from shapely.ops import Point\n",
    "from tqdm import tqdm\n",
    "import pyproj\n",
    "import math\n",
    "import json\n",
    "from shapely.ops import LineString\n",
    "\n",
    "import src.elevation_tools as elevation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['osmdwnld_fp'] / f\"osm_{config['geofabrik_year']}.gpkg\",layer=\"raw\")\n",
    "links.set_index('osmid',inplace=True)\n",
    "links.to_crs('epsg:4326',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get DEM TIFF download links from [USGS.gov](https://apps.nationalmap.gov/downloader/#/?z=4&y=37.99999999999999&x=-95&basemap=usgs_topo&datasets=&layerIds=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 TIFF files for the provided network\n",
      "Names: {'GA_Statewide_2018_B18_DRRA'}\n"
     ]
    }
   ],
   "source": [
    "#TODO add compression to reduce the file size or make it so that it reads the data live instead of downloading it\n",
    "dem_urls = elevation_tools.get_dem_urls(links)\n",
    "print(len(dem_urls),'TIFF files for the provided network')\n",
    "print(\"Names:\",set([dem_url.split('/')[-3] for dem_url in dem_urls]))\n",
    "#if you want to download the DEM files run this\n",
    "#elevation_tools.download_dem(urls,config['usgs_fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Network to Same CRS as TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_crs = rasterio.open(dem_urls[0]).crs\n",
    "links.to_crs(dem_crs,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Settings (Default is 10m)\n",
    "If a link is shorter than this, only the start and end point will be used. Last point will always be included in the profile (e.g., link with length 11 m will be sampled at 0, 10, and 11 meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925 links of 60908 total were less than 10 meters\n",
      "28302.0 of 7398225.0 meters\n"
     ]
    }
   ],
   "source": [
    "interpolate_dist_m = 10\n",
    "print((links.length < interpolate_dist_m).sum(),'links of',links.shape[0] ,'total were less than',interpolate_dist_m,'meters')\n",
    "print(links[links.length<interpolate_dist_m].length.sum().round(0),'of',links.length.sum().round(0),'meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate points on each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_points_dict = elevation_tools.interpolate_points(links,interpolate_dist_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample values from DEM (17-25 minutes for study area)\n",
    "Replace the nan values on the interpolated points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 9/36 [04:17<12:52, 28.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/66/68r0k8s534v4gf9flsfnxnsr0000gn/T/ipykernel_49315/928217480.py\", line 2, in <module>\n",
      "    elevation_tools.sample_elevation(dem_url,links,interpolated_points_dict)\n",
      "  File \"/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/network/src/elevation_tools.py\", line 221, in sample_elevation\n",
      "  File \"/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/network/src/elevation_tools.py\", line 221, in <listcomp>\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/rasterio/sample.py\", line 67, in sample_gen\n",
      "    data = read(indexes, window=window, masked=masked)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "for dem_url in tqdm(dem_urls):\n",
    "    elevation_tools.sample_elevation(dem_url,links,interpolated_points_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for storing the interpolated points with sampled elevation data\n",
    "import pickle\n",
    "with (config['network_fp']/'elevation.pkl').open('wb') as fh:\n",
    "    pickle.dump(interpolated_points_dict,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bridge Deck Elevations from USGS LiDAR\n",
    "Install [laspy and lazrs](https://laspy.readthedocs.io/en/latest/installation.html). This step takes a while (~2 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.to_crs('epsg:4326',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 LAZ files for the provided network\n",
      "Names: {'GA_BRYAN_COUNTY_2010'}\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "lidar_urls = elevation_tools.get_lidar_urls(links)\n",
    "print(len(lidar_urls),'LAZ files for the provided network')\n",
    "print(\"Names:\",set([lidar_url.split('/')[-3] for lidar_url in lidar_urls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_gate_bridge_example = [\"https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CA_West_Coast_LiDAR_2016_B16/CA_WestCoastElNinoUTM10_2016/LAZ/USGS_LPC_CA_West_Coast_LiDAR_2016_B16_10SEG54454185.laz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bridge deck (1/50)\n",
      "No bridge deck (2/50)\n",
      "No bridge deck (3/50)\n",
      "No bridge deck (4/50)\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000006.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Read timed out.\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000006.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000007.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000007.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b1910>: Failed to establish a new connection: [Errno 51] Network is unreachable'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000007.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000008.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000008.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ac8d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000008.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000009.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000009.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5af910>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000009.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000010.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000010.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ad0d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000010.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000011.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000011.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ae890>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000011.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000012.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000012.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ac290>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000012.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000013.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000013.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ae990>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000013.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000014.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000014.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ae7d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000014.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000015.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000015.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5af050>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000015.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000016.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000016.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5afa50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000016.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000017.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000017.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5affd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000017.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000018.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000018.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5adf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000018.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000019.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000019.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b2490>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000019.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000020.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000020.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5aee90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000020.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000021.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000021.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b2c90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000021.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000022.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000022.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ad250>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000022.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000023.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000023.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58ca10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000023.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000024.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000024.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58e210>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000024.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000025.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000025.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58dd50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000025.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000026.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000026.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58e2d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000026.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000027.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000027.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58db90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000027.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000028.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000028.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58fa10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000028.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000029.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000029.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58cb90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000029.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000030.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000030.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58dcd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000030.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000031.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000031.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58c110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000031.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000032.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000032.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58d390>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000032.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000033.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000033.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58c810>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000033.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000034.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000034.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58cd90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000034.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000035.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000035.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5afcd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000035.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000036.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000036.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58c610>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000036.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000037.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000037.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b2c90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000037.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000038.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000038.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a58e3d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000038.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000039.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000039.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8410>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000039.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000040.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000040.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8a50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000040.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000041.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000041.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8c50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000041.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000042.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000042.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8dd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000042.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000043.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000043.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b9110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000043.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000044.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000044.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b94d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000044.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000045.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000045.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8950>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000045.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000046.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000046.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b9810>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000046.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000047.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000047.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b96d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000047.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000048.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000048.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b8350>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000048.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000049.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000049.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ba090>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000049.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000050.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000050.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5b9b90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000050.laz after 10 retries.\n",
      "Error for https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000051.laz: HTTPSConnectionPool(host='rockyweb.usgs.gov', port=443): Max retries exceeded with url: /vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000051.laz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16a5ba6d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Failed to download https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/legacy/GA_BRYAN_COUNTY_2010/LAZ/USGS_LPC_GA_BRYAN_COUNTY_2010_000051.laz after 10 retries.\n"
     ]
    }
   ],
   "source": [
    "bridge_decks = elevation_tools.get_bridge_decks(lidar_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork_fp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbridge_deck_elevations.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(bridge_decks,fh)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with (config['network_fp']/'bridge_deck_elevations.pkl').open('wb') as fh:\n",
    "    pickle.dump(bridge_decks,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Bridges from LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['osmdwnld_fp'] / f\"osm_{config['geofabrik_year']}.gpkg\",layer=\"raw\")\n",
    "links.set_index('osmid',inplace=True)\n",
    "links.to_crs('epsg:4326',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['network_fp']/'elevation.pkl').open('rb') as fh:\n",
    "    interpolated_points_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['network_fp']/'bridge_deck_elevations.pkl').open('rb') as fh:\n",
    "    bridge_decks = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9080900,\n",
       " 9081262,\n",
       " 9081629,\n",
       " 9083774,\n",
       " 9084843,\n",
       " 9086855,\n",
       " 9091127,\n",
       " 9093121,\n",
       " 9093176,\n",
       " 37392723,\n",
       " 37392856,\n",
       " 37392858,\n",
       " 37392999,\n",
       " 37393001,\n",
       " 37393005,\n",
       " 37393007,\n",
       " 37393008,\n",
       " 37393010,\n",
       " 37393013,\n",
       " 37393014,\n",
       " 37393167,\n",
       " 37393169,\n",
       " 37393173,\n",
       " 37393174,\n",
       " 37393178,\n",
       " 37393191,\n",
       " 37393193,\n",
       " 45715490,\n",
       " 50061424,\n",
       " 51814537,\n",
       " 51814606,\n",
       " 51814609,\n",
       " 51822877,\n",
       " 51823711,\n",
       " 51824230,\n",
       " 51825414,\n",
       " 51825422,\n",
       " 51826720,\n",
       " 51826722,\n",
       " 51826724,\n",
       " 51831638,\n",
       " 51831639,\n",
       " 51831845,\n",
       " 51831849,\n",
       " 51834648,\n",
       " 51834650,\n",
       " 51834654,\n",
       " 51834657,\n",
       " 51834662,\n",
       " 51834667,\n",
       " 51834685,\n",
       " 51834698,\n",
       " 51834706,\n",
       " 51834778,\n",
       " 51834804,\n",
       " 51835579,\n",
       " 51835583,\n",
       " 51835585,\n",
       " 51835587,\n",
       " 51835588,\n",
       " 51835613,\n",
       " 51852998,\n",
       " 51853000,\n",
       " 51853287,\n",
       " 51853288,\n",
       " 51853304,\n",
       " 51853311,\n",
       " 51854139,\n",
       " 51876521,\n",
       " 51902712,\n",
       " 51902720,\n",
       " 51902726,\n",
       " 51902738,\n",
       " 51937067,\n",
       " 51937069,\n",
       " 51971385,\n",
       " 51971387,\n",
       " 51971443,\n",
       " 51971449,\n",
       " 51971455,\n",
       " 51971460,\n",
       " 51972113,\n",
       " 56541070,\n",
       " 56628959,\n",
       " 56628960,\n",
       " 56628965,\n",
       " 56628966,\n",
       " 56628968,\n",
       " 56628970,\n",
       " 58744780,\n",
       " 58744782,\n",
       " 58744783,\n",
       " 65909363,\n",
       " 65909386,\n",
       " 65913836,\n",
       " 65913840,\n",
       " 65913850,\n",
       " 65913853,\n",
       " 65913865,\n",
       " 65917219,\n",
       " 65917226,\n",
       " 65917296,\n",
       " 65922820,\n",
       " 65934351,\n",
       " 65934363,\n",
       " 65938249,\n",
       " 65938263,\n",
       " 65939997,\n",
       " 65951639,\n",
       " 77049625,\n",
       " 83195453,\n",
       " 87906484,\n",
       " 87906488,\n",
       " 87906491,\n",
       " 87906512,\n",
       " 87906524,\n",
       " 87906528,\n",
       " 87906542,\n",
       " 87906551,\n",
       " 87906559,\n",
       " 87906576,\n",
       " 87906598,\n",
       " 87910268,\n",
       " 87910301,\n",
       " 87910335,\n",
       " 87910430,\n",
       " 87910454,\n",
       " 87910471,\n",
       " 87910509,\n",
       " 87910519,\n",
       " 87910534,\n",
       " 87910538,\n",
       " 87910580,\n",
       " 88766053,\n",
       " 88973667,\n",
       " 89635619,\n",
       " 89635632,\n",
       " 89765507,\n",
       " 89765511,\n",
       " 90535556,\n",
       " 91361428,\n",
       " 91361447,\n",
       " 91361456,\n",
       " 100946830,\n",
       " 100946832,\n",
       " 115789932,\n",
       " 116305966,\n",
       " 116305980,\n",
       " 116381011,\n",
       " 116381019,\n",
       " 121886499,\n",
       " 121886501,\n",
       " 121895683,\n",
       " 121980555,\n",
       " 124708374,\n",
       " 130173062,\n",
       " 130209204,\n",
       " 143645987,\n",
       " 143797445,\n",
       " 147153251,\n",
       " 147153257,\n",
       " 147153554,\n",
       " 147219462,\n",
       " 147219470,\n",
       " 147219481,\n",
       " 147219488,\n",
       " 147221068,\n",
       " 147221072,\n",
       " 147221073,\n",
       " 147378690,\n",
       " 147379512,\n",
       " 156277289,\n",
       " 156277291,\n",
       " 156277293,\n",
       " 156558698,\n",
       " 156558701,\n",
       " 156558717,\n",
       " 156558735,\n",
       " 156558736,\n",
       " 156558745,\n",
       " 158287431,\n",
       " 163789118,\n",
       " 166975141,\n",
       " 166975142,\n",
       " 172520231,\n",
       " 174696366,\n",
       " 181378665,\n",
       " 187002307,\n",
       " 187002308,\n",
       " 187002309,\n",
       " 192436099,\n",
       " 193343830,\n",
       " 193440125,\n",
       " 193440126,\n",
       " 229569461,\n",
       " 231492883,\n",
       " 231492901,\n",
       " 231492903,\n",
       " 235708863,\n",
       " 235708867,\n",
       " 244502208,\n",
       " 244502214,\n",
       " 244502215,\n",
       " 244502216,\n",
       " 244502217,\n",
       " 244502227,\n",
       " 255479957,\n",
       " 255479958,\n",
       " 261119223,\n",
       " 261119224,\n",
       " 261119228,\n",
       " 262961035,\n",
       " 265002080,\n",
       " 265002084,\n",
       " 265351156,\n",
       " 265351175,\n",
       " 265907567,\n",
       " 288580228,\n",
       " 290274551,\n",
       " 290274655,\n",
       " 290274884,\n",
       " 290274926,\n",
       " 295315352,\n",
       " 295316447,\n",
       " 295317920,\n",
       " 295317921,\n",
       " 301683150,\n",
       " 301683155,\n",
       " 301683164,\n",
       " 303402966,\n",
       " 306627215,\n",
       " 306627222,\n",
       " 306627227,\n",
       " 306627230,\n",
       " 330284886,\n",
       " 330284888,\n",
       " 330290205,\n",
       " 330290209,\n",
       " 330377462,\n",
       " 340328545,\n",
       " 340328548,\n",
       " 340328550,\n",
       " 340328551,\n",
       " 353904407,\n",
       " 364701243,\n",
       " 364701244,\n",
       " 384222098,\n",
       " 394525849,\n",
       " 419803153,\n",
       " 419803156,\n",
       " 423222140,\n",
       " 423222143,\n",
       " 423222144,\n",
       " 423222149,\n",
       " 423223132,\n",
       " 423234128,\n",
       " 429821509,\n",
       " 429821513,\n",
       " 429821517,\n",
       " 429821521,\n",
       " 429821524,\n",
       " 429821525,\n",
       " 429821526,\n",
       " 429821530,\n",
       " 429821532,\n",
       " 429821540,\n",
       " 429821543,\n",
       " 429821555,\n",
       " 429821582,\n",
       " 429850001,\n",
       " 430114713,\n",
       " 442110790,\n",
       " 443449157,\n",
       " 454748401,\n",
       " 454748846,\n",
       " 454748866,\n",
       " 454748867,\n",
       " 454749324,\n",
       " 454749325,\n",
       " 454749326,\n",
       " 454749327,\n",
       " 454749328,\n",
       " 454749329,\n",
       " 454749330,\n",
       " 454749331,\n",
       " 454749332,\n",
       " 454749333,\n",
       " 454749334,\n",
       " 454752243,\n",
       " 454754141,\n",
       " 454754142,\n",
       " 454754143,\n",
       " 454754144,\n",
       " 454754145,\n",
       " 454754146,\n",
       " 454756163,\n",
       " 455188436,\n",
       " 455593002,\n",
       " 457549665,\n",
       " 458933810,\n",
       " 458933812,\n",
       " 458933814,\n",
       " 458933817,\n",
       " 458933819,\n",
       " 458933821,\n",
       " 458933823,\n",
       " 458933826,\n",
       " 458933828,\n",
       " 458933830,\n",
       " 458933832,\n",
       " 458933834,\n",
       " 458933836,\n",
       " 460358802,\n",
       " 460358805,\n",
       " 460358809,\n",
       " 460358811,\n",
       " 460358813,\n",
       " 460358815,\n",
       " 460358817,\n",
       " 460358819,\n",
       " 460358820,\n",
       " 460358822,\n",
       " 460358824,\n",
       " 460358826,\n",
       " 460358828,\n",
       " 460358830,\n",
       " 460358831,\n",
       " 460358833,\n",
       " 460358835,\n",
       " 460358837,\n",
       " 460358839,\n",
       " 460358841,\n",
       " 460358842,\n",
       " 460358844,\n",
       " 460358845,\n",
       " 460358847,\n",
       " 460358849,\n",
       " 460358851,\n",
       " 460358853,\n",
       " 460358855,\n",
       " 460358857,\n",
       " 460358859,\n",
       " 460358861,\n",
       " 460358863,\n",
       " 460359040,\n",
       " 460359041,\n",
       " 468468496,\n",
       " 473726834,\n",
       " 473726835,\n",
       " 491240425,\n",
       " 533822312,\n",
       " 539519992,\n",
       " 539519993,\n",
       " 539942017,\n",
       " 539942018,\n",
       " 539942056,\n",
       " 539942057,\n",
       " 539942059,\n",
       " 539942062,\n",
       " 540575981,\n",
       " 540575982,\n",
       " 572105502,\n",
       " 572473512,\n",
       " 585469925,\n",
       " 632674888,\n",
       " 634209809,\n",
       " 634214420,\n",
       " 634215773,\n",
       " 655220231,\n",
       " 692061734,\n",
       " 692061736,\n",
       " 705848614,\n",
       " 722377397,\n",
       " 732226047,\n",
       " 745688417,\n",
       " 753884679,\n",
       " 753884681,\n",
       " 754022704,\n",
       " 758017613,\n",
       " 758017615,\n",
       " 762389406,\n",
       " 770072383,\n",
       " 770072387,\n",
       " 770072389,\n",
       " 775205997,\n",
       " 776121011,\n",
       " 776121014,\n",
       " 776121016,\n",
       " 776121017,\n",
       " 802208330,\n",
       " 809875240,\n",
       " 813893371,\n",
       " 813893372,\n",
       " 816916641,\n",
       " 817934532,\n",
       " 827237678,\n",
       " 828702229,\n",
       " 828702231,\n",
       " 828702233,\n",
       " 835960314,\n",
       " 837300555,\n",
       " 845217250,\n",
       " 852546807,\n",
       " 852546809,\n",
       " 852571584,\n",
       " 866854007,\n",
       " 875642229,\n",
       " 897763019,\n",
       " 897763020,\n",
       " 897763021,\n",
       " 899959109,\n",
       " 900653531,\n",
       " 902771184,\n",
       " 905925697,\n",
       " 905925712,\n",
       " 909804435,\n",
       " 926386105,\n",
       " 929680627,\n",
       " 929680629,\n",
       " 929680631,\n",
       " 929680633,\n",
       " 929680635,\n",
       " 936524397,\n",
       " 943684996,\n",
       " 943684997,\n",
       " 943684998,\n",
       " 943684999,\n",
       " 954619671,\n",
       " 962796149,\n",
       " 963018233,\n",
       " 963018234,\n",
       " 963060306,\n",
       " 972330669,\n",
       " 972373485,\n",
       " 972376312,\n",
       " 984124930,\n",
       " 984124932,\n",
       " 984124936,\n",
       " 984124937,\n",
       " 984128089,\n",
       " 984128091,\n",
       " 984128093,\n",
       " 984128105,\n",
       " 987664485,\n",
       " 988099147,\n",
       " 1008080559,\n",
       " 1015932068,\n",
       " 1015932077,\n",
       " 1020563667,\n",
       " 1021075993,\n",
       " 1022982694,\n",
       " 1025610172,\n",
       " 1028144382,\n",
       " 1028144384,\n",
       " 1028155373,\n",
       " 1028155376,\n",
       " 1029202026,\n",
       " 1029202027,\n",
       " 1029202029,\n",
       " 1035929228,\n",
       " 1035929231,\n",
       " 1038905509,\n",
       " 1038905686,\n",
       " 1044293941,\n",
       " 1044293945,\n",
       " 1044295744,\n",
       " 1044295745,\n",
       " 1044295746,\n",
       " 1053168370,\n",
       " 1058591209,\n",
       " 1059703657,\n",
       " 1063051138,\n",
       " 1076240999,\n",
       " 1079813982,\n",
       " 1081747478,\n",
       " 1084114499,\n",
       " 1084114501,\n",
       " 1084114503,\n",
       " 1087619551,\n",
       " 1088166549,\n",
       " 1090266934,\n",
       " 1094893212,\n",
       " 1094893225,\n",
       " 1094893226,\n",
       " 1096122910,\n",
       " 1102782884,\n",
       " 1102782885,\n",
       " 1118000049,\n",
       " 1118186482,\n",
       " 1118700566,\n",
       " 1118700587,\n",
       " 1118700590,\n",
       " 1118700592,\n",
       " 1118700594,\n",
       " 1118715434,\n",
       " 1119213980,\n",
       " 1119243840,\n",
       " 1119243843,\n",
       " 1119539252,\n",
       " 1119540670,\n",
       " 1119615746,\n",
       " 1119663244,\n",
       " 1119674606,\n",
       " 1119744396,\n",
       " 1120149809,\n",
       " 1120219579,\n",
       " 1120788802,\n",
       " 1120788804,\n",
       " 1120788808,\n",
       " 1120919967,\n",
       " 1121058064,\n",
       " 1121058068,\n",
       " 1121058070,\n",
       " 1121067360,\n",
       " 1121509930,\n",
       " 1121519235,\n",
       " 1121869985,\n",
       " 1123332949]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridge_linkids = links[links['bridge'].notna()].index.tolist()\n",
    "elevation_tools.sample_lidar(bridge_linkids,interpolated_points_dict,bridge_decks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some examples to visaulize here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move on to Step 6 (Below code is test code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating grade from sampled elevation\n",
    "# #for storing the interpolated points with sampled elevation data\n",
    "# import pickle\n",
    "# with (network_filepath.parent/'elevation.pkl').open('rb') as fh:\n",
    "#     interpolated_points_dict = pickle.load(fh)\n",
    "# Calculate average up-grade and down-grade for each link using the interpolated points with sampled elevations\n",
    "# # all_rise = {}\n",
    "# # all_down = {}\n",
    "# # max_rise = {}\n",
    "# # min_rise = {}\n",
    "# grade_threshold = 15\n",
    "\n",
    "# for key, item in tqdm(interpolated_points_dict.items(),total=len(interpolated_points_dict)):     \n",
    "\n",
    "#     #find the total distance to get average grade\n",
    "#     total_distance = np.array(item['distances']).max()\n",
    "    \n",
    "#     #caluclate the elevation change between points and add to list\n",
    "#     elevation_deltas = []\n",
    "#     grades = []\n",
    "#     bad_grades = []\n",
    "#     for x in range(0,len(item['elevations'])-1):        \n",
    "#         elev1 = item['elevations'][x]\n",
    "#         elev2 = item['elevations'][x+1]\n",
    "#         dist1 = item['distances'][x]\n",
    "#         dist2 = item['distances'][x+1]\n",
    "#         elevation_delta = (elev2-elev1)\n",
    "#         elevation_deltas.append(elevation_delta)\n",
    "#         distance_delta = (dist2-dist1)\n",
    "\n",
    "#         segment_grade = elevation_delta / distance_delta * 100\n",
    "#         grades.append(segment_grade)\n",
    "\n",
    "#         #flag potentially bad elevation points\n",
    "#         if np.abs(segment_grade) >= grade_threshold:\n",
    "#             bad_grades.append(x)\n",
    "\n",
    "#     #get total up and down\n",
    "#     elevation_deltas = np.asarray(elevation_deltas)\n",
    "#     up = elevation_deltas[elevation_deltas>0].sum()\n",
    "#     down = np.absolute(elevation_deltas[elevation_deltas<0].sum()) #take absolute value at this point\n",
    "\n",
    "#     #get average up and down grade\n",
    "#     up_grade = up / total_distance * 100\n",
    "#     down_grade = down / total_distance * 100\n",
    "    \n",
    "#     interpolated_points_dict[key].update(\n",
    "#         {\n",
    "#             'up': up,\n",
    "#             'down': down, \n",
    "#             'up_grade': up_grade,\n",
    "#             'down_grade': down_grade,\n",
    "#             'elevation_deltas': elevation_deltas,\n",
    "#             'grade_segments': grades,\n",
    "#             'bad_grades': bad_grades\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # Tasks\n",
    "# - We have a good way to plot/examine\n",
    "# - We just need to clean the rest of the data\n",
    "# - We have taken out underpasses, so now we should look at bridges and sample lidar stuff and then examine the results\n",
    "# - Once that is done, smooth everything and caclulate the different variables\n",
    "# # Plotting\n",
    "# We want to better visualize the problem and identify the different types of situations:\n",
    "# - Vertical profile with bad grades highlighed\n",
    "#     - Different colors for up/down (arrows?)\n",
    "#     - Ignore vertical exageration for now\n",
    "# - Grade profile just showing the grades with bad ones highlighted (maybe even a dual axis graph)\n",
    "# - Static map of where the link is + bad grades highlighted\n",
    "# - Really, we want to export all the bad figures with a link to the osm way in the title\n",
    "\n",
    "\n",
    "# # use west paces ferry to start with\n",
    "# #linkid = 42901\n",
    "\n",
    "# fig, (ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(12,3))\n",
    "\n",
    "# # for linkid, item in tqdm(interpolated_points_dict.items()):\n",
    "\n",
    "# #     if len(item['bad_grades']) == 0:\n",
    "# #         continue\n",
    "\n",
    "# #     if len(item['distances']) <= 2:\n",
    "# #         continue\n",
    "\n",
    "# cond = True\n",
    "# while cond == True:\n",
    "#     linkid = links['linkid'].sample(1).item()\n",
    "#     item = interpolated_points_dict[linkid]\n",
    "#     if (len(item['bad_grades']) > 0) & (len(item['distances']) > 2):\n",
    "#         cond = False\n",
    "    \n",
    "\n",
    "# #https://github.com/geopandas/geopandas/issues/2279\n",
    "# #https://stackoverflow.com/questions/8247973/how-do-i-specify-an-arrow-like-linestyle-in-matplotlib\n",
    "\n",
    "# #Extract values\n",
    "# x = np.array(item['distances'])\n",
    "# y = np.array(item['elevations'])\n",
    "\n",
    "# #gives you a boolean mask\n",
    "# bad_up_grades = np.array(item['grade_segments']) >= grade_threshold\n",
    "# bad_down_grades = np.array(item['grade_segments']) <= -grade_threshold\n",
    "\n",
    "# #add an additional value\n",
    "# bad_up_grades = np.hstack([np.array((False)),bad_up_grades])\n",
    "# bad_down_grades = np.hstack([np.array((False)),bad_down_grades])\n",
    "\n",
    "# bad_up_x = x[bad_up_grades]\n",
    "# bad_up_y = y[bad_up_grades]\n",
    "\n",
    "# bad_down_x = x[bad_down_grades]\n",
    "# bad_down_y = y[bad_down_grades]\n",
    "\n",
    "# #First Figure\n",
    "# # Plot the original data and the smoothed curve\n",
    "# ax1.plot(x, y, 'o', label='Original Data')\n",
    "# #ax1.plot(x, new_y, 'x',label='Resampled with Lidar')\n",
    "# ax1.grid(True,linestyle='-.')\n",
    "\n",
    "# # plot bad points\n",
    "# ax1.plot(bad_up_x,bad_up_y,'o',color='green',label=f'Above {grade_threshold}%')\n",
    "# ax1.plot(bad_down_x,bad_down_y,'o',color='red',label=f'Below -{grade_threshold}%')\n",
    "\n",
    "# #ax1.set_title(f'{road_name} (Linkid:{linkid}) Veritcal Cross-Section')\n",
    "# ax1.set_xlabel('Distance (m)')\n",
    "# ax1.set_ylabel('Elevation (m)')\n",
    "# ax1.legend()\n",
    "\n",
    "# #Second and Third figure\n",
    "\n",
    "# #create geos to plot\n",
    "# points = np.array([Point(x,y) for x,y in item['geometry']])\n",
    "# line = LineString(item['geometry'])\n",
    "# minx, miny, maxx, maxy = line.bounds\n",
    "# # line_gdf = gpd.GeoDataFrame({'geometry':line},crs=dem_crs,index=[0])\n",
    "\n",
    "# # use mask to just get bad one\n",
    "# bad_up_grades_points = points[bad_up_grades]\n",
    "# bad_up_grades_points = gpd.GeoDataFrame({'geometry':bad_up_grades_points},geometry='geometry',crs=dem_crs)\n",
    "# bad_up_grades_points['type'] = '> 15%'\n",
    "\n",
    "# bad_down_grades_points = points[bad_down_grades]\n",
    "# bad_down_grades_points = gpd.GeoDataFrame({'geometry':bad_down_grades_points},geometry='geometry',crs=dem_crs)\n",
    "# bad_down_grades_points['type'] = '< -15%'\n",
    "\n",
    "# bad_grades_points = pd.concat([bad_up_grades_points,bad_down_grades_points])\n",
    "\n",
    "\n",
    "# color_dict = {\n",
    "#     '> 15%': 'green',\n",
    "#     '< -15%': 'red',\n",
    "# }\n",
    "# bad_grades_points['color'] = bad_grades_points['type'].map(color_dict)\n",
    "\n",
    "# bad_grades_points.plot(ax=ax2,color=bad_grades_points['color'],zorder=4)\n",
    "# bad_grades_points.plot(ax=ax3,color=bad_grades_points['color'],zorder=4)\n",
    "\n",
    "# #for drawing the link\n",
    "# x = np.array([x for x, y in item['geometry']])\n",
    "# y = np.array([y for x, y in item['geometry']])\n",
    "# # length of line segment\n",
    "# ds=10\n",
    "# # number of line segments per interval\n",
    "# Ns = np.round(np.sqrt( (x[1:]-x[:-1])**2 + (y[1:]-y[:-1])**2 ) / ds).astype(int)\n",
    "# # sub-divide intervals w.r.t. Ns\n",
    "# subdiv = lambda x, Ns=Ns: np.concatenate([ np.linspace(x[ii], x[ii+1], Ns[ii]) for ii, _ in enumerate(x[:-1]) ])\n",
    "# x, y = subdiv(x), subdiv(y)\n",
    "# ax2.quiver(x[:-1], y[:-1], x[1:]-x[:-1], y[1:]-y[:-1], scale_units='xy', angles='xy', scale=1, width=.004, headlength=4, headwidth=4)\n",
    "# ax3.quiver(x[:-1], y[:-1], x[1:]-x[:-1], y[1:]-y[:-1], scale_units='xy', angles='xy', scale=1, width=.004, headlength=4, headwidth=4)\n",
    "\n",
    "# #If you want a legend for map (didnot figure out arrow in the legend)\n",
    "# # from matplotlib.lines import Line2D\n",
    "# # from matplotlib.patches import Arrow\n",
    "# # custom_points = [Line2D([0], [0], marker=\"o\", linestyle=\"none\", markersize=10, color=color) for color in color_dict.values()]\n",
    "# # #custom_line = Arrow(0,0,dx=0.1,dy=0,width=0.1,linewidth=0.5,color='black')\n",
    "# # #custom_points.append()\n",
    "# # leg_points = ax2.legend(custom_points, ['> 15%','< -15%'])#, title = 'Legend', alignment='right')\n",
    "# # ax2.add_artist(leg_points)\n",
    "\n",
    "# #make sure fig is square\n",
    "# padding = 100\n",
    "# x_diff = np.abs(maxx - minx)\n",
    "# y_diff = np.abs(maxy - miny)\n",
    "# diff = (x_diff - y_diff)/2\n",
    "# if diff > 0:\n",
    "#     ax2.set_xlim(minx-padding,maxx+padding)\n",
    "#     ax2.set_ylim(miny-padding-diff,maxy+padding+diff)\n",
    "\n",
    "#     ax3.set_xlim(minx-padding,maxx+padding)\n",
    "#     ax3.set_ylim(miny-padding-diff,maxy+padding+diff)\n",
    "# else:\n",
    "#     ax2.set_xlim(minx-padding-np.abs(diff),maxx+padding+np.abs(diff))\n",
    "#     ax2.set_ylim(miny-padding,maxy+padding)\n",
    "\n",
    "#     ax3.set_xlim(minx-padding-np.abs(diff),maxx+padding+np.abs(diff))\n",
    "#     ax3.set_ylim(miny-padding,maxy+padding)\n",
    "\n",
    "# ax2.set_axis_off()\n",
    "# ax3.set_axis_off()\n",
    "\n",
    "# cx.add_basemap(ax2,zoom=17,source=cx.providers.MapTiler.Satellite(key=maptilerapikey),crs=bad_grades_points.crs,alpha=0.5)\n",
    "# cx.add_basemap(ax3,zoom=16,source=cx.providers.MapTiler.Streets(key=maptilerapikey),crs=bad_grades_points.crs)\n",
    "\n",
    "# #maybe if we wanted a high res version of this later\n",
    "# #https://stackoverflow.com/questions/42483449/mapbox-gl-js-export-map-to-png-or-pdf\n",
    "\n",
    "# name = links.loc[links['linkid']==linkid,'name'].item()\n",
    "# plt.suptitle(f'{name} ({linkid}) vertical profile')\n",
    "# plt.show()\n",
    "\n",
    "# # try: \n",
    "# #     plt.savefig(Path(f'D:/bad_grades/{name}_{linkid}.png'),dpi=300)\n",
    "# # except:\n",
    "# #     'invalid filename'\n",
    "\n",
    "# # #clear the axis\n",
    "# # ax1.cla()\n",
    "# # ax2.cla()\n",
    "# # ax3.cla()\n",
    "\n",
    "# from scipy.interpolate import splrep, splev\n",
    "\n",
    "# #pick a random one to examine\n",
    "# #linkid = int(abnormal_links.loc[new,'linkid'].sample(1).item())\n",
    "# linkid = links.loc[still_bad,'linkid'].sample(1).item()\n",
    "# #linkid = 53107\n",
    "\n",
    "# #linkid = 28303#44061\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# #title\n",
    "# road_name = links.loc[links.index==linkid,'name'].item()\n",
    "\n",
    "# #ax1 elements\n",
    "# x = np.array(item['distances'])\n",
    "# y = np.array(item['elevations'])\n",
    "# new_y = np.array(lidar_sampled[linkid])\n",
    "\n",
    "# #ax2 elements\n",
    "# grade_x = np.array(range(0,len(x) - 1))\n",
    "# grade_delta = np.diff(y) / 10 * 100\n",
    "# lidar_delta = np.diff(new_y) / 10 * 100\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(9,3))\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# ax1.plot(x, y, 'o', label='Original Data')\n",
    "# ax1.plot(x, new_y, 'x',label='Resampled with Lidar')\n",
    "# ax1.grid(True,linestyle='-.')\n",
    "\n",
    "# #find min\n",
    "# y_min = np.min([y.min(),new_y.min()])\n",
    "# y_max = np.max([y.max(),new_y.max()])\n",
    "\n",
    "# ax1.set_xlim(0,np.ceil(x.max() / 10) * 10)\n",
    "# ax1.set_ylim(np.floor(y_min/10)*10,np.ceil(y_max/10)*10)\n",
    "# ax1.set_box_aspect(1)\n",
    "\n",
    "# #ax1.set_title(f'{road_name} (Linkid:{linkid}) Veritcal Cross-Section')\n",
    "# ax1.set_xlabel('Distance (m)')\n",
    "# ax1.set_ylabel('Elevation (m)')\n",
    "# ax1.legend()\n",
    "\n",
    "# ax2.plot(grade_x, grade_delta, 'o', label='Original Grade')\n",
    "# ax2.plot(grade_x, lidar_delta, 'x', label='lidar grade')\n",
    "\n",
    "\n",
    "# ax2.set_xlabel('Distance (m)')\n",
    "# ax2.set_ylabel('Grade %')\n",
    "# ax2.set_box_aspect(1)\n",
    "# ax2.legend()\n",
    "\n",
    "# fig.suptitle(f'{road_name} (Linkid:{linkid})')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Set ticks\n",
    "# #plt.xlim(0,x.max())\n",
    "# #plt.ylim()\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# #plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "\n",
    "# #turn item into a dataframe\n",
    "# #df = pd.DataFrame.from_dict(item,orient='columns')\n",
    "\n",
    "# # df['elev_change'] = df['elevations'].diff()\n",
    "# # df['dist_change'] = df['distances'].diff()\n",
    "# # df['change_rate'] = np.abs(df['elev_change'] / df['dist_change'])\n",
    "\n",
    "#     total_down =  \n",
    "#     all_rise[key] = total_rise\n",
    "#     all_down[key] = total_down\n",
    "\n",
    "#     if total_rise > 0:\n",
    "#         max_rise[key] = elevation_deltas[elevation_deltas>0].max()\n",
    "#     else:\n",
    "#         max_rise[key] = 0\n",
    "\n",
    "#     if total_down > 0:\n",
    "#         min_rise[key] = np.absolute(elevation_deltas[elevation_deltas<0].min())\n",
    "#     else:\n",
    "#         min_rise[key] = 0\n",
    "\n",
    "# #forward direction\n",
    "# links['rise_m'] = pd.Series(all_rise).round(3)\n",
    "# links['maxrise_m'] = pd.Series(max_rise).round(3)\n",
    "# links['up_grade'] = (links['rise_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'max_grade'] = (links['maxrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "# links.loc[links['max_grade'].isna(),'max_grade'] = (links['maxrise_m'] / links.length * 100).round(1)\n",
    "\n",
    "# #reverse direction\n",
    "# links['down_m'] = pd.Series(all_down).round(3)\n",
    "# links['minrise_m'] = pd.Series(min_rise).round(3)\n",
    "# links['down_grade'] = (links['down_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'min_grade'] = (links['minrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "# links.loc[links['min_grade'].isna(),'min_grade'] = (links['minrise_m'] / links.length * 100).round(1)\n",
    "# #reproject data and export\n",
    "# #links.to_crs('epsg:2240',inplace=True)\n",
    "# #links.to_crs(prev_crs).reset_index(drop=True).to_file(project_dir/'reconciled_network.gpkg',layer='links_w_signals_elevation')\n",
    "# # Sample bridge elevations using LIDAR data\n",
    "# Bridges and tunnels will have inaccurate grades becuase they don't follow the terrain. DEMs represent the lowest point possible so that they show the underlying natural terrain. Raw LIDAR data will have points representing builidngs, trees, and other things on the earth's surface.\n",
    "\n",
    "# The download lidar script will download .LAZ files for the study area (LIDAR data is also available from the USGS site). These are then converted into TIF files using the lidar notebook. Once the TIF files have been made, the following code blocks sample new data that replaces previous elevation samples if the new sampled elevation is greater than the existing.\n",
    "\n",
    "# A new column is created for the link geodataframe to examine where the newly sampled points increased/decreased the accuracy of the elevation data. The assumption is that more accurate data should reduce the number of extreme grade changes and by extension the average grade. It may not do that in all cases, so the next step will be to smooth the data.\n",
    "# linkids = []\n",
    "# for key, item in interpolated_points_dict.items():\n",
    "#     if len(item['bad_grades']) > 0:\n",
    "#         linkids.append(key)\n",
    "# print(len(linkids),'exceed the threshold')\n",
    "# exceeds_threshold = links.loc[linkids]\n",
    "# #grab ones that are not bridges and don't exceed the threshold\n",
    "# not_bridges = exceeds_threshold.loc[exceeds_threshold['bridge'].isna() ,['linkid','geometry']]\n",
    "# print(len(not_bridges),'are not bridges')\n",
    "# ### Find links that cross bridges, railroads, or creeks/rivers (likely an underpass)\n",
    "# #grab bridges\n",
    "# raw_osm = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_links')\n",
    "# osm_attr = pd.read_pickle(network_filepath/'osm_attr.pkl')\n",
    "# merged = raw_osm.merge(osm_attr,on='osm_linkid')\n",
    "# bridges = merged.loc[~merged['bridge'].isna(),['osm_linkid','geometry']]\n",
    "# bridges.to_crs(links.crs,inplace=True)\n",
    "# #check if bridge crosses non-bridge\n",
    "# crossing_links = []\n",
    "# for idx, row in bridges.iterrows():\n",
    "#     bridge = row['geometry']\n",
    "#     crosses = not_bridges.loc[not_bridges.crosses(bridge),'linkid'].tolist()\n",
    "#     if len(crosses) > 0:\n",
    "#         crossing_links = crossing_links + crosses\n",
    "# mask = list(set(crossing_links))\n",
    "# not_bridges.loc[mask].reset_index(drop=True).explore()\n",
    "# intersection = gpd.overlay(bridges,not_bridges,keep_geom_type=False)\n",
    "# intersection.explore()\n",
    "# ### Examine cross sections for these\n",
    "# intersection['linkid'].nunique()\n",
    "# len(mask)\n",
    "# import contextily as cx\n",
    "\n",
    "# # use west paces ferry to start with\n",
    "# #linkid = 42901\n",
    "\n",
    "# fig, (ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(12,3))\n",
    "\n",
    "# # for linkid, item in tqdm(interpolated_points_dict.items()):\n",
    "\n",
    "# #     if len(item['bad_grades']) == 0:\n",
    "# #         continue\n",
    "\n",
    "# #     if len(item['distances']) <= 2:\n",
    "# #         continue\n",
    "\n",
    "# linkid = not_bridges.loc[mask,'linkid'].sample(1).item()#intersection['linkid'].sample(1).item()\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# #https://github.com/geopandas/geopandas/issues/2279\n",
    "# #https://stackoverflow.com/questions/8247973/how-do-i-specify-an-arrow-like-linestyle-in-matplotlib\n",
    "\n",
    "# #Extract values\n",
    "# x = np.array(item['distances'])\n",
    "# y = np.array(item['elevations'])\n",
    "\n",
    "# #gives you a boolean mask\n",
    "# bad_up_grades = np.array(item['grade_segments']) >= grade_threshold\n",
    "# bad_down_grades = np.array(item['grade_segments']) <= -grade_threshold\n",
    "\n",
    "# #add an additional value\n",
    "# bad_up_grades = np.hstack([np.array((False)),bad_up_grades])\n",
    "# bad_down_grades = np.hstack([np.array((False)),bad_down_grades])\n",
    "\n",
    "# bad_up_x = x[bad_up_grades]\n",
    "# bad_up_y = y[bad_up_grades]\n",
    "\n",
    "# bad_down_x = x[bad_down_grades]\n",
    "# bad_down_y = y[bad_down_grades]\n",
    "\n",
    "# #First Figure\n",
    "# # Plot the original data and the smoothed curve\n",
    "# ax1.plot(x, y, 'o', label='Original Data')\n",
    "# #ax1.plot(x, new_y, 'x',label='Resampled with Lidar')\n",
    "# ax1.grid(True,linestyle='-.')\n",
    "\n",
    "# # plot bad points\n",
    "# ax1.plot(bad_up_x,bad_up_y,'o',color='green',label=f'Above {grade_threshold}%')\n",
    "# ax1.plot(bad_down_x,bad_down_y,'o',color='red',label=f'Below -{grade_threshold}%')\n",
    "\n",
    "# #ax1.set_title(f'{road_name} (Linkid:{linkid}) Veritcal Cross-Section')\n",
    "# ax1.set_xlabel('Distance (m)')\n",
    "# ax1.set_ylabel('Elevation (m)')\n",
    "# ax1.legend()\n",
    "\n",
    "# #Second and Third figure\n",
    "\n",
    "# #create geos to plot\n",
    "# points = np.array([Point(x,y) for x,y in item['geometry']])\n",
    "# line = LineString(item['geometry'])\n",
    "# minx, miny, maxx, maxy = line.bounds\n",
    "# # line_gdf = gpd.GeoDataFrame({'geometry':line},crs=dem_crs,index=[0])\n",
    "\n",
    "# # use mask to just get bad one\n",
    "# bad_up_grades_points = points[bad_up_grades]\n",
    "# bad_up_grades_points = gpd.GeoDataFrame({'geometry':bad_up_grades_points},geometry='geometry',crs=dem_crs)\n",
    "# bad_up_grades_points['type'] = '> 15%'\n",
    "\n",
    "# bad_down_grades_points = points[bad_down_grades]\n",
    "# bad_down_grades_points = gpd.GeoDataFrame({'geometry':bad_down_grades_points},geometry='geometry',crs=dem_crs)\n",
    "# bad_down_grades_points['type'] = '< -15%'\n",
    "\n",
    "# bad_grades_points = pd.concat([bad_up_grades_points,bad_down_grades_points])\n",
    "\n",
    "\n",
    "# color_dict = {\n",
    "#     '> 15%': 'green',\n",
    "#     '< -15%': 'red',\n",
    "# }\n",
    "# bad_grades_points['color'] = bad_grades_points['type'].map(color_dict)\n",
    "\n",
    "# bad_grades_points.plot(ax=ax2,color=bad_grades_points['color'],zorder=4)\n",
    "# bad_grades_points.plot(ax=ax3,color=bad_grades_points['color'],zorder=4)\n",
    "\n",
    "# #for drawing the link\n",
    "# x = np.array([x for x, y in item['geometry']])\n",
    "# y = np.array([y for x, y in item['geometry']])\n",
    "# # length of line segment\n",
    "# ds=10\n",
    "# # number of line segments per interval\n",
    "# Ns = np.round(np.sqrt( (x[1:]-x[:-1])**2 + (y[1:]-y[:-1])**2 ) / ds).astype(int)\n",
    "# # sub-divide intervals w.r.t. Ns\n",
    "# subdiv = lambda x, Ns=Ns: np.concatenate([ np.linspace(x[ii], x[ii+1], Ns[ii]) for ii, _ in enumerate(x[:-1]) ])\n",
    "# x, y = subdiv(x), subdiv(y)\n",
    "# ax2.quiver(x[:-1], y[:-1], x[1:]-x[:-1], y[1:]-y[:-1], scale_units='xy', angles='xy', scale=1, width=.004, headlength=4, headwidth=4)\n",
    "# ax3.quiver(x[:-1], y[:-1], x[1:]-x[:-1], y[1:]-y[:-1], scale_units='xy', angles='xy', scale=1, width=.004, headlength=4, headwidth=4)\n",
    "\n",
    "# #If you want a legend for map (didnot figure out arrow in the legend)\n",
    "# # from matplotlib.lines import Line2D\n",
    "# # from matplotlib.patches import Arrow\n",
    "# # custom_points = [Line2D([0], [0], marker=\"o\", linestyle=\"none\", markersize=10, color=color) for color in color_dict.values()]\n",
    "# # #custom_line = Arrow(0,0,dx=0.1,dy=0,width=0.1,linewidth=0.5,color='black')\n",
    "# # #custom_points.append()\n",
    "# # leg_points = ax2.legend(custom_points, ['> 15%','< -15%'])#, title = 'Legend', alignment='right')\n",
    "# # ax2.add_artist(leg_points)\n",
    "\n",
    "# #make sure fig is square\n",
    "# padding = 100\n",
    "# x_diff = np.abs(maxx - minx)\n",
    "# y_diff = np.abs(maxy - miny)\n",
    "# diff = (x_diff - y_diff)/2\n",
    "# if diff > 0:\n",
    "#     ax2.set_xlim(minx-padding,maxx+padding)\n",
    "#     ax2.set_ylim(miny-padding-diff,maxy+padding+diff)\n",
    "\n",
    "#     ax3.set_xlim(minx-padding,maxx+padding)\n",
    "#     ax3.set_ylim(miny-padding-diff,maxy+padding+diff)\n",
    "# else:\n",
    "#     ax2.set_xlim(minx-padding-np.abs(diff),maxx+padding+np.abs(diff))\n",
    "#     ax2.set_ylim(miny-padding,maxy+padding)\n",
    "\n",
    "#     ax3.set_xlim(minx-padding-np.abs(diff),maxx+padding+np.abs(diff))\n",
    "#     ax3.set_ylim(miny-padding,maxy+padding)\n",
    "\n",
    "# ax2.set_axis_off()\n",
    "# ax3.set_axis_off()\n",
    "\n",
    "# cx.add_basemap(ax2,zoom=17,source=cx.providers.MapTiler.Satellite(key=maptilerapikey),crs=bad_grades_points.crs,alpha=0.5)\n",
    "# cx.add_basemap(ax3,zoom=16,source=cx.providers.MapTiler.Streets(key=maptilerapikey),crs=bad_grades_points.crs)\n",
    "\n",
    "# #maybe if we wanted a high res version of this later\n",
    "# #https://stackoverflow.com/questions/42483449/mapbox-gl-js-export-map-to-png-or-pdf\n",
    "\n",
    "# name = links.loc[links['linkid']==linkid,'name'].item()\n",
    "# plt.suptitle(f'{name} ({linkid}) vertical profile')\n",
    "# plt.show()\n",
    "\n",
    "# # try: \n",
    "# #     plt.savefig(Path(f'D:/bad_grades/{name}_{linkid}.png'),dpi=300)\n",
    "# # except:\n",
    "# #     'invalid filename'\n",
    "\n",
    "# # #clear the axis\n",
    "# # ax1.cla()\n",
    "# # ax2.cla()\n",
    "# # ax3.cla()\n",
    "# linkid = 28689\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# distances = np.array(item['distances'])\n",
    "# elevations = np.array(item['elevations'])\n",
    "# bad_elevs = item['bad_grades']\n",
    "# #temp_anom = [-0.17, -0.09, -0.11, -0.18, -0.3] # and so on...\n",
    "\n",
    "# # further step could be to identify the high points and assign a lower weight \n",
    "# weights = np.ones_like(elevations)\n",
    "# weights[elevations>311] = 0\n",
    "\n",
    "# whittaker_smoother = WhittakerSmoother(\n",
    "#     lmbda=150, order=2, data_length=len(elevations)#, weights=weights\n",
    "# )\n",
    "\n",
    "# smoothed = whittaker_smoother.smooth(elevations)\n",
    "\n",
    "# plt.plot(distances,elevations)\n",
    "# plt.plot(distances,smoothed)\n",
    "# test1 = pd.Series(elevations).diff()\n",
    "# test1_up = test1[test1>0].sum() / distances.max() * 100\n",
    "# test2_down = test1[test1<0].sum() / distances.max() * 100\n",
    "# print(test1_up,test2_down)\n",
    "# test1 = pd.Series(smoothed).diff()\n",
    "# test1_up = test1[test1>0].sum() / distances.max() * 100\n",
    "# test2_down = test1[test1<0].sum() / distances.max() * 100\n",
    "# print(test1_up,test2_down)\n",
    "# # For these, Lidar probably isn't gonna help\n",
    "# # so we just want to try the spline fit\n",
    "\n",
    "# #identify large abnormalities and exclude stair cases (>25%)\n",
    "# # thresholds = range(6,25+5)\n",
    "# # counts = []\n",
    "# # for threshold in thresholds:\n",
    "# #     abnormal = ((links['max_grade'] > threshold) | (links['min_grade'] > threshold))#& (links['highway'] != 'steps')\n",
    "# #     counts.append(links.loc[abnormal].shape[0])\n",
    "# # np.array(counts)\n",
    "\n",
    "# #before sensitvity, just use the haobing one (15% for local roads)\n",
    "# threshold = 15\n",
    "# abnormal = ((links['max_grade'] > threshold) | (links['min_grade'] > threshold))#& (links['highway'] != 'steps')\n",
    "# abnormal_links = links[abnormal]\n",
    "# print(f\"{abnormal.sum()}/{links.shape[0]} links have at least one point exceeding {threshold}% ({abnormal_links.length.sum().round(0)}/{links.length.sum().round(0)} km)\")\n",
    "# abnormal_links['length_km'] = abnormal_links.length\n",
    "# print(abnormal_links.groupby('highway')['length_km'].sum().round(0).sort_values(ascending=False))\n",
    "\n",
    "# print(abnormal_links['highway'].value_counts().sort_values(ascending=False))\n",
    "# # Method 1\n",
    "# bridge_tif_fps = list((Path('D:/') / 'bridge_tif').glob('*.tif'))\n",
    "# abnormal_links.to_crs(rasterio.open(bridge_tif_fps[0]).crs,inplace=True)\n",
    "# lidar_sampled = dict()\n",
    "\n",
    "# for bridge_tif_fp in tqdm(bridge_tif_fps):\n",
    "#     #open the raster using the link\n",
    "#     bridge_tif = rasterio.open(bridge_tif_fp)\n",
    "\n",
    "#     #find all links that intersect with the current raster\n",
    "#     xmin, ymin, xmax, ymax = bridge_tif.bounds\n",
    "#     bbox = box(xmin,ymin,xmax,ymax)\n",
    "#     intersection = abnormal_links.intersects(bbox)\n",
    "    \n",
    "#     if (intersection == True).any():\n",
    "#         for index in abnormal_links[intersection].index:\n",
    "#             dict_values = interpolated_points_dict.get(index)\n",
    "\n",
    "#             #change the crs\n",
    "#             #open the first one to just get the crs\n",
    "#             geometry = [Point(x,y) for x,y in dict_values['geometry']]\n",
    "#             gdf = gpd.GeoDataFrame({'geometry':geometry},crs=dem_crs)\n",
    "#             gdf.to_crs(bridge_tif.crs,inplace=True)\n",
    "#             geometry = list(zip(gdf.geometry.x,gdf.geometry.y))\n",
    "\n",
    "#             sampled = np.array([val[0] for val in bridge_tif.sample(geometry)])\n",
    "\n",
    "#             #check for nan values in sampled\n",
    "#             #match the nan points to the nearest cell\n",
    "            \n",
    "\n",
    "#             #if at least one non-null value\n",
    "#             #replace elevation if value is higher?\n",
    "#             if np.isnan(sampled).all() == False:\n",
    "#                 lidar_sampled[index] =  np.nanmax([sampled,dict_values['elevations']],axis = 0)\n",
    "\n",
    "# # Method 2\n",
    "# Uses the raw lidar points instead.\n",
    "# #grab bridges\n",
    "\n",
    "# import pickle\n",
    "# with Path('D:/lidar_points.pkl').open('rb') as fh:\n",
    "#     lidar_points = pickle.load(fh)\n",
    "\n",
    "# lidar_points.to_crs(prev_crs,inplace=True)\n",
    "# spatial_index = lidar_points.sindex\n",
    "\n",
    "\n",
    "# lidar_sampled = dict()\n",
    "# incomplete = []\n",
    "\n",
    "# for index in tqdm(abnormal_links.index):\n",
    "#     dict_values = interpolated_points_dict.get(index)\n",
    "\n",
    "#     geometry = [Point(x,y) for x,y in dict_values['geometry']]\n",
    "#     gdf = gpd.GeoDataFrame({'geometry':geometry},crs=dem_crs)\n",
    "#     gdf.to_crs(prev_crs,inplace=True)\n",
    "\n",
    "#     #buffer the data\n",
    "#     buffer_m = 20\n",
    "#     gdf.geometry = gdf.buffer(buffer_m)\n",
    "\n",
    "#     #get the gdf bounding box\n",
    "#     polygon = gdf.geometry.unary_union.convex_hull\n",
    "    \n",
    "#     #use spatial index to only select a small number of points\n",
    "#     possible_matches_index = list(spatial_index.intersection(polygon.bounds))\n",
    "#     possible_matches = lidar_points.iloc[possible_matches_index]\n",
    "    \n",
    "#     #add an index column for the overlay part\n",
    "#     gdf.reset_index(inplace=True)\n",
    "#     precise_matches = gpd.overlay(possible_matches,gdf,how='intersection')\n",
    "\n",
    "#     if len(precise_matches) == 0:\n",
    "#         continue\n",
    "\n",
    "#     if gdf['index'].isin(set(precise_matches['index'].tolist())).all() == False:\n",
    "#         #this is where we might want to increase the buffer on the remaining points\n",
    "        \n",
    "#         #assign nan\n",
    "#         incomplete.append(index)\n",
    "\n",
    "#     new_values = precise_matches.groupby('index')['elevation_m'].mean()\n",
    "#     gdf['new_elevation_m'] = gdf['index'].map(new_values)\n",
    "#     new_values = np.array(gdf['new_elevation_m'])\n",
    "\n",
    "#     lidar_sampled[index] = np.nanmax([new_values,dict_values['elevations']],axis = 0)\n",
    "# lidar_sampled[36]\n",
    "# #interpolated_points_dict[36]\n",
    "# all_rise = {}\n",
    "# all_down = {}\n",
    "# max_rise = {}\n",
    "# min_rise = {}\n",
    "\n",
    "# for key, item in tqdm(lidar_sampled.items(),total=len(lidar_sampled)):     \n",
    "\n",
    "#     elevation_deltas = []\n",
    "    \n",
    "#     #then caluclate the elevation change with the smoothed data\n",
    "#     for x in range(0,len(item)-1):        \n",
    "#         elev1 = item[x]\n",
    "#         elev2 = item[x+1]\n",
    "#         elevation_delta = (elev2-elev1)\n",
    "#         elevation_deltas.append(elevation_delta)\n",
    "\n",
    "#     elevation_deltas = np.asarray(elevation_deltas)\n",
    "#     total_rise = elevation_deltas[elevation_deltas>0].sum()\n",
    "#     total_down = np.absolute(elevation_deltas[elevation_deltas<0].sum()) #take absolute value at this point\n",
    "#     all_rise[key] = total_rise\n",
    "#     all_down[key] = total_down\n",
    "\n",
    "#     if total_rise > 0:\n",
    "#         max_rise[key] = elevation_deltas[elevation_deltas>0].max()\n",
    "#     else:\n",
    "#         max_rise[key] = 0\n",
    "\n",
    "#     if total_down > 0:\n",
    "#         min_rise[key] = np.absolute(elevation_deltas[elevation_deltas<0].min())\n",
    "#     else:\n",
    "#         min_rise[key] = 0\n",
    "\n",
    "# #forward direction\n",
    "# links['new_rise_m'] = pd.Series(all_rise).round(3)\n",
    "# links['new_maxrise_m'] = pd.Series(max_rise).round(3)\n",
    "# links['new_up_grade'] = (links['new_rise_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'new_max_grade'] = (links['new_maxrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "# links.loc[links['new_max_grade'].isna(),'new_max_grade'] = (links['new_maxrise_m'] / links.length * 100).round(1)\n",
    "\n",
    "# #reverse direction\n",
    "# links['new_down_m'] = pd.Series(all_down).round(3)\n",
    "# links['new_minrise_m'] = pd.Series(min_rise).round(3)\n",
    "# links['new_down_grade'] = (links['new_down_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'new_min_grade'] = (links['new_minrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "# links.loc[links['new_min_grade'].isna(),'new_min_grade'] = (links['new_minrise_m'] / links.length * 100).round(1)\n",
    "\n",
    "# # See where elevation data improved\n",
    "# all_rise = {}\n",
    "# all_down = {}\n",
    "# max_rise = {}\n",
    "# min_rise = {}\n",
    "\n",
    "# for key, item in tqdm(lidar_sampled.items(),total=len(lidar_sampled)):     \n",
    "\n",
    "#     elevation_deltas = []\n",
    "    \n",
    "#     #then caluclate the elevation change with the smoothed data\n",
    "#     for x in range(0,len(item)-1):        \n",
    "#         elev1 = item[x]\n",
    "#         elev2 = item[x+1]\n",
    "#         elevation_delta = (elev2-elev1)\n",
    "#         elevation_deltas.append(elevation_delta)\n",
    "\n",
    "#     elevation_deltas = np.asarray(elevation_deltas)\n",
    "#     total_rise = elevation_deltas[elevation_deltas>0].sum()\n",
    "#     total_down = np.absolute(elevation_deltas[elevation_deltas<0].sum()) #take absolute value at this point\n",
    "#     all_rise[key] = total_rise\n",
    "#     all_down[key] = total_down\n",
    "\n",
    "#     if total_rise > 0:\n",
    "#         max_rise[key] = elevation_deltas[elevation_deltas>0].max()\n",
    "#     else:\n",
    "#         max_rise[key] = 0\n",
    "\n",
    "#     if total_down > 0:\n",
    "#         min_rise[key] = np.absolute(elevation_deltas[elevation_deltas<0].min())\n",
    "#     else:\n",
    "#         min_rise[key] = 0\n",
    "\n",
    "# #forward direction\n",
    "# links['new_rise_m'] = pd.Series(all_rise).round(3)\n",
    "# links['new_maxrise_m'] = pd.Series(max_rise).round(3)\n",
    "# links['new_up_grade'] = (links['new_rise_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'new_max_grade'] = (links['new_maxrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "# links.loc[links['new_max_grade'].isna(),'new_max_grade'] = (links['new_maxrise_m'] / links.length * 100).round(1)\n",
    "\n",
    "# #reverse direction\n",
    "# links['new_down_m'] = pd.Series(all_down).round(3)\n",
    "# links['new_minrise_m'] = pd.Series(min_rise).round(3)\n",
    "# links['new_down_grade'] = (links['new_down_m'] / links.geometry.length * 100).round(1)\n",
    "# links.loc[links.length > interpolate_dist_m,'new_min_grade'] = (links['new_minrise_m'] / interpolate_dist_m * 100).round(1)\n",
    "\n",
    "# prev = abnormal_links.shape[0]\n",
    "# fixed = ((links['new_max_grade'] <= threshold) & (links['new_min_grade'] <= threshold))\n",
    "# still_bad = ((links['new_max_grade'] > threshold) & (links['new_min_grade'] > threshold))\n",
    "# print(f'{fixed.sum()} / {prev} abnormal links fixed')\n",
    "# print(f'{still_bad.sum()} are still abnormal')\n",
    "# print(f'{prev-fixed.sum()-still_bad.sum()} did not overlap with a bridge tif')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import splrep, splev\n",
    "\n",
    "# #pick a random one to examine\n",
    "# #linkid = int(abnormal_links.loc[new,'linkid'].sample(1).item())\n",
    "# linkid = links.loc[still_bad,'linkid'].sample(1).item()\n",
    "# #linkid = 53107\n",
    "\n",
    "# #linkid = 28303#44061\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# #title\n",
    "# road_name = links.loc[links.index==linkid,'name'].item()\n",
    "\n",
    "# #ax1 elements\n",
    "# x = np.array(item['distances'])\n",
    "# y = np.array(item['elevations'])\n",
    "# new_y = np.array(lidar_sampled[linkid])\n",
    "\n",
    "# #ax2 elements\n",
    "# grade_x = np.array(range(0,len(x) - 1))\n",
    "# grade_delta = np.diff(y) / 10 * 100\n",
    "# lidar_delta = np.diff(new_y) / 10 * 100\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(9,3))\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# ax1.plot(x, y, 'o', label='Original Data')\n",
    "# ax1.plot(x, new_y, 'x',label='Resampled with Lidar')\n",
    "# ax1.grid(True,linestyle='-.')\n",
    "\n",
    "# #find min\n",
    "# y_min = np.min([y.min(),new_y.min()])\n",
    "# y_max = np.max([y.max(),new_y.max()])\n",
    "\n",
    "# ax1.set_xlim(0,np.ceil(x.max() / 10) * 10)\n",
    "# ax1.set_ylim(np.floor(y_min/10)*10,np.ceil(y_max/10)*10)\n",
    "# ax1.set_box_aspect(1)\n",
    "\n",
    "# #ax1.set_title(f'{road_name} (Linkid:{linkid}) Veritcal Cross-Section')\n",
    "# ax1.set_xlabel('Distance (m)')\n",
    "# ax1.set_ylabel('Elevation (m)')\n",
    "# ax1.legend()\n",
    "\n",
    "# ax2.plot(grade_x, grade_delta, 'o', label='Original Grade')\n",
    "# ax2.plot(grade_x, lidar_delta, 'x', label='lidar grade')\n",
    "\n",
    "\n",
    "# ax2.set_xlabel('Distance (m)')\n",
    "# ax2.set_ylabel('Grade %')\n",
    "# ax2.set_box_aspect(1)\n",
    "# ax2.legend()\n",
    "\n",
    "# fig.suptitle(f'{road_name} (Linkid:{linkid})')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Set ticks\n",
    "# #plt.xlim(0,x.max())\n",
    "# #plt.ylim()\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# #plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "\n",
    "# #turn item into a dataframe\n",
    "# #df = pd.DataFrame.from_dict(item,orient='columns')\n",
    "\n",
    "# # df['elev_change'] = df['elevations'].diff()\n",
    "# # df['dist_change'] = df['distances'].diff()\n",
    "# # df['change_rate'] = np.abs(df['elev_change'] / df['dist_change'])\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import splrep, splev\n",
    "\n",
    "# #pick a random one to examine\n",
    "# #linkid = int(abnormal_links.loc[new,'linkid'].sample(1).item())\n",
    "# linkid = links.loc[still_bad,'linkid'].sample(1).item()\n",
    "# #linkid = 53107\n",
    "\n",
    "# #linkid = 28303#44061\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# links.loc[links.index==linkid,['up_grade','max_grade','min_grade','new_up_grade','down_grade','new_down_grade']].squeeze()\n",
    "# links.loc[links.index==linkid,['up_grade','max_grade','min_grade','new_up_grade','down_grade','new_down_grade']].squeeze()\n",
    "# links.loc[links.index==linkid,['up_grade','max_grade','min_grade','new_up_grade','down_grade','new_down_grade']].squeeze()\n",
    "# #title\n",
    "# road_name = links.loc[links.index==linkid,'name'].item()\n",
    "\n",
    "# #ax1 elements\n",
    "# x = np.array(item['distances'])\n",
    "# y = np.array(item['elevations'])\n",
    "# new_y = np.array(lidar_sampled[linkid])\n",
    "\n",
    "# #ax2 elements\n",
    "# grade_x = np.array(range(0,len(x) - 1))\n",
    "# grade_delta = np.diff(y) / 10 * 100\n",
    "# lidar_delta = np.diff(new_y) / 10 * 100\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(9,3))\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# ax1.plot(x, y, 'o', label='Original Data')\n",
    "# ax1.plot(x, new_y, 'x',label='Resampled with Lidar')\n",
    "# ax1.grid(True,linestyle='-.')\n",
    "\n",
    "# #find min\n",
    "# y_min = np.min([y.min(),new_y.min()])\n",
    "# y_max = np.max([y.max(),new_y.max()])\n",
    "\n",
    "# ax1.set_xlim(0,np.ceil(x.max() / 10) * 10)\n",
    "# ax1.set_ylim(np.floor(y_min/10)*10,np.ceil(y_max/10)*10)\n",
    "# ax1.set_box_aspect(1)\n",
    "\n",
    "# #ax1.set_title(f'{road_name} (Linkid:{linkid}) Veritcal Cross-Section')\n",
    "# ax1.set_xlabel('Distance (m)')\n",
    "# ax1.set_ylabel('Elevation (m)')\n",
    "# ax1.legend()\n",
    "\n",
    "# ax2.plot(grade_x, grade_delta, 'o', label='Original Grade')\n",
    "# ax2.plot(grade_x, lidar_delta, 'x', label='lidar grade')\n",
    "\n",
    "\n",
    "# ax2.set_xlabel('Distance (m)')\n",
    "# ax2.set_ylabel('Grade %')\n",
    "# ax2.set_box_aspect(1)\n",
    "# ax2.legend()\n",
    "\n",
    "# fig.suptitle(f'{road_name} (Linkid:{linkid})')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Set ticks\n",
    "# #plt.xlim(0,x.max())\n",
    "# #plt.ylim()\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# #plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "\n",
    "# #turn item into a dataframe\n",
    "# #df = pd.DataFrame.from_dict(item,orient='columns')\n",
    "\n",
    "# # df['elev_change'] = df['elevations'].diff()\n",
    "# # df['dist_change'] = df['distances'].diff()\n",
    "# # df['change_rate'] = np.abs(df['elev_change'] / df['dist_change'])prev = abnormal_links.shape[0]\n",
    "# fixed = ((links['new_max_grade'] <= threshold) & (links['new_min_grade'] <= threshold))\n",
    "# still_bad = ((links['new_max_grade'] > threshold) & (links['new_min_grade'] > threshold))\n",
    "# print(f'{fixed.sum()} / {prev} abnormal links fixed')\n",
    "# print(f'{still_bad.sum()} are still abnormal')\n",
    "# print(f'{prev-fixed.sum()-still_bad.sum()} did not overlap with a bridge tif')\n",
    "# prev = abnormal_links.shape[0]\n",
    "# fixed = ((links['new_max_grade'] <= threshold) & (links['new_min_grade'] <= threshold))\n",
    "# still_bad = ((links['new_max_grade'] > threshold) & (links['new_min_grade'] > threshold))\n",
    "# print(f'{fixed.sum()} / {prev} abnormal links fixed')\n",
    "# print(f'{still_bad.sum()} are still abnormal')\n",
    "# print(f'{prev-fixed.sum()-still_bad.sum()} did not overlap with a bridge tif')links.loc[links['new_min_grade'].isna(),'new_min_grade'] = (links['new_minrise_m'] / links.length * 100).round(1)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import splrep, splev\n",
    "\n",
    "# linkid = 28303#44061\n",
    "# item = interpolated_points_dict[linkid]\n",
    "\n",
    "# x = item['distances']\n",
    "# y = item['elevations']\n",
    "# new_y = new[linkid]\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# plt.plot(x, y, 'o', label='Original Data')\n",
    "# plt.plot(x, new_y, 'o',label='Resampled with Lidar')\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# #plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "# #plt.title('10th Street Northwest (westward direction, tech to midtown) Veritcal Cross-Section')\n",
    "# plt.xlabel('Distance (m)')\n",
    "# plt.ylabel('Elevation (m)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# #turn item into a dataframe\n",
    "# #df = pd.DataFrame.from_dict(item,orient='columns')\n",
    "\n",
    "# # df['elev_change'] = df['elevations'].diff()\n",
    "# # df['dist_change'] = df['distances'].diff()\n",
    "# # df['change_rate'] = np.abs(df['elev_change'] / df['dist_change'])\n",
    "# ### Based on Haobing's paper\n",
    "# Spline fitting function\n",
    "# x as linear distance and y as elevation\n",
    "\n",
    "# current issue is that segments are not long enough as is, bridges need to extend forwards/backwards to have more data on the surrounding terrain. In the paper there are 3 km long segments. We can either try to linemerge lines to make them longer or add extensions\n",
    "\n",
    "# this is where the weighting prolly comes in\n",
    "\n",
    "# [Scipy Splrep](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splrep.html#scipy.interpolate.splrep)\n",
    "\n",
    "\n",
    "# # Assuming x, y, x_dropped, y_dropped, and spl are defined as in your code\n",
    "# x = np.array(df_copy['distances'])\n",
    "# y = np.array(df_copy['elevations'])\n",
    "\n",
    "# df_dropped = df.loc[~df.index.isin(df_copy.index)]\n",
    "\n",
    "# x_dropped = np.array(df_dropped['distances'])\n",
    "# y_dropped = np.array(df_dropped['elevations'])\n",
    "\n",
    "# #spline technique (we're not doing OLS i think because we don't have ground truth data?)\n",
    "# lambda_parameter = 3000 # 500 for local road and 3000 for highways\n",
    "# alpha = 99999990000 #paper used between 1000 and 10000\n",
    "# # i believe higher is smoother\n",
    "# spl = splrep(x,y,s=alpha)\n",
    "# y2 = splev(x,spl)\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# plt.plot(x, y, 'o', label='Original Data')\n",
    "# plt.plot(x, y2, label='Smoothed Curve')\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "# plt.title('10th Street Northwest (westward direction, tech to midtown) Veritcal Cross-Section')\n",
    "# plt.xlabel('Distance (m)')\n",
    "# plt.ylabel('Elevation (m)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# links_copy = links.copy()\n",
    "\n",
    "\n",
    "# # Assuming x, y, x_dropped, y_dropped, and spl are defined as in your code\n",
    "# x = np.array(df_copy['distances'])\n",
    "# y = np.array(df_copy['elevations'])\n",
    "\n",
    "# df_dropped = df.loc[~df.index.isin(df_copy.index)]\n",
    "\n",
    "# x_dropped = np.array(df_dropped['distances'])\n",
    "# y_dropped = np.array(df_dropped['elevations'])\n",
    "\n",
    "# #spline technique (we're not doing OLS i think because we don't have ground truth data?)\n",
    "# lambda_parameter = 3000 # 500 for local road and 3000 for highways\n",
    "# alpha = 99999990000 #paper used between 1000 and 10000\n",
    "# # i believe higher is smoother\n",
    "# spl = splrep(x,y,s=alpha)\n",
    "# y2 = splev(x,spl)\n",
    "\n",
    "# # Plot the original data and the smoothed curve\n",
    "# plt.plot(x, y, 'o', label='Original Data')\n",
    "# plt.plot(x, y2, label='Smoothed Curve')\n",
    "\n",
    "# # Plot the dropped points as 'x's\n",
    "# plt.scatter(x_dropped, y_dropped, marker='x', color='red', label='Dropped Points')\n",
    "\n",
    "# plt.title('10th Street Northwest (westward direction, tech to midtown) Veritcal Cross-Section')\n",
    "# plt.xlabel('Distance (m)')\n",
    "# plt.ylabel('Elevation (m)')\n",
    "# plt.legend()\n",
    "\n",
    "# links_copy['tunnel'].value_counts()\n",
    "\n",
    "# vals = ['yes','buidling_passage']\n",
    "# links_copy['tunnel'] = links_copy['tunnel'].isin(vals)\n",
    "# plt.show()\n",
    "\n",
    "# grade_cols = links_copy.columns.tolist()[-8:]\n",
    "# bridge_or_tunnel = (links_copy['tunnel']==True) | (links_copy['bridge']==True)\n",
    "# links_copy.loc[bridge_or_tunnel,['name','geometry']+grade_cols].explore()\n",
    "# links_copy.loc[bridge_or_tunnel,grade_cols] = 0\n",
    "# ## Side profile to show example (10th Street over the connector)\n",
    "# links.columns\n",
    "# linkid = 28303\n",
    "\n",
    "# street_name = links.at[linkid,'name']\n",
    "# distances = interpolated_points_dict[linkid]['distances']\n",
    "# elevations = interpolated_points_dict[linkid]['elevations']\n",
    "# geometries = interpolated_points_dict[linkid]['geometry']\n",
    "\n",
    "# plt.scatter(distances,elevations)\n",
    "# plt.title(street_name)\n",
    "# plt.xlabel('Distance (m)')\n",
    "# plt.ylabel('Elevation (m)')\n",
    "# import folium\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import LineString\n",
    "# import matplotlib.pyplot as plt\n",
    "# import base64\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Replace 'linkid' with your unique identifier for the road segment\n",
    "# linkid = 28303\n",
    "\n",
    "# # Extracting relevant data\n",
    "# street_name = links.at[linkid,'name']\n",
    "# distances = interpolated_points_dict[linkid]['distances']\n",
    "# elevations = interpolated_points_dict[linkid]['elevations']\n",
    "# geometries = interpolated_points_dict[linkid]['geometry']\n",
    "\n",
    "# # Creating a GeoDataFrame for the road segment\n",
    "# road_geometry = LineString(geometries)\n",
    "# road_gdf = gpd.GeoDataFrame(geometry=[road_geometry],crs=src.crs)\n",
    "# road_gdf.to_crs('epsg:4326',inplace=True)\n",
    "\n",
    "# # Create a Folium map centered on the road segment\n",
    "# map_center = [road_gdf.centroid.y, road_gdf.centroid.x]\n",
    "# mymap = folium.Map(location=map_center, zoom_start=15)\n",
    "\n",
    "# # Save the scatter plot as an image\n",
    "# scatter_plot_filename = 'scatter_plot.png'\n",
    "# plt.scatter(distances, elevations, color='red', marker='o', label='Cross-section')\n",
    "# plt.title(street_name)\n",
    "# plt.xlabel('Distance (m)')\n",
    "# plt.ylabel('Elevation (m)')\n",
    "# plt.legend()\n",
    "# plt.savefig(scatter_plot_filename)\n",
    "# plt.close()\n",
    "\n",
    "# # Encode the image to base64\n",
    "# with open(scatter_plot_filename, 'rb') as img_file:\n",
    "#     encoded_image = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "# # Add the scatter plot image to the map popup\n",
    "# popup_content = \"\"\"\n",
    "#     <h4>{}</h4>\n",
    "#     <img src=\"data:image/png;base64,{}\" alt=\"Scatter Plot\" width=\"400px\">\n",
    "# \"\"\".format(street_name, encoded_image)\n",
    "\n",
    "# popup = folium.Popup(html=popup_content, max_width=500)\n",
    "# folium.GeoJson(road_gdf,popup=popup,lazy=True).add_to(mymap)\n",
    "\n",
    "# # Save the Folium map as an HTML file\n",
    "# #map_filename = 'road_map_with_scatter_plot.html'\n",
    "# #mymap.save(map_filename)\n",
    "\n",
    "# # Display the Folium map\n",
    "# mymap\n",
    "\n",
    "# ## Set to zero for now (we'll update these once the rest of the paper is intergrated)\n",
    "# links.columns\n",
    "# links.columns\n",
    "# # #example point grade calculation for finding rapid changes\n",
    "# # linkid = 40\n",
    "\n",
    "# # point1 = Point(interpolated_points_dict[linkid]['geometry'][0])\n",
    "# # point2 = Point(interpolated_points_dict[linkid]['geometry'][1])\n",
    "# # point1.distance(point2)\n",
    "\n",
    "# # elev1 = interpolated_points_dict[linkid]['elevations'][0]\n",
    "# # elev2 = interpolated_points_dict[linkid]['elevations'][1]\n",
    "\n",
    "# # grade = (elev2-elev1)/(point1.distance(point2))\n",
    "# # grade\n",
    "\n",
    "# # calculates point grade (deprecated)\n",
    "# # item = interpolated_points_dict[linkid]\n",
    "# # grades = []\n",
    "\n",
    "# # for x in range(0,len(item['elevations'])-1):\n",
    "# #     point1 = Point(item['geometry'][x])\n",
    "# #     point2 = Point(item['geometry'][x+1])\n",
    "\n",
    "# #     elev1 = item['elevations'][x]\n",
    "# #     elev2 = item['elevations'][x+1]\n",
    "\n",
    "# #     grade = (elev2-elev1)/(point1.distance(point2))\n",
    "# #     grades.append(grade)\n",
    "\n",
    "# # grades = np.asarray(grades)\n",
    "# # grades[grades>0].mean()\n",
    "\n",
    "# # # calculate average point grade\n",
    "# # # 3 mins\n",
    "\n",
    "# # grades_dict = {}\n",
    "\n",
    "# # for key, item in tqdm(interpolated_points_dict.items(),total=len(interpolated_points_dict)): \n",
    "# #     grades = []\n",
    "\n",
    "\n",
    "# #     for x in range(0,len(item['elevations'])-1):\n",
    "# #         point1 = Point(item['geometry'][x])\n",
    "# #         point2 = Point(item['geometry'][x+1])\n",
    "\n",
    "# #         elev1 = item['elevations'][x]\n",
    "# #         elev2 = item['elevations'][x+1]\n",
    "\n",
    "# #         grade = (elev2-elev1)/(point1.distance(point2))\n",
    "# #         grades.append(grade)\n",
    "\n",
    "# #     grades = np.asarray(grades)\n",
    "# #     grades_dict[key] = grades[grades>0].mean()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
