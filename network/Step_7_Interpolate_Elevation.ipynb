{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate elevation data from the spline fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import nearest_points, LineString, Point\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code_directory': 'C:/Users/tpassmore6/Documents/GitHub/BikewaySimDev',\n",
       " 'project_directory': 'D:/PROJECTS/GDOT',\n",
       " 'studyarea': 'D:/RAW/Study_Areas/itp.gpkg',\n",
       " 'geofabrik_fp': 'D:/RAW/OSM/Geofabrik_GA_Extracts',\n",
       " 'here_fp': 'D:/RAW/HERE/Streets.shp',\n",
       " 'abm_fp': 'D:/RAW/ARC/rtp_amd6_2030_network.gdb',\n",
       " 'projected_crs_epsg': 'epsg:2240',\n",
       " 'geofabrik_year': '2023',\n",
       " 'usgs': 'D:/RAW/USGS',\n",
       " 'maptilerapikey': 'rJ9yamTFh9tXOj4PAxqv'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "network_fp = Path(config['project_directory']) / 'OSM_Download'\n",
    "export_fp = Path(config['project_directory']) / 'Network'\n",
    "if network_fp.exists() == False:\n",
    "    network_fp.mkdir()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for storing the interpolated points with sampled elevation data\n",
    "import pickle\n",
    "with (export_fp/'spline_fit_elevation.pkl').open('rb') as fh:\n",
    "    interpolated_points_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_links = gpd.read_file(network_fp / f\"osm_{config['geofabrik_year']}.gpkg\",layer=\"raw\")\n",
    "#set the osmid as the index\n",
    "raw_links.set_index('osmid',inplace=True)\n",
    "#raw_links = raw_links[['oneway','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(export_fp/'networks.gpkg',layer='osm_links')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_crs = links.crs\n",
    "\n",
    "tiff_links = list((Path(config['usgs']) / 'dem_files').glob('*.tif'))\n",
    "\n",
    "#open the first one to just get the crs\n",
    "src = rasterio.open(tiff_links[0])\n",
    "dem_crs = src.crs\n",
    "src.close()\n",
    "\n",
    "links.to_crs(dem_crs,inplace=True)\n",
    "#nodes.to_crs(dem_crs,inplace=True)\n",
    "raw_links.to_crs(dem_crs,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #select a link and try it\n",
    "# linkid = 637636161\n",
    "# link = links[links['osmid']==linkid].iloc[[0],:]\n",
    "\n",
    "# #get osm line\n",
    "# line = raw_links.loc[linkid,'geometry']#interpolated_points_dict[linkid]['geometry']\n",
    "# line = np.array(line.coords)\n",
    "\n",
    "# #get geo of start and end\n",
    "# #or just use the included line to reduce memory?\n",
    "# pointA = nodes[nodes['osm_N']==link['osm_A'].item()]\n",
    "# pointB = nodes[nodes['osm_N']==link['osm_B'].item()]\n",
    "# print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the coordinates of two additional points\n",
    "# point1 = (pointA.geometry.item().x,pointA.geometry.item().y)\n",
    "# point2 = (pointB.geometry.item().x,pointB.geometry.item().y)\n",
    "# print(point1,point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the GeoDataFrame and the additional points\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # plot the full link\n",
    "# ax.plot(line[:,0],line[:,1], color='gray', label='full osm')\n",
    "\n",
    "# link.plot(ax=ax, color='blue', label='osm segemnt')\n",
    "# ax.plot(point1[0], point1[1], marker='o', color='red', markersize=10, label='Point 1')\n",
    "# ax.plot(point2[0], point2[1], marker='o', color='green', markersize=10, label='Point 2')\n",
    "\n",
    "# # Add labels to the additional points\n",
    "# #ax.text(point1[0], point1[1], 'Point 1', fontsize=12, ha='right')\n",
    "# #ax.text(point2[0], point2[1], 'Point 2', fontsize=12, ha='right')\n",
    "\n",
    "# # Add legend and labels\n",
    "# ax.legend()\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "# ax.set_title('GeoDataFrame with Additional Points')\n",
    "\n",
    "# # Manually set limits to create a square aspect ratio\n",
    "# min_x, max_x = ax.get_xlim()\n",
    "# min_y, max_y = ax.get_ylim()\n",
    "# width = max(max_x - min_x, max_y - min_y)\n",
    "# center_x = (min_x + max_x) / 2\n",
    "# center_y = (min_y + max_y) / 2\n",
    "# ax.set_xlim(center_x - width / 2, center_x + width / 2)\n",
    "# ax.set_ylim(center_y - width / 2, center_y + width / 2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point1_geo = Point(point1)\n",
    "# point2_geo = Point(point2)\n",
    "# line_geo = LineString(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distance of the shapepoint on each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely import line_locate_point, equals_exact\n",
    "\n",
    "# point1_dist = line_locate_point(LineString(line),Point(point1))\n",
    "# point2_dist = line_locate_point(LineString(line),Point(point2))\n",
    "\n",
    "# #scenario 1: last point intersects with early point on a line (line loops into itself)\n",
    "# #so trim off the points before point 1\n",
    "# if point1_dist >= point2_dist:\n",
    "#     for first_i, point in enumerate(line):\n",
    "#         if equals_exact(Point(point),Point(point1),tolerance=1):\n",
    "#             break\n",
    "#     new_line = line[first_i+1:]\n",
    "#     point2_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "\n",
    "# #scenario 2: first point intersect with last point on a line\n",
    "# #so trim off the point at the end of the line\n",
    "# if point1_dist >= point2_dist:\n",
    "#     new_line = line[0:-1]\n",
    "#     point1_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "#     point2_dist = line_locate_point(LineString(line),Point(point1))\n",
    "    \n",
    "# if point1_dist >= point2_dist:\n",
    "#     print('error')\n",
    "# else:\n",
    "#     print(np.round(point1_dist),np.round(point2_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate distance on line\n",
    "For each link, we need the distance along the line of the start and end point to properly input into the fitted spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For polygons where a way intersects with itself, we may need some more advanced logic utilizing the node sequence. \n",
    "\n",
    "If we have the node sequence, start with the first node given, and see if the second node can be found after that. If it can't then we know we need to reverse the direction, but can we think of an example where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import line_locate_point, equals_exact\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from itertools import product\n",
    "\n",
    "interpolated_distance_dict = {}\n",
    "\n",
    "for idx, row in links.iterrows():\n",
    "    \n",
    "    #network link attributes\n",
    "    osmid = row['osmid']\n",
    "    a = row['osm_A']\n",
    "    b = row['osm_B']\n",
    "    network_line = np.array(row['geometry'].coords)\n",
    "    point1 = network_line[0]\n",
    "    point2 = network_line[-1]\n",
    "\n",
    "    #get raw osm attributes\n",
    "    line = np.array(raw_links.loc[osmid,'geometry'].coords)\n",
    "    points = [Point(x) for x in line]\n",
    "    points = gpd.GeoSeries(points)\n",
    "    distances = points.distance(points.shift(1)).cumsum().tolist()\n",
    "    distances[0] = 0\n",
    "    node_list = json.loads(raw_links.loc[osmid,'all_tags'])['@way_nodes']\n",
    "    a_idx = node_list.index(a)\n",
    "    b_idx = node_list.index(b)\n",
    "\n",
    "    #polygon check\n",
    "    poly_check = len(list(polygonize(unary_union(LineString(line))))) #> 0\n",
    "    poly_check_network = len(list(polygonize(unary_union(LineString(network_line))))) #> 0\n",
    "\n",
    "    method = 'none'\n",
    "    reverse_geometry = False\n",
    "    \n",
    "    # scenario 1: simple line segment no loops\n",
    "    if (poly_check == 0) & (poly_check_network == 0) & (a != b):\n",
    "        method = 'simple'\n",
    "        # step 1: check if network line is in the same direction as loop\n",
    "        if (a_idx > b_idx):    \n",
    "            reverse_geometry = True\n",
    "            a = row['osm_B']\n",
    "            b = row['osm_A']\n",
    "            a_idx = node_list.index(a)\n",
    "            b_idx = node_list.index(b)\n",
    "\n",
    "        # step 2: get distance of start and end point along the line\n",
    "        #point1_dist = line_locate_point(LineString(line),Point(point1))\n",
    "        #point2_dist = line_locate_point(LineString(line),Point(point2))\n",
    "        network_dist = distances[a_idx:b_idx+1]\n",
    "        point1_dist = network_dist[0]\n",
    "        point2_dist = network_dist[-1]\n",
    "\n",
    "        # step 3: check to see if distance matches the network geometry\n",
    "        difference = point2_dist - point1_dist\n",
    "        distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "        if distance_check == False:\n",
    "            print('error')\n",
    "\n",
    "        segment = [point1_dist,point2_dist]\n",
    "    \n",
    "    # scenario 2: network segment is not a loop but the line is\n",
    "    elif (poly_check > 0) & (poly_check_network == 0) & (a != b):\n",
    "        method = 'simple loop'\n",
    "\n",
    "        a_s = [idx for idx, val in enumerate(node_list) if val == a]\n",
    "        b_s = [idx for idx, val in enumerate(node_list) if val == b]\n",
    "\n",
    "        #get all possible combinations of A/B\n",
    "        combinations = list(product(a_s,b_s))\n",
    "        for a_idx, b_idx in combinations:\n",
    "            # step 1: see if network line direction matches line\n",
    "            if (a_idx > b_idx):\n",
    "                reverse_geometry = True\n",
    "                # a = row['osm_B']\n",
    "                # b = row['osm_A']\n",
    "                # a_idx = node_list.index(a)\n",
    "                # b_idx = node_list.index(b)\n",
    "                a_idx, b_idx = b_idx, a_idx\n",
    "\n",
    "            # step 2: get distance of start and end point along the line\n",
    "            # start = node_list.index(a)\n",
    "            # end = node_list[start+1:].index(b) + start + 1\n",
    "            network_dist = distances[a_idx:b_idx+1]\n",
    "            point1_dist = network_dist[0]\n",
    "            point2_dist = network_dist[-1]\n",
    "\n",
    "            # step 3: check to see if distance matches the network geometry\n",
    "            difference = point2_dist - point1_dist\n",
    "            distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "            \n",
    "            segment = [point1_dist,point2_dist]\n",
    "\n",
    "            if distance_check == True:\n",
    "                break\n",
    "\n",
    "        # step 4: if it doesn't then it is likely that the network segment crosses the loop\n",
    "        # we'll need multiple segments in that case\n",
    "        if distance_check == False:\n",
    "            method = 'complex loop'\n",
    "\n",
    "            #reset the reversed geometry bit\n",
    "            reverse_geometry = False\n",
    "            a = row['osm_A']\n",
    "            b = row['osm_B']\n",
    "            a_idx = node_list.index(a)\n",
    "            b_idx = node_list.index(b)\n",
    "\n",
    "            # if the network line crosses the loop then b_idx will be larger\n",
    "            if a_idx < b_idx:\n",
    "                reverse_geometry = True\n",
    "                a = row['osm_B']\n",
    "                b = row['osm_A']\n",
    "                a_idx = node_list.index(a)\n",
    "                b_idx = node_list.index(b)\n",
    "\n",
    "            # step 5: get the two segments\n",
    "            first_segment = [0,distances[b_idx]]\n",
    "            second_segment = [distances[a_idx],distances[-1]]\n",
    "\n",
    "            # step 6: check distance\n",
    "            difference = second_segment[-1] - second_segment[0] + first_segment[1]\n",
    "            distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "\n",
    "            # if distance_check == False:\n",
    "            #     print('error')\n",
    "            segment = [first_segment,second_segment]\n",
    "\n",
    "    else:\n",
    "        method = 'none'\n",
    "        segment = 999\n",
    "        distance_check = False\n",
    "    \n",
    "    #finaly assemble the dict\n",
    "    interpolated_distance_dict[idx] = {\n",
    "    'method': method,\n",
    "    'segment': segment,\n",
    "    'reverse_geometry': reverse_geometry,\n",
    "    'distance_check': distance_check,\n",
    "    'poly_check': poly_check\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(interpolated_distance_dict,orient='index')\n",
    "interpolated = pd.merge(links,df,left_index=True,right_index=True)\n",
    "\n",
    "#drop loops\n",
    "interpolated = interpolated[interpolated['method']!='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo create a checkpoint here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export['segment'] = export['segment'].astype(str)\n",
    "#export['length_m'] = export.length\n",
    "#export.to_file(Path.home()/'Downloads/scratch.gpkg',layer='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spline fit\n",
    "We need elevation data between the two points to interpolate an elevation profile for the smaller links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tpassmore6\\Documents\\GitHub\\BikewaySimDev\\network\\src\\elevation_tools.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ascent_grade = np.round(ascent / total_distance * 100,2)\n",
      "c:\\Users\\tpassmore6\\Documents\\GitHub\\BikewaySimDev\\network\\src\\elevation_tools.py:81: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  descent_grade = np.round(descent / total_distance * 100,2)\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import splrep, splev, BSpline\n",
    "import src.elevation_tools as elevation_tools\n",
    "\n",
    "interpolate_dist_m = 1\n",
    "new_elevations_dict = {}\n",
    "spline_or_nah = []\n",
    "\n",
    "for idx, row in interpolated.iterrows():\n",
    "    #get ids\n",
    "    osm_linkid = row['osm_linkid']\n",
    "    osmid = row['osmid']\n",
    "\n",
    "    #get osm elevation\n",
    "    item = interpolated_points_dict[osmid]\n",
    "\n",
    "    #retrieve the fitted spline if it exists\n",
    "    spline = item.get('spline',0)\n",
    "    \n",
    "    #get segments\n",
    "    segment = row['segment']\n",
    "    \n",
    "    #if no spline, do linear interpolatation\n",
    "    if spline == 0:\n",
    "        new_xs = item['distances']\n",
    "        new_elevations = item['elevations']\n",
    "        spline_or_nah.append(idx)\n",
    "\n",
    "    elif isinstance(segment[0],list):\n",
    "        #get x sequence\n",
    "        new_xs_segment1 = np.arange(int(segment[0][0]),int(segment[0][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_xs_segment2 = np.arange(int(segment[1][0]),int(segment[1][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "\n",
    "        #get new elevations\n",
    "        new_elevations_segment1 = splev(new_xs_segment1,spline)\n",
    "        new_elevations_segment2 = splev(new_xs_segment2,spline)\n",
    "\n",
    "        #combine\n",
    "        new_xs = np.arange(0,len(new_xs_segment1)+len(new_xs_segment2))\n",
    "        new_elevations = np.hstack([new_elevations_segment2,new_elevations_segment1])\n",
    "\n",
    "    else:\n",
    "        #get new elevation values\n",
    "        new_xs = np.arange(int(segment[0]),int(segment[1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_elevations = splev(new_xs, spline)\n",
    "        #recalculate elevations stats\n",
    "        #TODO if wanting to seperate grades by section use the elevation_stats function\n",
    "    \n",
    "    new_elevations_dict[idx] = elevation_tools.simple_elevation_stats(new_xs, new_elevations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated.loc[spline_or_nah,'spline_fit'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(new_elevations_dict,orient='index')\n",
    "elevations_added = pd.merge(interpolated,df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added['segment'] = elevations_added['segment'].astype(str)\n",
    "elevations_added.to_file(export_fp/'elevation.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import splrep, splev, BSpline\n",
    "\n",
    "# # case 1: only one segment to deal with\n",
    "# osm_linkid = 1125605250\n",
    "# osmid = 751119047\n",
    "\n",
    "# row = export[export['osm_linkid']==osm_linkid].squeeze()\n",
    "\n",
    "# #get osm elevation\n",
    "# item = interpolated_points_dict[osmid]\n",
    "\n",
    "# #retrieve the fitted spline\n",
    "# spline = item['spline']\n",
    "\n",
    "# #get segments\n",
    "# segment = row['segment']\n",
    "\n",
    "# #get x sequence\n",
    "# new_xs_segment1 = np.arange(int(segment[0][0]),int(segment[0][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "# new_xs_segment2 = np.arange(int(segment[1][0]),int(segment[1][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "\n",
    "# #get new elevations\n",
    "# new_elevations_segment1 = splev(new_xs_segment1,spline)\n",
    "# new_elevations_segment2 = splev(new_xs_segment2,spline)\n",
    "\n",
    "# #combine\n",
    "# new_xs = np.arange(0,len(new_xs_segment1)+len(new_xs_segment2))\n",
    "# new_elevations = np.hstack([new_elevations_segment2,new_elevations_segment1])\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs_segment1,new_elevations_segment1,'-.')\n",
    "# ax.plot(new_xs_segment2,new_elevations_segment2,'-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use fitted spline to from dict to create new values\n",
    "\n",
    "# item = interpolated_points_dict[osmid]\n",
    "# spline = interpolated_points_dict[osmid]['spline']\n",
    "\n",
    "# interpolate_dist_m = 1\n",
    "# new_xs = np.arange(int(point1_dist),int(point2_dist)+interpolate_dist_m,interpolate_dist_m)\n",
    "# new_elevations = splev(new_xs, spline)\n",
    "\n",
    "#new_grades = pd.Series(new_elevations).diff() #/ interpolate_dist_m * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import src.elevation_tools as elevation_tools\n",
    "# reload(elevation_tools)\n",
    "# elevation_tools.simple_elevation_stats(new_xs, new_elevations)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs,new_elevations,'-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid\n",
    "# item = interpolated_points_dict[linkid]\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import splrep, splev, BSpline\n",
    "\n",
    "# spline = interpolated_points_dict[linkid]['spline']\n",
    "\n",
    "# new_xs = np.arange(int(point1_dist),int(point2_dist)+10,10)\n",
    "# new_ys = splev(new_xs, spline)\n",
    "# new_ys\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs,new_ys,'-.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add elevation data to links (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade_cats = {}\n",
    "\n",
    "# for linkid, item in tqdm(interpolated_points_dict.items()):     \n",
    "\n",
    "#     outputs = elevation_tools.elevation_stats(item['distances'],item['smoothed'],grade_threshold)\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         'distance_deltas':outputs['distance_deltas'],\n",
    "#         'segment_grades':outputs['segment_grades']\n",
    "#         })\n",
    "#     #create bins (broach 2012 ones)\n",
    "#     #'(-inf,-6]','(-6,-4]','(-4,-2]','(-2,0]',\n",
    "#     #-np.inf,-6,-4,-2,\n",
    "#     bins = [-1,2,4,6,10,15,np.inf]\n",
    "#     names = ['(0,2]','(2,4]','(4,6]','(6,10]','(10,15]','(15,inf]']\n",
    "#     df['grade_category'] = pd.cut(df['segment_grades'].abs(), bins, labels = names)\n",
    "\n",
    "#     #determine if up or down (doesn't matter if flat)\n",
    "#     df.loc[df['segment_grades'] >= 0,'ascent_or_descent'] = 'ascent'\n",
    "#     df.loc[df['segment_grades'] < 0,'ascent_or_descent'] = 'descent'\n",
    "\n",
    "#     # how many meters at each grade category?\n",
    "#     test = df.groupby(['grade_category','ascent_or_descent'],observed=False)['distance_deltas'].sum().round(0)\n",
    "#     test = pd.DataFrame(test).transpose()\n",
    "#     test.index = [linkid]\n",
    "#     grade_cats[linkid] = {\n",
    "#         'ascent_m': outputs['ascent'],\n",
    "#         'descent_m': outputs['descent'],\n",
    "#         'ascent_grade': outputs['ascent_grade'],\n",
    "#         'descent_grade': outputs['descent_grade']\n",
    "#     }\n",
    "#     grade_cats[linkid].update(\n",
    "#         test.to_dict(orient='records')[0]\n",
    "#     )\n",
    "    \n",
    "# #.items())#.reseorient='t_index()#.pivot(\n",
    "#     # columns=['grade_category','up'],\n",
    "#     # values='distance_deltas'\n",
    "#     # )\n",
    "# #grade_cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
