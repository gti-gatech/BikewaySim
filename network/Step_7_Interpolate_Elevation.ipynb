{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate elevation data from the spline fit\n",
    "(combine this with 6 since we cleaned up the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import nearest_points, LineString, Point\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from scipy.interpolate import splrep, splev, BSpline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import elevation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for storing the interpolated points with sampled elevation data\n",
    "import pickle\n",
    "with (config['network_fp']/'spline_fit_elevation.pkl').open('rb') as fh:\n",
    "    interpolated_points_dict = pickle.load(fh)\n",
    "\n",
    "links = gpd.read_file(config['osmdwnld_fp']/'osm.gpkg',layer='edges')[['linkid','osmid','start_dist','end_dist','geometry']]\n",
    "links['start_dist'] = (links['start_dist'] / 3.28084).round(2) # convert to meters\n",
    "links['end_dist'] = (links['end_dist'] / 3.28084).round(2)\n",
    "\n",
    "#cross reference\n",
    "links = links[links['osmid'].isin(interpolated_points_dict.keys())]\n",
    "\n",
    "#reproject network to DEM crs\n",
    "with (config['network_fp']/'dem_crs.txt').open('r') as fh:\n",
    "    dem_crs = fh.read()\n",
    "links.to_crs(dem_crs,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[links['osmid']==155487818].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine some spline fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = interpolated_points_dict[155487818]\n",
    "\n",
    "test['spline']\n",
    "distance = test['distances']\n",
    "elevation = test['elevations']\n",
    "distance0 = np.array(list(range(0,distance[-1]+1,1)))\n",
    "# smoothed_elevations = splev(distance,test['spline'])\n",
    "smoothed_elevations = np.interp(distance0, distance, elevation)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the elevation profile\n",
    "ax.plot(distance, elevation, label='Elevation profile')\n",
    "ax.plot(distance0, smoothed_elevations, label='Smoothed Elevations')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Distance (m)')\n",
    "ax.set_ylabel('Elevation (m)')\n",
    "\n",
    "# Ensure no vertical exaggeration by setting equal scale\n",
    "# Here, the aspect ratio is based on the maximum range of the data\n",
    "aspect_ratio = (max(distance) - min(distance)) / (max(elevation) - min(elevation))\n",
    "ax.set_aspect(aspect_ratio)\n",
    "\n",
    "# Add a grid and legend\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# elevation_tools.elevation_stats(distance,elevation,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #select a link and try it\n",
    "# linkid = 637636161\n",
    "# link = links[links['osmid']==linkid].iloc[[0],:]\n",
    "\n",
    "# #get osm line\n",
    "# line = raw_links.loc[linkid,'geometry']#interpolated_points_dict[linkid]['geometry']\n",
    "# line = np.array(line.coords)\n",
    "\n",
    "# #get geo of start and end\n",
    "# #or just use the included line to reduce memory?\n",
    "# pointA = nodes[nodes['osm_N']==link['osm_A'].item()]\n",
    "# pointB = nodes[nodes['osm_N']==link['osm_B'].item()]\n",
    "# print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the coordinates of two additional points\n",
    "# point1 = (pointA.geometry.item().x,pointA.geometry.item().y)\n",
    "# point2 = (pointB.geometry.item().x,pointB.geometry.item().y)\n",
    "# print(point1,point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the GeoDataFrame and the additional points\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # plot the full link\n",
    "# ax.plot(line[:,0],line[:,1], color='gray', label='full osm')\n",
    "\n",
    "# link.plot(ax=ax, color='blue', label='osm segemnt')\n",
    "# ax.plot(point1[0], point1[1], marker='o', color='red', markersize=10, label='Point 1')\n",
    "# ax.plot(point2[0], point2[1], marker='o', color='green', markersize=10, label='Point 2')\n",
    "\n",
    "# # Add labels to the additional points\n",
    "# #ax.text(point1[0], point1[1], 'Point 1', fontsize=12, ha='right')\n",
    "# #ax.text(point2[0], point2[1], 'Point 2', fontsize=12, ha='right')\n",
    "\n",
    "# # Add legend and labels\n",
    "# ax.legend()\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "# ax.set_title('GeoDataFrame with Additional Points')\n",
    "\n",
    "# # Manually set limits to create a square aspect ratio\n",
    "# min_x, max_x = ax.get_xlim()\n",
    "# min_y, max_y = ax.get_ylim()\n",
    "# width = max(max_x - min_x, max_y - min_y)\n",
    "# center_x = (min_x + max_x) / 2\n",
    "# center_y = (min_y + max_y) / 2\n",
    "# ax.set_xlim(center_x - width / 2, center_x + width / 2)\n",
    "# ax.set_ylim(center_y - width / 2, center_y + width / 2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point1_geo = Point(point1)\n",
    "# point2_geo = Point(point2)\n",
    "# line_geo = LineString(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distance of the shapepoint on each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely import line_locate_point, equals_exact\n",
    "\n",
    "# point1_dist = line_locate_point(LineString(line),Point(point1))\n",
    "# point2_dist = line_locate_point(LineString(line),Point(point2))\n",
    "\n",
    "# #scenario 1: last point intersects with early point on a line (line loops into itself)\n",
    "# #so trim off the points before point 1\n",
    "# if point1_dist >= point2_dist:\n",
    "#     for first_i, point in enumerate(line):\n",
    "#         if equals_exact(Point(point),Point(point1),tolerance=1):\n",
    "#             break\n",
    "#     new_line = line[first_i+1:]\n",
    "#     point2_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "\n",
    "# #scenario 2: first point intersect with last point on a line\n",
    "# #so trim off the point at the end of the line\n",
    "# if point1_dist >= point2_dist:\n",
    "#     new_line = line[0:-1]\n",
    "#     point1_dist = line_locate_point(LineString(new_line),Point(point1))\n",
    "#     point2_dist = line_locate_point(LineString(line),Point(point1))\n",
    "    \n",
    "# if point1_dist >= point2_dist:\n",
    "#     print('error')\n",
    "# else:\n",
    "#     print(np.round(point1_dist),np.round(point2_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate distance on line\n",
    "For each network link, use the pre-calculated start_dist and end_dist to interpolate elevation data from the fitted spline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a more complicated case that we won't bother with\n",
    "links[links['start_dist']>links['end_dist']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = []\n",
    "# from tqdm import tqdm\n",
    "# for idx, row in tqdm(links.iterrows(),total=links.shape[0]):\n",
    "#     osmid = row['osmid']\n",
    "#     item = interpolated_points_dict.get(osmid,False)\n",
    "#     #retrieve the fitted spline if it exists\n",
    "#     spline = item.get('spline',0)\n",
    "#     if isinstance(spline,int):\n",
    "#         c.append(idx)\n",
    "# links.loc[c[2300]]\n",
    "# interpolated_points_dict.get(560689146,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUG make sure we are not extrapolating\n",
    "import math\n",
    "\n",
    "result = {}\n",
    "test = []\n",
    "for idx, row in tqdm(links.iterrows(),total=links.shape[0]):\n",
    "    osmid = row['osmid']\n",
    "    start_dist = row['start_dist']\n",
    "    end_dist = row['end_dist']\n",
    "    segment_length = row['geometry'].length # no need to convert to meters here\n",
    "\n",
    "    if start_dist > end_dist:\n",
    "        continue\n",
    "\n",
    "    #get osm distances and elevation\n",
    "    item = interpolated_points_dict.get(osmid,False)\n",
    "    if isinstance(item,bool):\n",
    "        print('no record for',idx)\n",
    "        continue\n",
    "    \n",
    "    #get the max osm_dist\n",
    "    osm_dist = item['distances'][-1]\n",
    "\n",
    "    #retrieve the fitted spline if it exists\n",
    "    spline = item.get('spline',0)\n",
    "\n",
    "    if isinstance(spline,int):\n",
    "        # # in these cases a spline wasn't fit to the data because there were\n",
    "        # # only three data points so just assign it the same data as the osm way\n",
    "        xs = item['distances']\n",
    "        # cond0 = (xs >= start_dist) & (xs <= end_dist)\n",
    "        # xs = xs[cond0]\n",
    "        ys = item['elevations']\n",
    "        if np.isnan(ys).any():\n",
    "            continue\n",
    "            # test.append(idx)\n",
    "        # ys = item['elevations'][cond0]\n",
    "        # #drop na\n",
    "        # cond1 = np.isnan(ys) == False\n",
    "        # xs = xs[cond1]\n",
    "        # ys = ys[cond1]\n",
    "        # if len(xs) <= 1:\n",
    "        #     test.append(idx)\n",
    "        #     continue\n",
    "        result[row['linkid']] = {'distances':xs,'elevations':ys}\n",
    "        continue\n",
    "\n",
    "    # normal case\n",
    "    if start_dist < end_dist:\n",
    "        #if the end dist is past the osm dist, use the osm dist\n",
    "        #this can happen if there's a rounding error\n",
    "        if end_dist > osm_dist:\n",
    "            end_dist = osm_dist\n",
    "        \n",
    "        # if the segment is less than 10 m, just use the first and last point for grade estimation\n",
    "        if segment_length < 10:\n",
    "            xs = [start_dist,end_dist]\n",
    "            ys = splev(xs,spline)\n",
    "        else:\n",
    "            #get x values from start_dist to end_dist every 10 m\n",
    "            xs = []\n",
    "            while start_dist < end_dist:\n",
    "                xs.append(start_dist)\n",
    "                start_dist += 10\n",
    "        \n",
    "        xs = np.array(xs)\n",
    "        # ys = splev(xs,spline)\n",
    "        #NOTE I was getting a spline fit that was giving ludicrous numbers when interpolating\n",
    "        # until I can fix that, using piecewise linear interpolation which should be okay\n",
    "        ys = np.interp(xs, item['distances'], item['elevations'])\n",
    "        #normalize xs so that it goes from 0 to end for the elevation stats function\n",
    "        xs = xs - xs[0]\n",
    "        result[row['linkid']] = {'distances':np.array(xs),'elevations':ys}\n",
    "    \n",
    "    # TODO applies to so few cases that i don't think it makes a lot of sense to bother just leave as na\n",
    "    # elif start_dist > end_dist:\n",
    "    #     # if segment is less than 10 meters\n",
    "    #     if math.abs(start_dist - end_dist) < 10:\n",
    "    #         xs0 = [0,end_dist]\n",
    "    #         ys0 = splev(xs0,spline)\n",
    "    #         xs1 = [start_dist,osm_dist]\n",
    "    #         ys1 = splev(xs1,spline)\n",
    "    #         result[row['linkid']] = {'distances':np.array(xs1+xs0),'elevations':np.hstack([segment_1_ys,segment_2_ys])}\n",
    "    #         continue\n",
    "        \n",
    "    #     # first segment goes from 0 m to end node\n",
    "    #     segment_1_dist = 0\n",
    "    #     segment_1 = []\n",
    "    #     while segment_1_dist < end_dist:\n",
    "    #         segment_1.append(segment_1_dist)\n",
    "    #         segment_1_dist += 10\n",
    "\n",
    "    #     # second segment goes from start node to end of osm way\n",
    "    #     segment_2_dist = start_dist\n",
    "    #     segment_2 = [segment_2_dist]\n",
    "    #     while segment_2_dist < osm_dist:\n",
    "    #         segment_2.append(segment_2_dist)\n",
    "    #         segment_2_dist += 10\n",
    "\n",
    "    #     xs = segment_2+segment_1\n",
    "    #     ys = splev(xs,spline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test)\n",
    "# interpolated_points_dict[links.loc[test[40],'osmid']]\n",
    "# links.loc[[test[1]]].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# links.loc[test].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(elevation_tools)\n",
    "# export into QGIS to examine\n",
    "export = {linkid:elevation_tools.simple_elevation_stats(item['distances'],item['elevations']) for linkid, item in result.items()}\n",
    "export = pd.DataFrame.from_dict(export,orient='index')\n",
    "\n",
    "df = pd.merge(links,export,left_on='linkid',right_index=True)\n",
    "df['ascent_ft'] = (df['ascent_m'] * 3.28084).round(0)\n",
    "df['descent_ft'] = (df['descent_m'] * 3.28084).round(0)\n",
    "df['max_elev'] = np.max(np.abs(df[['ascent_ft','descent_ft']].values),axis=1)\n",
    "df['max_grade'] = np.max(np.abs(df[['ascent_grade_%','descent_grade_%']].values),axis=1)\n",
    "df['descent_ft'] = df['descent_ft'].abs()\n",
    "df['descent_grade_%'] = df['descent_grade_%'].abs()\n",
    "gdf = gpd.GeoDataFrame(df,crs=dem_crs)\n",
    "gdf.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "print(gdf['max_grade'].isna().sum(),'nan grades')\n",
    "#remove nan grades, we'll fill them in the next one\n",
    "gdf = gdf[gdf['max_grade'].notna()]\n",
    "\n",
    "#fill in any nan values\n",
    "\n",
    "\n",
    "# turn into 3 categories [< 4, 4-6, > 6]\n",
    "bins = [0,4,6,np.inf]\n",
    "labels = ['[0,4)','[4,6)','[6,inf)']\n",
    "gdf['ascent_grade_cat'] = pd.cut(gdf['ascent_grade_%'],bins=bins,labels=labels,include_lowest=True).astype(str)\n",
    "gdf['descent_grade_cat'] = pd.cut(gdf['descent_grade_%'],bins=bins,labels=labels,include_lowest=True).astype(str)\n",
    "gdf['max_grade_cat'] = pd.cut(gdf['max_grade'],bins=bins,labels=labels,include_lowest=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gpd.read_file(config['network_fp']/'networks.gpkg',layer='osm_links',ignore_geometry=True)[['osm_linkid','link_type']]\n",
    "x = x.set_index('osm_linkid')['link_type'].to_dict()\n",
    "gdf['link_type'] = gdf['linkid'].map(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(config['network_fp']/'elevation.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[gdf['max_grade'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_points_dict[414497285]['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = links.loc[62421].squeeze()\n",
    "# idx = 62421\n",
    "\n",
    "# osmid = row['osmid']\n",
    "# start_dist = row['start_dist']\n",
    "# end_dist = row['end_dist']\n",
    "# segment_length = row['geometry'].length # no need to convert to meters here\n",
    "\n",
    "# # if start_dist > end_dist:\n",
    "# #     continue\n",
    "\n",
    "# #get osm distances and elevation\n",
    "# item = interpolated_points_dict.get(osmid,False)\n",
    "# # if isinstance(item,bool):\n",
    "# #     print('no record for',idx)\n",
    "# #     continue\n",
    "\n",
    "# #get the max osm_dist\n",
    "# osm_dist = item['distances'][-1]\n",
    "\n",
    "# #retrieve the fitted spline if it exists\n",
    "# spline = item.get('spline',0)\n",
    "\n",
    "# if isinstance(spline,int):\n",
    "#     # # in these cases a spline wasn't fit to the data because there were\n",
    "#     # # only three data points so just assign it the same data as the osm way\n",
    "#     xs = item['distances']\n",
    "#     # cond0 = (xs >= start_dist) & (xs <= end_dist)\n",
    "#     # xs = xs[cond0]\n",
    "#     ys = item['elevations']\n",
    "#     # if np.isnan(ys).any():\n",
    "#         # continue\n",
    "#         # test.append(idx)\n",
    "#     # ys = item['elevations'][cond0]\n",
    "#     # #drop na\n",
    "#     # cond1 = np.isnan(ys) == False\n",
    "#     # xs = xs[cond1]\n",
    "#     # ys = ys[cond1]\n",
    "#     # if len(xs) <= 1:\n",
    "#     #     test.append(idx)\n",
    "#     #     continue\n",
    "#     result[row['linkid']] = {'distances':xs,'elevations':ys}\n",
    "#     # continue\n",
    "\n",
    "# # normal case\n",
    "# if start_dist < end_dist:\n",
    "#     #if the end dist is past the osm dist, use the osm dist\n",
    "#     #this can happen if there's a rounding error\n",
    "#     if end_dist > osm_dist:\n",
    "#         end_dist = osm_dist\n",
    "    \n",
    "#     # if the segment is less than 10 m, just use the first and last point for grade estimation\n",
    "#     if segment_length < 10:\n",
    "#         xs = [start_dist,end_dist]\n",
    "#         ys = splev(xs,spline)\n",
    "#     else:\n",
    "#         #get x values from start_dist to end_dist every 10 m\n",
    "#         xs = []\n",
    "#         i = start_dist\n",
    "#         while i < end_dist:\n",
    "#             xs.append(i)\n",
    "#             i += 10\n",
    "    \n",
    "#     xs = np.array(xs)\n",
    "#     ys = splev(xs,spline)\n",
    "#     #normalize xs so that it goes from 0 to end for the elevation stats function\n",
    "#     # xs = xs - xs[0]\n",
    "#     #result[row['linkid']] = {'distances':np.array(xs),'elevations':ys}\n",
    "# xs\n",
    "# ys\n",
    "# # spits out high values?\n",
    "# splev(601,spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(Path.home()/'Downloads/scratch.gpkg',layer='network_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['max_grade'].isna()].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[13803]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_points_dict[176229031]['spline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.sort_values('max_elev').tail(20).explore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['max_grade']>30].explore()#.shape[0]\n",
    "# gdf[gdf['max_grade']>15].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['max_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.sort_values('max_grade').tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[gdf['linkid']==62421]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = result[62421]\n",
    "item['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_points_dict[414497285]['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item['elevations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_tools.elevation_stats(item['distances'],item['elevations'],5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "interpolate_dist_m = 1\n",
    "new_elevations_dict = {}\n",
    "spline_or_nah = []\n",
    "\n",
    "for idx, row in interpolated.iterrows():\n",
    "    #get ids\n",
    "    osm_linkid = row['osm_linkid']\n",
    "    osmid = row['osmid']\n",
    "\n",
    "    #get osm elevation\n",
    "    item = interpolated_points_dict[osmid]\n",
    "\n",
    "    #retrieve the fitted spline if it exists\n",
    "    spline = item.get('spline',0)\n",
    "    \n",
    "    #get segments\n",
    "    segment = row['segment']\n",
    "    \n",
    "    #if no spline, do linear interpolatation\n",
    "    if spline == 0:\n",
    "        new_xs = item['distances']\n",
    "        new_elevations = item['elevations']\n",
    "        spline_or_nah.append(idx)\n",
    "\n",
    "    elif isinstance(segment[0],list):\n",
    "        #get x sequence\n",
    "        new_xs_segment1 = np.arange(int(segment[0][0]),int(segment[0][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_xs_segment2 = np.arange(int(segment[1][0]),int(segment[1][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "\n",
    "        #get new elevations\n",
    "        new_elevations_segment1 = splev(new_xs_segment1,spline)\n",
    "        new_elevations_segment2 = splev(new_xs_segment2,spline)\n",
    "\n",
    "        #combine\n",
    "        new_xs = np.arange(0,len(new_xs_segment1)+len(new_xs_segment2))\n",
    "        new_elevations = np.hstack([new_elevations_segment2,new_elevations_segment1])\n",
    "\n",
    "    else:\n",
    "        #get new elevation values\n",
    "        new_xs = np.arange(int(segment[0]),int(segment[1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_elevations = splev(new_xs, spline)\n",
    "        #recalculate elevations stats\n",
    "        #TODO if wanting to seperate grades by section use the elevation_stats function\n",
    "    \n",
    "    new_elevations_dict[idx] = elevation_tools.simple_elevation_stats(new_xs, new_elevations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import line_locate_point, equals_exact\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from itertools import product\n",
    "\n",
    "interpolated_distance_dict = {}\n",
    "\n",
    "for idx, row in links.iterrows():\n",
    "    \n",
    "    #network link attributes\n",
    "    osmid = row['osmid']\n",
    "    a = row['osm_A']\n",
    "    b = row['osm_B']\n",
    "    network_line = np.array(row['geometry'].coords)\n",
    "    point1 = network_line[0]\n",
    "    point2 = network_line[-1]\n",
    "\n",
    "    #get raw osm attributes\n",
    "    line = np.array(raw_links.loc[osmid,'geometry'].coords)\n",
    "    points = [Point(x) for x in line]\n",
    "    points = gpd.GeoSeries(points)\n",
    "    distances = points.distance(points.shift(1)).cumsum().tolist()\n",
    "    distances[0] = 0\n",
    "    node_list = json.loads(raw_links.loc[osmid,'all_tags'])['@way_nodes']\n",
    "    a_idx = node_list.index(a)\n",
    "    b_idx = node_list.index(b)\n",
    "\n",
    "    #polygon check\n",
    "    poly_check = len(list(polygonize(unary_union(LineString(line))))) #> 0\n",
    "    poly_check_network = len(list(polygonize(unary_union(LineString(network_line))))) #> 0\n",
    "\n",
    "    method = 'none'\n",
    "    reverse_geometry = False\n",
    "    \n",
    "    # scenario 1: simple line segment no loops\n",
    "    if (poly_check == 0) & (poly_check_network == 0) & (a != b):\n",
    "        method = 'simple'\n",
    "        # step 1: check if network line is in the same direction as loop\n",
    "        if (a_idx > b_idx):     \n",
    "            reverse_geometry = True\n",
    "            a = row['osm_B']\n",
    "            b = row['osm_A']\n",
    "            a_idx = node_list.index(a)\n",
    "            b_idx = node_list.index(b)\n",
    "\n",
    "        # step 2: get distance of start and end point along the line\n",
    "        #point1_dist = line_locate_point(LineString(line),Point(point1))\n",
    "        #point2_dist = line_locate_point(LineString(line),Point(point2))\n",
    "        network_dist = distances[a_idx:b_idx+1]\n",
    "        point1_dist = network_dist[0]\n",
    "        point2_dist = network_dist[-1]\n",
    "\n",
    "        # step 3: check to see if distance matches the network geometry\n",
    "        difference = point2_dist - point1_dist\n",
    "        distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "        if distance_check == False:\n",
    "            print('error')\n",
    "\n",
    "        segment = [point1_dist,point2_dist]\n",
    "    \n",
    "    # scenario 2: network segment is not a loop but the line is\n",
    "    elif (poly_check > 0) & (poly_check_network == 0) & (a != b):\n",
    "        method = 'simple loop'\n",
    "\n",
    "        a_s = [idx for idx, val in enumerate(node_list) if val == a]\n",
    "        b_s = [idx for idx, val in enumerate(node_list) if val == b]\n",
    "\n",
    "        #get all possible combinations of A/B\n",
    "        combinations = list(product(a_s,b_s))\n",
    "        for a_idx, b_idx in combinations:\n",
    "            # step 1: see if network line direction matches line\n",
    "            if (a_idx > b_idx):\n",
    "                reverse_geometry = True\n",
    "                # a = row['osm_B']\n",
    "                # b = row['osm_A']\n",
    "                # a_idx = node_list.index(a)\n",
    "                # b_idx = node_list.index(b)\n",
    "                a_idx, b_idx = b_idx, a_idx\n",
    "\n",
    "            # step 2: get distance of start and end point along the line\n",
    "            # start = node_list.index(a)\n",
    "            # end = node_list[start+1:].index(b) + start + 1\n",
    "            network_dist = distances[a_idx:b_idx+1]\n",
    "            point1_dist = network_dist[0]\n",
    "            point2_dist = network_dist[-1]\n",
    "\n",
    "            # step 3: check to see if distance matches the network geometry\n",
    "            difference = point2_dist - point1_dist\n",
    "            distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "            \n",
    "            segment = [point1_dist,point2_dist]\n",
    "\n",
    "            if distance_check == True:\n",
    "                break\n",
    "\n",
    "        # step 4: if it doesn't then it is likely that the network segment crosses the loop\n",
    "        # we'll need multiple segments in that case\n",
    "        if distance_check == False:\n",
    "            method = 'complex loop'\n",
    "\n",
    "            #reset the reversed geometry bit\n",
    "            reverse_geometry = False\n",
    "            a = row['osm_A']\n",
    "            b = row['osm_B']\n",
    "            a_idx = node_list.index(a)\n",
    "            b_idx = node_list.index(b)\n",
    "\n",
    "            # if the network line crosses the loop then b_idx will be larger\n",
    "            if a_idx < b_idx:\n",
    "                reverse_geometry = True\n",
    "                a = row['osm_B']\n",
    "                b = row['osm_A']\n",
    "                a_idx = node_list.index(a)\n",
    "                b_idx = node_list.index(b)\n",
    "\n",
    "            # step 5: get the two segments\n",
    "            first_segment = [0,distances[b_idx]]\n",
    "            second_segment = [distances[a_idx],distances[-1]]\n",
    "\n",
    "            # step 6: check distance\n",
    "            difference = second_segment[-1] - second_segment[0] + first_segment[1]\n",
    "            distance_check = np.abs(difference - LineString(network_line).length) < 0.02\n",
    "\n",
    "            # if distance_check == False:\n",
    "            #     print('error')\n",
    "            segment = [first_segment,second_segment]\n",
    "\n",
    "    else:\n",
    "        method = 'none'\n",
    "        segment = 999\n",
    "        distance_check = False\n",
    "    \n",
    "    #finaly assemble the dict\n",
    "    interpolated_distance_dict[idx] = {\n",
    "    'method': method,\n",
    "    'segment': segment,\n",
    "    'reverse_geometry': reverse_geometry,\n",
    "    'distance_check': distance_check,\n",
    "    'poly_check': poly_check\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(interpolated_distance_dict,orient='index')\n",
    "interpolated = pd.merge(links,df,left_index=True,right_index=True)\n",
    "\n",
    "#drop loops\n",
    "interpolated = interpolated[interpolated['method']!='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo create a checkpoint here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export['segment'] = export['segment'].astype(str)\n",
    "#export['length_m'] = export.length\n",
    "#export.to_file(Path.home()/'Downloads/scratch.gpkg',layer='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spline fit\n",
    "We need elevation data between the two points to interpolate an elevation profile for the smaller links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "interpolate_dist_m = 1\n",
    "new_elevations_dict = {}\n",
    "spline_or_nah = []\n",
    "\n",
    "for idx, row in interpolated.iterrows():\n",
    "    #get ids\n",
    "    osm_linkid = row['osm_linkid']\n",
    "    osmid = row['osmid']\n",
    "\n",
    "    #get osm elevation\n",
    "    item = interpolated_points_dict[osmid]\n",
    "\n",
    "    #retrieve the fitted spline if it exists\n",
    "    spline = item.get('spline',0)\n",
    "    \n",
    "    #get segments\n",
    "    segment = row['segment']\n",
    "    \n",
    "    #if no spline, do linear interpolatation\n",
    "    if spline == 0:\n",
    "        new_xs = item['distances']\n",
    "        new_elevations = item['elevations']\n",
    "        spline_or_nah.append(idx)\n",
    "\n",
    "    elif isinstance(segment[0],list):\n",
    "        #get x sequence\n",
    "        new_xs_segment1 = np.arange(int(segment[0][0]),int(segment[0][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_xs_segment2 = np.arange(int(segment[1][0]),int(segment[1][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "\n",
    "        #get new elevations\n",
    "        new_elevations_segment1 = splev(new_xs_segment1,spline)\n",
    "        new_elevations_segment2 = splev(new_xs_segment2,spline)\n",
    "\n",
    "        #combine\n",
    "        new_xs = np.arange(0,len(new_xs_segment1)+len(new_xs_segment2))\n",
    "        new_elevations = np.hstack([new_elevations_segment2,new_elevations_segment1])\n",
    "\n",
    "    else:\n",
    "        #get new elevation values\n",
    "        new_xs = np.arange(int(segment[0]),int(segment[1])+interpolate_dist_m,interpolate_dist_m)\n",
    "        new_elevations = splev(new_xs, spline)\n",
    "        #recalculate elevations stats\n",
    "        #TODO if wanting to seperate grades by section use the elevation_stats function\n",
    "    \n",
    "    new_elevations_dict[idx] = elevation_tools.simple_elevation_stats(new_xs, new_elevations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated.loc[spline_or_nah,'spline_fit'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(new_elevations_dict,orient='index')\n",
    "elevations_added = pd.merge(interpolated,df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added['segment'] = elevations_added['segment'].astype(str)\n",
    "elevations_added.to_file(config['network_fp']/'elevation.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added[['ascent_grade_%','descent_grade_%']].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(elevations_added[['ascent_grade_%','descent_grade_%']] > 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added[(elevations_added[['ascent_grade_%','descent_grade_%']] > 5).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevations_added[['ascent_grade_%','descent_grade_%']].abs().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import splrep, splev, BSpline\n",
    "\n",
    "# # case 1: only one segment to deal with\n",
    "# osm_linkid = 1125605250\n",
    "# osmid = 751119047\n",
    "\n",
    "# row = export[export['osm_linkid']==osm_linkid].squeeze()\n",
    "\n",
    "# #get osm elevation\n",
    "# item = interpolated_points_dict[osmid]\n",
    "\n",
    "# #retrieve the fitted spline\n",
    "# spline = item['spline']\n",
    "\n",
    "# #get segments\n",
    "# segment = row['segment']\n",
    "\n",
    "# #get x sequence\n",
    "# new_xs_segment1 = np.arange(int(segment[0][0]),int(segment[0][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "# new_xs_segment2 = np.arange(int(segment[1][0]),int(segment[1][1])+interpolate_dist_m,interpolate_dist_m)\n",
    "\n",
    "# #get new elevations\n",
    "# new_elevations_segment1 = splev(new_xs_segment1,spline)\n",
    "# new_elevations_segment2 = splev(new_xs_segment2,spline)\n",
    "\n",
    "# #combine\n",
    "# new_xs = np.arange(0,len(new_xs_segment1)+len(new_xs_segment2))\n",
    "# new_elevations = np.hstack([new_elevations_segment2,new_elevations_segment1])\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs_segment1,new_elevations_segment1,'-.')\n",
    "# ax.plot(new_xs_segment2,new_elevations_segment2,'-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use fitted spline to from dict to create new values\n",
    "\n",
    "# item = interpolated_points_dict[osmid]\n",
    "# spline = interpolated_points_dict[osmid]['spline']\n",
    "\n",
    "# interpolate_dist_m = 1\n",
    "# new_xs = np.arange(int(point1_dist),int(point2_dist)+interpolate_dist_m,interpolate_dist_m)\n",
    "# new_elevations = splev(new_xs, spline)\n",
    "\n",
    "#new_grades = pd.Series(new_elevations).diff() #/ interpolate_dist_m * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import src.elevation_tools as elevation_tools\n",
    "# reload(elevation_tools)\n",
    "# elevation_tools.simple_elevation_stats(new_xs, new_elevations)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs,new_elevations,'-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkid\n",
    "# item = interpolated_points_dict[linkid]\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import splrep, splev, BSpline\n",
    "\n",
    "# spline = interpolated_points_dict[linkid]['spline']\n",
    "\n",
    "# new_xs = np.arange(int(point1_dist),int(point2_dist)+10,10)\n",
    "# new_ys = splev(new_xs, spline)\n",
    "# new_ys\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(item['distances'],item['elevations'],'-')\n",
    "# ax.plot(new_xs,new_ys,'-.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add elevation data to links (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade_cats = {}\n",
    "\n",
    "# for linkid, item in tqdm(interpolated_points_dict.items()):     \n",
    "\n",
    "#     outputs = elevation_tools.elevation_stats(item['distances'],item['smoothed'],grade_threshold)\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         'distance_deltas':outputs['distance_deltas'],\n",
    "#         'segment_grades':outputs['segment_grades']\n",
    "#         })\n",
    "#     #create bins (broach 2012 ones)\n",
    "#     #'(-inf,-6]','(-6,-4]','(-4,-2]','(-2,0]',\n",
    "#     #-np.inf,-6,-4,-2,\n",
    "#     bins = [-1,2,4,6,10,15,np.inf]\n",
    "#     names = ['(0,2]','(2,4]','(4,6]','(6,10]','(10,15]','(15,inf]']\n",
    "#     df['grade_category'] = pd.cut(df['segment_grades'].abs(), bins, labels = names)\n",
    "\n",
    "#     #determine if up or down (doesn't matter if flat)\n",
    "#     df.loc[df['segment_grades'] >= 0,'ascent_or_descent'] = 'ascent'\n",
    "#     df.loc[df['segment_grades'] < 0,'ascent_or_descent'] = 'descent'\n",
    "\n",
    "#     # how many meters at each grade category?\n",
    "#     test = df.groupby(['grade_category','ascent_or_descent'],observed=False)['distance_deltas'].sum().round(0)\n",
    "#     test = pd.DataFrame(test).transpose()\n",
    "#     test.index = [linkid]\n",
    "#     grade_cats[linkid] = {\n",
    "#         'ascent_m': outputs['ascent'],\n",
    "#         'descent_m': outputs['descent'],\n",
    "#         'ascent_grade': outputs['ascent_grade'],\n",
    "#         'descent_grade': outputs['descent_grade']\n",
    "#     }\n",
    "#     grade_cats[linkid].update(\n",
    "#         test.to_dict(orient='records')[0]\n",
    "#     )\n",
    "    \n",
    "# #.items())#.reseorient='t_index()#.pivot(\n",
    "#     # columns=['grade_category','up'],\n",
    "#     # values='distance_deltas'\n",
    "#     # )\n",
    "# #grade_cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
