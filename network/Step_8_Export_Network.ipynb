{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prepare\n",
    "This step adds in the supplemental attributes prepared in the previous notebooks (e.g., traffic signals, bicycle facilities (with approx. install dates), elevation, etc.). Links where cyclists are absolutely not allowed to travel (Interstates) are removed. A psuedo dual graph for modeling turn movements is created, and the links, nodes, and turns are exported for further processing in the `impedance_calibration` module.\n",
    "\n",
    "For the GDOT/NCST projects, the following attributes were available: (TURN THIS INTO A TABLE LIKE IN THE REPORT LATER)\n",
    "- Length\n",
    "- Grade/Elevation\n",
    "- Bike Facility w Dates\n",
    "- Oneway\n",
    "- Signals\n",
    "- AADT\n",
    "- Truck %\n",
    "- Lanes\n",
    "- Speed Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from shapely.ops import Point\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import modeling_turns, add_attributes, prepare_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import network links and add attributes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197721 links 6892.0 miles 150880 nodes\n",
      "                         size    length_mi  length_pct\n",
      "road                    70233  3286.461080   47.685569\n",
      "service                 49685  1118.567079   16.230074\n",
      "parking_and_driveways   37505  1072.045948   15.555067\n",
      "sidewalk                22633   543.082566    7.879966\n",
      "restricted_access_road   2014   256.544600    3.722386\n",
      "pedestrian              11622   243.736461    3.536543\n",
      "no_bike                  1367   237.511755    3.446225\n",
      "bike                     2593   127.630901    1.851886\n",
      "no_access_or_private       18     3.367666    0.048864\n",
      "Raw network is 6938.0 miles\n"
     ]
    }
   ],
   "source": [
    "links = gpd.read_file(config['network_fp'] /'networks.gpkg',layer='osm_links')\n",
    "og_cols = links.columns\n",
    "nodes = gpd.read_file(config['network_fp'] / 'networks.gpkg',layer='osm_nodes')\n",
    "\n",
    "#TODO modify network filter to stop adding the network name like this\n",
    "links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "\n",
    "#calculate link lengths\n",
    "links['length_ft'] = links.length\n",
    "\n",
    "#basic stats\n",
    "print(links.shape[0],'links',(links.length.sum() / 5280).round(0),'miles',nodes.shape[0],'nodes')\n",
    "\n",
    "#types and lengths\n",
    "summary_df = pd.DataFrame({'size':links['link_type'].value_counts(),\n",
    "                           'length_mi':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum() / 5280),\n",
    "                           'length_pct':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum()) / links.length.sum() * 100})\n",
    "print(summary_df.sort_values('length_mi',ascending=False))\n",
    "\n",
    "#add osm attributes back (especially the oneway column)\n",
    "osm_attrs = gpd.read_file(config['osmdwnld_fp'] / f\"osm.gpkg\",layer='raw')\n",
    "\n",
    "# # get basic stats\n",
    "osm_attrs.to_crs(links.crs,inplace=True)\n",
    "print('Raw network is',(osm_attrs.length / 5280).sum().round(0),'miles')\n",
    "links = pd.merge(links,osm_attrs.drop(columns=['oneway','geometry']),on='osmid')\n",
    "del osm_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bicycle infrastructure and approximate date of opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facility            year  \n",
       "bike lane           2004.0     2.44\n",
       "                    2006.0     0.45\n",
       "                    2007.0     4.95\n",
       "                    2008.0    16.52\n",
       "                    2010.0     4.65\n",
       "                    2011.0     8.29\n",
       "                    2012.0     4.09\n",
       "                    2013.0     2.62\n",
       "                    2014.0     5.37\n",
       "                    2015.0     2.37\n",
       "                    2016.0     9.71\n",
       "                    2017.0     1.06\n",
       "                    2018.0     6.49\n",
       "                    2019.0     2.70\n",
       "                    2020.0     2.88\n",
       "                    2021.0     3.62\n",
       "                    2022.0     0.07\n",
       "                    2023.0     0.53\n",
       "buffered bike lane  2004.0     0.01\n",
       "                    2008.0     0.07\n",
       "                    2012.0     0.16\n",
       "                    2013.0     0.85\n",
       "                    2014.0     0.31\n",
       "                    2015.0     0.54\n",
       "                    2016.0     0.24\n",
       "                    2017.0     0.48\n",
       "                    2018.0     1.03\n",
       "                    2019.0     0.53\n",
       "                    2020.0     0.21\n",
       "                    2021.0     0.04\n",
       "cycletrack          2005.0     0.09\n",
       "                    2013.0     0.23\n",
       "                    2015.0     1.04\n",
       "                    2016.0     0.87\n",
       "                    2017.0     1.72\n",
       "                    2019.0     0.27\n",
       "                    2021.0     2.48\n",
       "multi use path      1970.0     1.39\n",
       "                    1976.0     2.39\n",
       "                    1995.0     0.15\n",
       "                    2005.0     3.07\n",
       "                    2006.0     0.68\n",
       "                    2007.0     8.80\n",
       "                    2008.0    13.85\n",
       "                    2009.0     3.43\n",
       "                    2010.0     2.75\n",
       "                    2011.0     0.06\n",
       "                    2012.0     5.26\n",
       "                    2013.0     1.78\n",
       "                    2014.0     1.45\n",
       "                    2015.0     5.62\n",
       "                    2016.0     8.41\n",
       "                    2017.0     7.35\n",
       "                    2018.0     6.36\n",
       "                    2019.0     3.62\n",
       "                    2020.0     4.06\n",
       "                    2021.0     6.26\n",
       "                    2022.0     0.99\n",
       "Name: length_ft, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycling_infra_dates = gpd.read_file(config['bicycle_facilities_fp']/'osm_cycleways_w_dates.gpkg',layer='dates_network')\n",
    "links = pd.merge(links,cycling_infra_dates[['osm_linkid','facility_fwd','facility_rev','facility','year']],left_on='linkid',right_on='osm_linkid',how='left')\n",
    "links.drop(columns=['osm_linkid'],inplace=True)\n",
    "(links.groupby(['facility','year'])['length_ft'].sum() / 5280).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove off street infrastructure built after 2016\n",
    "Some of these may have still existed as informal dirt paths (Beltline). In that case add them back in manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = 2016\n",
    "max_year_cond = links['year'] > max_year\n",
    "\n",
    "links.loc[max_year_cond].to_file(config['bicycle_facilities_fp']/'removed_bicycle_infra.gpkg')\n",
    "\n",
    "# # remove infra before 2016 so it doesn't match to these\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_fwd'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_rev'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility'] = None\n",
    "\n",
    "#TODO reimplement this but don't remove links from the link database, just the graph so that we can do it dynamically\n",
    "after = links['facility'].isin(['cycletrack','multi use path']) & \\\n",
    "          (links['link_type']!='road') & \\\n",
    "          links['year'].notna() & \\\n",
    "          (links['year']>max_year)\n",
    "links = links[after==False]\n",
    "\n",
    "# set no facility values to null\n",
    "links.loc[links['facility_fwd'] == 'no facility','facility_fwd'] = None\n",
    "links.loc[links['facility_rev'] == 'no facility','facility_rev'] = None\n",
    "\n",
    "# nans to None\n",
    "links.loc[links['facility_fwd'].isna(),'facility_fwd'] = None\n",
    "links.loc[links['facility_rev'].isna(),'facility_rev'] = None\n",
    "links.loc[links['facility'].isna(),'facility'] = None\n",
    "\n",
    "# save in new column for reference for comparison\n",
    "# links['future_facility'] = links['facility_fwd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidepaths\n",
    "Add adjacent multi-use paths and cycletracks to roads as an attribute and vice versa. Think Stone Mountain Trail or Beltline next to Wylie Street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to bike infra and roads\n",
    "mups_and_cycletracks = cycling_infra_dates.loc[cycling_infra_dates['link_type']!='road',['osm_linkid','facility','year','geometry']]\n",
    "mups_and_cycletracks.rename(columns={'osm_linkid':'sidepath_linkid','facility':'sidepath','year':'sidepath_year'},inplace=True)\n",
    "roads = links.loc[links['link_type']=='road',['linkid','geometry']].copy()\n",
    "roads['og_length'] = roads.length\n",
    "\n",
    "# get azimuth for getting angle change\n",
    "roads.to_crs('epsg:4326',inplace=True)\n",
    "roads[['fwd_azimuth','bck_azimuth']] = roads.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "roads.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "mups_and_cycletracks.to_crs('epsg:4326',inplace=True)\n",
    "mups_and_cycletracks[['fwd_azimuth','bck_azimuth']] = mups_and_cycletracks.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "mups_and_cycletracks.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "# buffer by small amount\n",
    "buffer_ft = 50\n",
    "mups_and_cycletracks.set_geometry(mups_and_cycletracks.buffer(buffer_ft),inplace=True)\n",
    "\n",
    "# intersect\n",
    "intersection = gpd.overlay(roads,mups_and_cycletracks)\n",
    "\n",
    "# calculate coverage and angle change (hausdorff distance returns too many false positives)\n",
    "intersection['new_length'] = intersection.length\n",
    "intersection['ratio'] = intersection['new_length']/intersection['og_length']\n",
    "\n",
    "# angle difference (take min to account for direction differences)\n",
    "intersection['diff1'] = np.abs(intersection['fwd_azimuth_1'] - intersection['bck_azimuth_2'])\n",
    "intersection['diff2'] = np.abs(intersection['fwd_azimuth_1'] - intersection['fwd_azimuth_2'])\n",
    "intersection['mindiff'] = intersection[['diff1','diff2']].min(axis=1)\n",
    "\n",
    "# set minimum conditions for accepting\n",
    "cond0 = intersection['ratio'] > 0.95 # this much coverage of the original link\n",
    "cond1 = intersection['mindiff'] < 30 # no more than this change in angle\n",
    "intersection = intersection[cond0&cond1]\n",
    "\n",
    "# just take the one with the most overlap after that\n",
    "has_sidepath = intersection.loc[intersection.groupby('linkid')['ratio'].idxmax()]#,['linkid','sidepath','sideear','geometry']]\n",
    "\n",
    "# buffer the sidepaths again and perform unary union to get the connected parts\n",
    "connected_parts = gpd.GeoDataFrame({'geometry':has_sidepath.buffer(50).unary_union},crs=config['projected_crs_epsg']).reset_index()\n",
    "\n",
    "# intersect with the has_sidepath layer again and group by\n",
    "# need 400 feet next to a road to count as sidepath\n",
    "intersect2 = gpd.overlay(has_sidepath,connected_parts)\n",
    "intersect2['adjacent_length_ft'] = intersect2.groupby('index')['og_length'].transform(sum)\n",
    "# intersect2[intersect2['adjacent_length_ft']>400].explore()\n",
    "final_sidepaths = intersect2.loc[intersect2['adjacent_length_ft']>400,['linkid','sidepath_linkid','sidepath','sidepath_year','geometry']]\n",
    "# final_sidepaths\n",
    "# final_sidepaths.explore()\n",
    "final_sidepaths.to_file(config['bicycle_facilities_fp']/'sidepaths.gpkg',layer='sidepaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back into main network dataframe\n",
    "links = pd.merge(links,final_sidepaths.drop(columns='geometry'),on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the facility to the road if it doesn't already have facility\n",
    "# links0 = links.copy()\n",
    "cond = links[['sidepath_linkid']].notna().all(axis=1) & links[['facility_fwd','facility_rev','facility']].isna().all(axis=1)\n",
    "links.loc[cond,['facility_fwd','facility_rev','facility']] = links.loc[cond,['sidepath','sidepath','sidepath']].values\n",
    "# assign year if there is one\n",
    "# cond = links['sidepath_year'].notna() & links['year'].isna()\n",
    "links.loc[cond,'year'] = links['sidepath_year']\n",
    "\n",
    "# assign the road attributes to the sidepath (i.e., attach the adjacent road linkid) (future step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Network Improvements (in development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atlanta Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='coa',ignore_geometry=True)\n",
    "# links = pd.merge(links,improvements,left_on='osm_linkid',right_on='linkid',how='left')\n",
    "# links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Savannah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='savannah',ignore_geometry=True)\n",
    "# links = pd.merge(links,improvements,on='osm_linkid',how='left')\n",
    "# links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GDOT data\n",
    "GDOT provides # of lanes data, AADT, and truck %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdot_lanes = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_lanes\",ignore_geometry=True)\n",
    "gdot_traffic = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_traffic\",ignore_geometry=True)\n",
    "\n",
    "links = pd.merge(links,gdot_lanes,on=\"osmid\",how='left')\n",
    "links = pd.merge(links,gdot_traffic,on='osmid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle null aadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['AADT'].isna()].explore()\n",
    "# give residential roads the lowest aadt category or below\n",
    "links.loc[links['AADT'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'AADT'] = '[0,4k)'\n",
    "# all others the middle category\n",
    "links.loc[links['AADT'].isna() & (links['link_type']=='road'),'AADT'] = '[4k,10k)'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get the lowest category)\n",
    "links.loc[links['AADT'].isna(),'AADT'] = '[0,4k)'\n",
    "\n",
    "#turn it into categorical data\n",
    "links['AADT'] = pd.Categorical(links['AADT'],ordered=True,categories=['[0,4k)','[4k,10k)','[10k,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add HERE data (SKIP IF NO HERE DATA)\n",
    "HERE provides speed and lanes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"here\",ignore_geometry=True)\n",
    "links = pd.merge(links,here,left_on='linkid',right_on='osm_linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling null speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['here_speed'].isna()].explore()\n",
    "# links[links['here_speed'].isna()&(links['link_type']=='road')]['highway'].unique()\n",
    "# give residential roads a speed limit of 30 or below\n",
    "links.loc[links['here_speed'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'here_speed'] = '[0,30]'\n",
    "# all others get 30 +\n",
    "links.loc[links['here_speed'].isna() & (links['link_type']=='road'),'here_speed'] = '(30,40]'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get a speed limit of 30 or below)\n",
    "links.loc[links['here_speed'].isna(),'here_speed'] = '[0,30]'\n",
    "links.rename(columns={'here_speed':'speed'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['speed'] = pd.Categorical(links['speed'],ordered=True,categories=['[0,30]', '(30,40]', '(40,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve GDOT/HERE lanes data\n",
    "- All non-road links get a 1 (doing this so lanes attribute isn't being confounded with vehicle access)\n",
    "- By direction is too detailed, use a per direction estimate (i.e. treat a 5 lane oneway road the same as a 10 lane twoway road or a 5 lane per direction)\n",
    "- Simplify to:\n",
    "    - 1 lane per direction\n",
    "    - 2 lanes per direction\n",
    "    - 3+ lanes per direction\n",
    "- If unequal number of lanes use direction that would result in the higher category\n",
    "    - Example: 10th Street NE would be 2 lanes per direction because it has 2/1 lanes by direction\n",
    "- Turn lanes (middle, right, etc) are NOT counted in HERE or GDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO figure out what to do when there is a disrepency between the lanes\n",
    "## Examine where there's a big mismatch between HERE and GDOT\n",
    "# - There are a couple of cases where GDOT will be way off, like North Highland Ave NE which shows up as having four lanes when it's mostly 2 lanes for most of its length.\n",
    "# - Memorial Drive is also marked as having four lanes but it was road dieted post 2016, so just use the old value.\n",
    "# - Unless it's a residential street or a few cases that were identified, use the GDOT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give everything a default value of 1 (before we would give non-motorized links a value of 0)\n",
    "links['lanes'] = 1\n",
    "\n",
    "#if one is null take the non null value\n",
    "links.loc[links['here_lanes'].isna() & links['gdot_lanes'].notna(),'lanes'] = links['gdot_lanes']\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].isna(),'lanes'] = links['here_lanes']\n",
    "\n",
    "#otherwise choose whichever is smaller\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].notna(),'lanes'] = links[['here_lanes','gdot_lanes']].min(axis=1)\n",
    "\n",
    "#drop to trim down the df\n",
    "links.drop(columns=['gdot_lanes','here_lanes'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add elevation data\n",
    "Assign the correct direction for reverse links later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = gpd.read_file(config['network_fp']/'elevation.gpkg',layer='elevation',ignore_geometry=True)\n",
    "elevation = elevation[['linkid','ascent_ft','descent_ft','ascent_grade_cat','descent_grade_cat']]\n",
    "links = pd.merge(links,elevation,on='linkid',how='left')\n",
    "# del elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ascent grade and descent grade to zero\n",
    "links.loc[links['ascent_grade_cat'].isna(),'ascent_grade_cat'] = '[0,4)'\n",
    "links.loc[links['descent_grade_cat'].isna(),'descent_grade_cat'] = '[0,4)'\n",
    "links.loc[:,['ascent_ft','descent_ft']] = links.loc[:,['ascent_ft','descent_ft']].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for remaining bridge where lidar data was not available set the grade to 0 if grade exceeds 10 percent\n",
    "# links.loc[(links['bridge'] == 'yes') & (links['ascent_grade_%'] > 10),'ascent_grade_%'] = 0\n",
    "# #also for tunnels\n",
    "# links.loc[(links['tunnel'] == 'yes'),'ascent_grade_%'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse links and turn dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change this to not create the turn graph (just make it an extra optional step)\n",
    "## Create turn graph dataframe\n",
    "from importlib import reload\n",
    "reload(modeling_turns)\n",
    "directed_links, turns_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "\n",
    "# find the degree of the intersection node and re-classify anything with degree 2 as straight turn movement?\n",
    "# what about interstate exits that got removed?\n",
    "from collections import Counter\n",
    "node_degree = dict(Counter(links['A'].tolist()+links['B'].tolist()))\n",
    "turns_df['node_degree'] = turns_df['source_B'].map(node_degree)\n",
    "# turns_df[turns_df['node_degree']==2,'turn_type'] = 'straight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add signals from OSM and GDOT to turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    747724\n",
       "True      18744\n",
       "Name: signalized, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_signals = pd.read_parquet(config['network_fp']/'osm_signals.parquet')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "gdot_signals = pd.read_parquet(config['network_fp']/'gdot_signals.parquet')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "\n",
    "osm_signals = set([tuple(x) for x in osm_signals.values])\n",
    "gdot_signals = set([tuple(x) for x in gdot_signals.values])\n",
    "added_signals = set.union(osm_signals,gdot_signals)\n",
    "\n",
    "turns_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "\n",
    "added_signals = set.intersection(set(turns_df.index.tolist()),added_signals)\n",
    "turns_df.loc[added_signals,'signalized'] = True\n",
    "turns_df.loc[turns_df['signalized'].isna(),'signalized'] = False\n",
    "\n",
    "turns_df.reset_index(inplace=True)\n",
    "\n",
    "turns_df['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in cross street variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_linkid</th>\n",
       "      <th>source_reverse_link</th>\n",
       "      <th>target_linkid</th>\n",
       "      <th>target_reverse_link</th>\n",
       "      <th>source_A</th>\n",
       "      <th>source_B</th>\n",
       "      <th>target_A</th>\n",
       "      <th>target_B</th>\n",
       "      <th>source_azimuth</th>\n",
       "      <th>target_azimuth</th>\n",
       "      <th>...</th>\n",
       "      <th>source_highway</th>\n",
       "      <th>source_link_type</th>\n",
       "      <th>source_lanes</th>\n",
       "      <th>source_AADT</th>\n",
       "      <th>source_speed</th>\n",
       "      <th>target_highway</th>\n",
       "      <th>target_link_type</th>\n",
       "      <th>target_lanes</th>\n",
       "      <th>target_AADT</th>\n",
       "      <th>target_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32689</td>\n",
       "      <td>False</td>\n",
       "      <td>13803</td>\n",
       "      <td>False</td>\n",
       "      <td>315350788</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69116629</td>\n",
       "      <td>250.7</td>\n",
       "      <td>233.9</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38135</td>\n",
       "      <td>False</td>\n",
       "      <td>13803</td>\n",
       "      <td>False</td>\n",
       "      <td>819937163</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69116629</td>\n",
       "      <td>272.0</td>\n",
       "      <td>233.9</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13803</td>\n",
       "      <td>True</td>\n",
       "      <td>32689</td>\n",
       "      <td>True</td>\n",
       "      <td>69116629</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>315350788</td>\n",
       "      <td>53.9</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38135</td>\n",
       "      <td>False</td>\n",
       "      <td>32689</td>\n",
       "      <td>True</td>\n",
       "      <td>819937163</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>315350788</td>\n",
       "      <td>272.0</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13803</td>\n",
       "      <td>True</td>\n",
       "      <td>38135</td>\n",
       "      <td>True</td>\n",
       "      <td>69116629</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>819937163</td>\n",
       "      <td>53.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766463</th>\n",
       "      <td>185139</td>\n",
       "      <td>True</td>\n",
       "      <td>185120</td>\n",
       "      <td>True</td>\n",
       "      <td>9517568994</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517568962</td>\n",
       "      <td>245.3</td>\n",
       "      <td>253.1</td>\n",
       "      <td>...</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766464</th>\n",
       "      <td>185120</td>\n",
       "      <td>False</td>\n",
       "      <td>185140</td>\n",
       "      <td>False</td>\n",
       "      <td>9517568962</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517577621</td>\n",
       "      <td>73.1</td>\n",
       "      <td>151.8</td>\n",
       "      <td>...</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>steps</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766465</th>\n",
       "      <td>185139</td>\n",
       "      <td>True</td>\n",
       "      <td>185140</td>\n",
       "      <td>False</td>\n",
       "      <td>9517568994</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517568993</td>\n",
       "      <td>9517577621</td>\n",
       "      <td>245.3</td>\n",
       "      <td>151.8</td>\n",
       "      <td>...</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>steps</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766466</th>\n",
       "      <td>184645</td>\n",
       "      <td>False</td>\n",
       "      <td>184646</td>\n",
       "      <td>False</td>\n",
       "      <td>9501667031</td>\n",
       "      <td>9501667032</td>\n",
       "      <td>9501667032</td>\n",
       "      <td>9501667033</td>\n",
       "      <td>241.1</td>\n",
       "      <td>241.4</td>\n",
       "      <td>...</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766467</th>\n",
       "      <td>184646</td>\n",
       "      <td>True</td>\n",
       "      <td>184645</td>\n",
       "      <td>True</td>\n",
       "      <td>9501667033</td>\n",
       "      <td>9501667032</td>\n",
       "      <td>9501667032</td>\n",
       "      <td>9501667031</td>\n",
       "      <td>61.4</td>\n",
       "      <td>61.1</td>\n",
       "      <td>...</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>footway</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766468 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_linkid  source_reverse_link  target_linkid  \\\n",
       "0               32689                False          13803   \n",
       "1               38135                False          13803   \n",
       "2               13803                 True          32689   \n",
       "3               38135                False          32689   \n",
       "4               13803                 True          38135   \n",
       "...               ...                  ...            ...   \n",
       "766463         185139                 True         185120   \n",
       "766464         185120                False         185140   \n",
       "766465         185139                 True         185140   \n",
       "766466         184645                False         184646   \n",
       "766467         184646                 True         184645   \n",
       "\n",
       "        target_reverse_link    source_A    source_B    target_A    target_B  \\\n",
       "0                     False   315350788    69123159    69123159    69116629   \n",
       "1                     False   819937163    69123159    69123159    69116629   \n",
       "2                      True    69116629    69123159    69123159   315350788   \n",
       "3                      True   819937163    69123159    69123159   315350788   \n",
       "4                      True    69116629    69123159    69123159   819937163   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "766463                 True  9517568994  9517568993  9517568993  9517568962   \n",
       "766464                False  9517568962  9517568993  9517568993  9517577621   \n",
       "766465                False  9517568994  9517568993  9517568993  9517577621   \n",
       "766466                False  9501667031  9501667032  9501667032  9501667033   \n",
       "766467                 True  9501667033  9501667032  9501667032  9501667031   \n",
       "\n",
       "        source_azimuth  target_azimuth  ...  source_highway  \\\n",
       "0                250.7           233.9  ...        motorway   \n",
       "1                272.0           233.9  ...   motorway_link   \n",
       "2                 53.9            70.7  ...        motorway   \n",
       "3                272.0            70.7  ...   motorway_link   \n",
       "4                 53.9            92.0  ...        motorway   \n",
       "...                ...             ...  ...             ...   \n",
       "766463           245.3           253.1  ...         footway   \n",
       "766464            73.1           151.8  ...         footway   \n",
       "766465           245.3           151.8  ...         footway   \n",
       "766466           241.1           241.4  ...         footway   \n",
       "766467            61.4            61.1  ...         footway   \n",
       "\n",
       "              source_link_type  source_lanes source_AADT source_speed  \\\n",
       "0                      no_bike           1.0      [0,4k)       [0,30]   \n",
       "1       restricted_access_road           1.0      [0,4k)       [0,30]   \n",
       "2                      no_bike           1.0      [0,4k)       [0,30]   \n",
       "3       restricted_access_road           1.0      [0,4k)       [0,30]   \n",
       "4                      no_bike           1.0      [0,4k)       [0,30]   \n",
       "...                        ...           ...         ...          ...   \n",
       "766463                sidewalk           1.0      [0,4k)       [0,30]   \n",
       "766464                sidewalk           1.0      [0,4k)       [0,30]   \n",
       "766465                sidewalk           1.0      [0,4k)       [0,30]   \n",
       "766466                sidewalk           1.0      [0,4k)       [0,30]   \n",
       "766467                sidewalk           1.0      [0,4k)       [0,30]   \n",
       "\n",
       "       target_highway        target_link_type target_lanes target_AADT  \\\n",
       "0            motorway                 no_bike          1.0      [0,4k)   \n",
       "1            motorway                 no_bike          1.0      [0,4k)   \n",
       "2            motorway                 no_bike          1.0      [0,4k)   \n",
       "3            motorway                 no_bike          1.0      [0,4k)   \n",
       "4       motorway_link  restricted_access_road          1.0      [0,4k)   \n",
       "...               ...                     ...          ...         ...   \n",
       "766463        footway                sidewalk          1.0      [0,4k)   \n",
       "766464          steps              pedestrian          1.0      [0,4k)   \n",
       "766465          steps              pedestrian          1.0      [0,4k)   \n",
       "766466        footway                sidewalk          1.0      [0,4k)   \n",
       "766467        footway                sidewalk          1.0      [0,4k)   \n",
       "\n",
       "       target_speed  \n",
       "0            [0,30]  \n",
       "1            [0,30]  \n",
       "2            [0,30]  \n",
       "3            [0,30]  \n",
       "4            [0,30]  \n",
       "...             ...  \n",
       "766463       [0,30]  \n",
       "766464       [0,30]  \n",
       "766465       [0,30]  \n",
       "766466       [0,30]  \n",
       "766467       [0,30]  \n",
       "\n",
       "[766468 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach speed, lanes, AADT, and osm hihgway\n",
    "link_attrs = links.copy()[['linkid','highway','link_type','lanes','AADT','speed']]\n",
    "link_attrs.set_index('linkid',inplace=True)\n",
    "\n",
    "source_cols = ['source_' + x for x in link_attrs.columns]\n",
    "target_cols = ['target_' + x for x in link_attrs.columns]\n",
    "\n",
    "link_attrs.columns = source_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='source_linkid',right_index=True,how='left')\n",
    "link_attrs.columns = target_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='target_linkid',right_index=True,how='left')\n",
    "turns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross street would be to the left or right\n",
    "cond1 = turns_df['turn_type'].isin(['left','right'])\n",
    "\n",
    "#only road to road for now\n",
    "cond2 = (turns_df['source_link_type'] == 'road') & (turns_df['target_link_type'] == 'road')\n",
    "cross_streets = turns_df[cond1&cond2]\n",
    "\n",
    "# get the worst possible cross street attribute\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_reverse_link'])['target_AADT','target_lanes','target_speed'].max()\n",
    "cross_streets.columns = ['cross_AADT','cross_lanes','cross_speed']\n",
    "test = turns_df.merge(cross_streets,left_on=['source_linkid','source_reverse_link'],right_index=True)#,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a stressful turn would be\n",
    "aadt_cross_cond = test['cross_AADT'] == '[10k,inf)'\n",
    "lanes_cross_cond = test['cross_lanes'] > 2\n",
    "speed_cross_cond = test['cross_speed'] >= '(30,40]'\n",
    "cross_high_stress = aadt_cross_cond | lanes_cross_cond | speed_cross_cond\n",
    "\n",
    "# if the source street has these stats then assume that there is a signal\n",
    "aadt_source_cond = test['source_AADT'] == '[10k,inf)'\n",
    "lanes_source_cond = test['source_lanes'] > 2\n",
    "speed_source_cond = test['source_speed'] >= '(30,40]'\n",
    "source_high_stress = aadt_source_cond | lanes_source_cond | speed_source_cond\n",
    "\n",
    "test['unsig_crossing'] = False\n",
    "test.loc[(source_high_stress==False) & cross_high_stress & (test['signalized']==False) & (test['turn_type'].isin(['straight','left'])),'unsig_crossing'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unsignalized crossing variable back in\n",
    "turns_df = pd.merge(turns_df,test[['source_linkid','source_reverse_link','target_linkid','target_reverse_link','unsig_crossing']],on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optional add geo data to turns and export for examination\n",
    "# reload(modeling_turns)\n",
    "# cross_streets_gdf = modeling_turns.turn_gdf(links,test)\n",
    "# for idx,x in enumerate(cross_streets_gdf.dtypes):\n",
    "#     if (str(x) == \"category\") | (str(x)=='object'):\n",
    "#         cross_streets_gdf.iloc[:,idx] = cross_streets_gdf.iloc[:,idx].astype(str)\n",
    "# cross_streets_gdf.to_file(config['network_fp']/'scratch.gpkg',layer='cross_streets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes[nodes['N'].isin(set(cross_streets_gdf.loc[cross_streets_gdf['unsig_crossing']==True,'source_B'].tolist()))].explore() # looks much more reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure hwat i was going for here\n",
    "# # get the worst possible cross street attribute\n",
    "# # cross_streets.groupby(['source_linkid','source_reverse_link'])['target_AADT','target_lanes','target_speed'].idxmax()\n",
    "# cross_streets.loc[18242]\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['target_speed'].max()\n",
    "\n",
    "\n",
    "# # find the worst cross street if there are multiple\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['aadt'].apply(lambda x: aadt_order)\n",
    "\n",
    "\n",
    "# # TODO do this for the other variables too\n",
    "# cols = ['AADT','lanes','speed']\n",
    "# for x in cols:\n",
    "#     print(links[x].unique())\n",
    "# # rules for high stress turns\n",
    "\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #traffic\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | \\\n",
    "#                            (links['highway'].isin(major_road_values) & (links['lanes'] < 2) ), \n",
    "#                             'linkid'].tolist())\n",
    "# cross_streets.loc[cross_streets['source_linkid']==3]\n",
    "# print(links[links['linkid']==3].squeeze())\n",
    "# links[links['linkid']==3].explore()\n",
    "\n",
    "# # grouby the source link\n",
    "# cross_streets.groupby(['source_linkid'])['target_highway'].agg(list)#['target_highway_order'].min()\n",
    "\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pd.merge(turns_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# # wasn't able to get major/minor to be significant\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | links['lanes'] < 2,'linkid'].tolist())\n",
    "\n",
    "# #unsignalized straight/left turn where crossing street is a major road\n",
    "# turns_df['unsig_major_road_crossing'] = (turns_df['signalized']==False) & \\\n",
    "#     turns_df['target_linkid'].isin(major_road) & \\\n",
    "#     turns_df['source_linkid'].isin(minor_road) & \\\n",
    "#     turns_df['turn_type'].isin(['left','straight'])\n",
    "\n",
    "# # #sets turns that are not from road to road to None, effectively ignoring them\n",
    "# # exclude = ['road','service']\n",
    "# # turns_df.loc[(turns_df['source_link_type'].isin(exclude)==False) & \n",
    "# #              (turns_df['target_link_type'].isin(exclude)==False),'turn_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create layer of unsignalized crossings for examining\n",
    "unsig_major_road_crossing = set(turns_df.loc[turns_df['unsig_crossing']==True,'source_B'].tolist())\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "nodes = nodes[nodes['N'].isin(unsig_major_road_crossing)]\n",
    "nodes.to_file(config['calibration_fp']/'unsig_major_road_crossing.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Interstates and Private Links\n",
    "Remove these because we're absolutely sure we don't want bikes on these links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_bike' 'restricted_access_road' 'service' 'parking_and_driveways'\n",
      " 'road' 'bike' 'pedestrian' 'sidewalk' None 'no_access_or_private']\n"
     ]
    }
   ],
   "source": [
    "print(links['link_type'].unique())\n",
    "remove = ['no_access_or_private','restricted_access_road','no_bike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399 links removed\n"
     ]
    }
   ],
   "source": [
    "remove_cond = links['link_type'].isin(remove)\n",
    "links = links[remove_cond==False]\n",
    "print(remove_cond.sum(),'links removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove isolated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before connected components: Links 193722 Nodes 4245\n",
      "After connected components: Links 193305 Nodes 4245\n"
     ]
    }
   ],
   "source": [
    "links, nodes = prepare_network.largest_comp_and_simplify(links,nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['A', 'B', 'linkid', 'oneway', 'link_type', 'osmid', 'geometry',\n",
    "       'length_ft', 'highway', 'name','all_tags',\n",
    "       'facility_fwd', 'facility_rev', 'facility', 'year', 'sidepath',\n",
    "       'sidepath_year', 'route_type', 'AADT',\n",
    "       'speed', 'lanes', 'ascent_ft', 'descent_ft', 'ascent_grade_cat',\n",
    "       'descent_grade_cat']\n",
    "\n",
    "#TODO create a function for performing this\n",
    "for idx,x in enumerate(links.dtypes):\n",
    "    if (str(x) == \"category\"): #| (str(x)=='object'):\n",
    "        links.iloc[:,idx] = links.iloc[:,idx].astype(str)\n",
    "\n",
    "links[final_cols].to_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes.to_file(config['network_fp']/'final_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directional attributes and flip as needed\n",
    "ascent_columns = ['ascent_ft', 'ascent_grade_cat']\n",
    "descent_columns = ['descent_ft', 'descent_grade_cat']\n",
    "directed_links = pd.merge(directed_links,links[['linkid','facility_fwd','facility_rev']+ascent_columns+descent_columns],on='linkid')\n",
    "directed_links.loc[directed_links['reverse_link']==True,ascent_columns+descent_columns] = directed_links.loc[directed_links['reverse_link']==True,descent_columns+ascent_columns].values\n",
    "directed_links.loc[directed_links['reverse_link']==True,['facility_fwd','facility_rev']] = directed_links.loc[directed_links['reverse_link']==True,['facility_rev','facility_fwd']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple columns not compatible with parquet\n",
    "# turns_df.drop(columns=['source','target'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pickles later\n",
    "turns_df.to_parquet(config['network_fp']/'turns_df.parquet')\n",
    "directed_links.to_parquet(config['network_fp']/'directed_edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optional add geo data to turns and export for examination\n",
    "# from shapely.ops import MultiLineString\n",
    "# geo_dict = dict(zip(links['linkid'],links['geometry']))\n",
    "# turns_df['source_geo'] = turns_df['source_linkid'].map(geo_dict)\n",
    "# turns_df['target_geo'] = turns_df['target_linkid'].map(geo_dict)\n",
    "# turns_df['geometry'] = turns_df.apply(lambda row: MultiLineString([row['source_geo'],row['target_geo']]),axis=1)\n",
    "# turns_df.drop(columns=['source_geo','target_geo'],inplace=True)\n",
    "# turns_gdf = gpd.GeoDataFrame(turns_df,crs=links.crs)\n",
    "# # turns_gdf.drop(columns=['source','target'])\n",
    "# turns_gdf.to_file(config['network_fp']/'final_network.gpkg',layer='turns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO serialize the attributes to add as needed?\n",
    "# with (config['network_fp'] / 'edges_with_attributes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['network_fp'] / 'edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'nodes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(nodes,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'directed_edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(edges,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'turn_df.pkl').open('wb') as fh:\n",
    "#     pickle.dump(turn_df,fh,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated past here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #add attributes back and then flip elevation/bicyccle attributes\n",
    "# #do so i don't have to re-flip everytime i import? could potentially save memory though\n",
    "# #TODO it would still be smarter to store as a dict or something\n",
    "# edges\n",
    "# links.columns\n",
    "# edges = pd.merge(edges,links.drop(columns=['A','B']),on='linkid')\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nana\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap if reverse geometry == true\n",
    "#     links.loc[links['reverse_geometry']==True,ascent_columns+descent_columns] = links.loc[links['reverse_geometry']==True,descent_columns+ascent_columns]\n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nan\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Rename columns\n",
    "\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# ## \n",
    "# ## Create turn graph dataframe\n",
    "# edges, turn_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "# ## Flip attributes if needed (elevation, bicycle facilities)\n",
    "# Turns should be good as is\n",
    "# #add geo (needed for map matching part)\n",
    "# df_edges = df_edges.merge(links.drop(columns=['A','B']),on=['linkid'])\n",
    "# df_edges = gpd.GeoDataFrame(df_edges,geometry='geometry',crs=links.crs)\n",
    "# df_edges = df_edges.loc[:,~df_edges.columns.duplicated()].copy()\n",
    "# df_edges.reset_index(drop=True,inplace=True)\n",
    "# #just export the df_edges?\n",
    "# df_edges.to_file(export_fp/'Map_Matching/matching.gpkg',layer='edges')\n",
    "# nodes.to_file(export_fp/'Map_Matching/matching.gpkg',layer='nodes')\n",
    "# pseudo_df.columns\n",
    "# #add geo to the turns too\n",
    "# from shapely.ops import MultiLineString\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='source_linkid',right_on='linkid')\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='target_linkid',right_on='linkid')\n",
    "\n",
    "# geometry = pseudo_df.apply(lambda row: MultiLineString([row['geometry_x'],row['geometry_y']]),axis=1)\n",
    "# pseudo_df.drop(columns=['geometry_x','geometry_y','linkid_x','linkid_y'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,geometry=geometry,crs=links.crs)\n",
    "\n",
    "# # pseudo_edges = pseudo_edges.loc[:,~pseudo_edges.columns.duplicated()].copy()\n",
    "# # pseudo_edges.reset_index(drop=True,inplace=True)\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "# pseudo_df.to_file(export_fp/'Map_Matching/matching.gpkg',layer='turns')\n",
    "# #pickle the graph\n",
    "# with (export_fp / 'Map_Matching/turn_G.pkl').open('wb') as fh:\n",
    "#     pickle.dump(pseudo_G,fh)\n",
    "# # Come back to below later\n",
    "# # Network Prepare\n",
    "# This notebook prepares the final routing network.\n",
    "\n",
    "# 1. Import the desired routing network\n",
    "# 1. Add attributes\n",
    "# 1. Add reconciled attributes\n",
    "# 1. Add signals\n",
    "# 1. Add elevation\n",
    "\n",
    "# Then the network will be turned into a directed network graph complete with an edge list representing the directed edges and another one representing turns. Some attribute values are reversed to account for direction (e.g., elevation, signals).\n",
    "# Import the data from previous notebooks and merge them. Merge here so updates can be done at each step without having to repeat everything.\n",
    "# network_filepath = Path.home() / \"Documents/BikewaySimData/Projects/gdot/networks\"\n",
    "# #filtered data\n",
    "# links = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_links')\n",
    "# nodes = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_nodes')\n",
    "# links.columns\n",
    "# #add osm data\n",
    "# links = add_attributes.add_osm_attr(links,network_filepath / 'osm_attr.pkl')\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# links.columns\n",
    "# #reconciled data\n",
    "# reconciled = gpd.read_file(network_filepath/'reconciled.gpkg',layer='links',ignore_geometry=True)\n",
    "# #[col for col in reconciled.columns if col not in links.columns]\n",
    "# cols_to_keep = ['osm_linkid','speedlimit_range_mph','lanes_per_direction']\n",
    "# links = links.merge(reconciled[cols_to_keep],on='osm_linkid',how='left')\n",
    "# del reconciled\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# #signals added\n",
    "# links_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='links',ignore_geometry=True)\n",
    "\n",
    "# nodes_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='nodes',ignore_geometry=True)\n",
    "# nodes_w_signals\n",
    "# #TODO change linkid to osm_linkid later\n",
    "# cols_to_keep = ['linkid','signal_A','signal_B']\n",
    "# links = links.merge(links_w_signals[cols_to_keep],on='linkid',how='left')\n",
    "# ##del nodes_w_signals\n",
    "\n",
    "# #elevation added\n",
    "# links_w_elevation = gpd.read_file(network_filepath/'elevation_added.gpkg',ignore_geometry=True)\n",
    "# links_w_elevation.columns\n",
    "# links_w_elevation.rename(columns={\n",
    "#     'a_s_c_e_n_t___m':'ascent_m',\n",
    "#     'd_e_s_c_e_n_t___m':'descent_m',\n",
    "#     'a_s_c_e_n_t___g_r_a_d_e':'ascent_grade',\n",
    "#     'd_e_s_c_e_n_t___g_r_a_d_e':'descent_grade',\n",
    "# }, inplace =True)\n",
    "# cols_to_keep = ['linkid','ascent_m','descent_m','ascent_grade','descent_grade','(0,2]_descent',\n",
    "#        '(2,4]_descent', '(4,6]_descent', '(6,10]_descent', '(10,15]_descent',\n",
    "#        '(15,inf]_descent', '(0,2]_ascent', '(2,4]_ascent', '(4,6]_ascent',\n",
    "#        '(6,10]_ascent', '(10,15]_ascent', '(15,inf]_ascent']\n",
    "# links = links.merge(links_w_elevation[cols_to_keep],on='linkid')\n",
    "# del links_w_elevation\n",
    "# links.columns\n",
    "# fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\"\n",
    "# edges = gpd.read_file(fp/'networks/elevation_added.gpkg',layer=\"links\")\n",
    "\n",
    "\n",
    "# edges.columns\n",
    "# #use geometry one last time\n",
    "# edges['length_ft'] = edges.length\n",
    "\n",
    "# #turn bridge and tunnel to boolean values\n",
    "# edges['tunnel'] = edges['tunnel'].notna()\n",
    "# edges['bridge'] = edges['bridge'].notna()\n",
    "# #turn bike facil into one column\n",
    "# edges['bike_facility_type'] = np.nan\n",
    "# edges.loc[(edges['mu'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'shared-use path'\n",
    "# edges.loc[(edges['pbl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'protected bike lane'\n",
    "# edges.loc[(edges['bl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'bike lane'\n",
    "# df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(edges,'A','B','linkid','oneway',True)\n",
    "# ## Add desired attributes from links to df_edges\n",
    "# #df_edges = df_edges.merge(edges[['linkid','geometry']])\n",
    "\n",
    "# basic_cols = ['linkid', 'osmid', 'link_type', 'name', 'oneway','length_ft']\n",
    "\n",
    "# #anything that's an instance or would be better as a count value (but not a turn)\n",
    "# event_cols = ['bridge','tunnel']\n",
    "\n",
    "# #anything that's for the duration of the entire link and has categories\n",
    "# category_cols = ['link_type','highway','speedlimit_range_mph',\n",
    "#                'lanes_per_direction','bike_facility_type']\n",
    "\n",
    "# #reverse in tuple form (these need to be flipped if going the other direction)\n",
    "# rev_columns = [('ascent_m','descent_m'),\n",
    "#                ('ascent_grade','descent_grade'),\n",
    "#                ('(0,2]_ascent','(0,2]_descent'),\n",
    "#                ('(2,4]_ascent','(2,4]_descent'),\n",
    "#                ('(4,6]_ascent','(4,6]_descent'),\n",
    "#                ('(6,10]_ascent','(6,10]_descent'),\n",
    "#                ('(10,15]_ascent','(10,15]_descent'),\n",
    "#                ('(15,inf]_ascent','(15,inf]_descent')]\n",
    "\n",
    "# from itertools import chain\n",
    "# keep_cols = basic_cols + event_cols + category_cols + list(chain(*rev_columns))\n",
    "# # attrs = ['linkid', 'osmid', 'link_type', 'name', 'highway',\n",
    "# #        'bridge', 'tunnel', 'bl', 'pbl', 'mu','speedlimit_range_mph',\n",
    "# #        'lanes_per_direction', 'up_grade', 'down_grade', 'length_ft',\n",
    "# #        'vehicle_separation','geometry']\n",
    "# df_edges = df_edges.merge(edges[keep_cols],on='linkid',how='left')\n",
    "# df_edges\n",
    "# ## Deal with grade\n",
    "# Need to flip sign of grade for reverse links\n",
    "# # def combine_up_down_tuples(lst):\n",
    "# #     result = []\n",
    "# #     current_tuple = []\n",
    "\n",
    "# #     for item in lst:\n",
    "# #         if 'ascent' in item or 'descent' in item:\n",
    "# #             current_tuple.append(item)\n",
    "# #             if len(current_tuple) == 2:\n",
    "# #                 result.append(tuple(current_tuple))\n",
    "# #                 current_tuple = []\n",
    "\n",
    "# #     return result\n",
    "\n",
    "# # rev_columns = ['ascent_m','descent_m','ascent_grade','descent_grade',\n",
    "# #                '(0,2]_down', '(2,4]_down', '(4,6]_down',\n",
    "# #                '(6,10]_down', '(10,15]_down','(15,inf]_down',\n",
    "# #                '(0,2]_up', '(2,4]_up', '(4,6]_up', '(6,10]_up',\n",
    "# #                '(10,15]_up', '(15,inf]_up'\n",
    "# #                ]\n",
    "\n",
    "# # combined_tuples = combine_up_down_tuples(rev_columns)\n",
    "\n",
    "# for elev_columns in rev_columns:\n",
    "#     df_edges[elev_columns[0]] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Turns and Signals\n",
    "# #add additional attributes needed for processing\n",
    "# source_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# target_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# source_links.columns = 'source_' + source_links.columns\n",
    "# target_links.columns = 'target_' + target_links.columns\n",
    "# pseudo_df = pseudo_df.merge(source_links,on='source_linkid',how='left')\n",
    "# pseudo_df = pseudo_df.merge(target_links,on='target_linkid',how='left')\n",
    "# ## Turn Restrictions\n",
    "# Two types in OSM (represented as OSM relations):\n",
    "# - No (blank) turns\n",
    "# - Only this turn allowed\n",
    "\n",
    "# For chosen we don't need to consider turn restrictions\n",
    "# # turn_restrictions = pd.read_csv(fp.parent/'osm_turn_restrictions.csv')\n",
    "# # pseudo_df = pseudo_df.merge(turn_restrictions,left_on=['source_osmid','target_osmid'],right_on=['from_way_id','to_way_id'],how='left')\n",
    "# # road_cond = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# # no_restr = pseudo_df['type'] == 'no'\n",
    "# # only_restr = pseudo_df['type'] == 'only'\n",
    "\n",
    "# # #add a remove column\n",
    "# # pseudo_df['remove'] = False\n",
    "\n",
    "# # #remove the no turns\n",
    "# # pseudo_df.loc[road_cond & no_restr,'remove'] = True\n",
    "\n",
    "# # #for only, find all instances road_cond + from source and set to True\n",
    "# # sources = set(turn_restrictions.loc[turn_restrictions['type']=='only','from_way_id'].tolist())\n",
    "# # pseudo_df.loc[road_cond & pseudo_df['source_osmid'].isin(sources) & pseudo_df['type'].isna(),'remove'] = True\n",
    "\n",
    "# # #Remove these turns and drop the added columns\n",
    "# # print((pseudo_df['remove']==True).sum(),'turns removed')\n",
    "# # pseudo_df = pseudo_df[pseudo_df['remove']==False]\n",
    "# # pseudo_df.drop(columns=['relation_id', 'restriction', 'from_way_id',\n",
    "# #        'to_way_id', 'type', 'remove'],inplace=True)\n",
    "# # Deal with signals\n",
    "# Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "# - For the source link, use signal_B if reverse == False else signal_A\n",
    "# - For the target link, use signal_A if reverse == False else signal_B\n",
    "# source = pseudo_df[['source_linkid','source_reverse_link']].merge(edges,left_on='source_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "# target = pseudo_df[['target_linkid','target_reverse_link']].merge(edges,left_on='target_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_B'], target['signal_A'])\n",
    "# ## Identifying signalized/unsignalized turns\n",
    "# - Only look at roads for now\n",
    "# - Filter to left/right turns per source linkid per direction\n",
    "# - Take the highest road classification and assign it as the cross street road classification\n",
    "# import pandas as pd\n",
    "# highway_order = {\n",
    "#     'trunk': 0,\n",
    "#     'trunk_link': 1,\n",
    "#     'primary': 2,\n",
    "#     'primary_link': 3,\n",
    "#     'secondary': 4,\n",
    "#     'secondary_link': 5,\n",
    "#     'tertiary': 6,\n",
    "#     'tertiary_link': 7,\n",
    "#     'unclassified': 8,\n",
    "#     'residential': 9\n",
    "# }\n",
    "# highway_order = pd.Series(highway_order)\n",
    "# highway_order = highway_order.reset_index()\n",
    "# highway_order.columns = ['highway','order']\n",
    "# #add highway ranking based on the above\n",
    "# pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# #remove straight and uturn\n",
    "# cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "# #only road to road for now\n",
    "# cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "# #use groupby to find the max target_highway order\n",
    "# cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# #change numbers back to normal\n",
    "# pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "# pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])\n",
    "# # TODO Add OSM crossing into this logic\n",
    "#     - Signals\n",
    "#         - Wait on this until we have the route attributes code done\n",
    "#         - Add crossings in signalization\n",
    "#         - Majority of crossings are nodes not ways\n",
    "#         - Cycleway crossings typically dealt the same way\n",
    "#         - If meeting nodes are both crossings and within the traffic signal buffer, they're signalized crossings\n",
    "#             - Or if both connecting links are crossings/connect to the road etc\n",
    "#         - Way attributes\n",
    "#             - Footway = crossing\n",
    "#             - Highway = footway\n",
    "#         - Node attributes\n",
    "#             - Crossing = * (traffic signals/marked/etc)\n",
    "#             - Highway = crossing\n",
    "#         - Link attributes\n",
    "#             - Some links are labeled as crossings but this is not as consistent\n",
    "\n",
    "# signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "# left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "# both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_street = pseudo_df['cross_street_order'] <= 5\n",
    "\n",
    "# #signalized\n",
    "# pseudo_df.loc[signalized & both_road,'signalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['signalized'].isna(),'signalized'] = False\n",
    "# # pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "# # pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "# pseudo_df.loc[-signalized & both_road & cross_street,'unsignalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['unsignalized'].isna(),'unsignalized'] = False\n",
    "\n",
    "# #clean up\n",
    "# rem =  ['source_osmid', 'source_link_type', 'source_name',\n",
    "#        'source_highway', 'target_osmid', 'target_link_type', 'target_name',\n",
    "#        'target_highway', 'source_signal', 'target_signal',\n",
    "#        'target_highway_order', 'source_highway_order', 'cross_street',\n",
    "#        'cross_street_order']\n",
    "# pseudo_df.drop(columns=rem,inplace=True)\n",
    "# # Export for impedance calibration\n",
    "\n",
    "# # df_edges = gpd.GeoDataFrame(df_edges,crs='epsg:2240')\n",
    "# df_edges.columns\n",
    "# with (fp.parent / 'chosen.pkl').open('wb') as fh:\n",
    "#     export = (df_edges,pseudo_df,pseudo_G)\n",
    "#     pickle.dump(export,fh)\n",
    "# ## Add geometry to examine results in QGIS\n",
    "# #add geo\n",
    "# link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "# pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "# pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "# pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "# pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "# #check results (may need a smaller road network to test on)\n",
    "# pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
