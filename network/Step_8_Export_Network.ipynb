{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prepare REVISED 4/08/24\n",
    "In this step, we add signals, bicycle facilities (with dates), and elevation attributes (avg up/down slop), remove links where cyclists are not allowed, and create a psuedo graph edge list for modeling turns.\n",
    "\n",
    "Further refinement of the attributes for impedance calibration pruposes should be done in the `impedance_calibration` module. This includes reconciling the different attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import src.modeling_turns as modeling_turns\n",
    "import src.add_attributes as add_attributes\n",
    "import src.prepare_network as prepare_network\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import network links and add attributes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['network_fp'] /'networks.gpkg',layer='osm_links')\n",
    "og_cols = links.columns\n",
    "nodes = gpd.read_file(config['network_fp'] / 'networks.gpkg',layer='osm_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #temporary\n",
    "# #also give raceways this\n",
    "# links.loc[links['highway']=='raceway','link_type'] = 'no_access_or_private'\n",
    "# links.loc[links['highway'].isin(['construction','proposed']),'link_type'] = 'construction or proposed'\n",
    "# links[og_cols].to_file(config['network_fp'] /'networks.gpkg',layer='osm_links')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129627 links 4268.0 miles 106786 nodes\n"
     ]
    }
   ],
   "source": [
    "#basic stats\n",
    "print(links.shape[0],'links',(links.length.sum() / 5280).round(0),'miles',nodes.shape[0],'nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>length_mi</th>\n",
       "      <th>length_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>50657</td>\n",
       "      <td>1957.762113</td>\n",
       "      <td>45.872864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>33303</td>\n",
       "      <td>1001.116198</td>\n",
       "      <td>23.457430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_access_or_private</th>\n",
       "      <td>7387</td>\n",
       "      <td>365.882754</td>\n",
       "      <td>8.573100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking_and_driveways</th>\n",
       "      <td>17472</td>\n",
       "      <td>327.137301</td>\n",
       "      <td>7.665244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedestrian</th>\n",
       "      <td>10279</td>\n",
       "      <td>260.741801</td>\n",
       "      <td>6.109513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_access_road</th>\n",
       "      <td>841</td>\n",
       "      <td>190.783647</td>\n",
       "      <td>4.470304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewalk</th>\n",
       "      <td>9449</td>\n",
       "      <td>147.701124</td>\n",
       "      <td>3.460826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bike</th>\n",
       "      <td>238</td>\n",
       "      <td>16.663768</td>\n",
       "      <td>0.390453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction or proposed</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           size    length_mi  length_pct\n",
       "link_type                                               \n",
       "road                      50657  1957.762113   45.872864\n",
       "service                   33303  1001.116198   23.457430\n",
       "no_access_or_private       7387   365.882754    8.573100\n",
       "parking_and_driveways     17472   327.137301    7.665244\n",
       "pedestrian                10279   260.741801    6.109513\n",
       "restricted_access_road      841   190.783647    4.470304\n",
       "sidewalk                   9449   147.701124    3.460826\n",
       "bike                        238    16.663768    0.390453\n",
       "construction or proposed      1     0.011368    0.000266"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types and length\n",
    "summary_df = pd.DataFrame({'size':links.groupby('link_type').size(),\n",
    "                           'length_mi':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum() / 5280),\n",
    "                           'length_pct':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum()) / links.length.sum() * 100})\n",
    "summary_df.sort_values('length_mi',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size          129627.000000\n",
       "length_mi       4267.800074\n",
       "length_pct       100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and add attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add attributes back (especially the oneway column)\n",
    "osm_attrs = gpd.read_file(config['osmdwnld_fp'] / f\"osm_{config['geofabrik_year']}.gpkg\",layer='raw')#ignore_geometry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60908"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_attrs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598.927912949249"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get basic stats\n",
    "osm_attrs.to_crs(links.crs,inplace=True)\n",
    "(osm_attrs.length / 5280).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.merge(links,osm_attrs.drop(columns=['geometry']),left_on='osmid',right_on='osmid')\n",
    "del osm_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn oneway into boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['oneway'] = links['oneway'].isin(['yes','-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bicycle infrastructure and dates (city of atlanta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO temporary version while i get the dates added\n",
    "# cycling_infra_dates = gpd.read_file(config['bicycle_facilities_fp']/'osm_cycleways_w_dates.gpkg',layer='test_dates',ignore_geometry=True)\n",
    "# links = pd.merge(links,cycling_infra_dates[['osmid','facility_fwd','facility_rev','year']],on='osmid',how='left')\n",
    "# del cycling_infra_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add network improvements (atlanta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='coa',ignore_geometry=True)\n",
    "# links = pd.merge(links,improvements,left_on='osm_linkid',right_on='linkid',how='left')\n",
    "# links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bicycle infrastructure and dates (savannah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'linkid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m improvements \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicycle_facilities_fp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork_improvements.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m,layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavannah\u001b[39m\u001b[38;5;124m'\u001b[39m,ignore_geometry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m links \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimprovements\u001b[49m\u001b[43m,\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mosm_linkid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinkid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m links\n",
      "File \u001b[0;32m~/mambaforge/envs/geo-env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/mambaforge/envs/geo-env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/mambaforge/envs/geo-env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/mambaforge/envs/geo-env/lib/python3.11/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'linkid'"
     ]
    }
   ],
   "source": [
    "improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='savannah',ignore_geometry=True)\n",
    "links = pd.merge(links,improvements,left_on='osm_linkid',right_on='linkid',how='left')\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_A</th>\n",
       "      <th>osm_B</th>\n",
       "      <th>osm_linkid</th>\n",
       "      <th>link_type</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>version</th>\n",
       "      <th>type</th>\n",
       "      <th>highway</th>\n",
       "      <th>...</th>\n",
       "      <th>cycleway</th>\n",
       "      <th>service</th>\n",
       "      <th>footway</th>\n",
       "      <th>sidewalk</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>foot</th>\n",
       "      <th>access</th>\n",
       "      <th>area</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>geom_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436633256</td>\n",
       "      <td>67075136</td>\n",
       "      <td>1125565548</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>37392645</td>\n",
       "      <td>LINESTRING (893138.256 776938.164, 895183.009 ...</td>\n",
       "      <td>1663252114</td>\n",
       "      <td>17</td>\n",
       "      <td>way</td>\n",
       "      <td>motorway</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [436633256, 68...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67075036</td>\n",
       "      <td>68560350</td>\n",
       "      <td>1125565549</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>9199408</td>\n",
       "      <td>LINESTRING (904256.082 770151.801, 903129.103 ...</td>\n",
       "      <td>1663252114</td>\n",
       "      <td>22</td>\n",
       "      <td>way</td>\n",
       "      <td>motorway</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [67075036, 685...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68527352</td>\n",
       "      <td>68527407</td>\n",
       "      <td>1125565550</td>\n",
       "      <td>road</td>\n",
       "      <td>9196359</td>\n",
       "      <td>LINESTRING (901673.835 774900.749, 901716.150 ...</td>\n",
       "      <td>1671551474</td>\n",
       "      <td>8</td>\n",
       "      <td>way</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [68527352, 685...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68527407</td>\n",
       "      <td>68527414</td>\n",
       "      <td>1125565552</td>\n",
       "      <td>road</td>\n",
       "      <td>9196359</td>\n",
       "      <td>LINESTRING (904294.606 774340.621, 904372.853 ...</td>\n",
       "      <td>1671551474</td>\n",
       "      <td>8</td>\n",
       "      <td>way</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [68527352, 685...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68527414</td>\n",
       "      <td>67023635</td>\n",
       "      <td>1125565562</td>\n",
       "      <td>road</td>\n",
       "      <td>9196359</td>\n",
       "      <td>LINESTRING (907384.760 775511.496, 907542.686 ...</td>\n",
       "      <td>1671551474</td>\n",
       "      <td>8</td>\n",
       "      <td>way</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [68527352, 685...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129622</th>\n",
       "      <td>10277959062</td>\n",
       "      <td>10277959063</td>\n",
       "      <td>1125695170</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1123883742</td>\n",
       "      <td>LINESTRING (983143.028 755057.980, 983355.927 ...</td>\n",
       "      <td>1671629260</td>\n",
       "      <td>1</td>\n",
       "      <td>way</td>\n",
       "      <td>service</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking_aisle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [10277959062, ...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129623</th>\n",
       "      <td>10277959064</td>\n",
       "      <td>10277959065</td>\n",
       "      <td>1125695171</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1123883743</td>\n",
       "      <td>LINESTRING (983197.892 755026.354, 983411.720 ...</td>\n",
       "      <td>1671629260</td>\n",
       "      <td>1</td>\n",
       "      <td>way</td>\n",
       "      <td>service</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking_aisle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [10277959064, ...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129624</th>\n",
       "      <td>10277959066</td>\n",
       "      <td>10277959067</td>\n",
       "      <td>1125695172</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1123883744</td>\n",
       "      <td>LINESTRING (983269.269 754985.176, 983483.742 ...</td>\n",
       "      <td>1671629260</td>\n",
       "      <td>1</td>\n",
       "      <td>way</td>\n",
       "      <td>service</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking_aisle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [10277959066, ...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129625</th>\n",
       "      <td>10277959068</td>\n",
       "      <td>10277959069</td>\n",
       "      <td>1125695173</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1123883745</td>\n",
       "      <td>LINESTRING (983326.064 754952.441, 983538.009 ...</td>\n",
       "      <td>1671629260</td>\n",
       "      <td>1</td>\n",
       "      <td>way</td>\n",
       "      <td>service</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking_aisle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [10277959068, ...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129626</th>\n",
       "      <td>10277959070</td>\n",
       "      <td>10277959071</td>\n",
       "      <td>1125695174</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1123883746</td>\n",
       "      <td>LINESTRING (983394.980 754912.694, 983605.702 ...</td>\n",
       "      <td>1671629260</td>\n",
       "      <td>1</td>\n",
       "      <td>way</td>\n",
       "      <td>service</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking_aisle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"@changeset\": 0, \"@way_nodes\": [10277959070, ...</td>\n",
       "      <td>LineString</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129627 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              osm_A        osm_B  osm_linkid               link_type  \\\n",
       "0         436633256     67075136  1125565548  restricted_access_road   \n",
       "1          67075036     68560350  1125565549  restricted_access_road   \n",
       "2          68527352     68527407  1125565550                    road   \n",
       "3          68527407     68527414  1125565552                    road   \n",
       "4          68527414     67023635  1125565562                    road   \n",
       "...             ...          ...         ...                     ...   \n",
       "129622  10277959062  10277959063  1125695170   parking_and_driveways   \n",
       "129623  10277959064  10277959065  1125695171   parking_and_driveways   \n",
       "129624  10277959066  10277959067  1125695172   parking_and_driveways   \n",
       "129625  10277959068  10277959069  1125695173   parking_and_driveways   \n",
       "129626  10277959070  10277959071  1125695174   parking_and_driveways   \n",
       "\n",
       "             osmid                                           geometry  \\\n",
       "0         37392645  LINESTRING (893138.256 776938.164, 895183.009 ...   \n",
       "1          9199408  LINESTRING (904256.082 770151.801, 903129.103 ...   \n",
       "2          9196359  LINESTRING (901673.835 774900.749, 901716.150 ...   \n",
       "3          9196359  LINESTRING (904294.606 774340.621, 904372.853 ...   \n",
       "4          9196359  LINESTRING (907384.760 775511.496, 907542.686 ...   \n",
       "...            ...                                                ...   \n",
       "129622  1123883742  LINESTRING (983143.028 755057.980, 983355.927 ...   \n",
       "129623  1123883743  LINESTRING (983197.892 755026.354, 983411.720 ...   \n",
       "129624  1123883744  LINESTRING (983269.269 754985.176, 983483.742 ...   \n",
       "129625  1123883745  LINESTRING (983326.064 754952.441, 983538.009 ...   \n",
       "129626  1123883746  LINESTRING (983394.980 754912.694, 983605.702 ...   \n",
       "\n",
       "         timestamp  version type       highway  ...  cycleway        service  \\\n",
       "0       1663252114       17  way      motorway  ...       NaN            NaN   \n",
       "1       1663252114       22  way      motorway  ...       NaN            NaN   \n",
       "2       1671551474        8  way  unclassified  ...       NaN            NaN   \n",
       "3       1671551474        8  way  unclassified  ...       NaN            NaN   \n",
       "4       1671551474        8  way  unclassified  ...       NaN            NaN   \n",
       "...            ...      ...  ...           ...  ...       ...            ...   \n",
       "129622  1671629260        1  way       service  ...       NaN  parking_aisle   \n",
       "129623  1671629260        1  way       service  ...       NaN  parking_aisle   \n",
       "129624  1671629260        1  way       service  ...       NaN  parking_aisle   \n",
       "129625  1671629260        1  way       service  ...       NaN  parking_aisle   \n",
       "129626  1671629260        1  way       service  ...       NaN  parking_aisle   \n",
       "\n",
       "       footway sidewalk bicycle foot access area  \\\n",
       "0          NaN      NaN      no  NaN    NaN  NaN   \n",
       "1          NaN      NaN      no  NaN    NaN  NaN   \n",
       "2          NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "3          NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "4          NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "...        ...      ...     ...  ...    ...  ...   \n",
       "129622     NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "129623     NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "129624     NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "129625     NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "129626     NaN      NaN     NaN  NaN    NaN  NaN   \n",
       "\n",
       "                                                 all_tags   geom_type  \n",
       "0       {\"@changeset\": 0, \"@way_nodes\": [436633256, 68...  LineString  \n",
       "1       {\"@changeset\": 0, \"@way_nodes\": [67075036, 685...  LineString  \n",
       "2       {\"@changeset\": 0, \"@way_nodes\": [68527352, 685...  LineString  \n",
       "3       {\"@changeset\": 0, \"@way_nodes\": [68527352, 685...  LineString  \n",
       "4       {\"@changeset\": 0, \"@way_nodes\": [68527352, 685...  LineString  \n",
       "...                                                   ...         ...  \n",
       "129622  {\"@changeset\": 0, \"@way_nodes\": [10277959062, ...  LineString  \n",
       "129623  {\"@changeset\": 0, \"@way_nodes\": [10277959064, ...  LineString  \n",
       "129624  {\"@changeset\": 0, \"@way_nodes\": [10277959066, ...  LineString  \n",
       "129625  {\"@changeset\": 0, \"@way_nodes\": [10277959068, ...  LineString  \n",
       "129626  {\"@changeset\": 0, \"@way_nodes\": [10277959070, ...  LineString  \n",
       "\n",
       "[129627 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add GDOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdot_lanes = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_lanes\",ignore_geometry=True)\n",
    "gdot_traffic = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_traffic\",ignore_geometry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.merge(links,gdot_lanes,on=\"osmid\",how='left')\n",
    "links = pd.merge(links,gdot_traffic,on='osmid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HERE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"here\",ignore_geometry=True)\n",
    "# links = pd.merge(links,here,on='osm_linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Bike Ottawa LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lts_paths = (Path.home() / \"Documents/GitHub/stressmodel/data\").glob(\"*.json\")\n",
    "# lts_list = []\n",
    "# for lts_path in lts_paths:\n",
    "#     lts_edges = gpd.read_file(lts_path,ignore_geometry=True)\n",
    "#     lts_edges['osmid'] = lts_edges['id'].str.split('/').apply(lambda x: x[1]).astype(int)\n",
    "#     lts = int(lts_path.name.split('_')[1].split('.')[0])\n",
    "#     lts_edges['lts'] = lts\n",
    "#     lts_list.append(lts_edges[['osmid','lts']])\n",
    "# lts_df = pd.concat(lts_list)\n",
    "# links = pd.merge(links,lts_df,on='osmid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add elevation data\n",
    "Assign the correct direction, then flip signs for reverse links later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = gpd.read_file(config['network_fp']/'elevation.gpkg',layer='elevation',ignore_geometry=True)\n",
    "ascent_columns = [col for col in elevation.columns if \"ascent\" in col]\n",
    "descent_columns = [col for col in elevation.columns if \"descent\" in col]\n",
    "links = pd.merge(links,elevation[['osm_linkid']+ascent_columns+descent_columns],on='osm_linkid',how='left')\n",
    "del elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE: fixed the reverse links bug so no longer need to flip the geometry here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first take the absolute value then flip the elevations to match the geometry\n",
    "# #TODO do this in the elevation script instead\n",
    "# links.loc[:,ascent_columns+descent_columns] = links.loc[:,ascent_columns+descent_columns].abs()\n",
    "# links.loc[links['reverse_geometry']==True,ascent_columns+descent_columns] = links.loc[links['reverse_geometry']==True,descent_columns+ascent_columns].values\n",
    "\n",
    "# #have to do this with bike facilities too\n",
    "# #TODO, at some point figure this part out during network filtering\n",
    "# #ONEWAY links do not have this issue\n",
    "# links.loc[links['reverse_geometry']==True,['facility_fwd','facility_rev']] = links.loc[links['reverse_geometry']==True,['facility_rev','facility_fwd']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually reverse the underlying geometry so it doesn't mess up the turns\n",
    "#links.loc[links['reverse_geometry']==True,'geometry'] = links['geometry'].apply(lambda geom: geom.reverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "nodes.rename(columns={'osm_N':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate link lengths\n",
    "links['length_ft'] = links.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove non-routable links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['link_type'].unique()\n",
    "keep_type = ['road', 'service', 'parking_and_driveways', 'pedestrian', 'bike', 'sidewalk_or_crossing']\n",
    "links = links[links['link_type'].isin(keep_type)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove isolated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, nodes = prepare_network.largest_comp_and_simplify(links,nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse links and turn dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change this to not create the turn graph (just make it an extra optional step)\n",
    "## Create turn graph dataframe\n",
    "directed_links, turns_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add signals (do later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_signals = pd.read_parquet(config['network_fp']/'osm_signals.parquet')\n",
    "osm_signals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_signals['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df = pd.merge(turns_df,osm_signals[['source_linkid','source_reverse_link','target_linkid','target_reverse_link','signalized']],on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df.loc[turns_df['signalized'].isna(),'signalized'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding stressful intersections\n",
    "# import pandas as pd\n",
    "# highway_order = {\n",
    "#     'trunk': 0,\n",
    "#     'trunk_link': 1,\n",
    "#     'primary': 2,\n",
    "#     'primary_link': 3,\n",
    "#     'secondary': 4,\n",
    "#     'secondary_link': 5,\n",
    "#     'tertiary': 6,\n",
    "#     'tertiary_link': 7,\n",
    "#     'unclassified': 8,\n",
    "#     'residential': 9\n",
    "# }\n",
    "# highway_order = pd.Series(highway_order)\n",
    "# highway_order = highway_order.reset_index()\n",
    "# highway_order.columns = ['highway','order']\n",
    "# #add highway ranking based on the above\n",
    "# pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# #remove straight and uturn\n",
    "# cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "# #only road to road for now\n",
    "# cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "# #use groupby to find the max target_highway order\n",
    "# cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# #change numbers back to normal\n",
    "# pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "# pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directional attributes and flip as needed\n",
    "directed_links = pd.merge(directed_links,links[['linkid','facility_fwd','facility_rev']+ascent_columns+descent_columns],on='linkid')\n",
    "directed_links.loc[directed_links['reverse_link']==True,ascent_columns+descent_columns] = directed_links.loc[directed_links['reverse_link']==True,descent_columns+ascent_columns].values\n",
    "directed_links.loc[directed_links['reverse_link']==True,['facility_fwd','facility_rev']] = directed_links.loc[directed_links['reverse_link']==True,['facility_rev','facility_fwd']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df.to_parquet(config['network_fp']/'turns_df.parquet')\n",
    "directed_links.to_parquet(config['network_fp']/'directed_edges.parquet')\n",
    "links.to_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes.to_file(config['network_fp']/'final_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional add geo data to turns and export for examination\n",
    "from shapely.ops import MultiLineString\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))\n",
    "turns_df['source_geo'] = turns_df['source_linkid'].map(geo_dict)\n",
    "turns_df['target_geo'] = turns_df['target_linkid'].map(geo_dict)\n",
    "turns_df['geometry'] = turns_df.apply(lambda row: MultiLineString([row['source_geo'],row['target_geo']]),axis=1)\n",
    "turns_df.drop(columns=['source_geo','target_geo'],inplace=True)\n",
    "turns_gdf = gpd.GeoDataFrame(turns_df,crs=links.crs)\n",
    "turns_gdf.drop(columns=['source','target']).to_file(config['network_fp']/'final_network.gpkg',layer='turns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO serialize the attributes to add as needed?\n",
    "# with (config['network_fp'] / 'edges_with_attributes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['network_fp'] / 'edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'nodes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(nodes,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'directed_edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(edges,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'turn_df.pkl').open('wb') as fh:\n",
    "#     pickle.dump(turn_df,fh,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated past here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #add attributes back and then flip elevation/bicyccle attributes\n",
    "# #do so i don't have to re-flip everytime i import? could potentially save memory though\n",
    "# #TODO it would still be smarter to store as a dict or something\n",
    "# edges\n",
    "# links.columns\n",
    "# edges = pd.merge(edges,links.drop(columns=['A','B']),on='linkid')\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nana\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap if reverse geometry == true\n",
    "#     links.loc[links['reverse_geometry']==True,ascent_columns+descent_columns] = links.loc[links['reverse_geometry']==True,descent_columns+ascent_columns]\n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nan\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Rename columns\n",
    "\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# ## \n",
    "# ## Create turn graph dataframe\n",
    "# edges, turn_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "# ## Flip attributes if needed (elevation, bicycle facilities)\n",
    "# Turns should be good as is\n",
    "# #add geo (needed for map matching part)\n",
    "# df_edges = df_edges.merge(links.drop(columns=['A','B']),on=['linkid'])\n",
    "# df_edges = gpd.GeoDataFrame(df_edges,geometry='geometry',crs=links.crs)\n",
    "# df_edges = df_edges.loc[:,~df_edges.columns.duplicated()].copy()\n",
    "# df_edges.reset_index(drop=True,inplace=True)\n",
    "# #just export the df_edges?\n",
    "# df_edges.to_file(export_fp/'Map_Matching/matching.gpkg',layer='edges')\n",
    "# nodes.to_file(export_fp/'Map_Matching/matching.gpkg',layer='nodes')\n",
    "# pseudo_df.columns\n",
    "# #add geo to the turns too\n",
    "# from shapely.ops import MultiLineString\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='source_linkid',right_on='linkid')\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='target_linkid',right_on='linkid')\n",
    "\n",
    "# geometry = pseudo_df.apply(lambda row: MultiLineString([row['geometry_x'],row['geometry_y']]),axis=1)\n",
    "# pseudo_df.drop(columns=['geometry_x','geometry_y','linkid_x','linkid_y'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,geometry=geometry,crs=links.crs)\n",
    "\n",
    "# # pseudo_edges = pseudo_edges.loc[:,~pseudo_edges.columns.duplicated()].copy()\n",
    "# # pseudo_edges.reset_index(drop=True,inplace=True)\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "# pseudo_df.to_file(export_fp/'Map_Matching/matching.gpkg',layer='turns')\n",
    "# #pickle the graph\n",
    "# with (export_fp / 'Map_Matching/turn_G.pkl').open('wb') as fh:\n",
    "#     pickle.dump(pseudo_G,fh)\n",
    "# # Come back to below later\n",
    "# # Network Prepare\n",
    "# This notebook prepares the final routing network.\n",
    "\n",
    "# 1. Import the desired routing network\n",
    "# 1. Add attributes\n",
    "# 1. Add reconciled attributes\n",
    "# 1. Add signals\n",
    "# 1. Add elevation\n",
    "\n",
    "# Then the network will be turned into a directed network graph complete with an edge list representing the directed edges and another one representing turns. Some attribute values are reversed to account for direction (e.g., elevation, signals).\n",
    "# Import the data from previous notebooks and merge them. Merge here so updates can be done at each step without having to repeat everything.\n",
    "# network_filepath = Path.home() / \"Documents/BikewaySimData/Projects/gdot/networks\"\n",
    "# #filtered data\n",
    "# links = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_links')\n",
    "# nodes = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_nodes')\n",
    "# links.columns\n",
    "# #add osm data\n",
    "# links = add_attributes.add_osm_attr(links,network_filepath / 'osm_attr.pkl')\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# links.columns\n",
    "# #reconciled data\n",
    "# reconciled = gpd.read_file(network_filepath/'reconciled.gpkg',layer='links',ignore_geometry=True)\n",
    "# #[col for col in reconciled.columns if col not in links.columns]\n",
    "# cols_to_keep = ['osm_linkid','speedlimit_range_mph','lanes_per_direction']\n",
    "# links = links.merge(reconciled[cols_to_keep],on='osm_linkid',how='left')\n",
    "# del reconciled\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# #signals added\n",
    "# links_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='links',ignore_geometry=True)\n",
    "\n",
    "# nodes_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='nodes',ignore_geometry=True)\n",
    "# nodes_w_signals\n",
    "# #TODO change linkid to osm_linkid later\n",
    "# cols_to_keep = ['linkid','signal_A','signal_B']\n",
    "# links = links.merge(links_w_signals[cols_to_keep],on='linkid',how='left')\n",
    "# ##del nodes_w_signals\n",
    "\n",
    "# #elevation added\n",
    "# links_w_elevation = gpd.read_file(network_filepath/'elevation_added.gpkg',ignore_geometry=True)\n",
    "# links_w_elevation.columns\n",
    "# links_w_elevation.rename(columns={\n",
    "#     'a_s_c_e_n_t___m':'ascent_m',\n",
    "#     'd_e_s_c_e_n_t___m':'descent_m',\n",
    "#     'a_s_c_e_n_t___g_r_a_d_e':'ascent_grade',\n",
    "#     'd_e_s_c_e_n_t___g_r_a_d_e':'descent_grade',\n",
    "# }, inplace =True)\n",
    "# cols_to_keep = ['linkid','ascent_m','descent_m','ascent_grade','descent_grade','(0,2]_descent',\n",
    "#        '(2,4]_descent', '(4,6]_descent', '(6,10]_descent', '(10,15]_descent',\n",
    "#        '(15,inf]_descent', '(0,2]_ascent', '(2,4]_ascent', '(4,6]_ascent',\n",
    "#        '(6,10]_ascent', '(10,15]_ascent', '(15,inf]_ascent']\n",
    "# links = links.merge(links_w_elevation[cols_to_keep],on='linkid')\n",
    "# del links_w_elevation\n",
    "# links.columns\n",
    "# fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\"\n",
    "# edges = gpd.read_file(fp/'networks/elevation_added.gpkg',layer=\"links\")\n",
    "\n",
    "\n",
    "# edges.columns\n",
    "# #use geometry one last time\n",
    "# edges['length_ft'] = edges.length\n",
    "\n",
    "# #turn bridge and tunnel to boolean values\n",
    "# edges['tunnel'] = edges['tunnel'].notna()\n",
    "# edges['bridge'] = edges['bridge'].notna()\n",
    "# #turn bike facil into one column\n",
    "# edges['bike_facility_type'] = np.nan\n",
    "# edges.loc[(edges['mu'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'shared-use path'\n",
    "# edges.loc[(edges['pbl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'protected bike lane'\n",
    "# edges.loc[(edges['bl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'bike lane'\n",
    "# df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(edges,'A','B','linkid','oneway',True)\n",
    "# ## Add desired attributes from links to df_edges\n",
    "# #df_edges = df_edges.merge(edges[['linkid','geometry']])\n",
    "\n",
    "# basic_cols = ['linkid', 'osmid', 'link_type', 'name', 'oneway','length_ft']\n",
    "\n",
    "# #anything that's an instance or would be better as a count value (but not a turn)\n",
    "# event_cols = ['bridge','tunnel']\n",
    "\n",
    "# #anything that's for the duration of the entire link and has categories\n",
    "# category_cols = ['link_type','highway','speedlimit_range_mph',\n",
    "#                'lanes_per_direction','bike_facility_type']\n",
    "\n",
    "# #reverse in tuple form (these need to be flipped if going the other direction)\n",
    "# rev_columns = [('ascent_m','descent_m'),\n",
    "#                ('ascent_grade','descent_grade'),\n",
    "#                ('(0,2]_ascent','(0,2]_descent'),\n",
    "#                ('(2,4]_ascent','(2,4]_descent'),\n",
    "#                ('(4,6]_ascent','(4,6]_descent'),\n",
    "#                ('(6,10]_ascent','(6,10]_descent'),\n",
    "#                ('(10,15]_ascent','(10,15]_descent'),\n",
    "#                ('(15,inf]_ascent','(15,inf]_descent')]\n",
    "\n",
    "# from itertools import chain\n",
    "# keep_cols = basic_cols + event_cols + category_cols + list(chain(*rev_columns))\n",
    "# # attrs = ['linkid', 'osmid', 'link_type', 'name', 'highway',\n",
    "# #        'bridge', 'tunnel', 'bl', 'pbl', 'mu','speedlimit_range_mph',\n",
    "# #        'lanes_per_direction', 'up_grade', 'down_grade', 'length_ft',\n",
    "# #        'vehicle_separation','geometry']\n",
    "# df_edges = df_edges.merge(edges[keep_cols],on='linkid',how='left')\n",
    "# df_edges\n",
    "# ## Deal with grade\n",
    "# Need to flip sign of grade for reverse links\n",
    "# # def combine_up_down_tuples(lst):\n",
    "# #     result = []\n",
    "# #     current_tuple = []\n",
    "\n",
    "# #     for item in lst:\n",
    "# #         if 'ascent' in item or 'descent' in item:\n",
    "# #             current_tuple.append(item)\n",
    "# #             if len(current_tuple) == 2:\n",
    "# #                 result.append(tuple(current_tuple))\n",
    "# #                 current_tuple = []\n",
    "\n",
    "# #     return result\n",
    "\n",
    "# # rev_columns = ['ascent_m','descent_m','ascent_grade','descent_grade',\n",
    "# #                '(0,2]_down', '(2,4]_down', '(4,6]_down',\n",
    "# #                '(6,10]_down', '(10,15]_down','(15,inf]_down',\n",
    "# #                '(0,2]_up', '(2,4]_up', '(4,6]_up', '(6,10]_up',\n",
    "# #                '(10,15]_up', '(15,inf]_up'\n",
    "# #                ]\n",
    "\n",
    "# # combined_tuples = combine_up_down_tuples(rev_columns)\n",
    "\n",
    "# for elev_columns in rev_columns:\n",
    "#     df_edges[elev_columns[0]] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Turns and Signals\n",
    "# #add additional attributes needed for processing\n",
    "# source_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# target_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# source_links.columns = 'source_' + source_links.columns\n",
    "# target_links.columns = 'target_' + target_links.columns\n",
    "# pseudo_df = pseudo_df.merge(source_links,on='source_linkid',how='left')\n",
    "# pseudo_df = pseudo_df.merge(target_links,on='target_linkid',how='left')\n",
    "# ## Turn Restrictions\n",
    "# Two types in OSM (represented as OSM relations):\n",
    "# - No (blank) turns\n",
    "# - Only this turn allowed\n",
    "\n",
    "# For chosen we don't need to consider turn restrictions\n",
    "# # turn_restrictions = pd.read_csv(fp.parent/'osm_turn_restrictions.csv')\n",
    "# # pseudo_df = pseudo_df.merge(turn_restrictions,left_on=['source_osmid','target_osmid'],right_on=['from_way_id','to_way_id'],how='left')\n",
    "# # road_cond = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# # no_restr = pseudo_df['type'] == 'no'\n",
    "# # only_restr = pseudo_df['type'] == 'only'\n",
    "\n",
    "# # #add a remove column\n",
    "# # pseudo_df['remove'] = False\n",
    "\n",
    "# # #remove the no turns\n",
    "# # pseudo_df.loc[road_cond & no_restr,'remove'] = True\n",
    "\n",
    "# # #for only, find all instances road_cond + from source and set to True\n",
    "# # sources = set(turn_restrictions.loc[turn_restrictions['type']=='only','from_way_id'].tolist())\n",
    "# # pseudo_df.loc[road_cond & pseudo_df['source_osmid'].isin(sources) & pseudo_df['type'].isna(),'remove'] = True\n",
    "\n",
    "# # #Remove these turns and drop the added columns\n",
    "# # print((pseudo_df['remove']==True).sum(),'turns removed')\n",
    "# # pseudo_df = pseudo_df[pseudo_df['remove']==False]\n",
    "# # pseudo_df.drop(columns=['relation_id', 'restriction', 'from_way_id',\n",
    "# #        'to_way_id', 'type', 'remove'],inplace=True)\n",
    "# # Deal with signals\n",
    "# Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "# - For the source link, use signal_B if reverse == False else signal_A\n",
    "# - For the target link, use signal_A if reverse == False else signal_B\n",
    "# source = pseudo_df[['source_linkid','source_reverse_link']].merge(edges,left_on='source_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "# target = pseudo_df[['target_linkid','target_reverse_link']].merge(edges,left_on='target_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_B'], target['signal_A'])\n",
    "# ## Identifying signalized/unsignalized turns\n",
    "# - Only look at roads for now\n",
    "# - Filter to left/right turns per source linkid per direction\n",
    "# - Take the highest road classification and assign it as the cross street road classification\n",
    "# import pandas as pd\n",
    "# highway_order = {\n",
    "#     'trunk': 0,\n",
    "#     'trunk_link': 1,\n",
    "#     'primary': 2,\n",
    "#     'primary_link': 3,\n",
    "#     'secondary': 4,\n",
    "#     'secondary_link': 5,\n",
    "#     'tertiary': 6,\n",
    "#     'tertiary_link': 7,\n",
    "#     'unclassified': 8,\n",
    "#     'residential': 9\n",
    "# }\n",
    "# highway_order = pd.Series(highway_order)\n",
    "# highway_order = highway_order.reset_index()\n",
    "# highway_order.columns = ['highway','order']\n",
    "# #add highway ranking based on the above\n",
    "# pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# #remove straight and uturn\n",
    "# cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "# #only road to road for now\n",
    "# cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "# #use groupby to find the max target_highway order\n",
    "# cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# #change numbers back to normal\n",
    "# pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "# pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])\n",
    "# # TODO Add OSM crossing into this logic\n",
    "#     - Signals\n",
    "#         - Wait on this until we have the route attributes code done\n",
    "#         - Add crossings in signalization\n",
    "#         - Majority of crossings are nodes not ways\n",
    "#         - Cycleway crossings typically dealt the same way\n",
    "#         - If meeting nodes are both crossings and within the traffic signal buffer, they're signalized crossings\n",
    "#             - Or if both connecting links are crossings/connect to the road etc\n",
    "#         - Way attributes\n",
    "#             - Footway = crossing\n",
    "#             - Highway = footway\n",
    "#         - Node attributes\n",
    "#             - Crossing = * (traffic signals/marked/etc)\n",
    "#             - Highway = crossing\n",
    "#         - Link attributes\n",
    "#             - Some links are labeled as crossings but this is not as consistent\n",
    "\n",
    "# signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "# left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "# both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_street = pseudo_df['cross_street_order'] <= 5\n",
    "\n",
    "# #signalized\n",
    "# pseudo_df.loc[signalized & both_road,'signalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['signalized'].isna(),'signalized'] = False\n",
    "# # pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "# # pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "# pseudo_df.loc[-signalized & both_road & cross_street,'unsignalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['unsignalized'].isna(),'unsignalized'] = False\n",
    "\n",
    "# #clean up\n",
    "# rem =  ['source_osmid', 'source_link_type', 'source_name',\n",
    "#        'source_highway', 'target_osmid', 'target_link_type', 'target_name',\n",
    "#        'target_highway', 'source_signal', 'target_signal',\n",
    "#        'target_highway_order', 'source_highway_order', 'cross_street',\n",
    "#        'cross_street_order']\n",
    "# pseudo_df.drop(columns=rem,inplace=True)\n",
    "# # Export for impedance calibration\n",
    "\n",
    "# # df_edges = gpd.GeoDataFrame(df_edges,crs='epsg:2240')\n",
    "# df_edges.columns\n",
    "# with (fp.parent / 'chosen.pkl').open('wb') as fh:\n",
    "#     export = (df_edges,pseudo_df,pseudo_G)\n",
    "#     pickle.dump(export,fh)\n",
    "# ## Add geometry to examine results in QGIS\n",
    "# #add geo\n",
    "# link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "# pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "# pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "# pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "# pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "# #check results (may need a smaller road network to test on)\n",
    "# pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
