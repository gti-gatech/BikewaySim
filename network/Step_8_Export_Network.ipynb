{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prepare\n",
    "This step adds in the supplemental attributes prepared in the previous notebooks (e.g., traffic signals, bicycle facilities (with approx. install dates), elevation, etc.). Links where cyclists are absolutely not allowed to travel (Interstates) are removed. A psuedo dual graph for modeling turn movements is created, and the links, nodes, and turns are exported for further processing in the `impedance_calibration` module.\n",
    "\n",
    "For the GDOT/NCST projects, the following attributes were available: (TURN THIS INTO A TABLE LIKE IN THE REPORT LATER)\n",
    "- Length\n",
    "- Grade/Elevation\n",
    "- Bike Facility w Dates\n",
    "- Oneway\n",
    "- Signals\n",
    "- AADT\n",
    "- Truck %\n",
    "- Lanes\n",
    "- Speed Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from shapely.ops import Point\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import modeling_turns, add_attributes, prepare_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import network links and add attributes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197721 links 6892.0 miles 150880 nodes\n",
      "                         size    length_mi  length_pct\n",
      "link_type                                             \n",
      "road                    70233  3286.461080   47.685569\n",
      "service                 49685  1118.567079   16.230074\n",
      "parking_and_driveways   37505  1072.045948   15.555067\n",
      "sidewalk                22633   543.082566    7.879966\n",
      "restricted_access_road   2014   256.544600    3.722386\n",
      "pedestrian              11622   243.736461    3.536543\n",
      "no_bike                  1367   237.511755    3.446225\n",
      "bike                     2593   127.630901    1.851886\n",
      "no_access_or_private       18     3.367666    0.048864\n",
      "Raw network is 6938.0 miles\n"
     ]
    }
   ],
   "source": [
    "links = gpd.read_file(config['network_fp'] /'networks.gpkg',layer='osm_links')\n",
    "og_cols = links.columns\n",
    "nodes = gpd.read_file(config['network_fp'] / 'networks.gpkg',layer='osm_nodes')\n",
    "\n",
    "#TODO modify network filter to stop adding the network name like this\n",
    "links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "\n",
    "#calculate link lengths\n",
    "links['length_ft'] = links.length\n",
    "\n",
    "#basic stats\n",
    "print(links.shape[0],'links',(links.length.sum() / 5280).round(0),'miles',nodes.shape[0],'nodes')\n",
    "\n",
    "#types and lengths\n",
    "summary_df = pd.DataFrame({'size':links['link_type'].value_counts(),\n",
    "                           'length_mi':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum() / 5280),\n",
    "                           'length_pct':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum()) / links.length.sum() * 100})\n",
    "print(summary_df.sort_values('length_mi',ascending=False))\n",
    "\n",
    "#add osm attributes back (especially the oneway column)\n",
    "osm_attrs = gpd.read_file(config['osmdwnld_fp'] / f\"osm.gpkg\",layer='raw')\n",
    "\n",
    "# # get basic stats\n",
    "osm_attrs.to_crs(links.crs,inplace=True)\n",
    "print('Raw network is',(osm_attrs.length / 5280).sum().round(0),'miles')\n",
    "links = pd.merge(links,osm_attrs.drop(columns=['oneway','geometry']),on='osmid')\n",
    "del osm_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bicycle infrastructure and approximate date of opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multi use path', 'bike lane', 'cycletrack', 'sharrow',\n",
       "       'buffered bike lane', None], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycling_infra_dates = gpd.read_file(config['bicycle_facilities_fp']/'osm_cycleways_w_dates.gpkg',layer='dates_network')\n",
    "cycling_infra_dates['facility_fwd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facility            year  \n",
       "bike lane           2004.0     2.44\n",
       "                    2006.0     0.45\n",
       "                    2007.0     4.95\n",
       "                    2008.0    16.52\n",
       "                    2010.0     4.65\n",
       "                    2011.0     8.29\n",
       "                    2012.0     4.09\n",
       "                    2013.0     2.62\n",
       "                    2014.0     5.37\n",
       "                    2015.0     2.37\n",
       "                    2016.0     9.71\n",
       "                    2017.0     1.06\n",
       "                    2018.0     6.49\n",
       "                    2019.0     2.70\n",
       "                    2020.0     2.88\n",
       "                    2021.0     3.62\n",
       "                    2022.0     0.07\n",
       "                    2023.0     0.53\n",
       "buffered bike lane  2004.0     0.01\n",
       "                    2008.0     0.07\n",
       "                    2012.0     0.16\n",
       "                    2013.0     0.85\n",
       "                    2014.0     0.31\n",
       "                    2015.0     0.54\n",
       "                    2016.0     0.24\n",
       "                    2017.0     0.48\n",
       "                    2018.0     1.03\n",
       "                    2019.0     0.53\n",
       "                    2020.0     0.21\n",
       "                    2021.0     0.04\n",
       "cycletrack          2005.0     0.09\n",
       "                    2013.0     0.23\n",
       "                    2015.0     1.04\n",
       "                    2016.0     0.87\n",
       "                    2017.0     1.72\n",
       "                    2019.0     0.27\n",
       "                    2021.0     2.48\n",
       "multi use path      1970.0     1.39\n",
       "                    1976.0     2.39\n",
       "                    1995.0     0.15\n",
       "                    2005.0     3.07\n",
       "                    2006.0     0.68\n",
       "                    2007.0     8.80\n",
       "                    2008.0    13.85\n",
       "                    2009.0     3.43\n",
       "                    2010.0     2.75\n",
       "                    2011.0     0.06\n",
       "                    2012.0     5.26\n",
       "                    2013.0     1.78\n",
       "                    2014.0     1.45\n",
       "                    2015.0     5.62\n",
       "                    2016.0     8.41\n",
       "                    2017.0     7.35\n",
       "                    2018.0     6.36\n",
       "                    2019.0     3.62\n",
       "                    2020.0     4.06\n",
       "                    2021.0     6.26\n",
       "                    2022.0     0.99\n",
       "Name: length_ft, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.merge(links,cycling_infra_dates[['osm_linkid','facility_fwd','facility_rev','facility','year']],left_on='linkid',right_on='osm_linkid',how='left')\n",
    "links.drop(columns=['osm_linkid'],inplace=True)\n",
    "(links.groupby(['facility','year'])['length_ft'].sum() / 5280).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove off street infrastructure built after 2016\n",
    "Some of these may have still existed as informal dirt paths (Beltline). In that case add them back in manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = 2016\n",
    "max_year_cond = links['year'] > max_year\n",
    "\n",
    "links.loc[max_year_cond].to_file(config['bicycle_facilities_fp']/'removed_bicycle_infra.gpkg')\n",
    "\n",
    "# # remove infra before 2016 so it doesn't match to these\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_fwd'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_rev'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility'] = None\n",
    "\n",
    "#TODO reimplement this but don't remove links from the link database, just the graph so that we can do it dynamically\n",
    "# NOTE this doesn't do anything because all the attributes are already set to none\n",
    "after = links['facility'].isin(['cycletrack','multi use path']) & \\\n",
    "          (links['link_type']!='road') & \\\n",
    "          links['year'].notna() & \\\n",
    "          (links['year']>max_year)\n",
    "links = links[after==False]\n",
    "\n",
    "# set no facility values to null\n",
    "links.loc[links['facility_fwd'] == 'no facility','facility_fwd'] = None\n",
    "links.loc[links['facility_rev'] == 'no facility','facility_rev'] = None\n",
    "\n",
    "# nans to None\n",
    "links.loc[links['facility_fwd'].isna(),'facility_fwd'] = None\n",
    "links.loc[links['facility_rev'].isna(),'facility_rev'] = None\n",
    "links.loc[links['facility'].isna(),'facility'] = None\n",
    "\n",
    "# save in new column for reference for comparison\n",
    "# links['future_facility'] = links['facility_fwd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidepaths\n",
    "Add adjacent multi-use paths and cycletracks to roads as an attribute and vice versa. Think Stone Mountain Trail or Beltline next to Wylie Street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to bike infra and roads\n",
    "mups_and_cycletracks = cycling_infra_dates.loc[cycling_infra_dates['link_type']!='road',['osm_linkid','facility','year','geometry']]\n",
    "mups_and_cycletracks.rename(columns={'osm_linkid':'sidepath_linkid','facility':'sidepath','year':'sidepath_year'},inplace=True)\n",
    "roads = links.loc[links['link_type']=='road',['linkid','geometry']].copy()\n",
    "roads['og_length'] = roads.length\n",
    "\n",
    "# get azimuth for getting angle change\n",
    "roads.to_crs('epsg:4326',inplace=True)\n",
    "roads[['fwd_azimuth','bck_azimuth']] = roads.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "roads.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "mups_and_cycletracks.to_crs('epsg:4326',inplace=True)\n",
    "mups_and_cycletracks[['fwd_azimuth','bck_azimuth']] = mups_and_cycletracks.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "mups_and_cycletracks.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "# buffer by small amount\n",
    "buffer_ft = 50\n",
    "mups_and_cycletracks.set_geometry(mups_and_cycletracks.buffer(buffer_ft),inplace=True)\n",
    "\n",
    "# intersect\n",
    "intersection = gpd.overlay(roads,mups_and_cycletracks)\n",
    "\n",
    "# calculate coverage and angle change (hausdorff distance returns too many false positives)\n",
    "intersection['new_length'] = intersection.length\n",
    "intersection['ratio'] = intersection['new_length']/intersection['og_length']\n",
    "\n",
    "# angle difference (take min to account for direction differences)\n",
    "intersection['diff1'] = np.abs(intersection['fwd_azimuth_1'] - intersection['bck_azimuth_2'])\n",
    "intersection['diff2'] = np.abs(intersection['fwd_azimuth_1'] - intersection['fwd_azimuth_2'])\n",
    "intersection['mindiff'] = intersection[['diff1','diff2']].min(axis=1)\n",
    "\n",
    "# set minimum conditions for accepting\n",
    "cond0 = intersection['ratio'] > 0.95 # this much coverage of the original link\n",
    "cond1 = intersection['mindiff'] < 30 # no more than this change in angle\n",
    "intersection = intersection[cond0&cond1]\n",
    "\n",
    "# just take the one with the most overlap after that\n",
    "has_sidepath = intersection.loc[intersection.groupby('linkid')['ratio'].idxmax()]#,['linkid','sidepath','sideear','geometry']]\n",
    "\n",
    "# buffer the sidepaths again and perform unary union to get the connected parts\n",
    "connected_parts = gpd.GeoDataFrame({'geometry':has_sidepath.buffer(50).unary_union},index=[0],crs=config['projected_crs_epsg']).reset_index()\n",
    "\n",
    "# intersect with the has_sidepath layer again and group by\n",
    "# need 400 feet next to a road to count as sidepath\n",
    "intersect2 = gpd.overlay(has_sidepath,connected_parts)\n",
    "intersect2['adjacent_length_ft'] = intersect2.groupby('index')['og_length'].transform(sum)\n",
    "# intersect2[intersect2['adjacent_length_ft']>400].explore()\n",
    "final_sidepaths = intersect2.loc[intersect2['adjacent_length_ft']>400,['linkid','sidepath_linkid','sidepath','sidepath_year','geometry']]\n",
    "# final_sidepaths\n",
    "# final_sidepaths.explore()\n",
    "final_sidepaths.to_file(config['bicycle_facilities_fp']/'sidepaths.gpkg',layer='sidepaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back into main network dataframe\n",
    "links = pd.merge(links,final_sidepaths.drop(columns='geometry'),on='linkid',how='left')\n",
    "\n",
    "# NOTE 10/14/24 instead of adding in the infra here, leave it as is becuase the buffer optimization should account for this\n",
    "# assign the facility to the road if it doesn't already have facility\n",
    "# links0 = links.copy()\n",
    "# cond = links[['sidepath_linkid']].notna().all(axis=1) & links[['facility_fwd','facility_rev','facility']].isna().all(axis=1)\n",
    "# links.loc[cond,['facility_fwd','facility_rev','facility']] = links.loc[cond,['sidepath','sidepath','sidepath']].values\n",
    "# assign year if there is one\n",
    "# cond = links['sidepath_year'].notna() & links['year'].isna()\n",
    "# links.loc[cond,'year'] = links['sidepath_year']\n",
    "\n",
    "# assign the road attributes to the sidepath (i.e., attach the adjacent road linkid) (future step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Network Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atlanta Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='coa',ignore_geometry=True)\n",
    "links = pd.merge(links,improvements,left_on='linkid',right_on='osm_linkid',how='left')\n",
    "links.drop(columns=['osm_linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Savannah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='savannah',ignore_geometry=True)\n",
    "# links = pd.merge(links,improvements,on='osm_linkid',how='left')\n",
    "# links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GDOT data\n",
    "GDOT provides # of lanes data, AADT, and truck %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdot_lanes = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_lanes\",ignore_geometry=True)\n",
    "gdot_lanes['state_route'] = gdot_lanes['route_type'] == 'State Route' # TODO add to the GDOT notebook\n",
    "gdot_traffic = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_traffic\",ignore_geometry=True)\n",
    "\n",
    "links = pd.merge(links,gdot_lanes,on=\"osmid\",how='left')\n",
    "links = pd.merge(links,gdot_traffic,on='osmid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle null aadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['AADT'].isna()].explore()\n",
    "# give residential roads the lowest aadt category or below\n",
    "links.loc[links['AADT'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'AADT'] = '[0,4k)'\n",
    "# all others the middle category\n",
    "links.loc[links['AADT'].isna() & (links['link_type']=='road'),'AADT'] = '[4k,10k)'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get the lowest category)\n",
    "links.loc[links['AADT'].isna(),'AADT'] = '[0,4k)'\n",
    "\n",
    "#turn it into categorical data\n",
    "links['AADT'] = pd.Categorical(links['AADT'],ordered=True,categories=['[0,4k)','[4k,10k)','[10k,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add HERE data (SKIP IF NO HERE DATA)\n",
    "HERE provides speed and lanes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"here\",ignore_geometry=True)\n",
    "links = pd.merge(links,here,left_on='linkid',right_on='osm_linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling null speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['here_speed'].isna()].explore()\n",
    "# links[links['here_speed'].isna()&(links['link_type']=='road')]['highway'].unique()\n",
    "# give residential roads a speed limit of 30 or below\n",
    "links.loc[links['here_speed'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'here_speed'] = '[0,30]'\n",
    "# all others get 30 +\n",
    "links.loc[links['here_speed'].isna() & (links['link_type']=='road'),'here_speed'] = '(30,40]'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get a speed limit of 30 or below)\n",
    "links.loc[links['here_speed'].isna(),'here_speed'] = '[0,30]'\n",
    "links.rename(columns={'here_speed':'speed'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['speed'] = pd.Categorical(links['speed'],ordered=True,categories=['[0,30]', '(30,40]', '(40,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve GDOT/HERE lanes data\n",
    "- All non-road links get a 1 (doing this so lanes attribute isn't being confounded with vehicle access)\n",
    "- By direction is too detailed, use a per direction estimate (i.e. treat a 5 lane oneway road the same as a 10 lane twoway road or a 5 lane per direction)\n",
    "- Simplify to:\n",
    "    - 1 lane per direction\n",
    "    - 2 lanes per direction\n",
    "    - 3+ lanes per direction\n",
    "- If unequal number of lanes use direction that would result in the higher category\n",
    "    - Example: 10th Street NE would be 2 lanes per direction because it has 2/1 lanes by direction\n",
    "- Turn lanes (middle, right, etc) are NOT counted in HERE or GDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO figure out what to do when there is a disrepency between the lanes\n",
    "## Examine where there's a big mismatch between HERE and GDOT\n",
    "# - There are a couple of cases where GDOT will be way off, like North Highland Ave NE which shows up as having four lanes when it's mostly 2 lanes for most of its length.\n",
    "# - Memorial Drive is also marked as having four lanes but it was road dieted post 2016, so just use the old value.\n",
    "# - Unless it's a residential street or a few cases that were identified, use the GDOT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give everything a default value of 1 (before we would give non-motorized links a value of 0)\n",
    "links['lanes'] = 1\n",
    "\n",
    "#if one is null take the non null value\n",
    "links.loc[links['here_lanes'].isna() & links['gdot_lanes'].notna(),'lanes'] = links['gdot_lanes']\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].isna(),'lanes'] = links['here_lanes']\n",
    "\n",
    "#otherwise choose whichever is smaller\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].notna(),'lanes'] = links[['here_lanes','gdot_lanes']].min(axis=1)\n",
    "\n",
    "#drop to trim down the df\n",
    "links.drop(columns=['gdot_lanes','here_lanes'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add elevation data\n",
    "Assign the correct direction for reverse links later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = gpd.read_file(config['network_fp']/'elevation.gpkg',layer='elevation',ignore_geometry=True)\n",
    "elevation = elevation[['linkid','ascent_ft','descent_ft','ascent_grade_cat','descent_grade_cat']]\n",
    "links = pd.merge(links,elevation,on='linkid',how='left')\n",
    "# del elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ascent grade and descent grade to zero\n",
    "links.loc[links['ascent_grade_cat'].isna(),'ascent_grade_cat'] = '[0,4)'\n",
    "links.loc[links['descent_grade_cat'].isna(),'descent_grade_cat'] = '[0,4)'\n",
    "links.loc[:,['ascent_ft','descent_ft']] = links.loc[:,['ascent_ft','descent_ft']].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for remaining bridge where lidar data was not available set the grade to 0 if grade exceeds 10 percent\n",
    "# links.loc[(links['bridge'] == 'yes') & (links['ascent_grade_%'] > 10),'ascent_grade_%'] = 0\n",
    "# #also for tunnels\n",
    "# links.loc[(links['tunnel'] == 'yes'),'ascent_grade_%'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse links and turn dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change this to not create the turn graph (just make it an extra optional step)\n",
    "## Create turn graph dataframe\n",
    "from importlib import reload\n",
    "reload(modeling_turns)\n",
    "directed_links, turns_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "\n",
    "# find the degree of the intersection node and re-classify anything with degree 2 as straight turn movement?\n",
    "# what about interstate exits that got removed?\n",
    "from collections import Counter\n",
    "node_degree = dict(Counter(links['A'].tolist()+links['B'].tolist()))\n",
    "turns_df['node_degree'] = turns_df['source_B'].map(node_degree)\n",
    "# turns_df[turns_df['node_degree']==2,'turn_type'] = 'straight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add signals from OSM and GDOT to turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signalized\n",
       "False    747298\n",
       "True      19170\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_signals = pd.read_pickle(config['network_fp']/'osm_signals.pkl')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "gdot_signals = pd.read_pickle(config['network_fp']/'gdot_signals.pkl')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "\n",
    "osm_signals = set([tuple(x) for x in osm_signals.values])\n",
    "gdot_signals = set([tuple(x) for x in gdot_signals.values])\n",
    "added_signals = set.union(osm_signals,gdot_signals)\n",
    "\n",
    "turns_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "\n",
    "added_signals = set.intersection(set(turns_df.index.tolist()),added_signals)\n",
    "turns_df.loc[list(added_signals),'signalized'] = True\n",
    "turns_df.loc[turns_df['signalized'].isna(),'signalized'] = False\n",
    "\n",
    "turns_df.reset_index(inplace=True)\n",
    "\n",
    "turns_df['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in cross street variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_linkid</th>\n",
       "      <th>source_reverse_link</th>\n",
       "      <th>target_linkid</th>\n",
       "      <th>target_reverse_link</th>\n",
       "      <th>source_A</th>\n",
       "      <th>source_B</th>\n",
       "      <th>target_A</th>\n",
       "      <th>target_B</th>\n",
       "      <th>source_azimuth</th>\n",
       "      <th>target_azimuth</th>\n",
       "      <th>...</th>\n",
       "      <th>source_highway</th>\n",
       "      <th>source_link_type</th>\n",
       "      <th>source_lanes</th>\n",
       "      <th>source_AADT</th>\n",
       "      <th>source_speed</th>\n",
       "      <th>target_highway</th>\n",
       "      <th>target_link_type</th>\n",
       "      <th>target_lanes</th>\n",
       "      <th>target_AADT</th>\n",
       "      <th>target_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13803</td>\n",
       "      <td>True</td>\n",
       "      <td>32689</td>\n",
       "      <td>True</td>\n",
       "      <td>69116629</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>315350788</td>\n",
       "      <td>53.9</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13803</td>\n",
       "      <td>True</td>\n",
       "      <td>38135</td>\n",
       "      <td>True</td>\n",
       "      <td>69116629</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>819937163</td>\n",
       "      <td>53.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32689</td>\n",
       "      <td>True</td>\n",
       "      <td>38088</td>\n",
       "      <td>True</td>\n",
       "      <td>69123159</td>\n",
       "      <td>315350788</td>\n",
       "      <td>315350788</td>\n",
       "      <td>816341008</td>\n",
       "      <td>70.7</td>\n",
       "      <td>30.5</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32689</td>\n",
       "      <td>True</td>\n",
       "      <td>32688</td>\n",
       "      <td>False</td>\n",
       "      <td>69123159</td>\n",
       "      <td>315350788</td>\n",
       "      <td>315350788</td>\n",
       "      <td>69108344</td>\n",
       "      <td>70.7</td>\n",
       "      <td>215.7</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>restricted_access_road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32689</td>\n",
       "      <td>False</td>\n",
       "      <td>13803</td>\n",
       "      <td>False</td>\n",
       "      <td>315350788</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69123159</td>\n",
       "      <td>69116629</td>\n",
       "      <td>250.7</td>\n",
       "      <td>233.9</td>\n",
       "      <td>...</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>motorway</td>\n",
       "      <td>no_bike</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766463</th>\n",
       "      <td>156271</td>\n",
       "      <td>False</td>\n",
       "      <td>173547</td>\n",
       "      <td>False</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>6840401971</td>\n",
       "      <td>5.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766464</th>\n",
       "      <td>156270</td>\n",
       "      <td>True</td>\n",
       "      <td>156269</td>\n",
       "      <td>True</td>\n",
       "      <td>7081874786</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>7081870781</td>\n",
       "      <td>115.8</td>\n",
       "      <td>182.9</td>\n",
       "      <td>...</td>\n",
       "      <td>service</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766465</th>\n",
       "      <td>156270</td>\n",
       "      <td>True</td>\n",
       "      <td>156271</td>\n",
       "      <td>False</td>\n",
       "      <td>7081874786</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>115.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>service</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766466</th>\n",
       "      <td>173548</td>\n",
       "      <td>True</td>\n",
       "      <td>156271</td>\n",
       "      <td>True</td>\n",
       "      <td>8404063942</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>7081870782</td>\n",
       "      <td>298.4</td>\n",
       "      <td>185.2</td>\n",
       "      <td>...</td>\n",
       "      <td>service</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766467</th>\n",
       "      <td>173548</td>\n",
       "      <td>True</td>\n",
       "      <td>173547</td>\n",
       "      <td>False</td>\n",
       "      <td>8404063942</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>8404063941</td>\n",
       "      <td>6840401971</td>\n",
       "      <td>298.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>service</td>\n",
       "      <td>parking_and_driveways</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "      <td>residential</td>\n",
       "      <td>road</td>\n",
       "      <td>1</td>\n",
       "      <td>[0,4k)</td>\n",
       "      <td>[0,30]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766468 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_linkid  source_reverse_link  target_linkid  \\\n",
       "0               13803                 True          32689   \n",
       "1               13803                 True          38135   \n",
       "2               32689                 True          38088   \n",
       "3               32689                 True          32688   \n",
       "4               32689                False          13803   \n",
       "...               ...                  ...            ...   \n",
       "766463         156271                False         173547   \n",
       "766464         156270                 True         156269   \n",
       "766465         156270                 True         156271   \n",
       "766466         173548                 True         156271   \n",
       "766467         173548                 True         173547   \n",
       "\n",
       "        target_reverse_link    source_A    source_B    target_A    target_B  \\\n",
       "0                      True    69116629    69123159    69123159   315350788   \n",
       "1                      True    69116629    69123159    69123159   819937163   \n",
       "2                      True    69123159   315350788   315350788   816341008   \n",
       "3                     False    69123159   315350788   315350788    69108344   \n",
       "4                     False   315350788    69123159    69123159    69116629   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "766463                False  7081870782  8404063941  8404063941  6840401971   \n",
       "766464                 True  7081874786  7081870782  7081870782  7081870781   \n",
       "766465                False  7081874786  7081870782  7081870782  8404063941   \n",
       "766466                 True  8404063942  8404063941  8404063941  7081870782   \n",
       "766467                False  8404063942  8404063941  8404063941  6840401971   \n",
       "\n",
       "        source_azimuth  target_azimuth  ...  source_highway  \\\n",
       "0                 53.9            70.7  ...        motorway   \n",
       "1                 53.9            92.0  ...        motorway   \n",
       "2                 70.7            30.5  ...        motorway   \n",
       "3                 70.7           215.7  ...        motorway   \n",
       "4                250.7           233.9  ...        motorway   \n",
       "...                ...             ...  ...             ...   \n",
       "766463             5.2            20.5  ...     residential   \n",
       "766464           115.8           182.9  ...         service   \n",
       "766465           115.8             5.2  ...         service   \n",
       "766466           298.4           185.2  ...         service   \n",
       "766467           298.4            20.5  ...         service   \n",
       "\n",
       "             source_link_type  source_lanes source_AADT source_speed  \\\n",
       "0                     no_bike             1      [0,4k)       [0,30]   \n",
       "1                     no_bike             1      [0,4k)       [0,30]   \n",
       "2                     no_bike             1      [0,4k)       [0,30]   \n",
       "3                     no_bike             1      [0,4k)       [0,30]   \n",
       "4                     no_bike             1      [0,4k)       [0,30]   \n",
       "...                       ...           ...         ...          ...   \n",
       "766463                   road             1      [0,4k)       [0,30]   \n",
       "766464  parking_and_driveways             1      [0,4k)       [0,30]   \n",
       "766465  parking_and_driveways             1      [0,4k)       [0,30]   \n",
       "766466  parking_and_driveways             1      [0,4k)       [0,30]   \n",
       "766467  parking_and_driveways             1      [0,4k)       [0,30]   \n",
       "\n",
       "       target_highway        target_link_type target_lanes target_AADT  \\\n",
       "0            motorway                 no_bike            1      [0,4k)   \n",
       "1       motorway_link  restricted_access_road            1      [0,4k)   \n",
       "2            motorway                 no_bike            1      [0,4k)   \n",
       "3       motorway_link  restricted_access_road            1      [0,4k)   \n",
       "4            motorway                 no_bike            1      [0,4k)   \n",
       "...               ...                     ...          ...         ...   \n",
       "766463    residential                    road            1      [0,4k)   \n",
       "766464    residential                    road            1      [0,4k)   \n",
       "766465    residential                    road            1      [0,4k)   \n",
       "766466    residential                    road            1      [0,4k)   \n",
       "766467    residential                    road            1      [0,4k)   \n",
       "\n",
       "       target_speed  \n",
       "0            [0,30]  \n",
       "1            [0,30]  \n",
       "2            [0,30]  \n",
       "3            [0,30]  \n",
       "4            [0,30]  \n",
       "...             ...  \n",
       "766463       [0,30]  \n",
       "766464       [0,30]  \n",
       "766465       [0,30]  \n",
       "766466       [0,30]  \n",
       "766467       [0,30]  \n",
       "\n",
       "[766468 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach speed, lanes, AADT, and osm hihgway\n",
    "link_attrs = links.copy()[['linkid','highway','link_type','lanes','AADT','speed']]\n",
    "link_attrs.set_index('linkid',inplace=True)\n",
    "\n",
    "source_cols = ['source_' + x for x in link_attrs.columns]\n",
    "target_cols = ['target_' + x for x in link_attrs.columns]\n",
    "\n",
    "link_attrs.columns = source_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='source_linkid',right_index=True,how='left')\n",
    "link_attrs.columns = target_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='target_linkid',right_index=True,how='left')\n",
    "turns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross street would be to the left or right\n",
    "cond1 = turns_df['turn_type'].isin(['left','right'])\n",
    "\n",
    "#only road to road for now\n",
    "cond2 = (turns_df['source_link_type'] == 'road') & (turns_df['target_link_type'] == 'road')\n",
    "cross_streets = turns_df[cond1&cond2]\n",
    "\n",
    "# get the worst possible cross street attribute\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_reverse_link'])[['target_AADT','target_lanes','target_speed']].max()\n",
    "cross_streets.columns = ['cross_AADT','cross_lanes','cross_speed']\n",
    "test = turns_df.merge(cross_streets,left_on=['source_linkid','source_reverse_link'],right_index=True)#,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a stressful turn would be\n",
    "aadt_cross_cond = test['cross_AADT'] == '[10k,inf)'\n",
    "lanes_cross_cond = test['cross_lanes'] > 2\n",
    "speed_cross_cond = test['cross_speed'] >= '(30,40]'\n",
    "cross_high_stress = aadt_cross_cond | lanes_cross_cond | speed_cross_cond\n",
    "\n",
    "# if the source street has these stats then assume that there is a signal\n",
    "aadt_source_cond = test['source_AADT'] == '[10k,inf)'\n",
    "lanes_source_cond = test['source_lanes'] > 2\n",
    "speed_source_cond = test['source_speed'] >= '(30,40]'\n",
    "source_high_stress = aadt_source_cond | lanes_source_cond | speed_source_cond\n",
    "\n",
    "test['unsig_crossing'] = False\n",
    "test.loc[(source_high_stress==False) & cross_high_stress & (test['signalized']==False) & (test['turn_type'].isin(['straight','left'])),'unsig_crossing'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unsignalized crossing variable back in\n",
    "turns_df = pd.merge(turns_df,test[['source_linkid','source_reverse_link','target_linkid','target_reverse_link','unsig_crossing']],on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optional add geo data to turns and export for examination\n",
    "# reload(modeling_turns)\n",
    "# cross_streets_gdf = modeling_turns.turn_gdf(links,test)\n",
    "# for idx,x in enumerate(cross_streets_gdf.dtypes):\n",
    "#     if (str(x) == \"category\") | (str(x)=='object'):\n",
    "#         cross_streets_gdf.iloc[:,idx] = cross_streets_gdf.iloc[:,idx].astype(str)\n",
    "# cross_streets_gdf.to_file(config['network_fp']/'scratch.gpkg',layer='cross_streets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes[nodes['N'].isin(set(cross_streets_gdf.loc[cross_streets_gdf['unsig_crossing']==True,'source_B'].tolist()))].explore() # looks much more reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure hwat i was going for here\n",
    "# # get the worst possible cross street attribute\n",
    "# # cross_streets.groupby(['source_linkid','source_reverse_link'])['target_AADT','target_lanes','target_speed'].idxmax()\n",
    "# cross_streets.loc[18242]\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['target_speed'].max()\n",
    "\n",
    "\n",
    "# # find the worst cross street if there are multiple\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['aadt'].apply(lambda x: aadt_order)\n",
    "\n",
    "\n",
    "# # TODO do this for the other variables too\n",
    "# cols = ['AADT','lanes','speed']\n",
    "# for x in cols:\n",
    "#     print(links[x].unique())\n",
    "# # rules for high stress turns\n",
    "\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #traffic\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | \\\n",
    "#                            (links['highway'].isin(major_road_values) & (links['lanes'] < 2) ), \n",
    "#                             'linkid'].tolist())\n",
    "# cross_streets.loc[cross_streets['source_linkid']==3]\n",
    "# print(links[links['linkid']==3].squeeze())\n",
    "# links[links['linkid']==3].explore()\n",
    "\n",
    "# # grouby the source link\n",
    "# cross_streets.groupby(['source_linkid'])['target_highway'].agg(list)#['target_highway_order'].min()\n",
    "\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pd.merge(turns_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# # wasn't able to get major/minor to be significant\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | links['lanes'] < 2,'linkid'].tolist())\n",
    "\n",
    "# #unsignalized straight/left turn where crossing street is a major road\n",
    "# turns_df['unsig_major_road_crossing'] = (turns_df['signalized']==False) & \\\n",
    "#     turns_df['target_linkid'].isin(major_road) & \\\n",
    "#     turns_df['source_linkid'].isin(minor_road) & \\\n",
    "#     turns_df['turn_type'].isin(['left','straight'])\n",
    "\n",
    "# # #sets turns that are not from road to road to None, effectively ignoring them\n",
    "# # exclude = ['road','service']\n",
    "# # turns_df.loc[(turns_df['source_link_type'].isin(exclude)==False) & \n",
    "# #              (turns_df['target_link_type'].isin(exclude)==False),'turn_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create layer of unsignalized crossings for examining\n",
    "unsig_major_road_crossing = set(turns_df.loc[turns_df['unsig_crossing']==True,'source_B'].tolist())\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "nodes = nodes[nodes['N'].isin(unsig_major_road_crossing)]\n",
    "nodes.to_file(config['calibration_fp']/'unsig_major_road_crossing.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Interstates and Private Links\n",
    "Remove these because we're absolutely sure we don't want bikes on these links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_bike' 'restricted_access_road' 'service' 'parking_and_driveways'\n",
      " 'road' 'bike' 'pedestrian' 'sidewalk' None 'no_access_or_private']\n"
     ]
    }
   ],
   "source": [
    "print(links['link_type'].unique())\n",
    "remove = ['no_access_or_private','restricted_access_road','no_bike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399 links removed\n"
     ]
    }
   ],
   "source": [
    "remove_cond = links['link_type'].isin(remove)\n",
    "links = links[remove_cond==False]\n",
    "print(remove_cond.sum(),'links removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove isolated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before connected components: Links 193722 Nodes 4210\n",
      "After connected components: Links 193305 Nodes 4210\n"
     ]
    }
   ],
   "source": [
    "links, nodes = prepare_network.largest_comp_and_simplify(links,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df = turns_df[turns_df['source_linkid'].isin(set(links['linkid'].tolist())) & turns_df['target_linkid'].isin(set(links['linkid'].tolist()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'linkid', 'oneway', 'link_type', 'osmid', 'geometry',\n",
       "       'length_ft', 'timestamp', 'version', 'type', 'highway', 'name',\n",
       "       'bridge', 'tunnel', 'cycleway', 'service', 'footway', 'sidewalk',\n",
       "       'bicycle', 'foot', 'access', 'area', 'surface', 'all_tags', 'geom_type',\n",
       "       'facility_fwd', 'facility_rev', 'facility', 'year', 'sidepath_linkid',\n",
       "       'sidepath', 'sidepath_year', 'coa_id', 'coa_name', 'improvement',\n",
       "       'route_type', 'state_route', 'AADT', 'truck_pct', 'osm_linkid', 'speed',\n",
       "       'lanes', 'ascent_ft', 'descent_ft', 'ascent_grade_cat',\n",
       "       'descent_grade_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed\n"
     ]
    }
   ],
   "source": [
    "final_cols = [\n",
    "    'A', 'B', 'linkid', 'osmid', 'oneway', 'highway', 'name','all_tags', # OSM derived or ID variables\n",
    "    'link_type',\n",
    "    'facility_fwd', 'facility_rev', 'facility', 'year',\n",
    "    # 'sidepath_linkid', 'sidepath', 'sidepath_year', # export this seperately\n",
    "    'state_route', 'AADT', 'speed', 'lanes',\n",
    "    'ascent_ft', 'descent_ft','ascent_grade_cat','descent_grade_cat',\n",
    "    'length_ft', 'geometry'\n",
    "    ]\n",
    "\n",
    "# export with the catagorical values\n",
    "links[final_cols].to_pickle(config['network_fp']/'final_network_edges.parquet')\n",
    "\n",
    "#TODO create a function for performing this\n",
    "for col, dtype in links.dtypes.to_dict().items():\n",
    "    if (str(dtype) == \"category\"):\n",
    "        links[col] = links[col].astype(str).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'AADT'\n",
    "links[col] = links[col].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18        [0,4k)\n",
       "20        [0,4k)\n",
       "21        [0,4k)\n",
       "22        [0,4k)\n",
       "23        [0,4k)\n",
       "           ...  \n",
       "197116    [0,4k)\n",
       "197117    [0,4k)\n",
       "197118    [0,4k)\n",
       "197119    [0,4k)\n",
       "197120    [0,4k)\n",
       "Name: AADT, Length: 193305, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.loc[:,'AADT'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18        [0,4k)\n",
       "20        [0,4k)\n",
       "21        [0,4k)\n",
       "22        [0,4k)\n",
       "23        [0,4k)\n",
       "           ...  \n",
       "197116    [0,4k)\n",
       "197117    [0,4k)\n",
       "197118    [0,4k)\n",
       "197119    [0,4k)\n",
       "197120    [0,4k)\n",
       "Name: AADT, Length: 193305, dtype: category\n",
       "Categories (3, object): ['[0,4k)' < '[4k,10k)' < '[10k,inf)']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.loc[:,'AADT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0,4k)'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['AADT'].astype(str)[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18        [0,4k)\n",
       "20        [0,4k)\n",
       "21        [0,4k)\n",
       "22        [0,4k)\n",
       "23        [0,4k)\n",
       "           ...  \n",
       "197116    [0,4k)\n",
       "197117    [0,4k)\n",
       "197118    [0,4k)\n",
       "197119    [0,4k)\n",
       "197120    [0,4k)\n",
       "Name: AADT, Length: 193305, dtype: category\n",
       "Categories (3, object): ['[0,4k)' < '[4k,10k)' < '[10k,inf)']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['AADT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                    False\n",
       "B                    False\n",
       "linkid               False\n",
       "osmid                False\n",
       "oneway               False\n",
       "highway              False\n",
       "name                 False\n",
       "all_tags             False\n",
       "link_type            False\n",
       "facility_fwd         False\n",
       "facility_rev         False\n",
       "facility             False\n",
       "year                 False\n",
       "state_route          False\n",
       "AADT                  True\n",
       "speed                 True\n",
       "lanes                False\n",
       "ascent_ft            False\n",
       "descent_ft           False\n",
       "ascent_grade_cat     False\n",
       "descent_grade_cat    False\n",
       "length_ft            False\n",
       "geometry             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[final_cols].dtypes == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AADT\n",
       "[0,4k)       172174\n",
       "[10k,inf)     12996\n",
       "[4k,10k)       8135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[''].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'CategoricalDtype(categories=['[0,4k)', '[4k,10k)', '[10k,inf)'], ordered=True, categories_dtype=object)' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlinks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfinal_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetwork_fp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_network.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m nodes\u001b[38;5;241m.\u001b[39mto_file(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork_fp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_network.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m,layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\bikewaysim\\Lib\\site-packages\\geopandas\\geodataframe.py:1249\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m \n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \n\u001b[0;32m   1246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1249\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\bikewaysim\\Lib\\site-packages\\geopandas\\io\\file.py:610\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 610\u001b[0m     \u001b[43m_to_file_fiona\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    612\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\bikewaysim\\Lib\\site-packages\\geopandas\\io\\file.py:619\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[1;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_file_fiona\u001b[39m(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[43minfer_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m crs:\n\u001b[0;32m    622\u001b[0m         crs \u001b[38;5;241m=\u001b[39m pyproj\u001b[38;5;241m.\u001b[39mCRS\u001b[38;5;241m.\u001b[39mfrom_user_input(crs)\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\bikewaysim\\Lib\\site-packages\\geopandas\\io\\file.py:693\u001b[0m, in \u001b[0;36minfer_schema\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    688\u001b[0m         out_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_type\n\u001b[0;32m    691\u001b[0m properties \u001b[38;5;241m=\u001b[39m OrderedDict(\n\u001b[0;32m    692\u001b[0m     [\n\u001b[1;32m--> 693\u001b[0m         (col, \u001b[43mconvert_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m col, _type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns, df\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m df\u001b[38;5;241m.\u001b[39m_geometry_column_name\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    697\u001b[0m )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    700\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are attempting to write an empty DataFrame to file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor some drivers, this operation may fail.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    704\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    705\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\bikewaysim\\Lib\\site-packages\\geopandas\\io\\file.py:686\u001b[0m, in \u001b[0;36minfer_schema.<locals>.convert_type\u001b[1;34m(column, in_type)\u001b[0m\n\u001b[0;32m    684\u001b[0m     out_type \u001b[38;5;241m=\u001b[39m types[\u001b[38;5;28mstr\u001b[39m(in_type)]\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m     out_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    688\u001b[0m     out_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret 'CategoricalDtype(categories=['[0,4k)', '[4k,10k)', '[10k,inf)'], ordered=True, categories_dtype=object)' as a data type"
     ]
    }
   ],
   "source": [
    "\n",
    "links[final_cols].to_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes.to_file(config['network_fp']/'final_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directional attributes and flip as needed\n",
    "ascent_columns = ['ascent_ft', 'ascent_grade_cat']\n",
    "descent_columns = ['descent_ft', 'descent_grade_cat']\n",
    "directed_links = pd.merge(directed_links,links[['linkid','facility_fwd','facility_rev']+ascent_columns+descent_columns],on='linkid')\n",
    "directed_links.loc[directed_links['reverse_link']==True,ascent_columns+descent_columns] = directed_links.loc[directed_links['reverse_link']==True,descent_columns+ascent_columns].values\n",
    "directed_links.loc[directed_links['reverse_link']==True,['facility_fwd','facility_rev']] = directed_links.loc[directed_links['reverse_link']==True,['facility_rev','facility_fwd']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple columns not compatible with parquet\n",
    "# turns_df.drop(columns=['source','target'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pickles later\n",
    "turns_df.to_parquet(config['network_fp']/'turns_df.parquet')\n",
    "directed_links.to_parquet(config['network_fp']/'directed_edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO create a function for performing this\n",
    "for idx,x in enumerate(turns_df.dtypes):\n",
    "    if (str(x) == \"category\"): #| (str(x)=='object'):\n",
    "        turns_df.iloc[:,idx] = turns_df.iloc[:,idx].astype(str)\n",
    "\n",
    "#optional add geo data to turns and export for examination\n",
    "from shapely.ops import MultiLineString\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))\n",
    "turns_df['source_geo'] = turns_df['source_linkid'].map(geo_dict)\n",
    "turns_df['target_geo'] = turns_df['target_linkid'].map(geo_dict)\n",
    "turns_df['geometry'] = turns_df.apply(lambda row: MultiLineString([row['source_geo'],row['target_geo']]),axis=1)\n",
    "turns_df.drop(columns=['source_geo','target_geo'],inplace=True)\n",
    "turns_gdf = gpd.GeoDataFrame(turns_df,crs=links.crs)\n",
    "# turns_gdf.drop(columns=['source','target'])\n",
    "turns_gdf.to_file(config['network_fp']/'final_network.gpkg',layer='turns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO serialize the attributes to add as needed?\n",
    "# with (config['network_fp'] / 'edges_with_attributes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['network_fp'] / 'edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(links,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'nodes.pkl').open('wb') as fh:\n",
    "#     pickle.dump(nodes,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'directed_edges.pkl').open('wb') as fh:\n",
    "#     pickle.dump(edges,fh,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with (config['network_fp'] / 'turn_df.pkl').open('wb') as fh:\n",
    "#     pickle.dump(turn_df,fh,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated past here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #add attributes back and then flip elevation/bicyccle attributes\n",
    "# #do so i don't have to re-flip everytime i import? could potentially save memory though\n",
    "# #TODO it would still be smarter to store as a dict or something\n",
    "# edges\n",
    "# links.columns\n",
    "# edges = pd.merge(edges,links.drop(columns=['A','B']),on='linkid')\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nana\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap if reverse geometry == true\n",
    "#     links.loc[links['reverse_geometry']==True,ascent_columns+descent_columns] = links.loc[links['reverse_geometry']==True,descent_columns+ascent_columns]\n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# #if reverse_geo == true then ascent should be descent and vice versa\n",
    "# # loops have reverse_geometry is np.nan\n",
    "# # assume that all elevation columns will be paired by what is after ascent/descent\n",
    "# elevation_columns = ['ascent_m', 'descent_m', 'ascent_grade_%','descent_grade_%']\n",
    "# # Remove elements containing \"ascent\" or \"descent\"\n",
    "# cleaned_columns = [col for col in elevation_columns if \"ascent\" not in col and \"descent\" not in col]    \n",
    "# # Remove duplicates by converting the list to a set and back to a list\n",
    "# cleaned_columns = list(set(cleaned_columns))\n",
    "\n",
    "# for cleaned_column in cleaned_columns:\n",
    "#     #swap\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_edges[] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Rename columns\n",
    "\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# ## \n",
    "# ## Create turn graph dataframe\n",
    "# edges, turn_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "# ## Flip attributes if needed (elevation, bicycle facilities)\n",
    "# Turns should be good as is\n",
    "# #add geo (needed for map matching part)\n",
    "# df_edges = df_edges.merge(links.drop(columns=['A','B']),on=['linkid'])\n",
    "# df_edges = gpd.GeoDataFrame(df_edges,geometry='geometry',crs=links.crs)\n",
    "# df_edges = df_edges.loc[:,~df_edges.columns.duplicated()].copy()\n",
    "# df_edges.reset_index(drop=True,inplace=True)\n",
    "# #just export the df_edges?\n",
    "# df_edges.to_file(export_fp/'Map_Matching/matching.gpkg',layer='edges')\n",
    "# nodes.to_file(export_fp/'Map_Matching/matching.gpkg',layer='nodes')\n",
    "# pseudo_df.columns\n",
    "# #add geo to the turns too\n",
    "# from shapely.ops import MultiLineString\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='source_linkid',right_on='linkid')\n",
    "# pseudo_df = pseudo_df.merge(links[['linkid','geometry']],left_on='target_linkid',right_on='linkid')\n",
    "\n",
    "# geometry = pseudo_df.apply(lambda row: MultiLineString([row['geometry_x'],row['geometry_y']]),axis=1)\n",
    "# pseudo_df.drop(columns=['geometry_x','geometry_y','linkid_x','linkid_y'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,geometry=geometry,crs=links.crs)\n",
    "\n",
    "# # pseudo_edges = pseudo_edges.loc[:,~pseudo_edges.columns.duplicated()].copy()\n",
    "# # pseudo_edges.reset_index(drop=True,inplace=True)\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "# pseudo_df.to_file(export_fp/'Map_Matching/matching.gpkg',layer='turns')\n",
    "# #pickle the graph\n",
    "# with (export_fp / 'Map_Matching/turn_G.pkl').open('wb') as fh:\n",
    "#     pickle.dump(pseudo_G,fh)\n",
    "# # Come back to below later\n",
    "# # Network Prepare\n",
    "# This notebook prepares the final routing network.\n",
    "\n",
    "# 1. Import the desired routing network\n",
    "# 1. Add attributes\n",
    "# 1. Add reconciled attributes\n",
    "# 1. Add signals\n",
    "# 1. Add elevation\n",
    "\n",
    "# Then the network will be turned into a directed network graph complete with an edge list representing the directed edges and another one representing turns. Some attribute values are reversed to account for direction (e.g., elevation, signals).\n",
    "# Import the data from previous notebooks and merge them. Merge here so updates can be done at each step without having to repeat everything.\n",
    "# network_filepath = Path.home() / \"Documents/BikewaySimData/Projects/gdot/networks\"\n",
    "# #filtered data\n",
    "# links = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_links')\n",
    "# nodes = gpd.read_file(network_filepath/'filtered.gpkg',layer='osm_nodes')\n",
    "# links.columns\n",
    "# #add osm data\n",
    "# links = add_attributes.add_osm_attr(links,network_filepath / 'osm_attr.pkl')\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# links.columns\n",
    "# #reconciled data\n",
    "# reconciled = gpd.read_file(network_filepath/'reconciled.gpkg',layer='links',ignore_geometry=True)\n",
    "# #[col for col in reconciled.columns if col not in links.columns]\n",
    "# cols_to_keep = ['osm_linkid','speedlimit_range_mph','lanes_per_direction']\n",
    "# links = links.merge(reconciled[cols_to_keep],on='osm_linkid',how='left')\n",
    "# del reconciled\n",
    "# #rename\n",
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)\n",
    "# #signals added\n",
    "# links_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='links',ignore_geometry=True)\n",
    "\n",
    "# nodes_w_signals = gpd.read_file(network_filepath/'signals_added.gpkg',layer='nodes',ignore_geometry=True)\n",
    "# nodes_w_signals\n",
    "# #TODO change linkid to osm_linkid later\n",
    "# cols_to_keep = ['linkid','signal_A','signal_B']\n",
    "# links = links.merge(links_w_signals[cols_to_keep],on='linkid',how='left')\n",
    "# ##del nodes_w_signals\n",
    "\n",
    "# #elevation added\n",
    "# links_w_elevation = gpd.read_file(network_filepath/'elevation_added.gpkg',ignore_geometry=True)\n",
    "# links_w_elevation.columns\n",
    "# links_w_elevation.rename(columns={\n",
    "#     'a_s_c_e_n_t___m':'ascent_m',\n",
    "#     'd_e_s_c_e_n_t___m':'descent_m',\n",
    "#     'a_s_c_e_n_t___g_r_a_d_e':'ascent_grade',\n",
    "#     'd_e_s_c_e_n_t___g_r_a_d_e':'descent_grade',\n",
    "# }, inplace =True)\n",
    "# cols_to_keep = ['linkid','ascent_m','descent_m','ascent_grade','descent_grade','(0,2]_descent',\n",
    "#        '(2,4]_descent', '(4,6]_descent', '(6,10]_descent', '(10,15]_descent',\n",
    "#        '(15,inf]_descent', '(0,2]_ascent', '(2,4]_ascent', '(4,6]_ascent',\n",
    "#        '(6,10]_ascent', '(10,15]_ascent', '(15,inf]_ascent']\n",
    "# links = links.merge(links_w_elevation[cols_to_keep],on='linkid')\n",
    "# del links_w_elevation\n",
    "# links.columns\n",
    "# fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\"\n",
    "# edges = gpd.read_file(fp/'networks/elevation_added.gpkg',layer=\"links\")\n",
    "\n",
    "\n",
    "# edges.columns\n",
    "# #use geometry one last time\n",
    "# edges['length_ft'] = edges.length\n",
    "\n",
    "# #turn bridge and tunnel to boolean values\n",
    "# edges['tunnel'] = edges['tunnel'].notna()\n",
    "# edges['bridge'] = edges['bridge'].notna()\n",
    "# #turn bike facil into one column\n",
    "# edges['bike_facility_type'] = np.nan\n",
    "# edges.loc[(edges['mu'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'shared-use path'\n",
    "# edges.loc[(edges['pbl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'protected bike lane'\n",
    "# edges.loc[(edges['bl'] == 1) & (edges['bike_facility_type'].isna()),'bike_facility_type'] = 'bike lane'\n",
    "# df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(edges,'A','B','linkid','oneway',True)\n",
    "# ## Add desired attributes from links to df_edges\n",
    "# #df_edges = df_edges.merge(edges[['linkid','geometry']])\n",
    "\n",
    "# basic_cols = ['linkid', 'osmid', 'link_type', 'name', 'oneway','length_ft']\n",
    "\n",
    "# #anything that's an instance or would be better as a count value (but not a turn)\n",
    "# event_cols = ['bridge','tunnel']\n",
    "\n",
    "# #anything that's for the duration of the entire link and has categories\n",
    "# category_cols = ['link_type','highway','speedlimit_range_mph',\n",
    "#                'lanes_per_direction','bike_facility_type']\n",
    "\n",
    "# #reverse in tuple form (these need to be flipped if going the other direction)\n",
    "# rev_columns = [('ascent_m','descent_m'),\n",
    "#                ('ascent_grade','descent_grade'),\n",
    "#                ('(0,2]_ascent','(0,2]_descent'),\n",
    "#                ('(2,4]_ascent','(2,4]_descent'),\n",
    "#                ('(4,6]_ascent','(4,6]_descent'),\n",
    "#                ('(6,10]_ascent','(6,10]_descent'),\n",
    "#                ('(10,15]_ascent','(10,15]_descent'),\n",
    "#                ('(15,inf]_ascent','(15,inf]_descent')]\n",
    "\n",
    "# from itertools import chain\n",
    "# keep_cols = basic_cols + event_cols + category_cols + list(chain(*rev_columns))\n",
    "# # attrs = ['linkid', 'osmid', 'link_type', 'name', 'highway',\n",
    "# #        'bridge', 'tunnel', 'bl', 'pbl', 'mu','speedlimit_range_mph',\n",
    "# #        'lanes_per_direction', 'up_grade', 'down_grade', 'length_ft',\n",
    "# #        'vehicle_separation','geometry']\n",
    "# df_edges = df_edges.merge(edges[keep_cols],on='linkid',how='left')\n",
    "# df_edges\n",
    "# ## Deal with grade\n",
    "# Need to flip sign of grade for reverse links\n",
    "# # def combine_up_down_tuples(lst):\n",
    "# #     result = []\n",
    "# #     current_tuple = []\n",
    "\n",
    "# #     for item in lst:\n",
    "# #         if 'ascent' in item or 'descent' in item:\n",
    "# #             current_tuple.append(item)\n",
    "# #             if len(current_tuple) == 2:\n",
    "# #                 result.append(tuple(current_tuple))\n",
    "# #                 current_tuple = []\n",
    "\n",
    "# #     return result\n",
    "\n",
    "# # rev_columns = ['ascent_m','descent_m','ascent_grade','descent_grade',\n",
    "# #                '(0,2]_down', '(2,4]_down', '(4,6]_down',\n",
    "# #                '(6,10]_down', '(10,15]_down','(15,inf]_down',\n",
    "# #                '(0,2]_up', '(2,4]_up', '(4,6]_up', '(6,10]_up',\n",
    "# #                '(10,15]_up', '(15,inf]_up'\n",
    "# #                ]\n",
    "\n",
    "# # combined_tuples = combine_up_down_tuples(rev_columns)\n",
    "\n",
    "# for elev_columns in rev_columns:\n",
    "#     df_edges[elev_columns[0]] = np.where(df_edges['reverse_link'], df_edges[elev_columns[1]].abs(), df_edges[elev_columns[0]])\n",
    "#     #drop the down version?\n",
    "#     df_edges.drop(columns=elev_columns[1],inplace=True)\n",
    "# ## Turns and Signals\n",
    "# #add additional attributes needed for processing\n",
    "# source_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# target_links = edges[['linkid','osmid','link_type','name','highway']]\n",
    "# source_links.columns = 'source_' + source_links.columns\n",
    "# target_links.columns = 'target_' + target_links.columns\n",
    "# pseudo_df = pseudo_df.merge(source_links,on='source_linkid',how='left')\n",
    "# pseudo_df = pseudo_df.merge(target_links,on='target_linkid',how='left')\n",
    "# ## Turn Restrictions\n",
    "# Two types in OSM (represented as OSM relations):\n",
    "# - No (blank) turns\n",
    "# - Only this turn allowed\n",
    "\n",
    "# For chosen we don't need to consider turn restrictions\n",
    "# # turn_restrictions = pd.read_csv(fp.parent/'osm_turn_restrictions.csv')\n",
    "# # pseudo_df = pseudo_df.merge(turn_restrictions,left_on=['source_osmid','target_osmid'],right_on=['from_way_id','to_way_id'],how='left')\n",
    "# # road_cond = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# # no_restr = pseudo_df['type'] == 'no'\n",
    "# # only_restr = pseudo_df['type'] == 'only'\n",
    "\n",
    "# # #add a remove column\n",
    "# # pseudo_df['remove'] = False\n",
    "\n",
    "# # #remove the no turns\n",
    "# # pseudo_df.loc[road_cond & no_restr,'remove'] = True\n",
    "\n",
    "# # #for only, find all instances road_cond + from source and set to True\n",
    "# # sources = set(turn_restrictions.loc[turn_restrictions['type']=='only','from_way_id'].tolist())\n",
    "# # pseudo_df.loc[road_cond & pseudo_df['source_osmid'].isin(sources) & pseudo_df['type'].isna(),'remove'] = True\n",
    "\n",
    "# # #Remove these turns and drop the added columns\n",
    "# # print((pseudo_df['remove']==True).sum(),'turns removed')\n",
    "# # pseudo_df = pseudo_df[pseudo_df['remove']==False]\n",
    "# # pseudo_df.drop(columns=['relation_id', 'restriction', 'from_way_id',\n",
    "# #        'to_way_id', 'type', 'remove'],inplace=True)\n",
    "# # Deal with signals\n",
    "# Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "# - For the source link, use signal_B if reverse == False else signal_A\n",
    "# - For the target link, use signal_A if reverse == False else signal_B\n",
    "# source = pseudo_df[['source_linkid','source_reverse_link']].merge(edges,left_on='source_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "# target = pseudo_df[['target_linkid','target_reverse_link']].merge(edges,left_on='target_linkid',right_on='linkid',how='left')\n",
    "# pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_B'], target['signal_A'])\n",
    "# ## Identifying signalized/unsignalized turns\n",
    "# - Only look at roads for now\n",
    "# - Filter to left/right turns per source linkid per direction\n",
    "# - Take the highest road classification and assign it as the cross street road classification\n",
    "# import pandas as pd\n",
    "# highway_order = {\n",
    "#     'trunk': 0,\n",
    "#     'trunk_link': 1,\n",
    "#     'primary': 2,\n",
    "#     'primary_link': 3,\n",
    "#     'secondary': 4,\n",
    "#     'secondary_link': 5,\n",
    "#     'tertiary': 6,\n",
    "#     'tertiary_link': 7,\n",
    "#     'unclassified': 8,\n",
    "#     'residential': 9\n",
    "# }\n",
    "# highway_order = pd.Series(highway_order)\n",
    "# highway_order = highway_order.reset_index()\n",
    "# highway_order.columns = ['highway','order']\n",
    "# #add highway ranking based on the above\n",
    "# pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])\n",
    "# #remove straight and uturn\n",
    "# cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "# #only road to road for now\n",
    "# cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "# #use groupby to find the max target_highway order\n",
    "# cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# #change numbers back to normal\n",
    "# pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "# pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])\n",
    "# # TODO Add OSM crossing into this logic\n",
    "#     - Signals\n",
    "#         - Wait on this until we have the route attributes code done\n",
    "#         - Add crossings in signalization\n",
    "#         - Majority of crossings are nodes not ways\n",
    "#         - Cycleway crossings typically dealt the same way\n",
    "#         - If meeting nodes are both crossings and within the traffic signal buffer, they're signalized crossings\n",
    "#             - Or if both connecting links are crossings/connect to the road etc\n",
    "#         - Way attributes\n",
    "#             - Footway = crossing\n",
    "#             - Highway = footway\n",
    "#         - Node attributes\n",
    "#             - Crossing = * (traffic signals/marked/etc)\n",
    "#             - Highway = crossing\n",
    "#         - Link attributes\n",
    "#             - Some links are labeled as crossings but this is not as consistent\n",
    "\n",
    "# signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "# left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "# both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# cross_street = pseudo_df['cross_street_order'] <= 5\n",
    "\n",
    "# #signalized\n",
    "# pseudo_df.loc[signalized & both_road,'signalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['signalized'].isna(),'signalized'] = False\n",
    "# # pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "# # pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "# pseudo_df.loc[-signalized & both_road & cross_street,'unsignalized'] = True\n",
    "# pseudo_df.loc[pseudo_df['unsignalized'].isna(),'unsignalized'] = False\n",
    "\n",
    "# #clean up\n",
    "# rem =  ['source_osmid', 'source_link_type', 'source_name',\n",
    "#        'source_highway', 'target_osmid', 'target_link_type', 'target_name',\n",
    "#        'target_highway', 'source_signal', 'target_signal',\n",
    "#        'target_highway_order', 'source_highway_order', 'cross_street',\n",
    "#        'cross_street_order']\n",
    "# pseudo_df.drop(columns=rem,inplace=True)\n",
    "# # Export for impedance calibration\n",
    "\n",
    "# # df_edges = gpd.GeoDataFrame(df_edges,crs='epsg:2240')\n",
    "# df_edges.columns\n",
    "# with (fp.parent / 'chosen.pkl').open('wb') as fh:\n",
    "#     export = (df_edges,pseudo_df,pseudo_G)\n",
    "#     pickle.dump(export,fh)\n",
    "# ## Add geometry to examine results in QGIS\n",
    "# #add geo\n",
    "# link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "# pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "# pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "# pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "# pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "# pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "# pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "# pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "# #check results (may need a smaller road network to test on)\n",
    "# pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
