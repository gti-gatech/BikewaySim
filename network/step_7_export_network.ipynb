{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prepare\n",
    "This step adds in the supplemental attributes prepared in the previous notebooks (e.g., traffic signals, bicycle facilities (with approx. install dates), elevation, etc.). Links where cyclists are absolutely not allowed to travel (Interstates) are removed. A psuedo dual graph for modeling turn movements is created, and the links, nodes, and turns are exported for further processing in the `impedance_calibration` module.\n",
    "\n",
    "For the GDOT/NCST projects, the following attributes were available: (TURN THIS INTO A TABLE LIKE IN THE REPORT LATER)\n",
    "- Length\n",
    "- Grade/Elevation\n",
    "- Bike Facility w Dates\n",
    "- Oneway\n",
    "- Signals\n",
    "- AADT\n",
    "- Truck %\n",
    "- Lanes\n",
    "- Speed Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from shapely.ops import Point\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import modeling_turns, add_attributes, prepare_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import network links and add attributes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33022 links 220.0 miles 23753 nodes\n",
      "                         size  length_mi  length_pct\n",
      "link_type                                           \n",
      "road                     8310  71.871846   32.599980\n",
      "sidewalk                10257  65.318927   29.627675\n",
      "parking_and_driveways    4020  25.144034   11.404952\n",
      "service                  5259  23.998295   10.885263\n",
      "pedestrian               3692  15.588511    7.070712\n",
      "bike                     1035   8.841100    4.010189\n",
      "restricted_access_road    167   5.272429    2.391494\n",
      "no_bike                   280   4.427084    2.008058\n",
      "Raw network is 221.0 miles\n"
     ]
    }
   ],
   "source": [
    "links = gpd.read_file(config['network_fp'] /'networks.gpkg',layer='osm_links')\n",
    "nodes = gpd.read_file(config['network_fp'] / 'networks.gpkg',layer='osm_nodes')\n",
    "\n",
    "#calculate link lengths\n",
    "links['length_ft'] = links.length\n",
    "\n",
    "#basic stats\n",
    "print(links.shape[0],'links',(links.length.sum() / 5280).round(0),'miles',nodes.shape[0],'nodes')\n",
    "\n",
    "#types and lengths\n",
    "summary_df = pd.DataFrame({'size':links['link_type'].value_counts(),\n",
    "                           'length_mi':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum() / 5280),\n",
    "                           'length_pct':links.groupby('link_type')['geometry'].apply(lambda x: x.length.sum()) / links.length.sum() * 100})\n",
    "print(summary_df.sort_values('length_mi',ascending=False))\n",
    "\n",
    "#add osm attributes back (especially the oneway column)\n",
    "osm_attrs = gpd.read_file(config['network_fp'] / f\"osm.gpkg\",layer='raw')\n",
    "\n",
    "# # get basic stats\n",
    "osm_attrs.to_crs(links.crs,inplace=True)\n",
    "print('Raw network is',(osm_attrs.length / 5280).sum().round(0),'miles')\n",
    "links = pd.merge(links,osm_attrs.drop(columns=['oneway','geometry']),on='osmid')\n",
    "del osm_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bicycle infrastructure and approximate date of opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multi use path', 'bike lane', 'cycletrack', 'buffered bike lane',\n",
       "       None, 'sharrow'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycling_infra_dates = gpd.read_file(config['bicycle_facilities_fp']/'osm_cycleways_w_dates.gpkg',layer='dates_network')\n",
    "cycling_infra_dates['facility_fwd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facility            year  \n",
       "bike lane           2007.0    0.16\n",
       "                    2008.0    1.58\n",
       "                    2010.0    0.25\n",
       "                    2011.0    0.23\n",
       "                    2012.0    0.01\n",
       "                    2013.0    0.18\n",
       "                    2014.0    0.19\n",
       "                    2015.0    0.12\n",
       "                    2016.0    0.03\n",
       "                    2017.0    0.09\n",
       "                    2018.0    0.40\n",
       "                    2020.0    0.41\n",
       "                    2021.0    0.13\n",
       "                    2023.0    0.02\n",
       "buffered bike lane  2013.0    0.24\n",
       "                    2014.0    0.02\n",
       "                    2015.0    0.05\n",
       "                    2016.0    0.01\n",
       "cycletrack          2005.0    0.06\n",
       "                    2013.0    0.07\n",
       "                    2015.0    0.31\n",
       "                    2016.0    0.19\n",
       "                    2017.0    0.21\n",
       "                    2019.0    0.07\n",
       "                    2021.0    0.20\n",
       "multi use path      1976.0    0.80\n",
       "                    2007.0    0.05\n",
       "                    2008.0    1.99\n",
       "                    2010.0    0.09\n",
       "                    2012.0    0.67\n",
       "                    2016.0    0.02\n",
       "                    2017.0    0.43\n",
       "                    2018.0    0.13\n",
       "                    2019.0    0.23\n",
       "                    2021.0    0.61\n",
       "                    2024.0    0.02\n",
       "Name: length_ft, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.merge(links,cycling_infra_dates[['linkid','facility_fwd','facility_rev','facility','year']],on='linkid',how='left')\n",
    "(links.groupby(['facility','year'])['length_ft'].sum() / 5280).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove off street infrastructure built after 2016\n",
    "Some of these may have still existed as informal dirt paths (Beltline). In that case add them back in manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = 2016\n",
    "max_year_cond = links['year'] > max_year\n",
    "\n",
    "links.loc[max_year_cond].to_file(config['bicycle_facilities_fp']/'removed_bicycle_infra.gpkg')\n",
    "\n",
    "# # remove infra before 2016 so it doesn't match to these\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_fwd'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility_rev'] = None\n",
    "links.loc[max_year_cond & (links['link_type']=='road'),'facility'] = None\n",
    "\n",
    "#TODO reimplement this but don't remove links from the link database, just the graph so that we can do it dynamically\n",
    "# NOTE this doesn't do anything because all the attributes are already set to none\n",
    "after = links['facility'].isin(['cycletrack','multi use path']) & \\\n",
    "          (links['link_type']!='road') & \\\n",
    "          links['year'].notna() & \\\n",
    "          (links['year']>max_year)\n",
    "links = links[after==False]\n",
    "\n",
    "# set no facility values to null\n",
    "links.loc[links['facility_fwd'] == 'no facility','facility_fwd'] = None\n",
    "links.loc[links['facility_rev'] == 'no facility','facility_rev'] = None\n",
    "\n",
    "# nans to None\n",
    "links.loc[links['facility_fwd'].isna(),'facility_fwd'] = None\n",
    "links.loc[links['facility_rev'].isna(),'facility_rev'] = None\n",
    "links.loc[links['facility'].isna(),'facility'] = None\n",
    "\n",
    "# save in new column for reference for comparison\n",
    "# links['future_facility'] = links['facility_fwd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidepaths\n",
    "Add adjacent multi-use paths and cycletracks to roads as an attribute and vice versa. Think Stone Mountain Trail or Beltline next to Wylie Street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to bike infra and roads\n",
    "mups_and_cycletracks = cycling_infra_dates.loc[cycling_infra_dates['link_type']!='road',['linkid','facility','year','geometry']]\n",
    "mups_and_cycletracks.rename(columns={'linkid':'sidepath_linkid','facility':'sidepath','year':'sidepath_year'},inplace=True)\n",
    "roads = links.loc[links['link_type']=='road',['linkid','geometry']].copy()\n",
    "roads['og_length'] = roads.length\n",
    "\n",
    "# get azimuth for getting angle change\n",
    "roads.to_crs('epsg:4326',inplace=True)\n",
    "roads[['fwd_azimuth','bck_azimuth']] = roads.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "roads.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "mups_and_cycletracks.to_crs('epsg:4326',inplace=True)\n",
    "mups_and_cycletracks[['fwd_azimuth','bck_azimuth']] = mups_and_cycletracks.apply(lambda row: modeling_turns.find_azimuth(row),axis=1)\n",
    "mups_and_cycletracks.to_crs(config['projected_crs_epsg'],inplace=True)\n",
    "\n",
    "# buffer by small amount\n",
    "buffer_ft = 50\n",
    "mups_and_cycletracks.set_geometry(mups_and_cycletracks.buffer(buffer_ft),inplace=True)\n",
    "\n",
    "# intersect\n",
    "intersection = gpd.overlay(roads,mups_and_cycletracks)\n",
    "\n",
    "# calculate coverage and angle change (hausdorff distance returns too many false positives)\n",
    "intersection['new_length'] = intersection.length\n",
    "intersection['ratio'] = intersection['new_length']/intersection['og_length']\n",
    "\n",
    "# angle difference (take min to account for direction differences)\n",
    "intersection['diff1'] = np.abs(intersection['fwd_azimuth_1'] - intersection['bck_azimuth_2'])\n",
    "intersection['diff2'] = np.abs(intersection['fwd_azimuth_1'] - intersection['fwd_azimuth_2'])\n",
    "intersection['mindiff'] = intersection[['diff1','diff2']].min(axis=1)\n",
    "\n",
    "# set minimum conditions for accepting\n",
    "cond0 = intersection['ratio'] > 0.95 # this much coverage of the original link\n",
    "cond1 = intersection['mindiff'] < 30 # no more than this change in angle\n",
    "intersection = intersection[cond0&cond1]\n",
    "\n",
    "# just take the one with the most overlap after that\n",
    "has_sidepath = intersection.loc[intersection.groupby('linkid')['ratio'].idxmax()]#,['linkid','sidepath','sideear','geometry']]\n",
    "\n",
    "# buffer the sidepaths again and perform unary union to get the connected parts\n",
    "connected_parts = gpd.GeoDataFrame({'geometry':has_sidepath.buffer(50).unary_union},index=[0],crs=config['projected_crs_epsg']).reset_index()\n",
    "\n",
    "# intersect with the has_sidepath layer again and group by\n",
    "# need 400 feet next to a road to count as sidepath\n",
    "intersect2 = gpd.overlay(has_sidepath,connected_parts)\n",
    "intersect2['adjacent_length_ft'] = intersect2.groupby('index')['og_length'].transform(sum)\n",
    "# intersect2[intersect2['adjacent_length_ft']>400].explore()\n",
    "final_sidepaths = intersect2.loc[intersect2['adjacent_length_ft']>400,['linkid','sidepath_linkid','sidepath','sidepath_year','geometry']]\n",
    "# final_sidepaths\n",
    "# final_sidepaths.explore()\n",
    "final_sidepaths.to_file(config['bicycle_facilities_fp']/'sidepaths.gpkg',layer='sidepaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back into main network dataframe\n",
    "links = pd.merge(links,final_sidepaths.drop(columns='geometry'),on='linkid',how='left')\n",
    "\n",
    "# NOTE 10/14/24 instead of adding in the infra here, leave it as is becuase the buffer optimization should account for this\n",
    "# assign the facility to the road if it doesn't already have facility\n",
    "# links0 = links.copy()\n",
    "# cond = links[['sidepath_linkid']].notna().all(axis=1) & links[['facility_fwd','facility_rev','facility']].isna().all(axis=1)\n",
    "# links.loc[cond,['facility_fwd','facility_rev','facility']] = links.loc[cond,['sidepath','sidepath','sidepath']].values\n",
    "# assign year if there is one\n",
    "# cond = links['sidepath_year'].notna() & links['year'].isna()\n",
    "# links.loc[cond,'year'] = links['sidepath_year']\n",
    "\n",
    "# assign the road attributes to the sidepath (i.e., attach the adjacent road linkid) (future step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Network Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atlanta Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "/Users/tannerpassmore/Documents/BikewaySim/Davis/Bicycle_Facilities/network_improvements.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m improvements \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbicycle_facilities_fp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetwork_improvements.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mignore_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m links \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(links,improvements,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinkid\u001b[39m\u001b[38;5;124m'\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/bikewaysim/lib/python3.13/site-packages/geopandas/io/file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[0;32m~/mambaforge/envs/bikewaysim/lib/python3.13/site-packages/geopandas/io/file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    544\u001b[0m     )\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bikewaysim/lib/python3.13/site-packages/pyogrio/geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/mambaforge/envs/bikewaysim/lib/python3.13/site-packages/pyogrio/raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDataSourceError\u001b[0m: /Users/tannerpassmore/Documents/BikewaySim/Davis/Bicycle_Facilities/network_improvements.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='coa',ignore_geometry=True)\n",
    "links = pd.merge(links,improvements,on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Savannah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements = gpd.read_file(config['bicycle_facilities_fp']/'network_improvements.gpkg',layer='savannah',ignore_geometry=True)\n",
    "# links = pd.merge(links,improvements,on='osm_linkid',how='left')\n",
    "# links.drop(columns=['linkid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GDOT data\n",
    "GDOT provides # of lanes data, AADT, and truck %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdot_lanes = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_lanes\",ignore_geometry=True)\n",
    "gdot_lanes['state_route'] = gdot_lanes['route_type'] == 'State Route' # TODO add to the GDOT notebook\n",
    "gdot_traffic = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"gdot_traffic\",ignore_geometry=True)\n",
    "\n",
    "links = pd.merge(links,gdot_lanes,on=\"osmid\",how='left')\n",
    "links = pd.merge(links,gdot_traffic,on='osmid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle null aadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['AADT'].isna()].explore()\n",
    "# give residential roads the lowest aadt category or below\n",
    "links.loc[links['AADT'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'AADT'] = '[0,4k)'\n",
    "# all others the middle category\n",
    "links.loc[links['AADT'].isna() & (links['link_type']=='road'),'AADT'] = '[4k,10k)'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get the lowest category)\n",
    "links.loc[links['AADT'].isna(),'AADT'] = '[0,4k)'\n",
    "\n",
    "#turn it into categorical data\n",
    "links['AADT'] = pd.Categorical(links['AADT'],ordered=True,categories=['[0,4k)','[4k,10k)','[10k,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add HERE data (SKIP IF NO HERE DATA)\n",
    "HERE provides speed and lanes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = gpd.read_file(config['network_fp']/\"conflation.gpkg\",layer=\"here\",ignore_geometry=True)\n",
    "links = pd.merge(links,here,on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling null speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this to explore na links\n",
    "# links[(links['link_type']=='road')&links['here_speed'].isna()].explore()\n",
    "# links[links['here_speed'].isna()&(links['link_type']=='road')]['highway'].unique()\n",
    "# give residential roads a speed limit of 30 or below\n",
    "links.loc[links['here_speed'].isna() &\n",
    "          (links['highway'].isin(['residential','service','unclassified','living_street'])) &\n",
    "          (links['link_type']=='road'),'here_speed'] = '[0,30]'\n",
    "# all others get 30 +\n",
    "links.loc[links['here_speed'].isna() & (links['link_type']=='road'),'here_speed'] = '(30,40]'\n",
    "# any remaining nulls (bike paths, service roads, parking lots, get a speed limit of 30 or below)\n",
    "links.loc[links['here_speed'].isna(),'here_speed'] = '[0,30]'\n",
    "links.rename(columns={'here_speed':'speed'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['speed'] = pd.Categorical(links['speed'],ordered=True,categories=['[0,30]', '(30,40]', '(40,inf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve GDOT/HERE lanes data\n",
    "- All non-road links get a 1 (doing this so lanes attribute isn't being confounded with vehicle access)\n",
    "- By direction is too detailed, use a per direction estimate (i.e. treat a 5 lane oneway road the same as a 10 lane twoway road or a 5 lane per direction)\n",
    "- Simplify to:\n",
    "    - 1 lane per direction\n",
    "    - 2 lanes per direction\n",
    "    - 3+ lanes per direction\n",
    "- If unequal number of lanes use direction that would result in the higher category\n",
    "    - Example: 10th Street NE would be 2 lanes per direction because it has 2/1 lanes by direction\n",
    "- Turn lanes (middle, right, etc) are NOT counted in HERE or GDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO figure out what to do when there is a disrepency between the lanes\n",
    "## Examine where there's a big mismatch between HERE and GDOT\n",
    "# - There are a couple of cases where GDOT will be way off, like North Highland Ave NE which shows up as having four lanes when it's mostly 2 lanes for most of its length.\n",
    "# - Memorial Drive is also marked as having four lanes but it was road dieted post 2016, so just use the old value.\n",
    "# - Unless it's a residential street or a few cases that were identified, use the GDOT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give everything a default value of 1 (before we would give non-motorized links a value of 0)\n",
    "links['lanes'] = 1\n",
    "\n",
    "#if one is null take the non null value\n",
    "links.loc[links['here_lanes'].isna() & links['gdot_lanes'].notna(),'lanes'] = links['gdot_lanes']\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].isna(),'lanes'] = links['here_lanes']\n",
    "\n",
    "#otherwise choose whichever is smaller\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].notna(),'lanes'] = links[['here_lanes','gdot_lanes']].min(axis=1)\n",
    "\n",
    "#drop to trim down the df\n",
    "links.drop(columns=['gdot_lanes','here_lanes'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add elevation data\n",
    "Assign the correct direction for reverse links later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = gpd.read_file(config['network_fp']/'elevation.gpkg',layer='elevation',ignore_geometry=True)\n",
    "elevation = elevation[['linkid','ascent_ft','descent_ft','ascent_grade_cat','descent_grade_cat']]\n",
    "links = pd.merge(links,elevation,on='linkid',how='left')\n",
    "# del elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ascent grade and descent grade to zero\n",
    "links.loc[links['ascent_grade_cat'].isna(),'ascent_grade_cat'] = '[0,4)'\n",
    "links.loc[links['descent_grade_cat'].isna(),'descent_grade_cat'] = '[0,4)'\n",
    "links.loc[:,['ascent_ft','descent_ft']] = links.loc[:,['ascent_ft','descent_ft']].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for remaining bridge where lidar data was not available set the grade to 0 if grade exceeds 10 percent\n",
    "# links.loc[(links['bridge'] == 'yes') & (links['ascent_grade_%'] > 10),'ascent_grade_%'] = 0\n",
    "# #also for tunnels\n",
    "# links.loc[(links['tunnel'] == 'yes'),'ascent_grade_%'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse links and turn dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change this to not create the turn graph (just make it an extra optional step)\n",
    "## Create turn graph dataframe\n",
    "from importlib import reload\n",
    "reload(modeling_turns)\n",
    "directed_links, turns_df = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n",
    "\n",
    "# find the degree of the intersection node and re-classify anything with degree 2 as straight turn movement?\n",
    "# what about interstate exits that got removed?\n",
    "from collections import Counter\n",
    "node_degree = dict(Counter(links['A'].tolist()+links['B'].tolist()))\n",
    "turns_df['node_degree'] = turns_df['source_B'].map(node_degree)\n",
    "# turns_df[turns_df['node_degree']==2,'turn_type'] = 'straight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add signals from OSM and GDOT to turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_signals = pd.read_pickle(config['network_fp']/'osm_signals.pkl')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "gdot_signals = pd.read_pickle(config['network_fp']/'gdot_signals.pkl')[['source_linkid','source_reverse_link','target_linkid','target_reverse_link']]\n",
    "\n",
    "osm_signals = set([tuple(x) for x in osm_signals.values])\n",
    "gdot_signals = set([tuple(x) for x in gdot_signals.values])\n",
    "added_signals = set.union(osm_signals,gdot_signals)\n",
    "\n",
    "turns_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "\n",
    "added_signals = set.intersection(set(turns_df.index.tolist()),added_signals)\n",
    "turns_df.loc[list(added_signals),'signalized'] = True\n",
    "turns_df.loc[turns_df['signalized'].isna(),'signalized'] = False\n",
    "\n",
    "turns_df.reset_index(inplace=True)\n",
    "\n",
    "turns_df['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in cross street variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach speed, lanes, AADT, and osm hihgway\n",
    "link_attrs = links.copy()[['linkid','highway','link_type','lanes','AADT','speed']]\n",
    "link_attrs.set_index('linkid',inplace=True)\n",
    "\n",
    "source_cols = ['source_' + x for x in link_attrs.columns]\n",
    "target_cols = ['target_' + x for x in link_attrs.columns]\n",
    "\n",
    "link_attrs.columns = source_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='source_linkid',right_index=True,how='left')\n",
    "link_attrs.columns = target_cols\n",
    "turns_df = pd.merge(turns_df,link_attrs,left_on='target_linkid',right_index=True,how='left')\n",
    "turns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross street would be to the left or right\n",
    "cond1 = turns_df['turn_type'].isin(['left','right'])\n",
    "\n",
    "#only road to road for now\n",
    "cond2 = (turns_df['source_link_type'] == 'road') & (turns_df['target_link_type'] == 'road')\n",
    "cross_streets = turns_df[cond1&cond2]\n",
    "\n",
    "# get the worst possible cross street attribute\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_reverse_link'])[['target_AADT','target_lanes','target_speed']].max()\n",
    "cross_streets.columns = ['cross_AADT','cross_lanes','cross_speed']\n",
    "test = turns_df.merge(cross_streets,left_on=['source_linkid','source_reverse_link'],right_index=True)#,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a stressful turn would be\n",
    "aadt_cross_cond = test['cross_AADT'] == '[10k,inf)'\n",
    "lanes_cross_cond = test['cross_lanes'] > 2\n",
    "speed_cross_cond = test['cross_speed'] >= '(30,40]'\n",
    "cross_high_stress = aadt_cross_cond | lanes_cross_cond | speed_cross_cond\n",
    "\n",
    "# if the source street has these stats then assume that there is a signal\n",
    "aadt_source_cond = test['source_AADT'] == '[10k,inf)'\n",
    "lanes_source_cond = test['source_lanes'] > 2\n",
    "speed_source_cond = test['source_speed'] >= '(30,40]'\n",
    "source_high_stress = aadt_source_cond | lanes_source_cond | speed_source_cond\n",
    "\n",
    "test['unsig_crossing'] = False\n",
    "test.loc[(source_high_stress==False) & cross_high_stress & (test['signalized']==False) & (test['turn_type'].isin(['straight','left'])),'unsig_crossing'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unsignalized crossing variable back in\n",
    "turns_df = pd.merge(turns_df,test[['source_linkid','source_reverse_link','target_linkid','target_reverse_link','unsig_crossing']],on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optional add geo data to turns and export for examination\n",
    "# reload(modeling_turns)\n",
    "# cross_streets_gdf = modeling_turns.turn_gdf(links,test)\n",
    "# for idx,x in enumerate(cross_streets_gdf.dtypes):\n",
    "#     if (str(x) == \"category\") | (str(x)=='object'):\n",
    "#         cross_streets_gdf.iloc[:,idx] = cross_streets_gdf.iloc[:,idx].astype(str)\n",
    "# cross_streets_gdf.to_file(config['network_fp']/'scratch.gpkg',layer='cross_streets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes[nodes['N'].isin(set(cross_streets_gdf.loc[cross_streets_gdf['unsig_crossing']==True,'source_B'].tolist()))].explore() # looks much more reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure hwat i was going for here\n",
    "# # get the worst possible cross street attribute\n",
    "# # cross_streets.groupby(['source_linkid','source_reverse_link'])['target_AADT','target_lanes','target_speed'].idxmax()\n",
    "# cross_streets.loc[18242]\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['target_speed'].max()\n",
    "\n",
    "\n",
    "# # find the worst cross street if there are multiple\n",
    "# cross_streets.groupby(['source_linkid','source_reverse_link'])['aadt'].apply(lambda x: aadt_order)\n",
    "\n",
    "\n",
    "# # TODO do this for the other variables too\n",
    "# cols = ['AADT','lanes','speed']\n",
    "# for x in cols:\n",
    "#     print(links[x].unique())\n",
    "# # rules for high stress turns\n",
    "\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #traffic\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | \\\n",
    "#                            (links['highway'].isin(major_road_values) & (links['lanes'] < 2) ), \n",
    "#                             'linkid'].tolist())\n",
    "# cross_streets.loc[cross_streets['source_linkid']==3]\n",
    "# print(links[links['linkid']==3].squeeze())\n",
    "# links[links['linkid']==3].explore()\n",
    "\n",
    "# # grouby the source link\n",
    "# cross_streets.groupby(['source_linkid'])['target_highway'].agg(list)#['target_highway_order'].min()\n",
    "\n",
    "# cross_streets.name = 'cross_street'\n",
    "\n",
    "# #add to main df\n",
    "# pd.merge(turns_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "# # wasn't able to get major/minor to be significant\n",
    "# #Major/minor road classification to create high traffic stress variable\n",
    "# major_road_values = ['primary','secondary']\n",
    "# major_road_values = major_road_values + [item + '_link' for item in major_road_values]\n",
    "# minor_road_values = ['tertiary','unclassified','residential','service','trunk','living_street','service']\n",
    "# minor_road_values = minor_road_values + [item + '_link' for item in minor_road_values]\n",
    "\n",
    "# #override major road if only one lane per direction\n",
    "# major_road = set(links.loc[links['highway'].isin(major_road_values) & (links['lanes'] >= 2),'linkid'].tolist())\n",
    "# minor_road = set(links.loc[links['highway'].isin(minor_road_values) | links['lanes'] < 2,'linkid'].tolist())\n",
    "\n",
    "# #unsignalized straight/left turn where crossing street is a major road\n",
    "# turns_df['unsig_major_road_crossing'] = (turns_df['signalized']==False) & \\\n",
    "#     turns_df['target_linkid'].isin(major_road) & \\\n",
    "#     turns_df['source_linkid'].isin(minor_road) & \\\n",
    "#     turns_df['turn_type'].isin(['left','straight'])\n",
    "\n",
    "# # #sets turns that are not from road to road to None, effectively ignoring them\n",
    "# # exclude = ['road','service']\n",
    "# # turns_df.loc[(turns_df['source_link_type'].isin(exclude)==False) & \n",
    "# #              (turns_df['target_link_type'].isin(exclude)==False),'turn_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create layer of unsignalized crossings for examining\n",
    "unsig_major_road_crossing = set(turns_df.loc[turns_df['unsig_crossing']==True,'source_B'].tolist())\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "nodes = nodes[nodes['N'].isin(unsig_major_road_crossing)]\n",
    "nodes.to_file(config['calibration_fp']/'unsig_major_road_crossing.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Interstates and Private Links\n",
    "Remove these because we're absolutely sure we don't want bikes on these links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links['link_type'].unique())\n",
    "remove = ['no_access_or_private','restricted_access_road','no_bike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cond = links['link_type'].isin(remove)\n",
    "links = links[remove_cond==False]\n",
    "print(remove_cond.sum(),'links removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove isolated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, nodes = prepare_network.largest_comp_and_simplify(links,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df = turns_df[turns_df['source_linkid'].isin(set(links['linkid'].tolist())) & turns_df['target_linkid'].isin(set(links['linkid'].tolist()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    'A', 'B', 'linkid', 'osmid', 'oneway', 'highway', 'name','all_tags', # OSM derived or ID variables\n",
    "    'link_type',\n",
    "    'facility_fwd', 'facility_rev', 'facility', 'year',\n",
    "    # 'sidepath_linkid', 'sidepath', 'sidepath_year', # export this seperately\n",
    "    'state_route', 'AADT', 'speed', 'lanes',\n",
    "    'ascent_ft', 'descent_ft','ascent_grade_cat','descent_grade_cat',\n",
    "    'length_ft', 'geometry'\n",
    "    ]\n",
    "\n",
    "# export with the catagorical values\n",
    "links[final_cols].to_pickle(config['network_fp']/'final_network_edges.parquet')\n",
    "\n",
    "#TODO create a function for performing this\n",
    "for col, dtype in links.dtypes.to_dict().items():\n",
    "    if (str(dtype) == \"category\"):\n",
    "        links[col] = links[col].astype(str).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'AADT'\n",
    "links[col] = links[col].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[:,'AADT'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[:,'AADT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['AADT'].astype(str)[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['AADT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[final_cols].dtypes == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[''].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links[final_cols].to_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes.to_file(config['network_fp']/'final_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directional attributes and flip as needed\n",
    "ascent_columns = ['ascent_ft', 'ascent_grade_cat']\n",
    "descent_columns = ['descent_ft', 'descent_grade_cat']\n",
    "directed_links = pd.merge(directed_links,links[['linkid','facility_fwd','facility_rev']+ascent_columns+descent_columns],on='linkid')\n",
    "directed_links.loc[directed_links['reverse_link']==True,ascent_columns+descent_columns] = directed_links.loc[directed_links['reverse_link']==True,descent_columns+ascent_columns].values\n",
    "directed_links.loc[directed_links['reverse_link']==True,['facility_fwd','facility_rev']] = directed_links.loc[directed_links['reverse_link']==True,['facility_rev','facility_fwd']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple columns not compatible with parquet\n",
    "# turns_df.drop(columns=['source','target'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pickles later\n",
    "turns_df.to_parquet(config['network_fp']/'turns_df.parquet')\n",
    "directed_links.to_parquet(config['network_fp']/'directed_edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO create a function for performing this\n",
    "for idx,x in enumerate(turns_df.dtypes):\n",
    "    if (str(x) == \"category\"): #| (str(x)=='object'):\n",
    "        turns_df.iloc[:,idx] = turns_df.iloc[:,idx].astype(str)\n",
    "\n",
    "#optional add geo data to turns and export for examination\n",
    "from shapely.ops import MultiLineString\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))\n",
    "turns_df['source_geo'] = turns_df['source_linkid'].map(geo_dict)\n",
    "turns_df['target_geo'] = turns_df['target_linkid'].map(geo_dict)\n",
    "turns_df['geometry'] = turns_df.apply(lambda row: MultiLineString([row['source_geo'],row['target_geo']]),axis=1)\n",
    "turns_df.drop(columns=['source_geo','target_geo'],inplace=True)\n",
    "turns_gdf = gpd.GeoDataFrame(turns_df,crs=links.crs)\n",
    "# turns_gdf.drop(columns=['source','target'])\n",
    "turns_gdf.to_file(config['network_fp']/'final_network.gpkg',layer='turns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikewaysim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
