{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a0e84c",
   "metadata": {},
   "source": [
    "## Step 2 Network Reconciliation\n",
    "---\n",
    "Use this notebook to setup a semi-automated reconciliation process between networks using functions available in 'conflation_tools.py' and 'network_reconcile.py.'\n",
    "\n",
    "In general, you want to select one network to act as the base network (ground-truth) and add network data/attributes from the other networks.\n",
    "\n",
    "These are the main functions in the conflation_tools module (type help(function_name) for a detailed description):\n",
    "- match_nodes: finds node pairs between base and join network\n",
    "- split_lines_create_points: Uses points from the join network to split links in the base network\n",
    "- add_split_links: add the split links\n",
    "\n",
    "From network_filter\n",
    "- add_ref_ids: adds new reference ids from the nodes layer\n",
    "\n",
    "Once finished reconciling, network can be exported for further manual reconciling or it can be prepped for network routing in BikewaySim.\n",
    "\n",
    "type \"help(insert_name_of_function)\" to get more information about what the function does."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b74c49",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7001d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.conflation_tools as conflation_tools\n",
    "import src.add_attributes as add_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c71c6",
   "metadata": {},
   "source": [
    "## Adding and processing attribute data\n",
    "These functions add in relevant attributes from the '.pkl' created in Step 1, or process supplemental data such as bicycle inventories.\n",
    "\n",
    "The following three functions add attribute data back into the network and pre-processes it to match up with the desired impedance columns. These are custom network specific functions, so if adding a new network, will need to make another specific function.\n",
    "- add_osm_attr\n",
    "- add_here_attr\n",
    "- add_abm_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac493e",
   "metadata": {},
   "source": [
    "# GDOT Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a75d5",
   "metadata": {},
   "source": [
    "### Add HERE road data to the OSM road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87432c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project directory\n",
    "project_dir = Path.home() / 'Documents/BikewaySimData/Projects/gdot/networks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756f5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_links')\n",
    "osm_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbc017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links = add_attributes.add_osm_attr(osm_links,project_dir / 'osm_attr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cfbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to roads\n",
    "osm_road_links = osm_links[osm_links['link_type']=='road']\n",
    "#osm_road_links = add_attributes.add_osm_attr(osm_road_links,project_dir / 'osm_attr.pkl')\n",
    "osm_road_nodes = osm_nodes[osm_nodes['osm_N'].isin(osm_road_links['osm_A'].append(osm_road_links['osm_B']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff696105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import here road layer\n",
    "here_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='here_links')\n",
    "here_road_links = here_links[here_links['link_type']=='road']\n",
    "\n",
    "#add attributes back\n",
    "here_road_links = add_attributes.add_here_attr(here_road_links,project_dir / 'here_attr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2c20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissolving by 9 columns\n"
     ]
    }
   ],
   "source": [
    "#function for adding attributes of one network network to another\n",
    "road_links, overlapping = conflation_tools.add_attributes(\n",
    "    osm_road_links, here_road_links, 'here', 100, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841d97c",
   "metadata": {},
   "source": [
    "This block modifies the street name attribute to compare the OSM street name vs the HERE assigned street name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e5ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_names = dict(zip(osm_road_links['temp_ID'],osm_road_links['name']))\n",
    "overlapping['name'] = overlapping['temp_ID'].map(street_names)\n",
    "\n",
    "overlapping['match name'] = overlapping['ST_NAME'].apply(lambda row: conflation_tools.simplify_names(row))\n",
    "overlapping['name'] = overlapping['name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900ab44",
   "metadata": {},
   "source": [
    "## Use these columns to examine the match quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014b1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check name\n",
    "overlapping['name_check'] = overlapping['match name'] == overlapping['name']\n",
    "\n",
    "#check overlap\n",
    "overlapping['overlap_check'] = overlapping['percent_overlap'] > 0.9\n",
    "\n",
    "#check bearing diff\n",
    "overlapping['bearing_check'] = overlapping['bearing_diff'] < 5\n",
    "\n",
    "#final check\n",
    "overlapping['final_check'] = overlapping.apply(lambda row: row['name_check']+row['overlap_check']+row['bearing_check'],axis=1)\n",
    "\n",
    "#drop 0s\n",
    "overlapping = overlapping[overlapping['final_check'] >= 1]\n",
    "\n",
    "#only keep max for each max\n",
    "keep = overlapping.groupby('temp_ID')['final_check'].idxmax().to_list()\n",
    "keep = overlapping.loc[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2808b8",
   "metadata": {},
   "source": [
    "## Add the here link id and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ba80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep here cols\n",
    "remove_cols = set(osm_road_links.columns.tolist())\n",
    "remove_cols.remove('temp_ID')\n",
    "remove_cols = remove_cols & set(keep.columns.tolist())\n",
    "keep.drop(columns=remove_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ead62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace temp_id with the linkid\n",
    "replace_temp_id = dict(zip(osm_road_links['temp_ID'],osm_road_links['osm_linkid']))\n",
    "keep['osm_linkid'] = keep['temp_ID'].map(replace_temp_id)\n",
    "keep.drop(columns=['temp_ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5afb47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links = pd.merge(osm_links,keep,on='osm_linkid')\n",
    "\n",
    "# osm_links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# osm_nodes.rename(columns={'osm_N':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bbb2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links.to_file(project_dir/'reconciled.gpkg',layer='links')\n",
    "#osm_nodes.to_file(project_dir/'reconciled.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779f5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import bike layer\n",
    "# bike_links = merged[merged['link_type']=='bike']\n",
    "# bike_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "# bike_nodes = bike_nodes[bike_nodes['osm_N'].isin(bike_links['osm_A'].append(bike_links['osm_B']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b404d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold off on this until the right before routing, this should only be for speeding up routing\n",
    "#simplify the graph by removing interstital nodes\n",
    "#merged = conflation_tools.remove_interstitial_nodes(osm_links,'osm_A','osm_B','osmid','osm_linkid',ignore_id=False)\n",
    "# #Re-calculate the azimuth/bearing\n",
    "# import pyproj\n",
    "# prev_crs = merged.crs\n",
    "# merged.to_crs('epsg:4326',inplace=True)\n",
    "# merged[['fwd_azimuth','bck_azimuth']] = merged.apply(lambda row: modeling_turns.find_azimuth(row), axis=1)\n",
    "# merged.to_crs(prev_crs,inplace=True)\n",
    "\n",
    "# import network_filter\n",
    "\n",
    "# nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "\n",
    "# #reassign link node ids\n",
    "# ref_nodes_added = network_filter.add_ref_ids(merged,nodes,'osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5af8ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get node count to find dead ends\n",
    "# bike_nodes['num_links'] = bike_nodes['osm_N'].map(pd.concat([bike_links['osm_A'],bike_links['osm_B']],ignore_index=True).value_counts())\n",
    "# dead_ends = bike_nodes[bike_nodes['num_links']==1]\n",
    "\n",
    "# #remove dead ends already connected to road network\n",
    "# dead_ends = dead_ends[-dead_ends['osm_N'].isin(osm_road_nodes['osm_N'])]\n",
    "\n",
    "# #use full network to fix disconnected links from dead ends (road crossing breaks etc)\n",
    "# osm_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_links')\n",
    "# osm_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "# connectors = conflation_tools.find_path(osm_links,osm_nodes,'osm',osm_road_nodes,dead_ends,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad21aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connectors.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c057155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = pd.concat([osm_road_links,connectors,bike_links],ignore_index=True).drop_duplicates()\n",
    "# nodes = pd.concat([osm_road_nodes,bike_nodes],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c42a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create unique link id column (make sure to find the max linkid using the full dataset)\n",
    "# max_linkid = int(links['osm_linkid'].max())\n",
    "# links.loc[links['osm_linkid'].isna(),'osm_linkid'] = range(max_linkid+1,max_linkid+links['osm_linkid'].isna().sum()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8034e1",
   "metadata": {},
   "source": [
    "## Remove isolated nodes/links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15ba5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_links = links.shape[0]\n",
    "# before_nodes = nodes.shape[0]\n",
    "\n",
    "# #create undirected graph\n",
    "# G = nx.Graph()  # create directed graph\n",
    "# for row in links[['osm_A','osm_B']].itertuples(index=False):\n",
    "#     # forward graph, time stored as minutes\n",
    "#     G.add_edges_from([(row[0],row[1])])\n",
    "\n",
    "# #only keep largest component\n",
    "# largest_cc = max(nx.connected_components(G), key=len)\n",
    "\n",
    "# #get nodes\n",
    "# nodes = nodes[nodes['osm_N'].isin(largest_cc)]\n",
    "# #get links\n",
    "# links = links[links['osm_A'].isin(largest_cc) & links['osm_B'].isin(largest_cc)]\n",
    "\n",
    "# print('Links removed:',before_links-links.shape[0],'Nodes removed:',before_nodes-nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73550e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links.rename(columns={'osm_A':'A','osm_B':'B','osm_linkid':'linkid'},inplace=True)\n",
    "# nodes.rename(columns={'osm_N':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd7d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# links.to_file(project_dir / 'reconciled_network.gpkg',layer='links')\n",
    "# nodes.to_file(project_dir / 'reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53caa3be",
   "metadata": {},
   "source": [
    "# Assessing Bike-Transit Accessibility\n",
    "---\n",
    "The code blocks below this are for creating a network to use for transitsim. Only uses OSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4452dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # project directory\n",
    "# project_dir = Path.home() / 'Documents/TransitSimData/Data/networks'\n",
    "\n",
    "# #import osm road layer\n",
    "# osm_road_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_links')\n",
    "# osm_road_links = osm_road_links[osm_road_links['link_type']=='road']\n",
    "# osm_road_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "# osm_road_nodes = osm_road_nodes[osm_road_nodes['osm_N'].isin(osm_road_links['osm_A'].append(osm_road_links['osm_B']))]\n",
    "\n",
    "# #import bike layer\n",
    "# bike_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_links')\n",
    "# bike_links = bike_links[bike_links['link_type']=='bike']\n",
    "# bike_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "# bike_nodes = bike_nodes[bike_nodes['osm_N'].isin(bike_links['osm_A'].append(bike_links['osm_B']))]\n",
    "\n",
    "# #get node count to find dead ends\n",
    "# bike_nodes['num_links'] = bike_nodes['osm_N'].map(pd.concat([bike_links['osm_A'],bike_links['osm_B']],ignore_index=True).value_counts())\n",
    "# dead_ends = bike_nodes[bike_nodes['num_links']==1]\n",
    "\n",
    "# #remove dead ends already connected to road network\n",
    "# dead_ends = dead_ends[-dead_ends['osm_N'].isin(osm_road_nodes['osm_N'])]\n",
    "\n",
    "# #use full network to fix disconnected links from dead ends (road crossing breaks etc)\n",
    "# #connectors are assigned a new unique link id before export\n",
    "# osm_links = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_links')\n",
    "# osm_nodes = gpd.read_file(project_dir / 'filtered.gpkg',layer='osm_nodes')\n",
    "# connectors = conflation_tools.find_path(osm_links,osm_nodes,'osm',osm_road_nodes,dead_ends,50)\n",
    "\n",
    "# #add connectors, bike links, and the new nodes\n",
    "# links = pd.concat([osm_road_links,connectors,bike_links],ignore_index=True).drop_duplicates()\n",
    "# nodes = pd.concat([osm_road_nodes,bike_nodes],ignore_index=True).drop_duplicates()\n",
    "# #create unique link id column (make sure to find the max linkid using the full dataset)\n",
    "# max_linkid = int(osm_links['osm_linkid'].max())\n",
    "# links.loc[links['osm_linkid'].isna(),'osm_linkid'] = range(max_linkid+1,max_linkid+links['osm_linkid'].isna().sum()+1)\n",
    "# #add attributes\n",
    "# links = add_osm_attr(links, project_dir / 'osm_attr.pkl')\n",
    "\n",
    "# #export\n",
    "# links.to_file(project_dir / 'reconciled_network.gpkg',layer='links')\n",
    "# nodes.to_file(project_dir / 'reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf8b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
