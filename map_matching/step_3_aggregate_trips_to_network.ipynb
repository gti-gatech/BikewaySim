{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate matched trips to links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.map_matching import post_process\n",
    "\n",
    "# combines the map match results into a single file\n",
    "post_process.combine_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "\n",
    "# load the trips\n",
    "with (config['cycleatl_fp']/'trips_4.pkl').open('rb') as fh:\n",
    "    trips_df = pickle.load(fh)\n",
    "\n",
    "# load the matches\n",
    "# NOTE use this to indicate which match results to load\n",
    "match_settings_idx = 0\n",
    "with (config['matching_fp'] / f\"match_dict_full_{match_settings_idx}.pkl\").open('rb') as fh:\n",
    "    match_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 / 682 (88%) successful matches\n",
      "81 / 682 (12%) partial matches\n",
      "4 / 682 (1%) failed matches\n"
     ]
    }
   ],
   "source": [
    "# NOTE determine the cutoff to use for an acceptable match\n",
    "cutoff = 0.90 # set pct of points that need to be matched\n",
    "above_threshold, below_threshold, failed_matches, match_ratios = post_process.mapmatch_results(match_dict,cutoff)\n",
    "match_dict = {key:item for key,item in match_dict.items() if key in above_threshold}\n",
    "\n",
    "# the linkid and direction of the matched edges\n",
    "matched_edges_dict = {tripid:[(int(x),bool(y)) for x,y in item['edges'].values] for tripid, item in match_dict.items()}\n",
    "# the lines that connect the GPS points to the network nodes\n",
    "match_lines = {tripid:int(item['match_lines']['length'].mean()) for tripid, item in match_dict.items()}\n",
    "# the pct of points that were matched\n",
    "match_ratios = {tripid:round(item['match_ratio'],1) for tripid, item in match_dict.items()}\n",
    "\n",
    "# add match dist and ration to the trips dataframe\n",
    "trips_df['match_dist'] = trips_df['tripid'].map(match_lines)\n",
    "trips_df['match_ratio'] = trips_df['tripid'].map(match_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate matches to links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "#feed in a subset of matched_edges to return counts for specific queries such as\n",
    "#the gender split on a link etc\n",
    "\n",
    "links_fwd = defaultdict(list)\n",
    "links_rev= defaultdict(list)\n",
    "links_undirected = defaultdict(list)\n",
    "for tripid, link_list in matched_edges_dict.items():\n",
    "    for linkid in link_list:\n",
    "        linkid0 = int(linkid[0])\n",
    "        linkid1 = linkid[1]\n",
    "        links_undirected[linkid[0]].append(tripid)\n",
    "        if linkid1 == False:\n",
    "            links_fwd[linkid0].append(tripid)\n",
    "        else:\n",
    "            links_rev[linkid0].append(tripid)\n",
    "\n",
    "links_fwd = pd.Series(links_fwd)\n",
    "links_rev = pd.Series(links_rev)\n",
    "links_undirected = pd.Series(links_undirected)\n",
    "\n",
    "link_counts = pd.DataFrame({'fwd':links_fwd,'rev':links_rev,'both':links_undirected})\n",
    "link_counts['total_fwd'] = link_counts['fwd'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_rev'] = link_counts['rev'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total'] = link_counts['both'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "\n",
    "#turn index back to int\n",
    "link_counts.index = link_counts.index.astype(int)\n",
    "#name the index\n",
    "link_counts.index.name = 'linkid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_pickle(config['cycleatl_fp']/'users_4.pkl')\n",
    "trips = pd.read_pickle(config['cycleatl_fp']/'trips_4.pkl')\n",
    "trips0 = pd.read_pickle(config['cycleatl_fp']/'trips_2.pkl')\n",
    "userid = trips['userid'].to_dict()\n",
    "users.set_index('userid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "link_counts['fwd_users'] = link_counts['fwd'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "link_counts['rev_users'] = link_counts['rev'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "link_counts['both_users'] = link_counts['both'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "\n",
    "link_counts['total_fwd_users'] = link_counts['fwd_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_rev_users'] = link_counts['rev_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_users'] = link_counts['both_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips0.set_index('tripid',inplace=True)\n",
    "test = trips0['start_time'].dt.year.to_dict()\n",
    "years = pd.DataFrame.from_dict(link_counts['both'].dropna().apply(lambda x: Counter([test.get(y) for y in x])).to_dict(),orient='index')\n",
    "years.columns = [str(x) for x in years.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "years.index.name = 'tripid'\n",
    "years = years.fillna(0).astype(int)\n",
    "link_counts = link_counts.merge(years,left_index=True,right_index=True,how='left')\n",
    "link_counts.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO script this to get the attributes we generally want\n",
    "# at some point look at more specific trip characterstics like average speed\n",
    "\n",
    "# Trip attributes\n",
    "commute = set(trips.loc[trips.trip_type == 'Commute'].index.tolist())\n",
    "link_counts['commute_trips'] = link_counts['both'].apply(lambda x: len([y for y in x if y in commute]) if isinstance(x,list) else 0)\n",
    "\n",
    "# User attributes\n",
    "female = set(users.loc[users['gender']=='Female'].index.tolist())\n",
    "male = set(users.loc[users['gender']=='Male'].index.tolist())\n",
    "link_counts['female_trips'] = link_counts['both_users'].apply(lambda x: len([y for y in x if y in female]) if isinstance(x,list) else 0)\n",
    "link_counts['male_trips'] = link_counts['both_users'].apply(lambda x: len([y for y in x if y in male]) if isinstance(x,list) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "linkid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "2014",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "62609820-f1c4-46fd-b0bd-747eeea247b2",
       "rows": [
        [
         "0",
         "0"
        ],
        [
         "1",
         "0"
        ],
        [
         "7",
         "0"
        ],
        [
         "67",
         "0"
        ],
        [
         "70",
         "1"
        ],
        [
         "77",
         "0"
        ],
        [
         "79",
         "0"
        ],
        [
         "89",
         "7"
        ],
        [
         "90",
         "5"
        ],
        [
         "91",
         "5"
        ],
        [
         "94",
         "0"
        ],
        [
         "96",
         "0"
        ],
        [
         "100",
         "0"
        ],
        [
         "101",
         "0"
        ],
        [
         "102",
         "0"
        ],
        [
         "106",
         "0"
        ],
        [
         "119",
         "0"
        ],
        [
         "127",
         "0"
        ],
        [
         "138",
         "0"
        ],
        [
         "144",
         "0"
        ],
        [
         "149",
         "0"
        ],
        [
         "156",
         "0"
        ],
        [
         "188",
         "0"
        ],
        [
         "192",
         "0"
        ],
        [
         "197",
         "0"
        ],
        [
         "213",
         "0"
        ],
        [
         "224",
         "0"
        ],
        [
         "232",
         "0"
        ],
        [
         "240",
         "0"
        ],
        [
         "249",
         "0"
        ],
        [
         "250",
         "3"
        ],
        [
         "251",
         "0"
        ],
        [
         "253",
         "0"
        ],
        [
         "257",
         "3"
        ],
        [
         "259",
         "0"
        ],
        [
         "271",
         "3"
        ],
        [
         "273",
         "0"
        ],
        [
         "276",
         "0"
        ],
        [
         "277",
         "0"
        ],
        [
         "278",
         "0"
        ],
        [
         "280",
         "0"
        ],
        [
         "282",
         "0"
        ],
        [
         "283",
         "4"
        ],
        [
         "285",
         "0"
        ],
        [
         "286",
         "0"
        ],
        [
         "287",
         "0"
        ],
        [
         "288",
         "0"
        ],
        [
         "289",
         "0"
        ],
        [
         "290",
         "0"
        ],
        [
         "292",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5711
       }
      },
      "text/plain": [
       "linkid\n",
       "0        0\n",
       "1        0\n",
       "7        0\n",
       "67       0\n",
       "70       1\n",
       "        ..\n",
       "32905    1\n",
       "32911    1\n",
       "32978    2\n",
       "32987    0\n",
       "32994    6\n",
       "Name: 2014, Length: 5711, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts['2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_links = pd.merge(links,link_counts,left_on='linkid',right_index=True)\n",
    "\n",
    "new_links.fillna(0,inplace=True)\n",
    "\n",
    "for col in ['fwd','rev','both','fwd_users','rev_users','both_users']:\n",
    "    new_links[col] = new_links[col].astype(str)\n",
    "new_links.to_file(Path.home()/'Downloads/link_counts.gpkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikewaysim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
