{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Map Match (combine this with get route attribtues?)\n",
    "- Get map match results\n",
    "- Aggregate matches to links\n",
    "- Get chosen route characterstics\n",
    "- Export for impedance calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim import map_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the full network with link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['matching_fp'] /'matched_4.pkl').open('rb') as fh:\n",
    "#     match_dict = pickle.load(fh)\n",
    "# with (config['matching_fp'] /'match_dict_full.pkl').open('rb') as fh:\n",
    "#     match_dict = pickle.load(fh)\n",
    "# match_dict = {tripid:item for tripid, item in match_dict.items() if isinstance(item,str)==False}\n",
    "\n",
    "with (config['cycleatl_fp']/'trips_4.pkl').open('rb') as fh:\n",
    "    trips_df = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['matching_fp'] / f\"match_dict_full.pkl\").open('rb') as fh:\n",
    "    match_dict = pickle.load(fh)\n",
    "\n",
    "cutoff = 0.90 # set pct of points that need to be matched\n",
    "above_threshold, below_threshold, failed_matches, match_ratios = map_match.mapmatch_results(match_dict,cutoff)\n",
    "match_dict = {key:item for key,item in match_dict.items() if key in above_threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_edges_dict = {tripid:[(int(x),bool(y)) for x,y in item['edges'].values] for tripid, item in match_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_lines = {tripid:int(item['match_lines']['length'].mean()) for tripid, item in match_dict.items()}\n",
    "match_ratios = {tripid:round(item['match_ratio'],1) for tripid, item in match_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df['match_dist'] = trips_df['tripid'].map(match_lines)\n",
    "trips_df['match_ratio'] = trips_df['tripid'].map(match_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.hist('match_dist',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate matches to links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "#feed in a subset of matched_edges to return counts for specific queries such as\n",
    "#the gender split on a link etc\n",
    "\n",
    "links_fwd = defaultdict(list)\n",
    "links_rev= defaultdict(list)\n",
    "links_undirected = defaultdict(list)\n",
    "for tripid, link_list in matched_edges_dict.items():\n",
    "    for linkid in link_list:\n",
    "        linkid0 = int(linkid[0])\n",
    "        linkid1 = linkid[1]\n",
    "        links_undirected[linkid[0]].append(tripid)\n",
    "        if linkid1 == False:\n",
    "            links_fwd[linkid0].append(tripid)\n",
    "        else:\n",
    "            links_rev[linkid0].append(tripid)\n",
    "\n",
    "links_fwd = pd.Series(links_fwd)\n",
    "links_rev = pd.Series(links_rev)\n",
    "links_undirected = pd.Series(links_undirected)\n",
    "\n",
    "link_counts = pd.DataFrame({'fwd':links_fwd,'rev':links_rev,'both':links_undirected})\n",
    "link_counts['total_fwd'] = link_counts['fwd'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_rev'] = link_counts['rev'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total'] = link_counts['both'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "\n",
    "#turn index back to int\n",
    "link_counts.index = link_counts.index.astype(int)\n",
    "#name the index\n",
    "link_counts.index.name = 'linkid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_pickle(config['cycleatl_fp']/'users_4.pkl')\n",
    "trips = pd.read_pickle(config['cycleatl_fp']/'trips_4.pkl')\n",
    "trips0 = pd.read_pickle(config['cycleatl_fp']/'trips_2.pkl')\n",
    "userid = trips['userid'].to_dict()\n",
    "users.set_index('userid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "link_counts['fwd_users'] = link_counts['fwd'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "link_counts['rev_users'] = link_counts['rev'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "link_counts['both_users'] = link_counts['both'].apply(lambda x: list(set([userid[y] for y in x])) if isinstance(x,list) else np.nan)\n",
    "\n",
    "link_counts['total_fwd_users'] = link_counts['fwd_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_rev_users'] = link_counts['rev_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "link_counts['total_users'] = link_counts['both_users'].apply(lambda x: len(x) if isinstance(x,list) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips0.set_index('tripid',inplace=True)\n",
    "test = trips0['start_time'].dt.year.to_dict()\n",
    "years = pd.DataFrame.from_dict(link_counts['both'].dropna().apply(lambda x: Counter([test.get(y) for y in x])).to_dict(),orient='index')\n",
    "years.columns = [str(x) for x in years.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years.index.name = 'tripid'\n",
    "years = years.fillna(0).astype(int)\n",
    "link_counts = link_counts.merge(years,left_index=True,right_index=True,how='left')\n",
    "link_counts.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO script this to get the attributes we generally want\n",
    "# at some point look at more specific trip characterstics like average speed\n",
    "\n",
    "# Trip attributes\n",
    "commute = set(trips.loc[trips.trip_type == 'Commute'].index.tolist())\n",
    "link_counts['commute_trips'] = link_counts['both'].apply(lambda x: len([y for y in x if y in commute]) if isinstance(x,list) else 0)\n",
    "\n",
    "# User attributes\n",
    "female = set(users.loc[users['gender']=='Female'].index.tolist())\n",
    "male = set(users.loc[users['gender']=='Male'].index.tolist())\n",
    "link_counts['female_trips'] = link_counts['both_users'].apply(lambda x: len([y for y in x if y in female]) if isinstance(x,list) else 0)\n",
    "link_counts['male_trips'] = link_counts['both_users'].apply(lambda x: len([y for y in x if y in male]) if isinstance(x,list) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_counts['2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_links = pd.merge(links,link_counts,left_on='linkid',right_index=True)\n",
    "\n",
    "new_links.fillna(0,inplace=True)\n",
    "\n",
    "for col in ['fwd','rev','both','fwd_users','rev_users','both_users']:\n",
    "    new_links[col] = new_links[col].astype(str)\n",
    "new_links.to_file(Path.home()/'Downloads/link_counts.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I think ignore everthing past here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route attributes for each trip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "links.set_index('linkid',inplace=True)\n",
    "directed_links = pd.read_parquet(config['network_fp']/'directed_edges.parquet')\n",
    "directed_links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "\n",
    "df2 = directed_links[['ascent_grade_cat', 'ascent_ft', 'ascent_grade_cat', 'descent_grade_cat',\n",
    "       'descent_ft']]\n",
    "directed_links.fillna(df2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how high?\n",
    "ascent_ft = directed_links['ascent_ft'].to_dict()\n",
    "# climb = {key:directed_links.loc[item,'ascent_ft'].sum() for key,item in matched_edges_dict.items()}\n",
    "climb = {key:np.sum([ascent_ft.get(x) for x in item]) for key,item in matched_edges_dict.items()}\n",
    "pd.Series(climb)\n",
    "# directed_links.loc[matched_edges_dict[71],'ascent_ft'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long\n",
    "length_dict = links.length\n",
    "length = {key:np.sum([length_dict.get(x[0]) for x in item]) for key,item in matched_edges_dict.items()}\n",
    "# length = (pd.Series(length) / 5280).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links['facility_fwd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(directed_links.loc[directed_links['facility_fwd']==bike_infras].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_infras = ['multi use path','bike lane','buffered bike lane','cycletrack']\n",
    "bike_results = []\n",
    "\n",
    "for bike_infra in bike_infras:\n",
    "    # how pct of route on bike lanes\n",
    "    bike_lanes = set(directed_links.loc[directed_links['facility_fwd']==bike_infra].index.tolist())\n",
    "    bike_lanes = {key: np.round(np.sum([length_dict.get(x[0]) for x in item if x in bike_lanes]) / length.get(key) * 100,0) for key,item in matched_edges_dict.items()}\n",
    "    bike_lanes = pd.Series(bike_lanes)\n",
    "    bike_lanes.name = bike_infra\n",
    "    bike_results.append(pd.Series(bike_lanes))\n",
    "bike_infra = pd.concat(bike_results,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links['link_type']=='road'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links['facility_fwd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_edges_dict[513]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_edges_dict[71])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(int(36689),bool(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_links.sort_values('total_users',ascending=False).head(400).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(links_fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_flat_list = [item for sublist in list_of_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def aggregate_trips_to_links(links,matched_traces,tripids,name):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if tripids is not None:\n",
    "        #use list of tripids to subset dict of matched traces\n",
    "        filtered_dict = {key:item for key,item in matched_traces.items() if key in set(tripids)}\n",
    "    else:\n",
    "        filtered_dict = matched_traces\n",
    "    #make one large series\n",
    "    list_of_links = [item['edges'] for key, item in filtered_dict.items()]\n",
    "    list_of_links = list(itertools.chain(*list_of_links))\n",
    "    series_of_links = pd.Series(list_of_links)\n",
    "    links[name] = links['linkid'].map(series_of_links.value_counts())\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def aggregate_trips_to_link(link_dict,matched_traces,tripids,name):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if tripids is not None:\n",
    "        #use list of tripids to subset dict of matched traces\n",
    "        filtered_dict = {key:item for key,item in matched_traces.items() if key in set(tripids)}\n",
    "    else:\n",
    "        filtered_dict = matched_traces\n",
    "    #make one large series\n",
    "    list_of_links = [item['edges'] for key, item in filtered_dict.items()]\n",
    "    list_of_links = list(itertools.chain(*list_of_links))\n",
    "    series_of_links = pd.Series(list_of_links)\n",
    "    links[name] = links['linkid'].map(series_of_links.value_counts())\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directed_links = pd.read_parquet(config['network_fp']/'directed_edges.parquet')\n",
    "\n",
    "aggregated_undirected_matched = { key : [] for key in directed_links['linkid'].tolist()}\n",
    "aggregated_directed_matched = { key : [] for key in list(zip(directed_links['linkid'],directed_links['reverse_link']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges')\n",
    "\n",
    "#add basic count\n",
    "#links.set_index('linkid',inplace=True)\n",
    "links['trips'] = links['linkid'].apply(lambda x: len(aggregated_undirected_matched.get(x,[])))\n",
    "links['trips'].describe()\n",
    "only_trips = links[links['trips']>0]\n",
    "only_trips.to_file(config['calibration_fp']/'scratch.gpkg',layer='link_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Aggregate tripids and userids to links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate route characterstics for each trip\n",
    "Think intentionally about what we include here\n",
    "- Length\n",
    "- Elevation (compare this to RWGPS)\n",
    "- Grade with different grade splits\n",
    "- Bike lane, cycletrack, bike path (PATH/BeltLine), pedestrian\n",
    "- Road heirarchy/classification\n",
    "- Speed\n",
    "- Lanes (1,2,3 and remove 1 where car=no)\n",
    "- AADT with a 10,000 AADT cutoff\n",
    "- Motor vehicles allowed\n",
    "- Adjacent to road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 * 3000 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
