{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Report Code\n",
    "This notebook walks through the analyses done for the NCST Report #: Simulating Bike-Transit Trips through BikewaySim.\n",
    "\n",
    "Before proceeding make sure to install packages listed in the modules.txt file.\n",
    "\n",
    "And clone this forked reporsitory with GTFS data and RAPTOR algorithm: [reidx19/transit-routing](https://github.com/reidx19/transit-routing). This forked repo already has the pre-processed MARTA GTFS data and contains a small edit to the transit-routing code used for post-processing the RAPTOR results.\n",
    "\n",
    "This notebook has the code to generate a study area from transit stops and perform shortest path routing for using bike or walk as a first-last mile mode. There are three scripts for running these analyses:\n",
    "\n",
    "1. find candidate stops\n",
    "1. raptor pre-processing\n",
    "1. raptor routing\n",
    "1. raptor mapping\n",
    "1. raptor stats and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add transit-routing repo to path so its modules can be imported\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,str(Path.home() / 'Documents/GitHub/transit-routing'))\n",
    "\n",
    "#custom modules\n",
    "from find_candidate_stops import *\n",
    "from create_transfers import *\n",
    "from raptor_routing import *\n",
    "from raptor_mapping import *\n",
    "from viz_and_metrics import *\n",
    "\n",
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'links', # name of links layer\n",
    "    'nodes_layer': 'nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 2.5, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 8, 0, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 1, 10, 0, 0, 0), # original end time is 10am\n",
    "    #'first_time': datetime(2022, 11, 24, 9, 0, 0, 0), # original start time is 9am\n",
    "    #'end_time': datetime(2022, 11, 24, 10, 0, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/Data' #path where you want things to output \n",
    "    }\n",
    "\n",
    "select_tazs = ['553','1071','1005','1377'] #'288','411'\n",
    "\n",
    "bike_settings = {\n",
    "    'thresh': 5280 * 2, # set access/egress thresh\n",
    "    'max_thresh': 5280 * 2 * 2, # set the max biking/walking amount\n",
    "    'spd': 8,\n",
    "    'mode':'bike',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':False,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False # only allow trips to start near rail stations\n",
    "    }\n",
    "\n",
    "walk_settings = {\n",
    "    'thresh': 5280 * 0.625,\n",
    "    'max_thresh': 5280 * 0.625 * 2, \n",
    "    'spd': 2.5,\n",
    "    'mode':'walk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':True,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False\n",
    "    }\n",
    "\n",
    "#this one assumes bike will be parked at start (does not consider availability of parking)\n",
    "bikewalk_settings = {\n",
    "    'thresh': (5280 * 2, 5280 * 0.625),\n",
    "    'max_thresh': 5280 * (2+0.625),\n",
    "    'spd': (8,2.5),\n",
    "    'mode':'bikewalk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':(False,True),\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running raptor algorithm')\n",
    "\n",
    "\n",
    "select_tazs = ['553']\n",
    "raptor_settings = settings\n",
    "mode_specific = bikewalk_settings\n",
    "\n",
    "#import routes for naming\n",
    "route = pd.read_csv(raptor_settings['gtfs_fp'] / 'route.txt')\n",
    "\n",
    "#retrieve info from dicts\n",
    "mode = mode_specific['mode']\n",
    "impedance = mode_specific['impedance']\n",
    "\n",
    "#deal with travel speeds if there are two\n",
    "if isinstance(mode_specific['spd'],tuple):\n",
    "    spd1 = mode_specific['spd'][0]\n",
    "    spd2 = mode_specific['spd'][1]\n",
    "else:\n",
    "    spd1 = mode_specific['spd']\n",
    "    spd2 = mode_specific['spd']\n",
    "\n",
    "print(f'First leg speed is {spd1} and last leg speed is {spd2}')\n",
    "\n",
    "#get filepaths for select tazs\n",
    "#set to where trips are stored\n",
    "trips_dir = raptor_settings['output_fp'] / f'{mode}_{impedance}/trips'\n",
    "all_trips = [trips_dir / f'{taz}.parquet' for taz in select_tazs]\n",
    "\n",
    "#import network files\n",
    "stops_file, trips_file, stop_times_file, transfers_file, stops_dict, stoptimes_dict, footpath_dict, routes_by_stop_dict, idx_by_route_stop_dict, routesindx_by_stop_dict = read_testcase(\n",
    "    raptor_settings['NETWORK_NAME'])\n",
    "\n",
    "#print details\n",
    "print_network_details(transfers_file, trips_file, stops_file)\n",
    "\n",
    "#get list of times\n",
    "start_times = get_times(raptor_settings['first_time'],raptor_settings['end_time'],raptor_settings['timestep'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_fp = Path.home() / 'Documents/TransitSimData/Data/bike_dist/trips/553.parquet'\n",
    "trips = pd.read_parquet(trips_fp)\n",
    "#trips = trips[trips['dest_taz']=='658']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = start_times[0]\n",
    "trips_fp = Path.home() / 'Documents/TransitSimData/Data/bike_dist/trips/1071.parquet'\n",
    "    \n",
    "#get start taz name\n",
    "taz_name = trips_fp.parts[-1].split('.')[0]\n",
    "\n",
    "#make file name\n",
    "time_name = f'{start_time.hour}_{start_time.minute}'\n",
    "\n",
    "#record starting time\n",
    "time_start = time.time()\n",
    "\n",
    "#import trips file\n",
    "trips = pd.read_parquet(trips_fp)\n",
    "\n",
    "#check mode restrictions\n",
    "if mode_specific['allow_bus_to_bus'] == False:\n",
    "        route_and_stop = gpd.read_file(raptor_settings['output_fp']/'base_layers.gpkg',layer='route_and_stop')[['stop_id','route_type']]\n",
    "        trips = pd.merge(trips,route_and_stop,left_on='src_stop',right_on='stop_id',how='left')\n",
    "        trips = pd.merge(trips,route_and_stop,left_on='dest_stop',right_on='stop_id',how='left')\n",
    "        check = (trips['route_type_y'] == 3) & (trips['route_type_x'] == 3)\n",
    "        trips = trips[-check]\n",
    "        print(f\"{check.sum()} trips were bus to bus\")\n",
    "        trips.drop(columns=['stop_id_x','stop_id_y','route_type_y','route_type_x'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#get actual first leg time (using feet and miles per hour)\n",
    "trips[f'{impedance}_to_time'] = pd.to_timedelta(trips[f'{impedance}_first_leg'] / 5280 / spd1 * 60 * 60, unit='s')#.dt.round(datetime.timedelta(minutes=1))\n",
    "\n",
    "#find actual final leg time\n",
    "trips[f'{impedance}_from_time'] = pd.to_timedelta(trips[f'{impedance}_last_leg'] / 5280 / spd2 * 60 * 60, unit='s')#.dt.round(datetime.timedelta(minutes=1))\n",
    "\n",
    "#get arrival time (to nearest minute) at first transit stop (needs to be datetime)\n",
    "trips['arrival_time'] = (start_time + trips[f'{impedance}_to_time']).dt.round(timedelta(minutes=1))\n",
    "\n",
    "#make empty cols to store raptor outputs\n",
    "trips['status'] = pd.Series(dtype=str)\n",
    "trips['transit_time'] = pd.Series(dtype='timedelta64[ns]')\n",
    "trips['travel_time'] = pd.Series(dtype='timedelta64[ns]')\n",
    "trips['num_transfers'] = pd.Series(dtype=int)\n",
    "trips['edge_list'] = pd.Series(dtype=object)\n",
    "\n",
    "#create a new raptor df for calucating the all unique src/dest transit stops with same arrival time at first stop\n",
    "raptor_df = trips[['src_stop','dest_stop','arrival_time']].drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips = trips[trips['dest_taz']=='658']\n",
    "#trips = trips[trips['src_stop']=='1074']\n",
    "#trips = trips[trips['dest_stop']=='3200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import solved raptor trips to see if it's already been calculated \n",
    "if ((raptor_settings['output_fp'] / f\"raptor_dict_{raptor_settings['MAX_TRANSFER']}_transfers.pkl\").exists()):\n",
    "        with (raptor_settings['output_fp'] / f\"raptor_dict_{raptor_settings['MAX_TRANSFER']}_transfers.pkl\").open(mode='rb') as fh:\n",
    "                pareto_dict = pickle.load(fh)\n",
    "        #remove rows from raptor_df if already solved\n",
    "        raptor_df['tup'] = list(zip(raptor_df['src_stop'].astype(int),raptor_df['dest_stop'].astype(int),raptor_df['arrival_time']))\n",
    "        previously_calculated = raptor_df['tup'].isin(list(pareto_dict.keys()))\n",
    "        raptor_df = raptor_df[-previously_calculated]\n",
    "else:\n",
    "        #initialize an empty dict to store pareto results\n",
    "        pareto_dict = {}\n",
    "\n",
    "if raptor_df.shape[0] != 0:\n",
    "        print(f'Performing transit routing from {taz_name} at {start_time}:')\n",
    "        #should loop through all unique times instead of every row (round arrival time to nearest minute)\n",
    "        for row in tqdm(raptor_df.itertuples(),total=raptor_df.shape[0]):\n",
    "                #for row in raptor_df.itertuples():\n",
    "                \n",
    "                #pull out the three inputs needed for raptor\n",
    "                SOURCE = int(row[1])\n",
    "                DESTINATION = int(row[2])\n",
    "                D_TIME = row[3]\n",
    "\n",
    "                #run standard raptor algorithm\n",
    "                output, pareto_set = raptor(SOURCE, DESTINATION, D_TIME, raptor_settings['MAX_TRANSFER'], \n",
    "                                raptor_settings['WALKING_FROM_SOURCE'], raptor_settings['CHANGE_TIME_SEC'], raptor_settings['PRINT_ITINERARY'],\n",
    "                                routes_by_stop_dict, stops_dict, stoptimes_dict, footpath_dict, idx_by_route_stop_dict)\n",
    "                \n",
    "                #store pareto set in dict for next step\n",
    "                pareto_dict[(SOURCE,DESTINATION,D_TIME)] = pareto_set\n",
    "else:\n",
    "        print(f\"RAPTOR solution already found from {taz_name} at {start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#need to change this from iterrows to concat instead\n",
    "print(f'Solving shortest {mode} + transit routing from {taz_name} at {start_time}:')\n",
    "for row in tqdm(trips.itertuples(),total=trips.shape[0]):\n",
    "#for row in trips.itertuples():\n",
    "        \n",
    "        #pull out the three inputs needed for raptor\n",
    "        SOURCE = int(row[3])\n",
    "        DESTINATION = int(row[4])\n",
    "        D_TIME = row[11]\n",
    "        \n",
    "        #get pareto set from the pareto dict\n",
    "        pareto_set = pareto_dict.get((SOURCE,DESTINATION,D_TIME),'Error')\n",
    "\n",
    "        #skip to next if no solutions\n",
    "        #come back to this\n",
    "        if pareto_set == None:\n",
    "                trips.at[row[0],'status'] = 'not possible'\n",
    "                continue\n",
    "        elif pareto_set == 'Error':\n",
    "                print('Error')\n",
    "                break\n",
    "\n",
    "        #create empty list for storing pareto results\n",
    "        shortest_time = []\n",
    "        \n",
    "        #go through each pareto optimal for the given number of transfers\n",
    "        for pareto_optimal in pareto_set:\n",
    "        \n",
    "                #pull out the number of transfers and the edge list\n",
    "                num_transfers = pareto_optimal[0]\n",
    "                edges = pareto_optimal[1]\n",
    "        \n",
    "        #get rid of final walking leg (will be replaced with network results)\n",
    "        while edges[-1][0] == 'walking':\n",
    "                edges = edges[:-1]\n",
    "\n",
    "        #get total travel time from start (time at final egress + last bike/walk leg - departure time)\n",
    "        travel_time = edges[-1][3] + row[10] - start_time\n",
    "\n",
    "        #get total transit travel time (final egress - departure time from first transit stop) \n",
    "        transit_time = edges[-1][3] - D_TIME\n",
    "\n",
    "        #store as list\n",
    "        candidate = [num_transfers,travel_time,transit_time,edges]\n",
    "\n",
    "        #only retain shortest travel time\n",
    "        if len(shortest_time) == 0:\n",
    "                shortest_time = candidate\n",
    "        elif candidate[1] < shortest_time[1]:\n",
    "                shortest_time = candidate\n",
    "        \n",
    "        #update trips dataframe with results from raptor \n",
    "        trips.at[row[0],'num_transfers'] = shortest_time[0]\n",
    "        trips.at[row[0],'travel_time'] = shortest_time[1]\n",
    "        trips.at[row[0],'transit_time'] = shortest_time[2]\n",
    "        \n",
    "        #initialize edge list for storing legs of transit trip\n",
    "        edge_list = []\n",
    "        \n",
    "        #track the wait time\n",
    "        wait_time = timedelta(minutes=0)\n",
    "\n",
    "        #store the first arrival time\n",
    "        arrive = D_TIME\n",
    "\n",
    "        #track transfer time\n",
    "        transfer_time = timedelta(minutes=0)\n",
    "\n",
    "        #edge list structure\n",
    "        #leg[0] : \"\"walking\" (str) or the boarding time (datetime) if transit\n",
    "        #leg[1] : starting transit stop\n",
    "        #leg[2] : ending transit stop\n",
    "        #leg[3] : if walking = travel time and if transit = time at egress\n",
    "        #leg[4] : only for transit = route and trip number\n",
    "\n",
    "        #transit tup to output for edge list\n",
    "        #(start stop, end stop, egress time - boarding time (travel time), route/trip, transit mode)\n",
    "\n",
    "        #go through each leg in edge list and format\n",
    "        for leg in shortest_time[3]:\n",
    "        \n",
    "                #format transit legs\n",
    "                if leg[0] != 'walking':\n",
    "                        \n",
    "                        #calculate wait time for segment (time at boarding - time arrived)\n",
    "                        segment_wait_time = leg[0] - arrive\n",
    "\n",
    "                        #add to total weight time\n",
    "                        wait_time += segment_wait_time\n",
    "                        \n",
    "                        #replace with the next arrival time at the next stop\n",
    "                        arrive = leg[3]\n",
    "\n",
    "                        #extract route_id\n",
    "                        route_id = str.split(leg[4],'_')[0]\n",
    "                        \n",
    "                        #get transit mode from the transit routes csv\n",
    "                        route_type = route[route['new_route_id'].astype(str)==route_id]['route_type'].item()\n",
    "\n",
    "                        #get transit line name\n",
    "                        name = route[route['new_route_id'].astype(str)==route_id]['route_long_name'].item()      \n",
    "                        \n",
    "                        #format transit tuple to add to the edge list\n",
    "                        #TODO work with prateek on ensuring that the newly labeled routes and stops are labeled in all GTFS files\n",
    "                        if (route_type == 1) | (route_type == '1'):\n",
    "                                tup = (leg[1],leg[2],leg[3]-leg[0],leg[4],'rail',name)\n",
    "                        elif (route_type == 3) | (route_type == '3'):\n",
    "                                tup = (leg[1],leg[2],leg[3]-leg[0],leg[4],'bus',name) \n",
    "\n",
    "                #format walk legs\n",
    "                else:\n",
    "                        #format the walking tuple and add to edge list\n",
    "                        tup = (leg[1],leg[2],leg[3],'walking')\n",
    "                        \n",
    "                        #track transfer time (so it can be subtracted from wait time)\n",
    "                        transfer_time += leg[3]\n",
    "\n",
    "        #add tuple to edge list\n",
    "        edge_list.append(tup)\n",
    "        \n",
    "        #get total wait time\n",
    "        trips.at[row[0],'wait_time'] = wait_time - transfer_time\n",
    "        \n",
    "        #get total transfer time\n",
    "        trips.at[row[0],'transfer_time'] = transfer_time\n",
    "\n",
    "        #add edge list to trips\n",
    "        trips.at[row[0],'edge_list'] = edge_list\n",
    "        \n",
    "        #set initial success message\n",
    "        trips.at[row[0],'status'] = 'success'\n",
    "        \n",
    "        # removed these two for now\n",
    "        # #check travel time\n",
    "        # if travel_time >= raptor_settings['timelimit']:\n",
    "        #     trips.at[row[0],'status'] = 'time limit exceeded'\n",
    "        \n",
    "        # #check mode restrictions\n",
    "        # if not mode_specific['allow_bus_to_bus']:\n",
    "        #     if len([x for x in edge_list if x[-1] == 'bus']) > 1:\n",
    "        #         trips.at[row[0],'status'] = 'two buses'\n",
    "\n",
    "#embed start time\n",
    "trips['start_time'] = start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[trips.travel_time.idxmin(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import numpy as np\n",
    "\n",
    "#import custom functions\n",
    "from helper_functions import process_results, load_files\n",
    "\n",
    "'''\n",
    "Notes:\n",
    "\n",
    "take more of a sql approach update/merge?\n",
    "\n",
    "have taz centroid/polygon layer instead seperating into many layers\n",
    "\n",
    "when merging, it's duplicating the dest_taz column\n",
    "\n",
    "'''\n",
    "\n",
    "def viz_and_metrics(settings:dict,impedance:str,mode:str,list_tazs:list):\n",
    "\n",
    "    # #get list of tazs\n",
    "    # list_tazs = settings['output_fp'].glob(f'{mode}_{impedance}/raptor_results/*')\n",
    "    # list_tazs = [x.parts[-1] for x in list_tazs]\n",
    "\n",
    "    # save to same .gpkg as taz name\n",
    "    # #make the vis folder\n",
    "    # if not (settings['output_fp'] / f'{mode}_{impedance}/visuals').exists():\n",
    "    #     (settings['output_fp'] / f'{mode}_{impedance}/visuals').mkdir()\n",
    "\n",
    "    for taz in tqdm(list_tazs):\n",
    "        \n",
    "        #import taz polygons\n",
    "        tazs = gpd.read_file(settings['output_fp'] / 'base_layers.gpkg',layer='tazs')[[settings['keyid'],'geometry']]\n",
    "\n",
    "        #import taz centroids\n",
    "        centroids = gpd.read_file(settings['output_fp'] / 'base_layers.gpkg',layer='centroids')[[settings['keyid'],'geometry']] \n",
    "\n",
    "        #map all transit routes used\n",
    "        transit_shed(settings,impedance,mode,taz)\n",
    "\n",
    "        #import walkable/bikable tazs\n",
    "        #bike_tazs = gpd.read_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer=f'{mode}able_tazs_polygons',ignore_geometry=True)\n",
    "\n",
    "        #get filepaths for all departure times\n",
    "        dep_times = settings['output_fp'].glob(f'{mode}_{impedance}/raptor_results/{taz}/*.pkl')\n",
    "\n",
    "        #initialize empty dataframe for storing all the trip data per departure time\n",
    "        all_trips = pd.DataFrame()\n",
    "\n",
    "        #loop through each departure time\n",
    "        for dep_time in dep_times:\n",
    "\n",
    "            #get departure time text\n",
    "            #dep = dep_time.parts[-1].split('.pkl')[0]\n",
    "\n",
    "            #read in results file and find the least time route per departure time\n",
    "            with fp.open(mode='rb') as fh:\n",
    "                trips = pickle.load(fh)\n",
    "            #only get successful trips\n",
    "            trips = trips[trips['status']=='success']\n",
    "            #groupby to get minimum\n",
    "            trips = trips.loc[trips.groupby(['src_taz','dest_taz'])['travel_time'].idxmin().to_list(),:]\n",
    "\n",
    "            #convert time cols from datetime to total minutes (round to 1 decimal)\n",
    "            time_cols = trip_df.columns[trip_df.dtypes == 'timedelta64[ns]']\n",
    "            for time_col in time_cols:\n",
    "                trip_df[time_col] = trip_df[time_col].apply(lambda x: round(x.total_seconds() / 60,1))\n",
    "\n",
    "            #append to all_trips dataframe\n",
    "            all_trips = pd.concat([all_trips,trip_df],ignore_index=True)\n",
    "\n",
    "        #get average transit time, travel time, and wait time\n",
    "        avg_transit_time = all_trips.groupby('dest_taz')['transit_time'].mean()\n",
    "        avg_travel_time = all_trips.groupby('dest_taz')['travel_time'].mean()\n",
    "        avg_wait_time = all_trips.groupby('dest_taz')['wait_time'].mean()\n",
    "\n",
    "        #get minimum number of transfers\n",
    "        min_transfers = all_trips.groupby('dest_taz')['num_transfers'].min()\n",
    "\n",
    "        # go through the edge list and concatanate all the transit modes together  \n",
    "        for idx, row in all_trips.iterrows():\n",
    "            \n",
    "            #list comp to get list of modes for each trip\n",
    "            modes = [edge[-1] for edge in row['edge_list'] if (edge[-1] == 'bus') or (edge[-1] == 'rail')]\n",
    "            \n",
    "            #turn to series\n",
    "            modes = pd.Series(modes)\n",
    "\n",
    "            try:\n",
    "            \n",
    "                #types\n",
    "                if modes.nunique() > 1:\n",
    "                    types = 'Two Modes'\n",
    "                elif modes[0] == 'rail':\n",
    "                    types = 'Rail'\n",
    "                elif modes[0] == 'bus':\n",
    "                    types = 'Bus'\n",
    "            except:\n",
    "                print(modes)\n",
    "                break\n",
    "            \n",
    "            #add to trip_df\n",
    "            all_trips.at[idx,'types'] = types\n",
    "\n",
    "        #get mode of transit type (bus, rail, mixed)\n",
    "        print(all_trips)\n",
    "        mode_type = all_trips.groupby('dest_taz')['types'].agg(pd.Series.mode)\n",
    "\n",
    "        #if more than one mode, say mixed\n",
    "        mode_type = mode_type.apply(lambda x: replace_list_with_string(x))\n",
    "\n",
    "        #join data to tazs (i think this is where it messes up, trying map instead)\n",
    "        tazs['avg_transit_time'] = tazs[settings['keyid']].map(avg_transit_time)\n",
    "        tazs['avg_travel_time'] = tazs[settings['keyid']].map(avg_travel_time)\n",
    "        tazs['avg_wait_time'] = tazs[settings['keyid']].map(avg_wait_time)\n",
    "        tazs['min_transfers'] = tazs[settings['keyid']].map(min_transfers)\n",
    "        tazs['mode_type'] = tazs[settings['keyid']].map(mode_type)\n",
    "        #prolly add min/max for the times and count how many time periods taz was inaccessible\n",
    "        \n",
    "        #drop null rows\n",
    "        tazs = tazs[-tazs.isna().any(axis=1)]\n",
    "\n",
    "        #export\n",
    "        tazs.to_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer='tazs_viz')\n",
    "        \n",
    "        #drop the geometry column\n",
    "        tazs.drop(columns=['geometry'],inplace=True)\n",
    "\n",
    "        #join data to centroids by merging with tazs\n",
    "        centroids = pd.merge(centroids,tazs,on=settings['keyid'])\n",
    "        \n",
    "        #drop null rows (shouldn't be any)\n",
    "        centroids = centroids[-centroids.isna().any(axis=1)]\n",
    "\n",
    "        #export\n",
    "        try: \n",
    "            centroids.to_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer='centroids_viz')\n",
    "        except:\n",
    "            print(centroids)\n",
    "\n",
    "\n",
    "def replace_list_with_string(lst):\n",
    "    if isinstance(lst, np.ndarray):\n",
    "        return 'Mixed'\n",
    "    elif isinstance(lst,list):\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        return lst\n",
    "\n",
    "def transit_shed(settings:dict,impedance:str,mode:str,list_taz:str):\n",
    "    '''\n",
    "    Creates polygon showing all the transit lines utilized using the RAPTOR outputs\n",
    "\n",
    "    would like to also figure out a betweenness centrality like metric but that will wait\n",
    "    '''\n",
    "\n",
    "    #get filepaths\n",
    "    fps = settings['output_fp'].glob(f'{mode}_{impedance}/mapped/{list_taz}/*.gpkg')\n",
    "\n",
    "    big_df = gpd.GeoDataFrame()\n",
    "    \n",
    "    for fp in fps:\n",
    "        #load each time\n",
    "        for start_time in fiona.listlayers(fp):\n",
    "        \n",
    "            trip = gpd.read_file(fp,layer=start_time)\n",
    "                \n",
    "            #only keep transit\n",
    "            trip = trip.loc[trip['mode'].isin(['rail','bus']),['mode','start_stop','end_stop','geometry']]\n",
    "            \n",
    "            big_df = pd.concat([big_df,trip],ignore_index=True)\n",
    "        \n",
    "        #drop duplicates\n",
    "        big_df.drop_duplicates(['mode','start_stop','end_stop'],inplace=True)\n",
    "    \n",
    "    #set activee geo column\n",
    "    big_df.set_geometry('geometry',inplace=True)\n",
    "\n",
    "    #buffer because polygons faster to dissolve than linestrings\n",
    "    big_df.geometry = big_df.buffer(400)\n",
    "    \n",
    "    #dissolve\n",
    "    big_df = big_df.dissolve('mode')\n",
    "    \n",
    "    #export\n",
    "    big_df.to_file(settings['output_fp'] / f'{mode}_{impedance}/{list_taz}.gpkg',layer='transitshed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "# create bike trip files\n",
    "raptor_preprocessing(settings,bike_settings,select_tazs)\n",
    "\n",
    "# create walk trip files\n",
    "raptor_preprocessing(settings,walk_settings,select_tazs)\n",
    "\n",
    "# create bikewalk trip files\n",
    "raptor_preprocessing(settings,bikewalk_settings,select_tazs)\n",
    "# can add more or comment out as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#410 minutes\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "run_raptor(select_tazs,settings,bike_settings)\n",
    "#160 minutes??\n",
    "run_raptor(select_tazs,settings,walk_settings)\n",
    "#430minutes\n",
    "run_raptor(select_tazs,settings,bikewalk_settings)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compact View (LTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'lowstress_links', # name of links layer\n",
    "    'nodes_layer': 'lowstress_nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 3, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 8, 0, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 1, 10, 0, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/LTS' #path where you want things to output \n",
    "    }\n",
    "\n",
    "#select_tazs = ['1071']#['288','553','411','1071']\n",
    "\n",
    "bikelts_settings = {\n",
    "    'thresh': 5280 * 2.5, # set access/egress thresh\n",
    "    'max_thresh': 5280 * 2.5 * 2, # set the max biking/walking amount\n",
    "    'spd': 8,\n",
    "    'mode':'bikelts',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':False,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True\n",
    "    }\n",
    "\n",
    "#create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "raptor_preprocessing(settings,bikelts_settings,select_tazs)\n",
    "\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "run_raptor(select_tazs,settings,bikelts_settings)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)\n",
    "\n",
    "impedance = 'dist'\n",
    "modes = ['bikelts']\n",
    "\n",
    "for mode in modes:\n",
    "    map_routes(settings,impedance,mode,select_tazs)\n",
    "    viz_and_metrics(settings,impedance,mode,select_tazs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using model OD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'links', # name of links layer\n",
    "    'nodes_layer': 'nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 3, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 4, 30, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 2, 00, 30, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/ABM', #path where you want things to output \n",
    "\n",
    "    #restrict to only starting at rail station\n",
    "    'rail_start' : True\n",
    "    }\n",
    "\n",
    "#bring in od data\n",
    "ods = pd.read_csv(settings['output_fp']/'ods.csv')\n",
    "ods['origin'] = ods['origin'].astype(str)\n",
    "ods['destination'] = ods['destination'].astype(str)\n",
    "#all tazs\n",
    "select_tazs = ods['origin'].unique().tolist()#['1071']#['288','553','411','1071']\n",
    "\n",
    "#check if trip is within 1 hr of the departure time (ABM specific)\n",
    "ods['year'] = settings['service_date'].year\n",
    "ods['month'] = settings['service_date'].month\n",
    "ods['day'] = settings['service_date'].day\n",
    "ods['adj_time'] = pd.to_datetime(ods[['year','month','day','hour','minute']])\n",
    "ods['adjusted'] = ods['adj_time'] + pd.to_timedelta(ods['depart_time'])\n",
    "\n",
    "# bike_settings = {\n",
    "#     'thresh': 5280 * 2.5, # set access/egress thresh\n",
    "#     'max_thresh': 5280 * 2.5 * 2, # set the max biking/walking amount\n",
    "#     'spd': 8,\n",
    "#     'mode':'bike',\n",
    "#     'impedance':'dist',\n",
    "#     'allow_wrongway':False,\n",
    "#     'allow_bus_to_bus':False,\n",
    "#     'overwrite_existing': False\n",
    "#     }\n",
    "\n",
    "walk_settings = {\n",
    "    'thresh': 5280 * 0.5,\n",
    "    'max_thresh': 5280 * 0.5 * 2, #set to twice\n",
    "    'spd': 3,\n",
    "    'mode':'walk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':True,\n",
    "    'allow_bus_to_bus':True,\n",
    "    'overwrite_existing': True\n",
    "    }\n",
    "\n",
    "#this one assumes bike will be parked at start (removes bus stops from first mile that aren't next to rail)\n",
    "bikewalk_settings = {\n",
    "    'thresh': (5280 * 2.5, 5280 * 0.5),\n",
    "    'max_thresh': 5280 * (3),\n",
    "    'spd': (8,2.5),\n",
    "    'mode':'bikewalk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':(False,True),\n",
    "    'allow_bus_to_bus':True,\n",
    "    'overwrite_existing': True\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "raptor_preprocessing(settings,bikewalk_settings,select_tazs,ods)\n",
    "raptor_preprocessing(settings,walk_settings,select_tazs,ods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "#run_raptor(select_tazs,settings,bikewalk_settings,ods)\n",
    "run_raptor(select_tazs,settings,walk_settings,ods)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "impedance = 'dist'\n",
    "modes = ['walk','bikewalk']\n",
    "\n",
    "for mode in modes:#\n",
    "    map_routes(settings,impedance,mode,select_tazs)\n",
    "    viz_and_metrics(settings,impedance,mode,select_tazs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
