{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Report Code\n",
    "This notebook walks through the analyses done for the NCST Report #: Simulating Bike-Transit Trips through BikewaySim.\n",
    "\n",
    "Before proceeding make sure to install packages listed in the modules.txt file.\n",
    "\n",
    "And clone this forked reporsitory with GTFS data and RAPTOR algorithm: [reidx19/transit-routing](https://github.com/reidx19/transit-routing). This forked repo already has the pre-processed MARTA GTFS data and contains a small edit to the transit-routing code used for post-processing the RAPTOR results.\n",
    "\n",
    "This notebook has the code to generate a study area from transit stops and perform shortest path routing for using bike or walk as a first-last mile mode. There are three scripts for running these analyses:\n",
    "\n",
    "1. find candidate stops\n",
    "1. raptor pre-processing\n",
    "1. raptor routing\n",
    "1. raptor mapping\n",
    "1. raptor stats and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add transit-routing repo to path so its modules can be imported\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,str(Path.home() / 'Documents/GitHub/transit-routing'))\n",
    "\n",
    "#custom modules\n",
    "from find_candidate_stops import *\n",
    "from create_transfers import *\n",
    "from raptor_routing import *\n",
    "from raptor_mapping import *\n",
    "from viz_and_metrics import *\n",
    "\n",
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'links', # name of links layer\n",
    "    'nodes_layer': 'nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 2.5, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 8, 0, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 1, 10, 0, 0, 0), # original end time is 10am\n",
    "    #'first_time': datetime(2022, 11, 24, 9, 0, 0, 0), # original start time is 9am\n",
    "    #'end_time': datetime(2022, 11, 24, 10, 0, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/Data' #path where you want things to output \n",
    "    }\n",
    "\n",
    "select_tazs = ['553','1071','1005','1377'] #'288','411'\n",
    "\n",
    "bike_settings = {\n",
    "    'thresh': 5280 * 2, # set access/egress thresh\n",
    "    'max_thresh': 5280 * 2 * 2, # set the max biking/walking amount\n",
    "    'spd': 8,\n",
    "    'mode':'bike',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':False,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False # only allow trips to start near rail stations\n",
    "    }\n",
    "\n",
    "walk_settings = {\n",
    "    'thresh': 5280 * 0.625,\n",
    "    'max_thresh': 5280 * 0.625 * 2, \n",
    "    'spd': 2.5,\n",
    "    'mode':'walk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':True,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False\n",
    "    }\n",
    "\n",
    "#this one assumes bike will be parked at start (does not consider availability of parking)\n",
    "bikewalk_settings = {\n",
    "    'thresh': (5280 * 2, 5280 * 0.625),\n",
    "    'max_thresh': 5280 * (2+0.625),\n",
    "    'spd': (8,2.5),\n",
    "    'mode':'bikewalk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':(False,True),\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True,\n",
    "    'rail_start':False\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running raptor algorithm\n",
      "First leg speed is 8 and last leg speed is 2.5\n",
      "___________________________Network Details__________________________\n",
      "| No. of Routes |  No. of Trips | No. of Stops | No. of Footapths  |\n",
      "|     342      |  7983        | 8966        | 26638             |\n",
      "____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Running raptor algorithm')\n",
    "\n",
    "\n",
    "select_tazs = ['553']\n",
    "raptor_settings = settings\n",
    "mode_specific = bikewalk_settings\n",
    "\n",
    "#import routes for naming\n",
    "route = pd.read_csv(raptor_settings['gtfs_fp'] / 'route.txt')\n",
    "\n",
    "#retrieve info from dicts\n",
    "mode = mode_specific['mode']\n",
    "impedance = mode_specific['impedance']\n",
    "\n",
    "#deal with travel speeds if there are two\n",
    "if isinstance(mode_specific['spd'],tuple):\n",
    "    spd1 = mode_specific['spd'][0]\n",
    "    spd2 = mode_specific['spd'][1]\n",
    "else:\n",
    "    spd1 = mode_specific['spd']\n",
    "    spd2 = mode_specific['spd']\n",
    "\n",
    "print(f'First leg speed is {spd1} and last leg speed is {spd2}')\n",
    "\n",
    "#get filepaths for select tazs\n",
    "#set to where trips are stored\n",
    "trips_dir = raptor_settings['output_fp'] / f'{mode}_{impedance}/trips'\n",
    "all_trips = [trips_dir / f'{taz}.parquet' for taz in select_tazs]\n",
    "\n",
    "#import network files\n",
    "stops_file, trips_file, stop_times_file, transfers_file, stops_dict, stoptimes_dict, footpath_dict, routes_by_stop_dict, idx_by_route_stop_dict, routesindx_by_stop_dict = read_testcase(\n",
    "    raptor_settings['NETWORK_NAME'])\n",
    "\n",
    "#print details\n",
    "print_network_details(transfers_file, trips_file, stops_file)\n",
    "\n",
    "#get list of times\n",
    "start_times = get_times(raptor_settings['first_time'],raptor_settings['end_time'],raptor_settings['timestep'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_fp = Path.home() / 'Documents/TransitSimData/Data/bike_dist/trips/553.parquet'\n",
    "trips = pd.read_parquet(trips_fp)\n",
    "#trips = trips[trips['dest_taz']=='658']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_taz</th>\n",
       "      <th>dest_taz</th>\n",
       "      <th>src_stop</th>\n",
       "      <th>dest_stop</th>\n",
       "      <th>dist_first_leg</th>\n",
       "      <th>dist_last_leg</th>\n",
       "      <th>first_leg</th>\n",
       "      <th>last_leg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>553</td>\n",
       "      <td>56</td>\n",
       "      <td>4548</td>\n",
       "      <td>1947</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>6773.07</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>6773.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553</td>\n",
       "      <td>56</td>\n",
       "      <td>4548</td>\n",
       "      <td>1941</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>6760.80</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>6760.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>553</td>\n",
       "      <td>8</td>\n",
       "      <td>4548</td>\n",
       "      <td>1946</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>9261.32</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>9261.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>553</td>\n",
       "      <td>55</td>\n",
       "      <td>4548</td>\n",
       "      <td>1946</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>7305.16</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>7305.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>553</td>\n",
       "      <td>59</td>\n",
       "      <td>4548</td>\n",
       "      <td>1946</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>3423.70</td>\n",
       "      <td>5032.94</td>\n",
       "      <td>3423.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132903</th>\n",
       "      <td>553</td>\n",
       "      <td>3723</td>\n",
       "      <td>157</td>\n",
       "      <td>8730</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>7794.87</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>7794.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132904</th>\n",
       "      <td>553</td>\n",
       "      <td>4607</td>\n",
       "      <td>157</td>\n",
       "      <td>8741</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>2763.64</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>2763.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132905</th>\n",
       "      <td>553</td>\n",
       "      <td>4610</td>\n",
       "      <td>157</td>\n",
       "      <td>8741</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>5723.95</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>5723.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132906</th>\n",
       "      <td>553</td>\n",
       "      <td>4607</td>\n",
       "      <td>157</td>\n",
       "      <td>6753</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>2758.59</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>2758.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132907</th>\n",
       "      <td>553</td>\n",
       "      <td>4610</td>\n",
       "      <td>157</td>\n",
       "      <td>6753</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>5718.90</td>\n",
       "      <td>10524.80</td>\n",
       "      <td>5718.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614264 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        src_taz dest_taz src_stop dest_stop  dist_first_leg  dist_last_leg  \\\n",
       "index                                                                        \n",
       "0           553       56     4548      1947         5032.94        6773.07   \n",
       "1           553       56     4548      1941         5032.94        6760.80   \n",
       "2           553        8     4548      1946         5032.94        9261.32   \n",
       "3           553       55     4548      1946         5032.94        7305.16   \n",
       "4           553       59     4548      1946         5032.94        3423.70   \n",
       "...         ...      ...      ...       ...             ...            ...   \n",
       "1132903     553     3723      157      8730        10524.80        7794.87   \n",
       "1132904     553     4607      157      8741        10524.80        2763.64   \n",
       "1132905     553     4610      157      8741        10524.80        5723.95   \n",
       "1132906     553     4607      157      6753        10524.80        2758.59   \n",
       "1132907     553     4610      157      6753        10524.80        5718.90   \n",
       "\n",
       "         first_leg  last_leg  \n",
       "index                         \n",
       "0          5032.94   6773.07  \n",
       "1          5032.94   6760.80  \n",
       "2          5032.94   9261.32  \n",
       "3          5032.94   7305.16  \n",
       "4          5032.94   3423.70  \n",
       "...            ...       ...  \n",
       "1132903   10524.80   7794.87  \n",
       "1132904   10524.80   2763.64  \n",
       "1132905   10524.80   5723.95  \n",
       "1132906   10524.80   2758.59  \n",
       "1132907   10524.80   5718.90  \n",
       "\n",
       "[614264 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213596 trips were bus to bus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = start_times[0]\n",
    "trips_fp = Path.home() / 'Documents/TransitSimData/Data/bike_dist/trips/1071.parquet'\n",
    "    \n",
    "#get start taz name\n",
    "taz_name = trips_fp.parts[-1].split('.')[0]\n",
    "\n",
    "#make file name\n",
    "time_name = f'{start_time.hour}_{start_time.minute}'\n",
    "\n",
    "#record starting time\n",
    "time_start = time.time()\n",
    "\n",
    "#import trips file\n",
    "trips = pd.read_parquet(trips_fp)\n",
    "\n",
    "#check mode restrictions\n",
    "if mode_specific['allow_bus_to_bus'] == False:\n",
    "        route_and_stop = gpd.read_file(raptor_settings['output_fp']/'base_layers.gpkg',layer='route_and_stop')[['stop_id','route_type']]\n",
    "        trips = pd.merge(trips,route_and_stop,left_on='src_stop',right_on='stop_id',how='left')\n",
    "        trips = pd.merge(trips,route_and_stop,left_on='dest_stop',right_on='stop_id',how='left')\n",
    "        check = (trips['route_type_y'] == 3) & (trips['route_type_x'] == 3)\n",
    "        trips = trips[-check]\n",
    "        print(f\"{check.sum()} trips were bus to bus\")\n",
    "        trips.drop(columns=['stop_id_x','stop_id_y','route_type_y','route_type_x'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#get actual first leg time (using feet and miles per hour)\n",
    "trips[f'{impedance}_to_time'] = pd.to_timedelta(trips[f'{impedance}_first_leg'] / 5280 / spd1 * 60 * 60, unit='s')#.dt.round(datetime.timedelta(minutes=1))\n",
    "\n",
    "#find actual final leg time\n",
    "trips[f'{impedance}_from_time'] = pd.to_timedelta(trips[f'{impedance}_last_leg'] / 5280 / spd2 * 60 * 60, unit='s')#.dt.round(datetime.timedelta(minutes=1))\n",
    "\n",
    "#get arrival time (to nearest minute) at first transit stop (needs to be datetime)\n",
    "trips['arrival_time'] = (start_time + trips[f'{impedance}_to_time']).dt.round(timedelta(minutes=1))\n",
    "\n",
    "#make empty cols to store raptor outputs\n",
    "trips['status'] = pd.Series(dtype=str)\n",
    "trips['transit_time'] = pd.Series(dtype='timedelta64[ns]')\n",
    "trips['travel_time'] = pd.Series(dtype='timedelta64[ns]')\n",
    "trips['num_transfers'] = pd.Series(dtype=int)\n",
    "trips['edge_list'] = pd.Series(dtype=object)\n",
    "\n",
    "#create a new raptor df for calucating the all unique src/dest transit stops with same arrival time at first stop\n",
    "raptor_df = trips[['src_stop','dest_stop','arrival_time']].drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips = trips[trips['dest_taz']=='658']\n",
    "#trips = trips[trips['src_stop']=='1074']\n",
    "#trips = trips[trips['dest_stop']=='3200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_taz</th>\n",
       "      <th>dest_taz</th>\n",
       "      <th>src_stop</th>\n",
       "      <th>dest_stop</th>\n",
       "      <th>dist_first_leg</th>\n",
       "      <th>dist_last_leg</th>\n",
       "      <th>first_leg</th>\n",
       "      <th>last_leg</th>\n",
       "      <th>dist_to_time</th>\n",
       "      <th>dist_from_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>status</th>\n",
       "      <th>transit_time</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>num_transfers</th>\n",
       "      <th>edge_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>1071</td>\n",
       "      <td>199</td>\n",
       "      <td>1122</td>\n",
       "      <td>6410</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>0 days 00:14:35.134090909</td>\n",
       "      <td>0 days 00:38:03.692727273</td>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>1071</td>\n",
       "      <td>199</td>\n",
       "      <td>1122</td>\n",
       "      <td>6410</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>0 days 00:14:35.134090909</td>\n",
       "      <td>0 days 00:38:03.692727273</td>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>1071</td>\n",
       "      <td>199</td>\n",
       "      <td>1122</td>\n",
       "      <td>6410</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>0 days 00:14:35.134090909</td>\n",
       "      <td>0 days 00:38:03.692727273</td>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>1071</td>\n",
       "      <td>199</td>\n",
       "      <td>1122</td>\n",
       "      <td>6410</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>8373.54</td>\n",
       "      <td>0 days 00:14:35.134090909</td>\n",
       "      <td>0 days 00:38:03.692727273</td>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>1071</td>\n",
       "      <td>204</td>\n",
       "      <td>1122</td>\n",
       "      <td>6410</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>7567.62</td>\n",
       "      <td>10268.24</td>\n",
       "      <td>7567.62</td>\n",
       "      <td>0 days 00:14:35.134090909</td>\n",
       "      <td>0 days 00:34:23.896363636</td>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357979</th>\n",
       "      <td>1071</td>\n",
       "      <td>1660</td>\n",
       "      <td>2051</td>\n",
       "      <td>2817</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>4681.30</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>4681.30</td>\n",
       "      <td>0 days 00:03:07.685795455</td>\n",
       "      <td>0 days 00:21:16.718181818</td>\n",
       "      <td>2023-03-01 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357980</th>\n",
       "      <td>1071</td>\n",
       "      <td>1711</td>\n",
       "      <td>2051</td>\n",
       "      <td>2817</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9904.62</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9904.62</td>\n",
       "      <td>0 days 00:03:07.685795455</td>\n",
       "      <td>0 days 00:45:01.260000</td>\n",
       "      <td>2023-03-01 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357981</th>\n",
       "      <td>1071</td>\n",
       "      <td>1711</td>\n",
       "      <td>2051</td>\n",
       "      <td>2817</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9904.62</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9904.62</td>\n",
       "      <td>0 days 00:03:07.685795455</td>\n",
       "      <td>0 days 00:45:01.260000</td>\n",
       "      <td>2023-03-01 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357982</th>\n",
       "      <td>1071</td>\n",
       "      <td>1712</td>\n",
       "      <td>2051</td>\n",
       "      <td>2817</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9814.43</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9814.43</td>\n",
       "      <td>0 days 00:03:07.685795455</td>\n",
       "      <td>0 days 00:44:36.662727273</td>\n",
       "      <td>2023-03-01 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357983</th>\n",
       "      <td>1071</td>\n",
       "      <td>1712</td>\n",
       "      <td>2051</td>\n",
       "      <td>2817</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9814.43</td>\n",
       "      <td>2202.18</td>\n",
       "      <td>9814.43</td>\n",
       "      <td>0 days 00:03:07.685795455</td>\n",
       "      <td>0 days 00:44:36.662727273</td>\n",
       "      <td>2023-03-01 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151632 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        src_taz dest_taz src_stop dest_stop  dist_first_leg  dist_last_leg  \\\n",
       "2156       1071      199     1122      6410        10268.24        8373.54   \n",
       "2157       1071      199     1122      6410        10268.24        8373.54   \n",
       "2158       1071      199     1122      6410        10268.24        8373.54   \n",
       "2159       1071      199     1122      6410        10268.24        8373.54   \n",
       "2160       1071      204     1122      6410        10268.24        7567.62   \n",
       "...         ...      ...      ...       ...             ...            ...   \n",
       "1357979    1071     1660     2051      2817         2202.18        4681.30   \n",
       "1357980    1071     1711     2051      2817         2202.18        9904.62   \n",
       "1357981    1071     1711     2051      2817         2202.18        9904.62   \n",
       "1357982    1071     1712     2051      2817         2202.18        9814.43   \n",
       "1357983    1071     1712     2051      2817         2202.18        9814.43   \n",
       "\n",
       "         first_leg  last_leg              dist_to_time  \\\n",
       "2156      10268.24   8373.54 0 days 00:14:35.134090909   \n",
       "2157      10268.24   8373.54 0 days 00:14:35.134090909   \n",
       "2158      10268.24   8373.54 0 days 00:14:35.134090909   \n",
       "2159      10268.24   8373.54 0 days 00:14:35.134090909   \n",
       "2160      10268.24   7567.62 0 days 00:14:35.134090909   \n",
       "...            ...       ...                       ...   \n",
       "1357979    2202.18   4681.30 0 days 00:03:07.685795455   \n",
       "1357980    2202.18   9904.62 0 days 00:03:07.685795455   \n",
       "1357981    2202.18   9904.62 0 days 00:03:07.685795455   \n",
       "1357982    2202.18   9814.43 0 days 00:03:07.685795455   \n",
       "1357983    2202.18   9814.43 0 days 00:03:07.685795455   \n",
       "\n",
       "                   dist_from_time        arrival_time status transit_time  \\\n",
       "2156    0 days 00:38:03.692727273 2023-03-01 08:15:00    NaN          NaT   \n",
       "2157    0 days 00:38:03.692727273 2023-03-01 08:15:00    NaN          NaT   \n",
       "2158    0 days 00:38:03.692727273 2023-03-01 08:15:00    NaN          NaT   \n",
       "2159    0 days 00:38:03.692727273 2023-03-01 08:15:00    NaN          NaT   \n",
       "2160    0 days 00:34:23.896363636 2023-03-01 08:15:00    NaN          NaT   \n",
       "...                           ...                 ...    ...          ...   \n",
       "1357979 0 days 00:21:16.718181818 2023-03-01 08:03:00    NaN          NaT   \n",
       "1357980    0 days 00:45:01.260000 2023-03-01 08:03:00    NaN          NaT   \n",
       "1357981    0 days 00:45:01.260000 2023-03-01 08:03:00    NaN          NaT   \n",
       "1357982 0 days 00:44:36.662727273 2023-03-01 08:03:00    NaN          NaT   \n",
       "1357983 0 days 00:44:36.662727273 2023-03-01 08:03:00    NaN          NaT   \n",
       "\n",
       "        travel_time  num_transfers edge_list  \n",
       "2156            NaT            NaN       NaN  \n",
       "2157            NaT            NaN       NaN  \n",
       "2158            NaT            NaN       NaN  \n",
       "2159            NaT            NaN       NaN  \n",
       "2160            NaT            NaN       NaN  \n",
       "...             ...            ...       ...  \n",
       "1357979         NaT            NaN       NaN  \n",
       "1357980         NaT            NaN       NaN  \n",
       "1357981         NaT            NaN       NaN  \n",
       "1357982         NaT            NaN       NaN  \n",
       "1357983         NaT            NaN       NaN  \n",
       "\n",
       "[151632 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import solved raptor trips to see if it's already been calculated \n",
    "if ((raptor_settings['output_fp'] / f\"raptor_dict_{raptor_settings['MAX_TRANSFER']}_transfers.pkl\").exists()):\n",
    "        with (raptor_settings['output_fp'] / f\"raptor_dict_{raptor_settings['MAX_TRANSFER']}_transfers.pkl\").open(mode='rb') as fh:\n",
    "                pareto_dict = pickle.load(fh)\n",
    "        #remove rows from raptor_df if already solved\n",
    "        raptor_df['tup'] = list(zip(raptor_df['src_stop'].astype(int),raptor_df['dest_stop'].astype(int),raptor_df['arrival_time']))\n",
    "        previously_calculated = raptor_df['tup'].isin(list(pareto_dict.keys()))\n",
    "        raptor_df = raptor_df[-previously_calculated]\n",
    "else:\n",
    "        #initialize an empty dict to store pareto results\n",
    "        pareto_dict = {}\n",
    "\n",
    "if raptor_df.shape[0] != 0:\n",
    "        print(f'Performing transit routing from {taz_name} at {start_time}:')\n",
    "        #should loop through all unique times instead of every row (round arrival time to nearest minute)\n",
    "        for row in tqdm(raptor_df.itertuples(),total=raptor_df.shape[0]):\n",
    "                #for row in raptor_df.itertuples():\n",
    "                \n",
    "                #pull out the three inputs needed for raptor\n",
    "                SOURCE = int(row[1])\n",
    "                DESTINATION = int(row[2])\n",
    "                D_TIME = row[3]\n",
    "\n",
    "                #run standard raptor algorithm\n",
    "                output, pareto_set = raptor(SOURCE, DESTINATION, D_TIME, raptor_settings['MAX_TRANSFER'], \n",
    "                                raptor_settings['WALKING_FROM_SOURCE'], raptor_settings['CHANGE_TIME_SEC'], raptor_settings['PRINT_ITINERARY'],\n",
    "                                routes_by_stop_dict, stops_dict, stoptimes_dict, footpath_dict, idx_by_route_stop_dict)\n",
    "                \n",
    "                #store pareto set in dict for next step\n",
    "                pareto_dict[(SOURCE,DESTINATION,D_TIME)] = pareto_set\n",
    "else:\n",
    "        print(f\"RAPTOR solution already found from {taz_name} at {start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#need to change this from iterrows to concat instead\n",
    "print(f'Solving shortest {mode} + transit routing from {taz_name} at {start_time}:')\n",
    "for row in tqdm(trips.itertuples(),total=trips.shape[0]):\n",
    "#for row in trips.itertuples():\n",
    "        \n",
    "        #pull out the three inputs needed for raptor\n",
    "        SOURCE = int(row[3])\n",
    "        DESTINATION = int(row[4])\n",
    "        D_TIME = row[11]\n",
    "        \n",
    "        #get pareto set from the pareto dict\n",
    "        pareto_set = pareto_dict.get((SOURCE,DESTINATION,D_TIME),'Error')\n",
    "\n",
    "        #skip to next if no solutions\n",
    "        #come back to this\n",
    "        if pareto_set == None:\n",
    "                trips.at[row[0],'status'] = 'not possible'\n",
    "                continue\n",
    "        elif pareto_set == 'Error':\n",
    "                print('Error')\n",
    "                break\n",
    "\n",
    "        #create empty list for storing pareto results\n",
    "        shortest_time = []\n",
    "        \n",
    "        #go through each pareto optimal for the given number of transfers\n",
    "        for pareto_optimal in pareto_set:\n",
    "        \n",
    "                #pull out the number of transfers and the edge list\n",
    "                num_transfers = pareto_optimal[0]\n",
    "                edges = pareto_optimal[1]\n",
    "        \n",
    "        #get rid of final walking leg (will be replaced with network results)\n",
    "        while edges[-1][0] == 'walking':\n",
    "                edges = edges[:-1]\n",
    "\n",
    "        #get total travel time from start (time at final egress + last bike/walk leg - departure time)\n",
    "        travel_time = edges[-1][3] + row[10] - start_time\n",
    "\n",
    "        #get total transit travel time (final egress - departure time from first transit stop) \n",
    "        transit_time = edges[-1][3] - D_TIME\n",
    "\n",
    "        #store as list\n",
    "        candidate = [num_transfers,travel_time,transit_time,edges]\n",
    "\n",
    "        #only retain shortest travel time\n",
    "        if len(shortest_time) == 0:\n",
    "                shortest_time = candidate\n",
    "        elif candidate[1] < shortest_time[1]:\n",
    "                shortest_time = candidate\n",
    "        \n",
    "        #update trips dataframe with results from raptor \n",
    "        trips.at[row[0],'num_transfers'] = shortest_time[0]\n",
    "        trips.at[row[0],'travel_time'] = shortest_time[1]\n",
    "        trips.at[row[0],'transit_time'] = shortest_time[2]\n",
    "        \n",
    "        #initialize edge list for storing legs of transit trip\n",
    "        edge_list = []\n",
    "        \n",
    "        #track the wait time\n",
    "        wait_time = timedelta(minutes=0)\n",
    "\n",
    "        #store the first arrival time\n",
    "        arrive = D_TIME\n",
    "\n",
    "        #track transfer time\n",
    "        transfer_time = timedelta(minutes=0)\n",
    "\n",
    "        #edge list structure\n",
    "        #leg[0] : \"\"walking\" (str) or the boarding time (datetime) if transit\n",
    "        #leg[1] : starting transit stop\n",
    "        #leg[2] : ending transit stop\n",
    "        #leg[3] : if walking = travel time and if transit = time at egress\n",
    "        #leg[4] : only for transit = route and trip number\n",
    "\n",
    "        #transit tup to output for edge list\n",
    "        #(start stop, end stop, egress time - boarding time (travel time), route/trip, transit mode)\n",
    "\n",
    "        #go through each leg in edge list and format\n",
    "        for leg in shortest_time[3]:\n",
    "        \n",
    "                #format transit legs\n",
    "                if leg[0] != 'walking':\n",
    "                        \n",
    "                        #calculate wait time for segment (time at boarding - time arrived)\n",
    "                        segment_wait_time = leg[0] - arrive\n",
    "\n",
    "                        #add to total weight time\n",
    "                        wait_time += segment_wait_time\n",
    "                        \n",
    "                        #replace with the next arrival time at the next stop\n",
    "                        arrive = leg[3]\n",
    "\n",
    "                        #extract route_id\n",
    "                        route_id = str.split(leg[4],'_')[0]\n",
    "                        \n",
    "                        #get transit mode from the transit routes csv\n",
    "                        route_type = route[route['new_route_id'].astype(str)==route_id]['route_type'].item()\n",
    "\n",
    "                        #get transit line name\n",
    "                        name = route[route['new_route_id'].astype(str)==route_id]['route_long_name'].item()      \n",
    "                        \n",
    "                        #format transit tuple to add to the edge list\n",
    "                        #TODO work with prateek on ensuring that the newly labeled routes and stops are labeled in all GTFS files\n",
    "                        if (route_type == 1) | (route_type == '1'):\n",
    "                                tup = (leg[1],leg[2],leg[3]-leg[0],leg[4],'rail',name)\n",
    "                        elif (route_type == 3) | (route_type == '3'):\n",
    "                                tup = (leg[1],leg[2],leg[3]-leg[0],leg[4],'bus',name) \n",
    "\n",
    "                #format walk legs\n",
    "                else:\n",
    "                        #format the walking tuple and add to edge list\n",
    "                        tup = (leg[1],leg[2],leg[3],'walking')\n",
    "                        \n",
    "                        #track transfer time (so it can be subtracted from wait time)\n",
    "                        transfer_time += leg[3]\n",
    "\n",
    "        #add tuple to edge list\n",
    "        edge_list.append(tup)\n",
    "        \n",
    "        #get total wait time\n",
    "        trips.at[row[0],'wait_time'] = wait_time - transfer_time\n",
    "        \n",
    "        #get total transfer time\n",
    "        trips.at[row[0],'transfer_time'] = transfer_time\n",
    "\n",
    "        #add edge list to trips\n",
    "        trips.at[row[0],'edge_list'] = edge_list\n",
    "        \n",
    "        #set initial success message\n",
    "        trips.at[row[0],'status'] = 'success'\n",
    "        \n",
    "        # removed these two for now\n",
    "        # #check travel time\n",
    "        # if travel_time >= raptor_settings['timelimit']:\n",
    "        #     trips.at[row[0],'status'] = 'time limit exceeded'\n",
    "        \n",
    "        # #check mode restrictions\n",
    "        # if not mode_specific['allow_bus_to_bus']:\n",
    "        #     if len([x for x in edge_list if x[-1] == 'bus']) > 1:\n",
    "        #         trips.at[row[0],'status'] = 'two buses'\n",
    "\n",
    "#embed start time\n",
    "trips['start_time'] = start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[trips.travel_time.idxmin(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import numpy as np\n",
    "\n",
    "#import custom functions\n",
    "from helper_functions import process_results, load_files\n",
    "\n",
    "'''\n",
    "Notes:\n",
    "\n",
    "take more of a sql approach update/merge?\n",
    "\n",
    "have taz centroid/polygon layer instead seperating into many layers\n",
    "\n",
    "when merging, it's duplicating the dest_taz column\n",
    "\n",
    "'''\n",
    "\n",
    "def viz_and_metrics(settings:dict,impedance:str,mode:str,list_tazs:list):\n",
    "\n",
    "    # #get list of tazs\n",
    "    # list_tazs = settings['output_fp'].glob(f'{mode}_{impedance}/raptor_results/*')\n",
    "    # list_tazs = [x.parts[-1] for x in list_tazs]\n",
    "\n",
    "    # save to same .gpkg as taz name\n",
    "    # #make the vis folder\n",
    "    # if not (settings['output_fp'] / f'{mode}_{impedance}/visuals').exists():\n",
    "    #     (settings['output_fp'] / f'{mode}_{impedance}/visuals').mkdir()\n",
    "\n",
    "    for taz in tqdm(list_tazs):\n",
    "        \n",
    "        #import taz polygons\n",
    "        tazs = gpd.read_file(settings['output_fp'] / 'base_layers.gpkg',layer='tazs')[[settings['keyid'],'geometry']]\n",
    "\n",
    "        #import taz centroids\n",
    "        centroids = gpd.read_file(settings['output_fp'] / 'base_layers.gpkg',layer='centroids')[[settings['keyid'],'geometry']] \n",
    "\n",
    "        #map all transit routes used\n",
    "        transit_shed(settings,impedance,mode,taz)\n",
    "\n",
    "        #import walkable/bikable tazs\n",
    "        #bike_tazs = gpd.read_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer=f'{mode}able_tazs_polygons',ignore_geometry=True)\n",
    "\n",
    "        #get filepaths for all departure times\n",
    "        dep_times = settings['output_fp'].glob(f'{mode}_{impedance}/raptor_results/{taz}/*.pkl')\n",
    "\n",
    "        #initialize empty dataframe for storing all the trip data per departure time\n",
    "        all_trips = pd.DataFrame()\n",
    "\n",
    "        #loop through each departure time\n",
    "        for dep_time in dep_times:\n",
    "\n",
    "            #get departure time text\n",
    "            #dep = dep_time.parts[-1].split('.pkl')[0]\n",
    "\n",
    "            #read in results file and find the least time route per departure time\n",
    "            with fp.open(mode='rb') as fh:\n",
    "                trips = pickle.load(fh)\n",
    "            #only get successful trips\n",
    "            trips = trips[trips['status']=='success']\n",
    "            #groupby to get minimum\n",
    "            trips = trips.loc[trips.groupby(['src_taz','dest_taz'])['travel_time'].idxmin().to_list(),:]\n",
    "\n",
    "            #convert time cols from datetime to total minutes (round to 1 decimal)\n",
    "            time_cols = trip_df.columns[trip_df.dtypes == 'timedelta64[ns]']\n",
    "            for time_col in time_cols:\n",
    "                trip_df[time_col] = trip_df[time_col].apply(lambda x: round(x.total_seconds() / 60,1))\n",
    "\n",
    "            #append to all_trips dataframe\n",
    "            all_trips = pd.concat([all_trips,trip_df],ignore_index=True)\n",
    "\n",
    "        #get average transit time, travel time, and wait time\n",
    "        avg_transit_time = all_trips.groupby('dest_taz')['transit_time'].mean()\n",
    "        avg_travel_time = all_trips.groupby('dest_taz')['travel_time'].mean()\n",
    "        avg_wait_time = all_trips.groupby('dest_taz')['wait_time'].mean()\n",
    "\n",
    "        #get minimum number of transfers\n",
    "        min_transfers = all_trips.groupby('dest_taz')['num_transfers'].min()\n",
    "\n",
    "        # go through the edge list and concatanate all the transit modes together  \n",
    "        for idx, row in all_trips.iterrows():\n",
    "            \n",
    "            #list comp to get list of modes for each trip\n",
    "            modes = [edge[-1] for edge in row['edge_list'] if (edge[-1] == 'bus') or (edge[-1] == 'rail')]\n",
    "            \n",
    "            #turn to series\n",
    "            modes = pd.Series(modes)\n",
    "\n",
    "            try:\n",
    "            \n",
    "                #types\n",
    "                if modes.nunique() > 1:\n",
    "                    types = 'Two Modes'\n",
    "                elif modes[0] == 'rail':\n",
    "                    types = 'Rail'\n",
    "                elif modes[0] == 'bus':\n",
    "                    types = 'Bus'\n",
    "            except:\n",
    "                print(modes)\n",
    "                break\n",
    "            \n",
    "            #add to trip_df\n",
    "            all_trips.at[idx,'types'] = types\n",
    "\n",
    "        #get mode of transit type (bus, rail, mixed)\n",
    "        print(all_trips)\n",
    "        mode_type = all_trips.groupby('dest_taz')['types'].agg(pd.Series.mode)\n",
    "\n",
    "        #if more than one mode, say mixed\n",
    "        mode_type = mode_type.apply(lambda x: replace_list_with_string(x))\n",
    "\n",
    "        #join data to tazs (i think this is where it messes up, trying map instead)\n",
    "        tazs['avg_transit_time'] = tazs[settings['keyid']].map(avg_transit_time)\n",
    "        tazs['avg_travel_time'] = tazs[settings['keyid']].map(avg_travel_time)\n",
    "        tazs['avg_wait_time'] = tazs[settings['keyid']].map(avg_wait_time)\n",
    "        tazs['min_transfers'] = tazs[settings['keyid']].map(min_transfers)\n",
    "        tazs['mode_type'] = tazs[settings['keyid']].map(mode_type)\n",
    "        #prolly add min/max for the times and count how many time periods taz was inaccessible\n",
    "        \n",
    "        #drop null rows\n",
    "        tazs = tazs[-tazs.isna().any(axis=1)]\n",
    "\n",
    "        #export\n",
    "        tazs.to_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer='tazs_viz')\n",
    "        \n",
    "        #drop the geometry column\n",
    "        tazs.drop(columns=['geometry'],inplace=True)\n",
    "\n",
    "        #join data to centroids by merging with tazs\n",
    "        centroids = pd.merge(centroids,tazs,on=settings['keyid'])\n",
    "        \n",
    "        #drop null rows (shouldn't be any)\n",
    "        centroids = centroids[-centroids.isna().any(axis=1)]\n",
    "\n",
    "        #export\n",
    "        try: \n",
    "            centroids.to_file(settings['output_fp'] / f'{mode}_{impedance}/{taz}.gpkg',layer='centroids_viz')\n",
    "        except:\n",
    "            print(centroids)\n",
    "\n",
    "\n",
    "def replace_list_with_string(lst):\n",
    "    if isinstance(lst, np.ndarray):\n",
    "        return 'Mixed'\n",
    "    elif isinstance(lst,list):\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        return lst\n",
    "\n",
    "def transit_shed(settings:dict,impedance:str,mode:str,list_taz:str):\n",
    "    '''\n",
    "    Creates polygon showing all the transit lines utilized using the RAPTOR outputs\n",
    "\n",
    "    would like to also figure out a betweenness centrality like metric but that will wait\n",
    "    '''\n",
    "\n",
    "    #get filepaths\n",
    "    fps = settings['output_fp'].glob(f'{mode}_{impedance}/mapped/{list_taz}/*.gpkg')\n",
    "\n",
    "    big_df = gpd.GeoDataFrame()\n",
    "    \n",
    "    for fp in fps:\n",
    "        #load each time\n",
    "        for start_time in fiona.listlayers(fp):\n",
    "        \n",
    "            trip = gpd.read_file(fp,layer=start_time)\n",
    "                \n",
    "            #only keep transit\n",
    "            trip = trip.loc[trip['mode'].isin(['rail','bus']),['mode','start_stop','end_stop','geometry']]\n",
    "            \n",
    "            big_df = pd.concat([big_df,trip],ignore_index=True)\n",
    "        \n",
    "        #drop duplicates\n",
    "        big_df.drop_duplicates(['mode','start_stop','end_stop'],inplace=True)\n",
    "    \n",
    "    #set activee geo column\n",
    "    big_df.set_geometry('geometry',inplace=True)\n",
    "\n",
    "    #buffer because polygons faster to dissolve than linestrings\n",
    "    big_df.geometry = big_df.buffer(400)\n",
    "    \n",
    "    #dissolve\n",
    "    big_df = big_df.dissolve('mode')\n",
    "    \n",
    "    #export\n",
    "    big_df.to_file(settings['output_fp'] / f'{mode}_{impedance}/{list_taz}.gpkg',layer='transitshed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "# create bike trip files\n",
    "raptor_preprocessing(settings,bike_settings,select_tazs)\n",
    "\n",
    "# create walk trip files\n",
    "raptor_preprocessing(settings,walk_settings,select_tazs)\n",
    "\n",
    "# create bikewalk trip files\n",
    "raptor_preprocessing(settings,bikewalk_settings,select_tazs)\n",
    "# can add more or comment out as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#410 minutes\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "run_raptor(select_tazs,settings,bike_settings)\n",
    "#160 minutes??\n",
    "run_raptor(select_tazs,settings,walk_settings)\n",
    "#430minutes\n",
    "run_raptor(select_tazs,settings,bikewalk_settings)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\geopandas\\io\\file.py:525: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\indexes\\range.py:385\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[0;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tpassmore6\\Documents\\GitHub\\TransitSimDevLocal\\trb_paper.ipynb Cell 5\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tpassmore6/Documents/GitHub/TransitSimDevLocal/trb_paper.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m modes \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbike\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mbikewalk\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tpassmore6/Documents/GitHub/TransitSimDevLocal/trb_paper.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m mode \u001b[39min\u001b[39;00m modes:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tpassmore6/Documents/GitHub/TransitSimDevLocal/trb_paper.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#map_routes(settings,impedance,mode,select_tazs)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tpassmore6/Documents/GitHub/TransitSimDevLocal/trb_paper.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     viz_and_metrics(settings,impedance,mode,select_tazs)\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Documents\\GitHub\\TransitSimDevLocal\\viz_and_metrics.py:97\u001b[0m, in \u001b[0;36mviz_and_metrics\u001b[1;34m(settings, impedance, mode, list_tazs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m modes\u001b[39m.\u001b[39mnunique() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     96\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTwo Modes\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 97\u001b[0m \u001b[39melif\u001b[39;00m modes[\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrail\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     98\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRail\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[39melif\u001b[39;00m modes[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbus\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\series.py:942\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    941\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 942\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    944\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    945\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    946\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\series.py:1051\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1050\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1052\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\indexes\\range.py:387\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[0;32m    386\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compact View (LTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'lowstress_links', # name of links layer\n",
    "    'nodes_layer': 'lowstress_nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 3, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 8, 0, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 1, 10, 0, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/LTS' #path where you want things to output \n",
    "    }\n",
    "\n",
    "#select_tazs = ['1071']#['288','553','411','1071']\n",
    "\n",
    "bikelts_settings = {\n",
    "    'thresh': 5280 * 2.5, # set access/egress thresh\n",
    "    'max_thresh': 5280 * 2.5 * 2, # set the max biking/walking amount\n",
    "    'spd': 8,\n",
    "    'mode':'bikelts',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':False,\n",
    "    'allow_bus_to_bus':False,\n",
    "    'overwrite_existing': True\n",
    "    }\n",
    "\n",
    "#create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "raptor_preprocessing(settings,bikelts_settings,select_tazs)\n",
    "\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "run_raptor(select_tazs,settings,bikelts_settings)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)\n",
    "\n",
    "impedance = 'dist'\n",
    "modes = ['bikelts']\n",
    "\n",
    "for mode in modes:\n",
    "    map_routes(settings,impedance,mode,select_tazs)\n",
    "    viz_and_metrics(settings,impedance,mode,select_tazs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using model OD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    #changed network from marta to martalatest\n",
    "    \n",
    "    #these are for the pre-processing steps\n",
    "    'gtfs_fp': Path.home() / 'Documents/GitHub/transit-routing/GTFS/martalatest', #filepath for processed GTFS files\n",
    "    'gtfs_zip': Path.home() / 'Documents/GitHub/transit-routing/martalatest_gtfs.zip', #filepath for original zipped GTFS files\n",
    "    'network_fp': Path.home() / 'Documents/TransitSimData/networks/final_network.gpkg', #fp to geopackage with a links and nodes layer\n",
    "    'links_layer': 'links', # name of links layer\n",
    "    'nodes_layer': 'nodes', # name of nodes layer\n",
    "    'impedance': 'dist', # specify which column of the links data should be used for shortest path routing\n",
    "    'service_date': date(2023,3,1),#date(2022, 11, 24), #select day to get service, a weekday was used for this study\n",
    "    'crs': 'epsg:2240', # the desired projected CRS to use\n",
    "    'thresh': 2.5 * 5280, #set candidate stop threshold distance in units of CRS (using bike service area from tcqsm page 5-20)\n",
    "    'tazs_fp': Path.home() / 'Documents/NewBikewaySimData/Data/ARC/Model_Traffic_Analysis_Zones_2020.geojson', # filepath of TAZs or origins/POIs\n",
    "    'keyid': 'OBJECTID', #column with the unique taz/origin id in it\n",
    "    \n",
    "    #this for making the transfers.txt file need for raptor\n",
    "    'transfer_time': 2, # allowed transfer time in minutes (DOES NOT INLCUDE WAIT TIME)\n",
    "    'walk_spd': 3, # assumed walking speed for transfers in miles per hour\n",
    "    \n",
    "    #these are specific to RAPTOR\n",
    "    'NETWORK_NAME': 'martalatest',#'marta',\n",
    "    'MAX_TRANSFER': 2, # no more than 1 transfer\n",
    "    'WALKING_FROM_SOURCE': 0, # if true (1), person can walk to a different transit station from start station\n",
    "    'CHANGE_TIME_SEC': 30, # time to enter/exit vehicle (NOT WAIT TIME)\n",
    "    'PRINT_ITINERARY': 0, # if running individual raptor trips, this prints the outputs\n",
    "    'OPTIMIZED': 0, # read transit-routing documentation, set to 0 for this project\n",
    "    \n",
    "    #times to test, datetime(YYYY,MM,DD,HH,MM,SS,MS)\n",
    "    'first_time': datetime(2023, 3, 1, 4, 30, 0, 0), # original start time is 9am\n",
    "    'end_time': datetime(2023, 3, 2, 00, 30, 0, 0), # original end time is 10am\n",
    "    'timestep': timedelta(minutes=15), # time increments to test (original is 9am,9:20am,9:40am,10am)\n",
    "    'timelimit': timedelta(hours=1), # set the max allowed total travel time in hours\n",
    "    'output_fp': Path.home() / 'Documents/TransitSimData/ABM', #path where you want things to output \n",
    "\n",
    "    #restrict to only starting at rail station\n",
    "    'rail_start' : True\n",
    "    }\n",
    "\n",
    "#bring in od data\n",
    "ods = pd.read_csv(settings['output_fp']/'ods.csv')\n",
    "ods['origin'] = ods['origin'].astype(str)\n",
    "ods['destination'] = ods['destination'].astype(str)\n",
    "#all tazs\n",
    "select_tazs = ods['origin'].unique().tolist()#['1071']#['288','553','411','1071']\n",
    "\n",
    "#check if trip is within 1 hr of the departure time (ABM specific)\n",
    "ods['year'] = settings['service_date'].year\n",
    "ods['month'] = settings['service_date'].month\n",
    "ods['day'] = settings['service_date'].day\n",
    "ods['adj_time'] = pd.to_datetime(ods[['year','month','day','hour','minute']])\n",
    "ods['adjusted'] = ods['adj_time'] + pd.to_timedelta(ods['depart_time'])\n",
    "\n",
    "# bike_settings = {\n",
    "#     'thresh': 5280 * 2.5, # set access/egress thresh\n",
    "#     'max_thresh': 5280 * 2.5 * 2, # set the max biking/walking amount\n",
    "#     'spd': 8,\n",
    "#     'mode':'bike',\n",
    "#     'impedance':'dist',\n",
    "#     'allow_wrongway':False,\n",
    "#     'allow_bus_to_bus':False,\n",
    "#     'overwrite_existing': False\n",
    "#     }\n",
    "\n",
    "walk_settings = {\n",
    "    'thresh': 5280 * 0.5,\n",
    "    'max_thresh': 5280 * 0.5 * 2, #set to twice\n",
    "    'spd': 3,\n",
    "    'mode':'walk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':True,\n",
    "    'allow_bus_to_bus':True,\n",
    "    'overwrite_existing': True\n",
    "    }\n",
    "\n",
    "#this one assumes bike will be parked at start (removes bus stops from first mile that aren't next to rail)\n",
    "bikewalk_settings = {\n",
    "    'thresh': (5280 * 2.5, 5280 * 0.5),\n",
    "    'max_thresh': 5280 * (3),\n",
    "    'spd': (8,2.5),\n",
    "    'mode':'bikewalk',\n",
    "    'impedance':'dist',\n",
    "    'allow_wrongway':(False,True),\n",
    "    'allow_bus_to_bus':True,\n",
    "    'overwrite_existing': True\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create transfers.txt\n",
    "create_transfers(settings)\n",
    "\n",
    "# function that creates the study area and various base layers\n",
    "process_studyarea(settings)\n",
    "\n",
    "candidate_stops_by_taz, centroids = candidate_stops(settings)\n",
    "\n",
    "raptor_preprocessing(settings,bikewalk_settings,select_tazs,ods)\n",
    "raptor_preprocessing(settings,walk_settings,select_tazs,ods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change cwd Fix this later\n",
    "cwd = os.getcwd()\n",
    "os.chdir(Path.home()/'Documents/GitHub/transit-routing')\n",
    "\n",
    "#run_raptor(select_tazs,settings,bikewalk_settings,ods)\n",
    "run_raptor(select_tazs,settings,walk_settings,ods)\n",
    "\n",
    "#change back\n",
    "os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "impedance = 'dist'\n",
    "modes = ['walk','bikewalk']\n",
    "\n",
    "for mode in modes:#\n",
    "    map_routes(settings,impedance,mode,select_tazs)\n",
    "    viz_and_metrics(settings,impedance,mode,select_tazs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
