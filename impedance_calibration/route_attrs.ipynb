{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Route Attributes from Dijkstra Results\n",
    "We have a list of edges or turns (depending on the settings) from Dijkstra, and we need to get the route attributes (how many turns, how much feet up, miles of bike facility, etc) to get a means of understanding this trip.\n",
    "\n",
    "For link attributes we the linkid and direction of travel (because of elevation).\n",
    "For turn attributes we just need linkid to linkid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from shapely.ops import MultiLineString\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# #TODO will need to fix this\n",
    "# sys.path.insert(0,str(Path.cwd().parent))\n",
    "# from network.src import modeling_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path.home() / \"Documents/BikewaySimData/Projects/gdot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tripid', 'initial_start_time', 'initial_end_time', 'initial_duration',\n",
       "       'initial_total_points', 'initial_avg_accuracy', 'total_points',\n",
       "       'duration', 'max_delta_time', 'mean_delta_time', 'max_distance_ft',\n",
       "       'avg_distance_ft', 'total_distance_ft', 'first_to_last_ft',\n",
       "       'max_speed_mph', 'min_speed_mph', 'avg_speed_mph'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path(fp/'gps_traces/cleaned_traces.pkl').open('rb') as fh:\n",
    "    trips_df = pickle.load(fh)[1]\n",
    "trips_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Already have link sequence (matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('D:/matched_traces/match_testing.pkl').open('rb') as fh:\n",
    "    matched_traces_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO deal with having multiple matching networks (two, oneway, etc?)\n",
    "# #Matching network\n",
    "# # with (fp / 'chosen.pkl').open('rb') as fh:\n",
    "# #     (df_edges,pseudo_df,pseudo_G) = pickle.load(fh)\n",
    "\n",
    "# edges = gpd.read_file(fp/'networks/final_network.gpkg',layer=\"final_network\")\n",
    "# edges.reset_index(inplace=True)\n",
    "# edges.rename(columns={'index':'linkid'},inplace=True)\n",
    "# #edges = edges[['A','B','linkid','oneway','tunnel','bridge','geometry']]\n",
    "\n",
    "# # #turn oneway into boolean (figure out why this is changing)\n",
    "# edges['oneway'] = edges['oneway'] == 1\n",
    "\n",
    "# #turn bridge and tunnel to boolean\n",
    "# edges['tunnel'] = edges['tunnel'].notna()\n",
    "# edges['bridge'] = edges['bridge'].notna()\n",
    "# #TODO add ability to model wrongway\n",
    "# df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(edges,'A','B','linkid','oneway',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (fp / 'chosen.pkl').open('rb') as fh:\n",
    "    df_edges,pseudo_df,pseudo_G = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'target', 'reverse_link', 'azimuth', 'linkid', 'osmid',\n",
       "       'link_type', 'name', 'oneway', 'length_ft', 'bridge', 'tunnel',\n",
       "       'link_type', 'highway', 'speedlimit_range_mph', 'lanes_per_direction',\n",
       "       'bike_facility_type', 'ascent_m', 'ascent_grade', '(0,2]_ascent',\n",
       "       '(2,4]_ascent', '(4,6]_ascent', '(6,10]_ascent', '(10,15]_ascent',\n",
       "       '(15,inf]_ascent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO this shows up twice FIX IT\n",
    "df_edges = df_edges.loc[:,~df_edges.columns.duplicated()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6148, 4100, 3592, 33804, 8204, 5133, 18451, 7703, 17433, 4121, 32282, 25120, 548, 16421, 2599, 10793, 555, 13355, 13358, 17974, 27705, 3647, 17473, 8258, 3139, 9797, 30277, 28749, 9806, 30799, 6737, 82, 11347, 11860, 11858, 12374, 3159, 3671, 15958, 7257, 29281, 24168, 15466, 32874, 27245, 31854, 17007, 16498, 2675, 33908, 3189, 4725, 9336, 121, 8825, 17534, 9860, 30345, 33929, 3209, 4745, 1162, 29837, 8335, 6800, 30352, 27283, 4243, 8348, 32417, 24737, 11432, 6312, 1194, 7341, 6830, 9393, 4277, 33976, 1212, 8893, 15552, 3265, 30913, 8900, 14022, 27850, 8402, 13526, 5338, 32476, 27871, 14050, 5859, 28388, 10982, 2279, 12008, 2281, 742, 235, 8429, 2804, 10998, 3322, 24828, 14077, 2814, 3333, 262, 12039, 1799, 9989, 12554, 14604, 29452, 7951, 1811, 4888, 7964, 15139, 16676, 6953, 17708, 34095, 30000, 305, 7473, 26422, 17207, 2871, 26426, 4412, 12098, 11590, 32074, 32076, 7503, 3413, 12119, 3419, 12636, 8029, 15710, 11618, 10596, 3941, 10601, 15727, 26479, 29557, 1400, 26488, 5499, 3963, 33663, 13185, 27012, 13704, 393, 24456, 5515, 33164, 13197, 910, 2443, 8074, 15250, 3987, 3995, 30204, 29597, 26529, 16804, 28072, 17837, 25517, 9134, 10163, 8628, 2485, 8630, 33729, 2499, 9667, 13253, 1990, 15302, 11721, 3531, 30156, 1493, 28118, 5079, 3548, 1503, 5604, 6628, 3051, 12269, 25582, 7667, 29174, 34294, 12796, 2559])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_traces_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripid = 29837\n",
    "\n",
    "# edges = matched_traces_dict[tripid]['edges']\n",
    "\n",
    "# # make list of edges and turns\n",
    "# list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "# df_edges['tup'] = list(zip(df_edges['linkid'],df_edges['reverse_link']))\n",
    "# chosen_links = df_edges.set_index('tup').loc[list_of_edges]\n",
    "\n",
    "# chosen_links['reverse_link']\n",
    "# list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "# chosen_turns = pseudo_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link']).loc[list_of_turns]\n",
    "\n",
    "# # # cols_to_summarize = ['highway','oneway','highway',\n",
    "# # #        'oneway', 'bridge', 'tunnel', 'bl', 'pbl', 'mu',\n",
    "# # #        'speedlimit_range_mph',\n",
    "# # #        'lanes_per_direction', 'FROM_LANES', 'TO_LANES', 'join_bearing',\n",
    "# # #        'percent_overlap', 'bearing_diff', 'match name', 'name_check',\n",
    "# # #        'overlap_check', 'bearing_check', 'final_check', 'signal_A', 'signal_B',\n",
    "# # #        'osm_url', 'rise_m', 'maxrise_m', 'up_grade', 'max_grade', 'down_m',\n",
    "# # #        'minrise_m', 'down_grade', 'min_grade', 'geometry']\n",
    "# # bool_cols = ['bl','mu','pbl']\n",
    "# # count_cols = ['bridge','tunnel']\n",
    "# # sum_cols = ['length','rise_m','down_m']\n",
    "# # length_cols = ['link_type','highway','speedlimit_range_mph','lanes_per_direction']\n",
    "# # elevation_cats = ['up_grade','down_grade']\n",
    "# # keep_cols = bool_cols + count_cols + length_cols\n",
    "# chosen_links.columns\n",
    "# #intialize summary dict\n",
    "# summary_attributes = {}\n",
    "\n",
    "# # Get Link Attributes\n",
    "\n",
    "# # #boolean columns to summarize\n",
    "# # bool_cols = ['bl','mu','pbl']\n",
    "# # for bool_col in bool_cols:\n",
    "# #     total_length = chosen_links.loc[chosen_links[bool_col] == 1,'length_ft'].sum()\n",
    "# #     summary_attributes[bool_col] = np.round(total_length/chosen_links['length_ft'].sum(),2)\n",
    "\n",
    "# #instance columns to summarize\n",
    "# count_cols = ['bridge','tunnel']\n",
    "# for count_col in count_cols:\n",
    "#     summary_attributes[count_col] = (chosen_links[count_col]==True).sum()\n",
    "\n",
    "# #pct of route columns to summarize\n",
    "# cols = ['link_type','highway','bike_facility_type','speedlimit_range_mph','lanes_per_direction']\n",
    "# for col in cols:\n",
    "#     for unique_val in chosen_links[col].unique():\n",
    "#         if (unique_val != None) | (unique_val == np.nan):\n",
    "#             total_length = chosen_links[chosen_links[col] == unique_val]['length_ft'].sum()\n",
    "#         else:\n",
    "#             continue\n",
    "#         if isinstance(unique_val,str) == False:\n",
    "#             unique_val = str(unique_val)\n",
    "#         summary_attributes[col+'.'+unique_val] = np.round(total_length/chosen_links['length_ft'].sum(),2)\n",
    "\n",
    "# # signalized\n",
    "\n",
    "# #turn attributes (these are all instances)\n",
    "# summary_attributes['signalized'] = chosen_turns['signalized'].sum()\n",
    "# summary_attributes['unsignalized'] = chosen_turns['unsignalized'].sum()\n",
    "\n",
    "# #turn type\n",
    "# turn_dict = chosen_turns['turn_type'].value_counts().to_dict()\n",
    "# summary_attributes.update(turn_dict)\n",
    "\n",
    "# summary_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_dict = {}\n",
    "\n",
    "for tripid in matched_traces_dict.keys():\n",
    "\n",
    "    if isinstance(matched_traces_dict[tripid],str):\n",
    "        continue\n",
    "\n",
    "    edges = matched_traces_dict[tripid]['edges']\n",
    "\n",
    "    # make list of edges and turns\n",
    "    list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "    df_edges['tup'] = list(zip(df_edges['linkid'],df_edges['reverse_link']))\n",
    "    chosen_links = df_edges.set_index('tup').loc[list_of_edges]\n",
    "    list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "    chosen_turns = pseudo_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link']).loc[list_of_turns]\n",
    "    chosen_links.columns\n",
    "    #intialize summary dict\n",
    "    summary_attributes = {}\n",
    "\n",
    "    #trip distance\n",
    "    summary_attributes['trip_distance_ft'] = chosen_links['length_ft'].sum()\n",
    "\n",
    "    #instance columns to summarize\n",
    "    count_cols = ['bridge','tunnel']\n",
    "    for count_col in count_cols:\n",
    "        summary_attributes[count_col] = (chosen_links[count_col]==True).sum()\n",
    "\n",
    "    #general elevation\n",
    "    total_ascent = (chosen_links['ascent_m'].sum() / 3.28).round(0)\n",
    "    summary_attributes['ascent_ft'] = total_ascent \n",
    "    summary_attributes['avg_ascent_grade'] = (total_ascent / chosen_links['length_ft'].sum() * 100).round(1)\n",
    "\n",
    "    #elevation broken by segment\n",
    "    elev_cols = ['(0,2]_ascent','(2,4]_ascent', '(4,6]_ascent', '(6,10]_ascent', '(10,15]_ascent','(15,inf]_ascent']\n",
    "    for elev_col in elev_cols:\n",
    "        total_length = (chosen_links[elev_col].sum() / 3.28).round(0)\n",
    "        summary_attributes[elev_col+'_ft'] = total_length\n",
    "\n",
    "    #pct of route columns to summarize\n",
    "    cols = ['link_type','highway','bike_facility_type','speedlimit_range_mph','lanes_per_direction']\n",
    "    for col in cols:\n",
    "        #make a summary column for every unique value in that column\n",
    "        for unique_val in chosen_links[col].unique():\n",
    "            if (unique_val != None) | (unique_val == np.nan):\n",
    "                total_length = chosen_links[chosen_links[col] == unique_val]['length_ft'].sum()\n",
    "            else:\n",
    "                continue\n",
    "            if isinstance(unique_val,str) == False:\n",
    "                unique_val = str(unique_val)\n",
    "            summary_attributes[col+'.'+unique_val] = np.round(total_length/chosen_links['length_ft'].sum(),2)\n",
    "\n",
    "    # signalized and turns\n",
    "    summary_attributes['signalized'] = (chosen_turns['signalized']==True).sum()\n",
    "    summary_attributes['unsignalized'] = (chosen_turns['unsignalized']==True).sum()\n",
    "    turn_dict = chosen_turns['turn_type'].value_counts().to_dict()\n",
    "    summary_attributes.update(turn_dict)\n",
    "\n",
    "    summary_dict[tripid] = summary_attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into geodataframe\n",
    "trips_df_info = pd.DataFrame.from_dict(summary_dict,orient='index')\n",
    "trips_df_info.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = trips_df.merge(trips_df_info,left_on='tripid',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO find the visualiztion code that we had already made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "# list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "\n",
    "# chosen_links = df_edges.set_index(['linkid','reverse_link'],drop=False).loc[list_of_edges]\n",
    "\n",
    "# chosen_links['bridge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add user info\n",
    "trip_and_user = pd.read_pickle(fp/'gps_traces/trip_and_user.pkl')\n",
    "\n",
    "trips_df = trips_df_info.merge(trip_and_user,left_index=True,right_on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv(fp/'all_attrs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of visualizing here visualize elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import stochastic_optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot'\n",
    "# #fp = Path.home() / 'Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/BikewaySim/Data'\n",
    "\n",
    "# with (fp / 'impedance_calibration.pkl').open('rb') as fh:\n",
    "#     (df_edges,pseudo_df,pseudo_G) = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve link/turn costs\n",
    "# default below is link distance\n",
    "# link_costs = dict(zip(list(zip(df_edges['source'],df_edges['target'],df_edges['linkid'])),df_edges['length_ft']))\n",
    "# tup = list(zip(pseudo_df['source_A'],pseudo_df['source_B'],pseudo_df['source_linkid']))\n",
    "# pseudo_df['source_cost'] = list(map(link_costs.get,tup))\n",
    "# tup = list(zip(pseudo_df['target_A'],pseudo_df['target_B'],pseudo_df['target_linkid']))\n",
    "\n",
    "# pseudo_df['target_cost'] = list(map(link_costs.get,tup))\n",
    "# pseudo_df['total_cost'] = pseudo_df['source_cost'] + pseudo_df['target_cost'] #+turn_cost\n",
    "\n",
    "# costs = pseudo_df.groupby(['source','target'])['total_cost'].min()\n",
    "# nx.set_edge_attributes(pseudo_G,values=costs,name='weight')\n",
    "# source = list(pseudo_G.nodes())[0]\n",
    "# target = list(pseudo_G.nodes())[420]\n",
    "# print(source,target)\n",
    "# import networkx as nx\n",
    "# length, edge_list = nx.single_source_dijkstra(pseudo_G,source,target,weight=\"weight\")\n",
    "# turn_list = [[edge_list[i][0],edge_list[i][1],edge_list[i+1][0],edge_list[i+1][1]] for i in range(len(edge_list)-1)]\n",
    "\n",
    "# turn_cols = ['turn_type','signalized_left_straight','unsignalized_left_straight_nonlocal']\n",
    "# linkid_cols = ['source_linkid','source_reverse_link','target_linkid','target_reverse_link']\n",
    "# chosen_turns = pseudo_df.set_index(['source_A','source_B','target_A','target_B'],drop=False).loc[turn_list,linkid_cols+turn_cols]\n",
    "\n",
    "# tripid = 302\n",
    "\n",
    "# #make a single row dataframe to attach to trips_df\n",
    "# stats_dict = {}\n",
    "# stats_dict[tripid] = {\n",
    "#     'tripid':tripid,\n",
    "#     'signalized_left_straight': chosen_turns['signalized_left_straight'].sum(),\n",
    "#     'unsignalized_left_straight_nonlocal': chosen_turns['unsignalized_left_straight_nonlocal'].sum()\n",
    "# }\n",
    "# turn_dict = chosen_turns['turn_type'].value_counts().to_dict()\n",
    "# stats_dict[tripid].update(turn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Need to run shortest paths to create link sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_links = chosen_turns[['source_linkid','source_reverse_link']]\n",
    "# target_links = chosen_turns[['target_linkid','target_reverse_link']]\n",
    "# source_links.columns = ['linkid','reverse_link']\n",
    "# target_links.columns = ['linkid','reverse_link']\n",
    "# linkids = pd.concat([source_links,target_links],ignore_index=True).drop_duplicates()\n",
    "# chosen_links = df_edges.merge(linkids,on=['linkid','reverse_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO recalculate bearing\n",
    "#create pseudo graph for modeling turns\n",
    "df_edges, pseudo_links, pseudo_G = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = list(pseudo_G.nodes())[0]\n",
    "target = list(pseudo_G.nodes())[420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (68209677, 68209675)\n",
    "target = (69200243, 69465418)\n",
    "\n",
    "import networkx as nx\n",
    "length, path = nx.single_source_dijkstra(pseudo_G,source,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [(linkids[i],linkids[i+1]) for i in range(len(linkids)-1)]\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [(*path[i],*path[i+1]) for i in range(len(path)-1)]\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_links.set_index(['source_A','source_B','target_A','target_B']).loc[edge_list,'turn_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
