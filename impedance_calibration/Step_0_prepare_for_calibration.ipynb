{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Matched Traces for Calibration\n",
    "- Determine which links should be included for routing (+ include all links found during map matching)\n",
    "- \n",
    "Before calibration, we need decide which traces made the cut using the match_ratio. Then we need to attach the start and end nodes and then examine how well the shortest path (with/without turns) explains the routing behavior to compare against the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shapely.ops import MultiLineString, LineString\n",
    "import geopandas as gpd\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.impedance_calibration import speedfactor, stochastic_optimization\n",
    "from bikewaysim import map_match\n",
    "from bikewaysim.network import prepare_network, modeling_turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the match map results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NOTE temporary for GDOT report, replace when done\n",
    "# # with (config['matching_fp'] /'match_dict_full.pkl').open('rb') as fh:\n",
    "# #     match_dict = pickle.load(fh)\n",
    "# with (Path('D:\\PROJECTS\\GDOT\\GDOT\\Map_Matching\\matched_0.pkl')).open('rb') as fh:\n",
    "#     match_dict = pickle.load(fh)\n",
    "    \n",
    "# cutoff = 0.90 # set pct of points that need to be matched\n",
    "\n",
    "# total = len(match_dict)\n",
    "# match_ratios = {tripid:item['match_ratio'] for tripid, item in match_dict.items() if isinstance(item,str)==False}\n",
    "# failed_matches = total - len(match_ratios)\n",
    "# match_ratios = pd.Series(match_ratios)\n",
    "# above_threshold = match_ratios[match_ratios > 0.90].index.tolist()\n",
    "# match_dict = {key:item for key, item in match_dict.items() if key in above_threshold}\n",
    "# below_threshold = total - failed_matches - len(above_threshold)\n",
    "\n",
    "# print(len(match_dict),'/',total,'successful matches')\n",
    "# print(failed_matches,'failed to match')\n",
    "# print(below_threshold,'partial match')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_dict_full_5']\n"
     ]
    }
   ],
   "source": [
    "# print the available match dicts\n",
    "print([x.stem for x in config['matching_fp'].glob('match_dict_full_*.pkl')])\n",
    "\n",
    "matching_index = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2577 / 2975 (87%) successful matches\n",
      "374 / 2975 (13%) partial matches\n",
      "24 / 2975 (1%) failed matches\n"
     ]
    }
   ],
   "source": [
    "#NOTE temporary delete after GDOT\n",
    "# gdot_trips = set(list(match_dict.keys()))\n",
    "with (config['matching_fp'] / f'match_dict_full_{matching_index}.pkl').open('rb') as fh:\n",
    "    match_dict = pickle.load(fh)\n",
    "\n",
    "cutoff = 0.90 # set pct of points that need to be matched\n",
    "above_threshold, below_threshold, failed_matches, match_ratios = map_match.mapmatch_results(match_dict,cutoff)\n",
    "match_dict = {key:item for key,item in match_dict.items() if key in above_threshold}\n",
    "\n",
    "#NOTE filter to just trips used for GDOT\n",
    "# match_dict = {tripid:item for tripid,item in match_dict.items() if (tripid in gdot_trips) & (isinstance(item,str)==False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2577 trips\n",
      "664 users\n"
     ]
    }
   ],
   "source": [
    "#get route attributes\n",
    "trips = pd.read_pickle(config['cycleatl_fp']/'trips_4.pkl')\n",
    "trips = trips.loc[trips['tripid'].isin(list(match_dict.keys()))]#,'userid'].nunique()\n",
    "users = pd.read_pickle(config['cycleatl_fp']/'users_4.pkl')\n",
    "users = users[users['userid'].isin(set(trips['userid'].tolist()))]\n",
    "print(trips.shape[0],'trips')\n",
    "print(users.shape[0],'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>userid</th>\n",
       "      <th>start_X</th>\n",
       "      <th>start_Y</th>\n",
       "      <th>end_X</th>\n",
       "      <th>end_Y</th>\n",
       "      <th>start_label</th>\n",
       "      <th>end_label</th>\n",
       "      <th>sort_start_label</th>\n",
       "      <th>sort_end_label</th>\n",
       "      <th>reverse_trajectory</th>\n",
       "      <th>trip_patterns</th>\n",
       "      <th>trip_pattern_prevalence</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>description</th>\n",
       "      <th>total_distance_ft</th>\n",
       "      <th>avg_speed_mph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>2.238127e+06</td>\n",
       "      <td>1.377715e+06</td>\n",
       "      <td>2.229160e+06</td>\n",
       "      <td>1.373953e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Commute</td>\n",
       "      <td>Kari</td>\n",
       "      <td>14590.486033</td>\n",
       "      <td>6.358433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>2.226210e+06</td>\n",
       "      <td>1.373792e+06</td>\n",
       "      <td>2.238098e+06</td>\n",
       "      <td>1.377739e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Commute</td>\n",
       "      <td>Kari</td>\n",
       "      <td>17701.004119</td>\n",
       "      <td>6.985759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>14</td>\n",
       "      <td>2.239771e+06</td>\n",
       "      <td>1.381325e+06</td>\n",
       "      <td>2.238099e+06</td>\n",
       "      <td>1.377744e+06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6114.889973</td>\n",
       "      <td>6.165858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>5943</td>\n",
       "      <td>14</td>\n",
       "      <td>2.230463e+06</td>\n",
       "      <td>1.375526e+06</td>\n",
       "      <td>2.226093e+06</td>\n",
       "      <td>1.373666e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Work-Related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8147.105751</td>\n",
       "      <td>5.111784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>4865</td>\n",
       "      <td>14</td>\n",
       "      <td>2.226262e+06</td>\n",
       "      <td>1.373812e+06</td>\n",
       "      <td>2.240540e+06</td>\n",
       "      <td>1.381260e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Social</td>\n",
       "      <td>Need a northeast exit from piedmont park</td>\n",
       "      <td>27358.720780</td>\n",
       "      <td>6.303299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34269</th>\n",
       "      <td>34269</td>\n",
       "      <td>1733</td>\n",
       "      <td>2.224865e+06</td>\n",
       "      <td>1.373146e+06</td>\n",
       "      <td>2.215088e+06</td>\n",
       "      <td>1.382788e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social</td>\n",
       "      <td>ballet class</td>\n",
       "      <td>16427.640243</td>\n",
       "      <td>13.243730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34277</th>\n",
       "      <td>34277</td>\n",
       "      <td>1738</td>\n",
       "      <td>2.258530e+06</td>\n",
       "      <td>1.383091e+06</td>\n",
       "      <td>2.229927e+06</td>\n",
       "      <td>1.365538e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49309.595062</td>\n",
       "      <td>11.016927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34289</th>\n",
       "      <td>34289</td>\n",
       "      <td>1733</td>\n",
       "      <td>2.245986e+06</td>\n",
       "      <td>1.369955e+06</td>\n",
       "      <td>2.257314e+06</td>\n",
       "      <td>1.373259e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14594.897768</td>\n",
       "      <td>10.451568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34320</th>\n",
       "      <td>34320</td>\n",
       "      <td>1706</td>\n",
       "      <td>2.239482e+06</td>\n",
       "      <td>1.359251e+06</td>\n",
       "      <td>2.228574e+06</td>\n",
       "      <td>1.359356e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social</td>\n",
       "      <td>Home to Braves</td>\n",
       "      <td>12069.185658</td>\n",
       "      <td>7.516342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34325</th>\n",
       "      <td>34325</td>\n",
       "      <td>1733</td>\n",
       "      <td>2.226254e+06</td>\n",
       "      <td>1.374033e+06</td>\n",
       "      <td>2.233857e+06</td>\n",
       "      <td>1.378437e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Work-Related</td>\n",
       "      <td>botanical gardens to study</td>\n",
       "      <td>13049.441751</td>\n",
       "      <td>10.255412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2577 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tripid  userid       start_X       start_Y         end_X  \\\n",
       "tripid                                                             \n",
       "68          68      14  2.238127e+06  1.377715e+06  2.229160e+06   \n",
       "71          71      14  2.226210e+06  1.373792e+06  2.238098e+06   \n",
       "1092      1092      14  2.239771e+06  1.381325e+06  2.238099e+06   \n",
       "5943      5943      14  2.230463e+06  1.375526e+06  2.226093e+06   \n",
       "4865      4865      14  2.226262e+06  1.373812e+06  2.240540e+06   \n",
       "...        ...     ...           ...           ...           ...   \n",
       "34269    34269    1733  2.224865e+06  1.373146e+06  2.215088e+06   \n",
       "34277    34277    1738  2.258530e+06  1.383091e+06  2.229927e+06   \n",
       "34289    34289    1733  2.245986e+06  1.369955e+06  2.257314e+06   \n",
       "34320    34320    1706  2.239482e+06  1.359251e+06  2.228574e+06   \n",
       "34325    34325    1733  2.226254e+06  1.374033e+06  2.233857e+06   \n",
       "\n",
       "               end_Y  start_label  end_label  sort_start_label  \\\n",
       "tripid                                                           \n",
       "68      1.373953e+06          0.0        1.0               0.0   \n",
       "71      1.377739e+06          2.0        0.0               0.0   \n",
       "1092    1.377744e+06          3.0        0.0               0.0   \n",
       "5943    1.373666e+06          1.0        2.0               1.0   \n",
       "4865    1.381260e+06          2.0        3.0               2.0   \n",
       "...              ...          ...        ...               ...   \n",
       "34269   1.382788e+06         -1.0       -1.0              -1.0   \n",
       "34277   1.365538e+06         -1.0       -1.0              -1.0   \n",
       "34289   1.373259e+06          1.0       -1.0              -1.0   \n",
       "34320   1.359356e+06          1.0       -1.0              -1.0   \n",
       "34325   1.378437e+06         -1.0       -1.0              -1.0   \n",
       "\n",
       "        sort_end_label  reverse_trajectory  trip_patterns  \\\n",
       "tripid                                                      \n",
       "68                 1.0               False            0.0   \n",
       "71                 2.0                True            0.0   \n",
       "1092               3.0                True            0.0   \n",
       "5943               2.0               False            1.0   \n",
       "4865               3.0               False            0.0   \n",
       "...                ...                 ...            ...   \n",
       "34269             -1.0               False            NaN   \n",
       "34277             -1.0               False            NaN   \n",
       "34289              1.0                True            NaN   \n",
       "34320              1.0                True            NaN   \n",
       "34325             -1.0               False            NaN   \n",
       "\n",
       "        trip_pattern_prevalence     trip_type  \\\n",
       "tripid                                          \n",
       "68                          4.0       Commute   \n",
       "71                          3.0       Commute   \n",
       "1092                        2.0        School   \n",
       "5943                        1.0  Work-Related   \n",
       "4865                        1.0        Social   \n",
       "...                         ...           ...   \n",
       "34269                       NaN        Social   \n",
       "34277                       NaN       Commute   \n",
       "34289                       NaN        Social   \n",
       "34320                       NaN        Social   \n",
       "34325                       NaN  Work-Related   \n",
       "\n",
       "                                     description  total_distance_ft  \\\n",
       "tripid                                                                \n",
       "68                                          Kari       14590.486033   \n",
       "71                                          Kari       17701.004119   \n",
       "1092                                         NaN        6114.889973   \n",
       "5943                                         NaN        8147.105751   \n",
       "4865    Need a northeast exit from piedmont park       27358.720780   \n",
       "...                                          ...                ...   \n",
       "34269                               ballet class       16427.640243   \n",
       "34277                                        NaN       49309.595062   \n",
       "34289                                        NaN       14594.897768   \n",
       "34320                             Home to Braves       12069.185658   \n",
       "34325                 botanical gardens to study       13049.441751   \n",
       "\n",
       "        avg_speed_mph  \n",
       "tripid                 \n",
       "68           6.358433  \n",
       "71           6.985759  \n",
       "1092         6.165858  \n",
       "5943         5.111784  \n",
       "4865         6.303299  \n",
       "...               ...  \n",
       "34269       13.243730  \n",
       "34277       11.016927  \n",
       "34289       10.451568  \n",
       "34320        7.516342  \n",
       "34325       10.255412  \n",
       "\n",
       "[2577 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edges', 'last_matched', 'match_ratio', 'max_lattice_width', 'trace', 'match_lines', 'interpolated_points', 'match_time_sec', 'gps_distance', 'time', 'settings'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_dict[71].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all links used in map matching to make sure these are kept in the calibration network\n",
    "map_matching_links = set()\n",
    "for tripid, items in match_dict.items():\n",
    "    map_matching_links.update(set([tuple(x) for x in items['edges'].values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create calibration network\n",
    "Create dummy variables and make any other changes that weren't done in the final network export step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links = pd.read_parquet(config['network_fp']/'directed_edges.parquet') # has the directional variables\n",
    "links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges') # has the non-directional variables\n",
    "nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "nodes = dict(zip(nodes['N'],nodes.geometry))\n",
    "turns = pd.read_parquet(config['network_fp']/'turns_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with links\n",
    "link_cols_drop = ['A','B','ascent_ft','ascent_grade_cat','descent_ft','descent_grade_cat','facility_fwd','facility_rev']\n",
    "links.drop(columns=link_cols_drop,inplace=True)\n",
    "directed_cols_to_add = ['linkid','A','B','reverse_link','ascent_ft','ascent_grade_cat','facility_fwd']\n",
    "links = pd.merge(links,directed_links[directed_cols_to_add],on='linkid')\n",
    "# del directed_links\n",
    "# links.rename(columns={'source':'A','target':'B'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove wrongway\n",
    "oneway_dict = dict(zip(links['linkid'],links['oneway']))\n",
    "turns['source_oneway'] = turns['source_linkid'].map(oneway_dict)\n",
    "turns['target_oneway'] = turns['target_linkid'].map(oneway_dict)\n",
    "del oneway_dict\n",
    "\n",
    "source_exception = [(linkid,reverse_link) in map_matching_links for linkid, reverse_link in turns[['source_linkid','source_reverse_link']].values]\n",
    "target_exception = [(linkid,reverse_link) in map_matching_links for linkid, reverse_link in turns[['target_linkid','target_reverse_link']].values]\n",
    "# source_wrongway = ((turns['source_oneway'] == True) & (turns['source_reverse_link'] == True)) == False\n",
    "# target_wrongway = ((turns['target_oneway'] == True) & (turns['target_reverse_link'] == True)) == False\n",
    "source_wrongway = ((turns[['source_oneway','source_reverse_link']] == True).all(axis=1)==False) | (source_exception)\n",
    "target_wrongway = ((turns[['target_oneway','target_reverse_link']] == True).all(axis=1)==False) | (target_exception)\n",
    "turns = turns[source_wrongway & target_wrongway]\n",
    "\n",
    "#remove wrongway links\n",
    "#TODO did we remove these in the export network step too?\n",
    "exception = [(linkid,reverse_link) in map_matching_links for linkid, reverse_link in links[['linkid','reverse_link']].values]\n",
    "links = links.loc[((links[['oneway','reverse_link']]==True).all(axis=1) == False) | exception]\n",
    "\n",
    "#TODO post GDOT\n",
    "#add elevation adjusted travel times based on assumed speed on flat ground\n",
    "# speedfactor.calculate_adjusted_speed(links,9)\n",
    "assumed_speed_mph = 9\n",
    "links['travel_time_min'] = links.length / 5280 / assumed_speed_mph * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for modeling\n",
    "links['2lpd'] = (links['lanes'] == 2).astype(int)\n",
    "links['3+lpd'] = (links['lanes'] == 3).astype(int)\n",
    "links['(30,40] mph'] = (links['speed']=='(30,40]').astype(int)\n",
    "links['(40,inf) mph'] = (links['speed']=='(40,inf)').astype(int)\n",
    "links['[4k,10k) aadt'] = (links['AADT']=='[4k,10k)').astype(int)\n",
    "links['[10k,inf) aadt'] = (links['AADT']=='[10k,inf)').astype(int)\n",
    "links['[4,6) grade'] = (links['ascent_grade_cat']=='[4,6)').astype(int)\n",
    "links['[6,inf) grade'] = (links['ascent_grade_cat']=='[6,inf)').astype(int)\n",
    "links['bike lane'] = links['facility_fwd'].isin(['bike lane','bufferred bike lane']).astype(int)\n",
    "links['cycletrack'] = links['facility_fwd'].isin(['cycletrack']).astype(int)\n",
    "links['multi use path'] = links['facility_fwd'].isin(['multi use path']).astype(int)\n",
    "\n",
    "#condensed variables\n",
    "links['(30,inf) mph'] = (links[['(30,40] mph','(40,inf) mph']] == 1).any(axis=1)\n",
    "links['multi use path and cycletrack'] = (links[['cycletrack','multi use path']] == 1).any(axis=1)\n",
    "\n",
    "#TODO add sidepath variables here\n",
    "\n",
    "# the report variables\n",
    "links0 = links.copy()\n",
    "links0['multi use path report'] = links0['facility_fwd'].isin(['multi use path','cycletrack']).astype(int)\n",
    "links0['bike lane report'] = links0['facility_fwd'].isin(['bike lane','bufferred bike lane']).astype(int)\n",
    "links0.loc[(links0['multi use path report']==True) | (links['link_type'].isin(['bike','pedestrian','sidewalk'])),'lanes'] = 0\n",
    "links0\n",
    "links0['above_4 report'] = links0['ascent_grade_cat'].isin(['[4,6)','[6,inf)'])\n",
    "links0 = links0[['linkid','reverse_link','multi use path report','bike lane report','lanes','above_4 report']]\n",
    "links = pd.merge(links,links0,suffixes=('',' report'),on=['linkid','reverse_link'])\n",
    "\n",
    "turns.loc[turns['unsig_crossing'].isna(),'unsig_crossing'] = False\n",
    "turns['unsig_crossing'] = turns['unsig_crossing'].astype(int)\n",
    "\n",
    "# #create layer of unsignalized crossings for examining (#NOTE I think this is a duplicate)\n",
    "# unsig__crossing = set(turns.loc[turns['unsig__crossing']==True,'source_B'].tolist())\n",
    "# nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "# nodes = nodes[nodes['N'].isin(unsig__crossing)]\n",
    "# nodes.to_file(config['calibration_fp']/'unsig__crossing.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['linkid', 'oneway', 'link_type', 'osmid', 'length_ft', 'highway',\n",
       "       'name', 'all_tags', 'facility', 'year', 'sidepath', 'sidepath_year',\n",
       "       'route_type', 'AADT', 'speed', 'lanes', 'geometry', 'A', 'B',\n",
       "       'reverse_link', 'ascent_ft', 'ascent_grade_cat', 'facility_fwd',\n",
       "       'travel_time_min', '2lpd', '3+lpd', '(30,40] mph', '(40,inf) mph',\n",
       "       '[4k,10k) aadt', '[10k,inf) aadt', '[4,6) grade', '[6,inf) grade',\n",
       "       'bike lane', 'cycletrack', 'multi use path', '(30,inf) mph',\n",
       "       'multi use path and cycletrack', 'multi use path report',\n",
       "       'bike lane report', 'lanes report', 'above_4 report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only allow these types for routing\n",
    "link_types_allowed = ['bike','pedestrian','road']\n",
    "exception = [(linkid,reverse_link) in map_matching_links for linkid, reverse_link in links[['linkid','reverse_link']].values]\n",
    "links = links[links['link_type'].isin(link_types_allowed) | exception]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = links.copy()\n",
    "exception = [(linkid,reverse_link) in map_matching_links for linkid, reverse_link in before[['linkid','reverse_link']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before connected components: Links 160405 Nodes 73697\n",
      "After connected components: Links 153217 Nodes 69873\n",
      "Before connected components: Turns 698828\n",
      "After connected components: Turns 239353\n",
      "153217 links and 69873 nodes\n",
      "239353 turns\n"
     ]
    }
   ],
   "source": [
    "# remove isolated links\n",
    "links, turns = prepare_network.remove_isolates(links,turns)\n",
    "\n",
    "print(links.shape[0],'links and',len(set(links['A'].append(links['B']).tolist())),'nodes')\n",
    "print(turns.shape[0],'turns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkid</th>\n",
       "      <th>sidepath_linkid</th>\n",
       "      <th>oneway</th>\n",
       "      <th>link_type</th>\n",
       "      <th>osmid</th>\n",
       "      <th>length_ft</th>\n",
       "      <th>highway</th>\n",
       "      <th>name</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>facility</th>\n",
       "      <th>...</th>\n",
       "      <th>[6,inf) grade</th>\n",
       "      <th>bike lane</th>\n",
       "      <th>cycletrack</th>\n",
       "      <th>multi use path</th>\n",
       "      <th>(30,inf) mph</th>\n",
       "      <th>multi use path and cycletrack</th>\n",
       "      <th>multi use path report</th>\n",
       "      <th>bike lane report</th>\n",
       "      <th>lanes report</th>\n",
       "      <th>above_4 report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>525</td>\n",
       "      <td>64133</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>436921075</td>\n",
       "      <td>41.900260</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>Interstate North Parkway Southeast</td>\n",
       "      <td>{\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525</td>\n",
       "      <td>64133</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>436921075</td>\n",
       "      <td>41.900260</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>Interstate North Parkway Southeast</td>\n",
       "      <td>{\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64139</td>\n",
       "      <td>64133</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>436921075</td>\n",
       "      <td>960.389155</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>Interstate North Parkway Southeast</td>\n",
       "      <td>{\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64139</td>\n",
       "      <td>64133</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>436921075</td>\n",
       "      <td>960.389155</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>Interstate North Parkway Southeast</td>\n",
       "      <td>{\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64144</td>\n",
       "      <td>64133</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>755746276</td>\n",
       "      <td>209.317544</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>Interstate North Parkway Southeast</td>\n",
       "      <td>{\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>178926</td>\n",
       "      <td>178923</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>439444040</td>\n",
       "      <td>16.658550</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Overton Park Drive</td>\n",
       "      <td>{\"highway\": \"unclassified\", \"name\": \"Overton P...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>178928</td>\n",
       "      <td>178923</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>439444040</td>\n",
       "      <td>197.640268</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Overton Park Drive</td>\n",
       "      <td>{\"highway\": \"unclassified\", \"name\": \"Overton P...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>178928</td>\n",
       "      <td>178923</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>439444040</td>\n",
       "      <td>197.640268</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Overton Park Drive</td>\n",
       "      <td>{\"highway\": \"unclassified\", \"name\": \"Overton P...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>178931</td>\n",
       "      <td>178921</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>439444040</td>\n",
       "      <td>433.972855</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Overton Park Drive</td>\n",
       "      <td>{\"highway\": \"unclassified\", \"name\": \"Overton P...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>178931</td>\n",
       "      <td>178921</td>\n",
       "      <td>False</td>\n",
       "      <td>road</td>\n",
       "      <td>439444040</td>\n",
       "      <td>433.972855</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Overton Park Drive</td>\n",
       "      <td>{\"highway\": \"unclassified\", \"name\": \"Overton P...</td>\n",
       "      <td>multi use path</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1665 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      linkid  sidepath_linkid  oneway link_type      osmid   length_ft  \\\n",
       "0        525            64133   False      road  436921075   41.900260   \n",
       "1        525            64133   False      road  436921075   41.900260   \n",
       "2      64139            64133   False      road  436921075  960.389155   \n",
       "3      64139            64133   False      road  436921075  960.389155   \n",
       "4      64144            64133   False      road  755746276  209.317544   \n",
       "...      ...              ...     ...       ...        ...         ...   \n",
       "1660  178926           178923   False      road  439444040   16.658550   \n",
       "1661  178928           178923   False      road  439444040  197.640268   \n",
       "1662  178928           178923   False      road  439444040  197.640268   \n",
       "1663  178931           178921   False      road  439444040  433.972855   \n",
       "1664  178931           178921   False      road  439444040  433.972855   \n",
       "\n",
       "           highway                                name  \\\n",
       "0         tertiary  Interstate North Parkway Southeast   \n",
       "1         tertiary  Interstate North Parkway Southeast   \n",
       "2         tertiary  Interstate North Parkway Southeast   \n",
       "3         tertiary  Interstate North Parkway Southeast   \n",
       "4         tertiary  Interstate North Parkway Southeast   \n",
       "...            ...                                 ...   \n",
       "1660  unclassified                  Overton Park Drive   \n",
       "1661  unclassified                  Overton Park Drive   \n",
       "1662  unclassified                  Overton Park Drive   \n",
       "1663  unclassified                  Overton Park Drive   \n",
       "1664  unclassified                  Overton Park Drive   \n",
       "\n",
       "                                               all_tags        facility  ...  \\\n",
       "0     {\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...  multi use path  ...   \n",
       "1     {\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...  multi use path  ...   \n",
       "2     {\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...  multi use path  ...   \n",
       "3     {\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...  multi use path  ...   \n",
       "4     {\"bicycle\": \"yes\", \"foot\": \"yes\", \"highway\": \"...  multi use path  ...   \n",
       "...                                                 ...             ...  ...   \n",
       "1660  {\"highway\": \"unclassified\", \"name\": \"Overton P...  multi use path  ...   \n",
       "1661  {\"highway\": \"unclassified\", \"name\": \"Overton P...  multi use path  ...   \n",
       "1662  {\"highway\": \"unclassified\", \"name\": \"Overton P...  multi use path  ...   \n",
       "1663  {\"highway\": \"unclassified\", \"name\": \"Overton P...  multi use path  ...   \n",
       "1664  {\"highway\": \"unclassified\", \"name\": \"Overton P...  multi use path  ...   \n",
       "\n",
       "      [6,inf) grade bike lane  cycletrack multi use path (30,inf) mph  \\\n",
       "0                 0         0           0              1         True   \n",
       "1                 0         0           0              1         True   \n",
       "2                 0         0           0              1         True   \n",
       "3                 0         0           0              1         True   \n",
       "4                 0         0           0              1         True   \n",
       "...             ...       ...         ...            ...          ...   \n",
       "1660              0         0           0              1        False   \n",
       "1661              0         0           0              1        False   \n",
       "1662              0         0           0              1        False   \n",
       "1663              0         0           0              1        False   \n",
       "1664              0         0           0              1        False   \n",
       "\n",
       "     multi use path and cycletrack  multi use path report bike lane report  \\\n",
       "0                             True                      1                0   \n",
       "1                             True                      1                0   \n",
       "2                             True                      1                0   \n",
       "3                             True                      1                0   \n",
       "4                             True                      1                0   \n",
       "...                            ...                    ...              ...   \n",
       "1660                          True                      1                0   \n",
       "1661                          True                      1                0   \n",
       "1662                          True                      1                0   \n",
       "1663                          True                      1                0   \n",
       "1664                          True                      1                0   \n",
       "\n",
       "      lanes report  above_4 report  \n",
       "0              0.0           False  \n",
       "1              0.0           False  \n",
       "2              0.0           False  \n",
       "3              0.0           False  \n",
       "4              0.0           False  \n",
       "...            ...             ...  \n",
       "1660           0.0           False  \n",
       "1661           0.0           False  \n",
       "1662           0.0           False  \n",
       "1663           0.0           False  \n",
       "1664           0.0            True  \n",
       "\n",
       "[1665 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure this out later\n",
    "\n",
    "\n",
    "# assign attributes to the sidepaths\n",
    "sidepaths = gpd.read_file(config['bicycle_facilities_fp']/'sidepaths.gpkg',layer='sidepaths',ignore_geometry=True)[['linkid','sidepath_linkid']]\n",
    "replace = sidepaths.merge(links,on='linkid')\n",
    "replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all the attributes\n",
    "all_attrs = ['2lpd', '3+lpd', '(30,40] mph', '(40,inf) mph',\n",
    "       '[4k,10k) aadt', '[10k,inf) aadt', '[4,6) grade', '[6,inf) grade',\n",
    "       'bike lane', 'cycletrack', 'multi use path', '(30,inf) mph',\n",
    "       'multi use path and cycletrack', 'multi use path report',\n",
    "       'bike lane report', 'lanes report', 'above_4 report']\n",
    "replace = replace[['sidepath_linkid']+all_attrs]\n",
    "replace = replace[replace['sidepath_linkid'].duplicated()==False]\n",
    "replace\n",
    "\n",
    "links = pd.merge(links,replace,left_on='linkid',right_on='sidepath_linkid',suffixes=(None,'_new'),how='left')\n",
    "for col in replace.columns:\n",
    "    if col != 'sidepath_linkid':\n",
    "        links[col] = links[f'{col}_new'].fillna(links[col])\n",
    "links.drop(columns=[x+'_new' for x in all_attrs],inplace=True)\n",
    "# replace\n",
    "#[['multi use path','sidepath']]\n",
    "# links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE for the set inf variable\n",
    "links['not_street'] = links['link_type'] != 'road'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export calibration network\n",
    "with (config['calibration_fp']/\"calibration_network.pkl\").open('wb') as fh:\n",
    "    pickle.dump((links,turns),fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links.to_file(config['calibration_fp']/'calibration_network.gpkg',layer='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without_isolates = set([tuple([x,y]) for x,y in links[['linkid','reverse_link']].values])\n",
    "# missing = [tuple([x,y]) not in without_isolates for x,y in before[['linkid','reverse_link']].values]\n",
    "# before[np.array(exception) & np.array(missing)].explore()#.to_file(Path.home()/'Downloads/')\n",
    "# ((links[['linkid','reverse_link']]==(35062.0,False)).all(axis=1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the match data for shortest path routing and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2577 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2577/2577 [05:07<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True,drop=False)\n",
    "match_results = {}\n",
    "#shortest_results = {}\n",
    "failed_shortest_path = []\n",
    "\n",
    "for tripid, items in tqdm(match_dict.items()):\n",
    "\n",
    "    #get start and end linkid\n",
    "    start = tuple(match_dict[tripid]['edges'].iloc[0,:].values)\n",
    "    end = tuple(match_dict[tripid]['edges'].iloc[-1,:].values)\n",
    "\n",
    "    #get start and end node for shortest and impedance routing\n",
    "    #TODO change this to be live so we don't run into errors when the matching network is different\n",
    "    start = links.loc[start,'A']\n",
    "    end = links.loc[end,'B']\n",
    "\n",
    "    # start = (round(nodes.get(start).x,2),round(nodes.get(start).y,2))\n",
    "    # end = (round(nodes.get(end).x,2),round(nodes.get(end).y,2))\n",
    "\n",
    "    match_results[tripid] = {\n",
    "    'origin_node': start,\n",
    "    'destination_node': end,\n",
    "    'trip_start_time': items['trace'].iloc[0,2].year,\n",
    "    'match_ratio': items['match_ratio'],\n",
    "    'matched_edges': match_dict[tripid]['edges'],\n",
    "    'shortest_edges': pd.DataFrame(stochastic_optimization.impedance_path(turns,turn_G,links,start,end)['edge_list'],columns=['linkid','reverse_link'])\n",
    "    }\n",
    "# trip_ods = pd.DataFrame.from_dict(match_results,orient='index')\n",
    "# trip_ods.reset_index(inplace=True)\n",
    "# trip_ods.rename(columns={'index':'tripid'},inplace=True)\n",
    "#export for impedance calibration\n",
    "with (config['calibration_fp']/'ready_for_calibration.pkl').open('wb') as fh:\n",
    "    pickle.dump(match_results,fh)\n",
    "# links.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linkid  reverse_link\n",
       "127691  False           0.068667\n",
       "52985   False           0.189647\n",
       "130054  False           0.493511\n",
       "26418   False           1.928068\n",
       "        True            1.928068\n",
       "                          ...   \n",
       "187406  False           0.167904\n",
       "187407  False           0.217123\n",
       "193609  False           0.099004\n",
       "197312  True            0.190865\n",
       "        False           0.190865\n",
       "Name: link_cost, Length: 153217, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['link_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 12.0,\n",
       " 'edge_list': [(162671, True),\n",
       "  (5532, True),\n",
       "  (162677, True),\n",
       "  (104532, True),\n",
       "  (4095, True),\n",
       "  (162666, True),\n",
       "  (162616, True),\n",
       "  (4402, True),\n",
       "  (162623, True),\n",
       "  (34586, True),\n",
       "  (34585, False),\n",
       "  (34493, False),\n",
       "  (162639, False),\n",
       "  (34584, False),\n",
       "  (179436, False),\n",
       "  (12442, True),\n",
       "  (89302, True),\n",
       "  (106242, True),\n",
       "  (2943, True),\n",
       "  (4243, True),\n",
       "  (175746, True),\n",
       "  (175748, True),\n",
       "  (4242, True),\n",
       "  (4239, True),\n",
       "  (4237, True),\n",
       "  (4235, True),\n",
       "  (90141, True),\n",
       "  (90152, True),\n",
       "  (90146, True),\n",
       "  (17828, True),\n",
       "  (90154, True),\n",
       "  (90162, True),\n",
       "  (168889, True),\n",
       "  (17826, True),\n",
       "  (177911, True),\n",
       "  (168957, True),\n",
       "  (19996, True),\n",
       "  (16621, True),\n",
       "  (31045, True),\n",
       "  (168826, True),\n",
       "  (24051, True),\n",
       "  (168832, True),\n",
       "  (182064, True),\n",
       "  (190473, True),\n",
       "  (23202, True),\n",
       "  (190479, True),\n",
       "  (31044, True),\n",
       "  (148016, True),\n",
       "  (88742, True),\n",
       "  (182060, True),\n",
       "  (25410, True),\n",
       "  (162220, True),\n",
       "  (88747, True),\n",
       "  (24226, True)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 5424013809\n",
    "end = 69359617\n",
    "stochastic_optimization.impedance_path(turns,turn_G,links,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add this to the export network section\n",
    "# # add this for later\n",
    "# link_types = dict(zip(links['linkid'],links['link_type']))\n",
    "# turns['source_link_type'] = turns['source_linkid'].map(link_types)\n",
    "# turns['target_link_type'] = turns['source_linkid'].map(link_types)\n",
    "\n",
    "# # #unit conversions\n",
    "# links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "# links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "# #links.drop(columns=['length_ft','ascent_m'],inplace=True)\n",
    "\n",
    "# #get node degree\n",
    "# degree = links['A'].append(links['B']).value_counts()\n",
    "# links['A_deg'] = links['A'].map(degree)\n",
    "# links['B_deg'] = links['B'].map(degree)\n",
    "# #remove excess dead end pedestrian links\n",
    "# dead_ends = (links['link_type']=='pedestrian')&((links['A_deg']==1)|(links['B_deg']==1))\n",
    "# links = links[dead_ends==False]\n",
    "# #unique scenario but there's an expressway tag that needs to be removed\n",
    "# import ast\n",
    "# john_lewis_freedom_pkwy = links['all_tags'].apply(lambda x: ast.literal_eval(x).get('expressway',0)=='yes')\n",
    "# links = links[john_lewis_freedom_pkwy==False]\n",
    "# surfaces = ['dirt','unpaved','gravel','fine_gravel','dirt/sand','ground']\n",
    "# unpaved = links['all_tags'].apply(lambda x: ast.literal_eval(x).get('surface',0) in surfaces)\n",
    "# #links[unpaved].explore(tooltip=False)\n",
    "# links = links[unpaved==False]\n",
    "# #unpaved.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move on after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     # #euclidean distance between points\n",
    "#     # snode = nodes.loc[nodes['N']==start,'geometry'].item()\n",
    "#     # dnode = nodes.loc[nodes['N']==end,'geometry'].item()\n",
    "    \n",
    "#     # #add geo features\n",
    "#     # edge_geo = pd.merge(match_dict[tripid]['edges'],edges[['linkid','geometry']],on=['linkid'],how='left')\n",
    "#     # edge_geo = gpd.GeoDataFrame(edge_geo,geometry='geometry')\n",
    "#     # edge_geo_dissolved = MultiLineString(edge_geo['geometry'].tolist())\n",
    "#     # linkids = set(edge_geo['linkid'].tolist())\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     #TODO use .array version to get rid of errors\n",
    "\n",
    "#     forward = pd.merge(edge_df,edges[['source','target','linkid','geometry']],on=['source','target'])[['linkid','geometry']]\n",
    "#     reverse = pd.merge(edge_df,edges[['source','target','linkid','geometry']],left_on=['target','source'],right_on=['source','target'])[['linkid','geometry']]\n",
    "#     shortest_path = pd.concat([forward,reverse],ignore_index=True)\n",
    "#     shortest_linkids = set(shortest_path['linkid'].tolist())\n",
    "#     shortest_geo = gpd.GeoDataFrame(shortest_path)\n",
    "#     shortest_geo_dissolved = MultiLineString(shortest_geo['geometry'].tolist())\n",
    "\n",
    "#     #exact overlap\n",
    "#     chosen_and_shortest = linkids & shortest_linkids\n",
    "#     overlap_length = edges.set_index('linkid').loc[list(chosen_and_shortest)]['length_ft'].sum()\n",
    "#     exact_overlap = overlap_length / edge_geo.length.sum()\n",
    "\n",
    "#     #buffer overlap\n",
    "#     buffer_ft = 500\n",
    "#     chosen = edge_geo_dissolved.buffer(buffer_ft)\n",
    "#     shortest = shortest_geo_dissolved.buffer(buffer_ft)\n",
    "#     intersection = chosen.intersection(shortest)\n",
    "#     buffer_overlap = intersection.area / (chosen.area + shortest.area - intersection.area)\n",
    "\n",
    "#     #collapse to multilinestring with length\n",
    "#     #add length\n",
    "#     matched_trips[tripid] = {'start':start,\n",
    "#                             'end':end,\n",
    "#                             'start_end_dist_ft': snode.distance(dnode),\n",
    "#                             'match_ratio': match_dict[tripid]['match_ratio'], \n",
    "#                             'linkids':str(linkids),\n",
    "#                             'geometry':edge_geo_dissolved,\n",
    "#                             'length_ft':edge_geo.length.sum(),\n",
    "#                             'shortest_length_ft': impedance,\n",
    "#                             'shortest_linkids': shortest_linkids,\n",
    "#                             'shortest_geo': shortest_geo_dissolved,\n",
    "#                             'shortest_exact_overlap_length': overlap_length,\n",
    "#                             'shortest_exact_overlap_prop': exact_overlap,\n",
    "#                             'shortest_buffer_overlap': buffer_overlap,\n",
    "#                             'shortest_intersect_geo': intersection\n",
    "#                             }\n",
    "# # matched_trips = {}\n",
    "# # loop_trips = []\n",
    "\n",
    "# # for tripid,items in tqdm(match_dict.items()):\n",
    "\n",
    "# #     #failed matches will be str type\n",
    "# #     if isinstance(items,dict):\n",
    "\n",
    "# #         #get start and end linkid\n",
    "# #         start = match_dict[tripid]['edges'].iloc[0,:]\n",
    "# #         end = match_dict[tripid]['edges'].iloc[-1,:]\n",
    "        \n",
    "# #         #get start and end node\n",
    "# #         start_a_b = edges.loc[(edges['linkid']==start['linkid']) & (edges['reverse_link']==start['reverse_link']),['source','target']]\n",
    "# #         end_a_b = edges.loc[(edges['linkid']==end['linkid']) & (edges['reverse_link']==end['reverse_link']),['source','target']]\n",
    "\n",
    "# #         if start['reverse_link']:\n",
    "# #             start = start_a_b['source'].item()\n",
    "# #         else:\n",
    "# #             start = start_a_b['target'].item()\n",
    "\n",
    "# #         if end['reverse_link']:\n",
    "# #             end = end_a_b['target'].item()\n",
    "# #         else:\n",
    "# #             end = end_a_b['source'].item()\n",
    "\n",
    "# #         #euclidean distance between points\n",
    "# #         snode = nodes.loc[nodes['N']==start,'geometry'].item()\n",
    "# #         dnode = nodes.loc[nodes['N']==end,'geometry'].item()\n",
    "        \n",
    "# #         #add geo features\n",
    "# #         edge_geo = pd.merge(match_dict[tripid]['edges'],edges[['linkid','geometry']],on=['linkid'],how='left')\n",
    "# #         edge_geo = gpd.GeoDataFrame(edge_geo,geometry='geometry')\n",
    "# #         edge_geo_dissolved = MultiLineString(edge_geo['geometry'].tolist())\n",
    "# #         linkids = set(edge_geo['linkid'].tolist())\n",
    "\n",
    "# #         #shortest path routing here\n",
    "# #         impedance, path = nx.single_source_dijkstra(MDG,start,end,weight=\"length_ft\")\n",
    "        \n",
    "# #         if len(path) < 2:\n",
    "# #             loop_trips.append(tripid)\n",
    "# #             continue\n",
    "\n",
    "# #         #turn to edge list\n",
    "# #         edge_list = [(path[i],path[i+1]) for i in range(len(path)-1)]\n",
    "# #         edge_df = pd.DataFrame(edge_list,columns=['source','target'])\n",
    "\n",
    "# #         #TODO use .array version to get rid of errors\n",
    "\n",
    "# #         forward = pd.merge(edge_df,edges[['source','target','linkid','geometry']],on=['source','target'])[['linkid','geometry']]\n",
    "# #         reverse = pd.merge(edge_df,edges[['source','target','linkid','geometry']],left_on=['target','source'],right_on=['source','target'])[['linkid','geometry']]\n",
    "# #         shortest_path = pd.concat([forward,reverse],ignore_index=True)\n",
    "# #         shortest_linkids = set(shortest_path['linkid'].tolist())\n",
    "# #         shortest_geo = gpd.GeoDataFrame(shortest_path)\n",
    "# #         shortest_geo_dissolved = MultiLineString(shortest_geo['geometry'].tolist())\n",
    "\n",
    "# #         #exact overlap\n",
    "# #         chosen_and_shortest = linkids & shortest_linkids\n",
    "# #         overlap_length = edges.set_index('linkid').loc[list(chosen_and_shortest)]['length_ft'].sum()\n",
    "# #         exact_overlap = overlap_length / edge_geo.length.sum()\n",
    "\n",
    "# #         #buffer overlap\n",
    "# #         buffer_ft = 500\n",
    "# #         chosen = edge_geo_dissolved.buffer(buffer_ft)\n",
    "# #         shortest = shortest_geo_dissolved.buffer(buffer_ft)\n",
    "# #         intersection = chosen.intersection(shortest)\n",
    "# #         buffer_overlap = intersection.area / (chosen.area + shortest.area - intersection.area)\n",
    "\n",
    "# #         #collapse to multilinestring with length\n",
    "# #         #add length\n",
    "# #         matched_trips[tripid] = {'start':start,\n",
    "# #                               'end':end,\n",
    "# #                               'start_end_dist_ft': snode.distance(dnode),\n",
    "# #                               'match_ratio': match_dict[tripid]['match_ratio'], \n",
    "# #                               'linkids':str(linkids),\n",
    "# #                               'geometry':edge_geo_dissolved,\n",
    "# #                               'length_ft':edge_geo.length.sum(),\n",
    "# #                               'shortest_length_ft': impedance,\n",
    "# #                               'shortest_linkids': shortest_linkids,\n",
    "# #                               'shortest_geo': shortest_geo_dissolved,\n",
    "# #                               'shortest_exact_overlap_length': overlap_length,\n",
    "# #                               'shortest_exact_overlap_prop': exact_overlap,\n",
    "# #                               'shortest_buffer_overlap': buffer_overlap,\n",
    "# #                               'shortest_intersect_geo': intersection\n",
    "# #                               }\n",
    "# Want to display when a trip goes through a signalized intersection and also how many times they do it. Need to take the list of edges from the matched_traces_dict and contruct a list of turns from it. This list of turns can then be used to get the right node ids. Later turn this into a function.\n",
    "# tripid = 4100\n",
    "# edges = match_dict[tripid]['edges']\n",
    "\n",
    "# # make list of edges and turns\n",
    "# list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "# df_edges['tup'] = list(zip(df_edges['linkid'],df_edges['reverse_link']))\n",
    "# chosen_links = df_edges.set_index('tup').loc[list_of_edges]\n",
    "# list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "# df_of_turns = pd.DataFrame(list_of_turns,columns=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n",
    "# df_of_turns\n",
    "# subset = pseudo_df.merge(df_of_turns,on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n",
    "\n",
    "# # get list of nodes\n",
    "# signals = subset.loc[subset['signalized']==True,'source_B'].value_counts()\n",
    "# two_way_stops = subset.loc[subset['unsignalized']==True,'source_B'].value_counts()\n",
    "\n",
    "# #get node coordinates\n",
    "# #nodes.merge(signals,left_on='N',right_index=True)\n",
    "\n",
    "# test = nodes.merge(signals,left_on='N',right_index=True)\n",
    "# test.columns = ['N','geometry','num_times']\n",
    "\n",
    "\n",
    "# # now value counts \n",
    "# #two_way_stops.value_counts().head(20)\n",
    "# ## Use linkids to add network summaries \n",
    "\n",
    "# #turn into dataframe\n",
    "# df = pd.DataFrame.from_dict(matched_trips,orient='index')\n",
    "# #into geodataframe\n",
    "# gdf = gpd.GeoDataFrame(df,geometry='geometry',crs='epsg:2240')\n",
    "\n",
    "# gdf.reset_index(inplace=True)\n",
    "# gdf.rename(columns={'index':'tripid'},inplace=True)\n",
    "\n",
    "# test_merge = pd.read_csv(config['network_fp'].parent/'all_attrs.csv')\n",
    "# prev = gdf.copy()\n",
    "# gdf = gdf.merge(test_merge,on='tripid')\n",
    "# gdf\n",
    "# def visualize(tripid,gdf,nodes):\n",
    "\n",
    "#    '''\n",
    "#    This function displays the matched vs shortest route for a particular trip\n",
    "#    It also displays the trip characteristics side be side and plots the any signalized\n",
    "#    intersections and stressful turns passed through.\n",
    "#    '''\n",
    "\n",
    "#    #gdf contains all the trips and the trip gemometries as mutlilinestrings\n",
    "#    gdf = gdf.copy()\n",
    "\n",
    "#    # Your GeoDataFrames\n",
    "#    chosen_path = gdf.loc[gdf['tripid']==tripid,['tripid','geometry']]\n",
    "#    shortest_path = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_geo']].set_geometry('shortest_geo').set_crs(gdf.crs)\n",
    "#    intersection = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_intersect_geo']].set_geometry('shortest_intersect_geo').set_crs(gdf.crs)\n",
    "\n",
    "#    #from these we want to get the locations and number of singalized intersections and stressful crossing passed through\n",
    "#    edges = match_dict[tripid]['edges']\n",
    "#    list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "#    list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "#    df_of_turns = pd.DataFrame(list_of_turns,columns=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n",
    "#    subset = pseudo_df.merge(df_of_turns,on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n",
    "\n",
    "#    # from this subset we can get the right node ids\n",
    "#    #TODO turns should be by edges probably?\n",
    "#    #turns = subset[['source_B','turn_type']]\n",
    "#    signals = subset.loc[subset['signalized']==True,'source_B'].value_counts()\n",
    "#    two_way_stops = subset.loc[subset['unsignalized']==True,'source_B'].value_counts()\n",
    "\n",
    "#    #and then get the correct rows of the gdf\n",
    "#    #turns = nodes.merge(signals,left_on='N',right_on='')\n",
    "#    signals = nodes.merge(signals,left_on='N',right_index=True)\n",
    "#    signals.columns = ['N','geometry','num_times']\n",
    "#    two_way_stops = nodes.merge(two_way_stops,left_on='N',right_index=True)\n",
    "#    two_way_stops.columns = ['N','geometry','num_times']\n",
    "\n",
    "#    # get the start and end point for plotting\n",
    "#    start_N = gdf.loc[gdf['tripid']==tripid,'start'].item()\n",
    "#    start_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==start_N,'geometry'].item()\n",
    "#    end_N = gdf.loc[gdf['tripid']==tripid,'end'].item()\n",
    "#    end_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==end_N,'geometry'].item()\n",
    "\n",
    "#    # Create a Folium map centered around the mean of the chosen route\n",
    "#    x_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.x\n",
    "#    y_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.y\n",
    "#    center = [y_mean,x_mean]\n",
    "#    mymap = folium.Map(location=center, zoom_start=14)\n",
    "\n",
    "#    # Convert GeoDataFrames to GeoJSON\n",
    "#    chosen_path_geojson = chosen_path.to_crs(epsg='4326').to_json()\n",
    "#    shortest_path_geojson = shortest_path.to_crs(epsg='4326').to_json()\n",
    "#    intersection_geojson = intersection.to_crs(epsg='4326').to_json()\n",
    "\n",
    "#    # Create FeatureGroups for each GeoDataFrame\n",
    "#    chosen_path_fg = FeatureGroup(name='Chosen Path')\n",
    "#    shortest_path_fg = FeatureGroup(name='Shortest Path',show=False)\n",
    "#    intersection_fg = FeatureGroup(name='Buffer Intersection',show=False)\n",
    "\n",
    "#    # Add GeoJSON data to FeatureGroups\n",
    "#    folium.GeoJson(chosen_path_geojson, name='Chosen Path', style_function=lambda x: {'color': 'red'}).add_to(chosen_path_fg)\n",
    "#    folium.GeoJson(shortest_path_geojson, name='Shortest Path', style_function=lambda x: {'color': 'blue'}).add_to(shortest_path_fg)\n",
    "#    folium.GeoJson(intersection_geojson, name='Buffer Intersection', style_function=lambda x: {'color': 'yellow'}).add_to(intersection_fg)\n",
    "\n",
    "#    # Add FeatureGroups to the map\n",
    "#    chosen_path_fg.add_to(mymap)\n",
    "#    shortest_path_fg.add_to(mymap)\n",
    "#    intersection_fg.add_to(mymap)\n",
    "\n",
    "#    if signals.shape[0] > 0:\n",
    "#       signals_geojson = signals.to_crs(epsg='4326').to_json()\n",
    "#       signals_fg = FeatureGroup(name='Signals')\n",
    "\n",
    "#       folium.GeoJson(\n",
    "#       signals_geojson,\n",
    "#       name=\"Traffic Signal Turn Movement\",\n",
    "#       marker=folium.Circle(radius=20, fill_color=\"red\", fill_opacity=.5, color=\"black\", weight=1),\n",
    "#       tooltip=folium.GeoJsonTooltip(fields=['N','num_times']),\n",
    "#       popup=folium.GeoJsonPopup(fields=['N','num_times']),\n",
    "#       #    style_function= lambda feature: {\n",
    "#       #        'fillColor': colormap(feature['properties']['speed_mph']),\n",
    "#       #    },\n",
    "#       highlight_function=lambda feature: {\"color\":\"yellow\",\"weight\":3}\n",
    "#       ).add_to(signals_fg)\n",
    "#       signals_fg.add_to(mymap)\n",
    "\n",
    "#    if two_way_stops.shape[0] > 0:\n",
    "#       two_way_stops_geojson = two_way_stops.to_crs(epsg='4326').to_json()\n",
    "#       two_way_stops_fg = FeatureGroup(name='Two Way Stop (chosen)')\n",
    "\n",
    "#       folium.GeoJson(\n",
    "#       two_way_stops_geojson,\n",
    "#       name=\"Two Way Stop with High Stress Cross Street\",\n",
    "#       marker=folium.Circle(radius=20, fill_color=\"yellow\", fill_opacity=.5, color=\"black\", weight=1),\n",
    "#       tooltip=folium.GeoJsonTooltip(fields=['N','num_times']),\n",
    "#       popup=folium.GeoJsonPopup(fields=['N','num_times']),\n",
    "#       #    style_function= lambda feature: {\n",
    "#       #        'fillColor': colormap(feature['properties']['speed_mph']),\n",
    "#       #    },\n",
    "#       highlight_function=lambda feature: {\"color\":\"yellow\",\"weight\":3}\n",
    "#       ).add_to(two_way_stops_fg)\n",
    "\n",
    "#       two_way_stops_fg.add_to(mymap)\n",
    "\n",
    "\n",
    "#    # Add start and end points with play and stop buttons\n",
    "#    start_icon = folium.Icon(color='green',icon='play',prefix='fa')\n",
    "#    end_icon = folium.Icon(color='red',icon='stop',prefix='fa')\n",
    "#    folium.Marker(location=[start_pt.y, start_pt.x],icon=start_icon).add_to(mymap)\n",
    "#    folium.Marker(location=[end_pt.y, end_pt.x],icon=end_icon).add_to(mymap)\n",
    "\n",
    "#    #autofit content not in this version?\n",
    "#    #folium.FitOverlays().add_to(mymap)\n",
    "\n",
    "#    # Add layer control to toggle layers on/off\n",
    "#    folium.LayerControl().add_to(mymap)\n",
    "\n",
    "#    #retrive overlap\n",
    "#    exact_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_exact_overlap_prop'].item()\n",
    "#    buffer_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_buffer_overlap'].item()\n",
    "\n",
    "#    attr = gdf.loc[gdf['tripid']==tripid].squeeze()\n",
    "\n",
    "#    # Add legend with statistics\n",
    "#    legend_html = f'''\n",
    "#    <div style=\"position: fixed; \n",
    "#             bottom: 5px; left: 5px; width: 300px; height: 500px; \n",
    "#             border:2px solid grey; z-index:9999; font-size:14px;\n",
    "#             background-color: white;\n",
    "#             opacity: 0.9;\">\n",
    "#    &nbsp; <b>Tripid: {tripid}</b> <br>\n",
    "#    &nbsp; Start Point &nbsp; <i class=\"fa fa-play\" style=\"color:green\"></i><br>\n",
    "#    &nbsp; End Point &nbsp; <i class=\"fa fa-stop\" style=\"color:red\"></i><br>\n",
    "#    &nbsp; Exact Overlap: {exact_overlap*100:.2f}% <br>\n",
    "#    &nbsp; Buffer Overlap: {buffer_overlap*100:.2f}% <br>\n",
    "\n",
    "#    &nbsp; Trip Type: {attr['trip_type']} <br>\n",
    "#    &nbsp; Length (mi): {attr['length_ft']/5280:.0f} <br>\n",
    "#    &nbsp; Age: {attr['age']} <br>\n",
    "#    &nbsp; Gender: {attr['gender']} <br>\n",
    "#    &nbsp; Income: {attr['income']} <br>\n",
    "#    &nbsp; Ethnicity: {attr['ethnicity']} <br>\n",
    "#    &nbsp; Cycling Frequency: {attr['cyclingfreq']} <br>\n",
    "#    &nbsp; Rider History: {attr['rider_history']} <br>\n",
    "#    &nbsp; Rider Type: {attr['rider_type']} <br><br>\n",
    "\n",
    "#    &nbsp; Residential %: {attr['highway.residential']*100:.2f}% <br>\n",
    "#    &nbsp; Secondary %: {attr['highway.secondary']*100:.2f}% <br>\n",
    "#    &nbsp; Tertiary %: {attr['highway.tertiary']*100:.2f}% <br>\n",
    "\n",
    "#    &nbsp; # of bridges: {int(attr['bridge'])} <br>\n",
    "#    &nbsp; # of left turns: {int(attr['left'])} <br>\n",
    "#    &nbsp; # of straight turns: {int(attr['straight'])} <br>\n",
    "#    &nbsp; # of right turns: {int(attr['right'])} <br>\n",
    "#    &nbsp; # of stressful turns: {int(attr['unsignalized'])} <br>\n",
    "#    &nbsp; # of signalized turns: {int(attr['signalized'])} <br>\n",
    "\n",
    "#    </div>\n",
    "#    '''\n",
    "\n",
    "#    mymap.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "#    # Save the map to an HTML file or display it in a Jupyter notebook\n",
    "#    #mymap.save('map.html')\n",
    "#    # mymap.save('/path/to/save/map.html')  # Use an absolute path if needed\n",
    "#    return mymap  # Uncomment if you are using Jupyter notebook\n",
    "\n",
    "#    #TODO add in the legend with trip info and then we're golden\n",
    "\n",
    "# gdf\n",
    "# examined = []\n",
    "# #TODO add dots for signals and unsignalized\n",
    "# #have slides on turns\n",
    "# gdf.head()\n",
    "# tripid = gdf['tripid'].sample(1).item()\n",
    "# tripid = 2499\n",
    "# examined.append(tripid)\n",
    "# visualize(tripid,gdf,nodes)\n",
    "# with (export_fp/'ready4calibration.pkl').open('wb') as fh:\n",
    "#     pickle.dump(gdf,fh)\n",
    "# with (export_fp/'ready4calibration.pkl').open('wb') as fh:\n",
    "#     pickle.dump(gdf,fh)\n",
    "# #viz version (used for optimization too)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
