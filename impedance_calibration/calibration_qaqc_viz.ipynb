{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration QAQC\n",
    "- Visualize calibration routes and compare to the chosen and shortest routes\n",
    "- Trip-specific impedance routing to see if chosen route can be found\n",
    "- Test different objective functions\n",
    "- Try using coordinates in case the map matched trace is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import src.stochastic_optimization as stochastic_optimization\n",
    "import src.speedfactor as speedfactor\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import Point, MultiLineString\n",
    "from importlib import reload\n",
    "import datetime\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "path = Path.cwd().parent\n",
    "sys.path.insert(0,str(path))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths(path)\n",
    "\n",
    "from network.src import modeling_turns\n",
    "from scipy.spatial.distance import directed_hausdorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add google bike layer and a sat layer\n",
    "import xyzservices.providers as xyz\n",
    "tile_info_dict = {\n",
    "    \"tiles\": xyz.MapTiler.Streets.build_url(key=config['maptilerapikey']),\n",
    "    \"name\": str.replace(xyz.MapTiler.Streets.name,'.',' '),\n",
    "    \"attr\": xyz.MapTiler.Streets.html_attribution\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('rb') as fh:\n",
    "    full_set = pickle.load(fh)\n",
    "full_ods = stochastic_optimization.match_results_to_ods(full_set)\n",
    "# for viz parts\n",
    "with (config['cycleatl_fp']/\"rdp.pkl\").open('rb') as fh:\n",
    "    coords = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_calibration_fps = (config['calibration_fp']/'post_calibration').glob('*.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a calibration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_list = []\n",
    "for post_calibration_fp in post_calibration_fps:\n",
    "    with post_calibration_fp.open('rb') as fh:\n",
    "        modeled_dict = pickle.load(fh)\n",
    "    modeled_list.append((post_calibration_fp.stem,modeled_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_performing = [x for x in post_calibration_fps if 'calibration2' in x.stem][0]\n",
    "with best_performing.open('rb') as fh:\n",
    "    modeled_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_well_explained = [tripid for tripid, item in modeled.items() if item['modeled_buffer'] < 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get user and trip variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['cycleatl_fp']/\"trips_2.pkl\").open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "with (config['cycleatl_fp']/\"users_2.pkl\").open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "trips.set_index('tripid',inplace=True)\n",
    "users.set_index('userid',inplace=True)\n",
    "trips = trips.loc[list(full_set.keys())]\n",
    "users = users.loc[users.index.isin(set(list(trips['userid'])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First an overview of how to use the QAQC functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a random trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "pool = not_well_explained#list(full_set.keys())\n",
    "tripid = random.choice(pool)\n",
    "print(tripid)\n",
    "# tripid = 861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "print(trips.loc[tripid,['avg_speed_mph','trip_type','description']])\n",
    "print(users.loc[trips.at[tripid,'userid']])\n",
    "stochastic_optimization.visualize_three(tripid,full_set,modeled_list,geo_dict,coords,config['projected_crs_epsg'],tile_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalibrate one trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # determine the ouput name of the calibration outputs\n",
    "# calibration_name = 'calibration2'\n",
    "\n",
    "# determine variables, impedance type, and search range\n",
    "betas_tup = (\n",
    "    {'col':'2lpd','type':'link','range':[0,3]},\n",
    "    {'col':'3+lpd','type':'link','range':[0,3]},\n",
    "    {'col':'(30,40] mph','type':'link','range':[0,3]},\n",
    "    {'col':'(40,inf) mph','type':'link','range':[0,3]},\n",
    "    {'col':'[4k,10k) aadt','type':'link','range':[0,3]},\n",
    "    {'col':'[10k,inf) aadt','type':'link','range':[0,3]},\n",
    "    {'col':'[4,6) grade','type':'link','range':[0,3]},\n",
    "    {'col':'[6,inf) grade','type':'link','range':[0,3]},\n",
    "    {'col':'bike lane','type':'link','range':[-1,0]},\n",
    "    {'col':'cycletrack','type':'link','range':[-1,0]},\n",
    "    {'col':'multi use path','type':'link','range':[-1,0]},\n",
    "    # {'col':'unsig_major_road_crossing','type':'turn','range':[0,2]}\n",
    ")\n",
    "\n",
    "# determine the objective function to use and other settings\n",
    "objective_function = stochastic_optimization.buffer_overlap\n",
    "batching = False\n",
    "stochastic_optimization_settings = {\n",
    "    'method':'pso',\n",
    "    'options': {'maxiter':100,'popsize':3}\n",
    "}\n",
    "\n",
    "# links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "\n",
    "one_set = {key:item for key, item in full_set.items() if key == tripid}\n",
    "\n",
    "args = (\n",
    "    [], # empty list for storing past calibration results\n",
    "    betas_tup, # tuple containing the impedance spec\n",
    "    stochastic_optimization.match_results_to_ods(one_set), # list of OD network node pairs needed for shortest path routing\n",
    "    one_set, # dict containing the origin/dest node and map matched edges\n",
    "    stochastic_optimization.link_impedance_function, # link impedance function to use\n",
    "    \"travel_time_min\", # column with the base the base impedance in travel time or distance\n",
    "    stochastic_optimization.turn_impedance_function, # turn impedance function to use\n",
    "    links,turns,turn_G, # network parts\n",
    "    objective_function, # loss function to use\n",
    "    {'length_dict':length_dict,'geo_dict':geo_dict},#,'trace_dict':traces}, # keyword arguments for loss function\n",
    "    True, #whether to print the results of each iteration\n",
    "    True, #whether to store calibration results\n",
    "    batching # whether to batch results to help speed up computation time, if yes input the number to batch with\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "print([x['col'] for x in betas_tup]+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration,\n",
    "             stochastic_optimization.extract_bounds(betas_tup),\n",
    "             args=args,\n",
    "             **stochastic_optimization_settings)\n",
    "end = time.time()\n",
    "print(f\"Took {str(pd.Timedelta(seconds=end-start).round('s'))} hours\")\n",
    "print(f\"{args[10].__name__}: {x.fun}\")\n",
    "print(x)\n",
    "\n",
    "calibration_result = {\n",
    "    'betas_tup': tuple({**item,'beta':x.x[idx].round(4)} for idx,item in enumerate(betas_tup)), # contains the betas\n",
    "    'settings': stochastic_optimization_settings, # contains the optimization settings\n",
    "    'objective_function': args[10].__name__, # objective function used\n",
    "    'results': x, # stochastic optimization outputs\n",
    "    'trips_calibrated': set(full_set.keys()), # saves which trips were calibrated\n",
    "    'past_vals': args[0], # all of the past values/guesses\n",
    "    'runtime': pd.Timedelta(end-start),\n",
    "    'time': datetime.datetime.now()\n",
    "}\n",
    "# #export but don't overwrite\n",
    "# export_fp = config['calibration_fp'] / f'calibration_results/{calibration_name}.pkl'\n",
    "# with stochastic_optimization.uniquify(export_fp).open('wb') as fh:\n",
    "#         pickle.dump(calibration_result,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_impedance_col = \"travel_time_min\"\n",
    "betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "print(betas)\n",
    "one_od = stochastic_optimization.match_results_to_ods(one_set)\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                        stochastic_optimization.link_impedance_function,\n",
    "                        base_impedance_col,\n",
    "                        stochastic_optimization.turn_impedance_function,\n",
    "                        links,turns,turn_G)\n",
    "modeled_results_sp = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in tqdm(one_od,total=len(one_od))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results_dict = {}\n",
    "for tripid, item in one_set.items():\n",
    "    chosen = item['matched_edges'].values\n",
    "    shortest = item['shortest_edges'].values\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled = modeled_results_sp[od]['edge_list']\n",
    "\n",
    "    modeled_results_dict[tripid] = {\n",
    "        'modeled_edges': pd.DataFrame(modeled,columns=['linkid','reverse_link']),\n",
    "        'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,1),\n",
    "        'modeled_detour': round(stochastic_optimization.detour_factor(modeled,shortest,length_dict),2),\n",
    "        'modeled_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,modeled,length_dict),2),\n",
    "        'modeled_buffer': round(stochastic_optimization.buffer_overlap(chosen,modeled,geo_dict),2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [('original',modeled_dict),('recalibrated',modeled_results_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.visualize_three(tripid,full_set,test,geo_dict,coords,config['projected_crs_epsg'],tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_dict[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"calibration_results.pkl\").open('rb') as fh:\n",
    "#     calibration_results = pickle.load(fh)\n",
    "# calibration_result = caalibration_results[-1]\n",
    "# calibration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_trip = {tripid:modeled_results[tripid]}\n",
    "args = (\n",
    "    [], # empty list for storing past calibration results\n",
    "    calibration_result['betas_tup'], # tuple containing the impedance spec\n",
    "    stochastic_optimization.match_results_to_ods(one_trip), # list of OD network node pairs needed for shortest path routing\n",
    "    one_trip, # dict containing the origin/dest node and map matched edges\n",
    "    stochastic_optimization.link_impedance_function, # link impedance function to use\n",
    "    \"travel_time_min\", # column with the base the base impedance in travel time or distance\n",
    "    stochastic_optimization.turn_impedance_function, # turn impedance function to use\n",
    "    links,turns,turn_G, # network parts\n",
    "    stochastic_optimization.jaccard_index_func, # loss function to use\n",
    "    {'length_dict':length_dict,'geo_dict':geo_dict}, # keyword arguments for loss function\n",
    "    True, #whether to print the results of each iteration\n",
    "    False #whether to store calibration results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print([x['col'] for x in calibration_result['betas_tup']]+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration,\n",
    "             stochastic_optimization.extract_bounds(calibration_result['betas_tup']),\n",
    "             args=args,\n",
    "             method='pso',\n",
    "             options={'maxiter':20,\"popsize\":10})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reroute one trip after recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betas = [-0.184,-0.398,0.126,0.325,0.324]\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "betas = x.x\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "one_trip_od = stochastic_optimization.match_results_to_ods(one_trip)[0]\n",
    "new_result = stochastic_optimization.impedance_path(turns,turn_G,links,*one_trip_od) #for start_node, end_node in one_trip_od}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[tripid]['Recalibrated'] = pd.DataFrame(new_result['edge_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize new modeled one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[tripid].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "line_dict = stochastic_optimization.construct_line_dict(['matched_edges','shortest_edges','modeled_edges','Recalibrated'],modeled_results[tripid],geo_dict)\n",
    "line_dict = stochastic_optimization.add_metrics_to_tooltip(line_dict,length_dict,geo_dict)\n",
    "stochastic_optimization.visualize_three(tripid,line_dict,modeled_results[tripid]['coords'],links.crs,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the chosen, shortest, and modeled route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "tripid = 243\n",
    "print(trips.loc[tripid,['trip_type','description']])\n",
    "mymap = stochastic_optimization.basic_three_viz(tripid,modeled_results,links,tile_info_dict)\n",
    "mymap.save(Path.home()/'Downloads/troubleshooting.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to re-route or re-calibrate trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have more than one modeled route or other routes, then use this sequence of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dict = stochastic_optimization.construct_line_dict(['matched_edges','shortest_edges','modeled_edges'],modeled_results[tripid],geo_dict)\n",
    "line_dict = stochastic_optimization.add_metrics_to_tooltip(line_dict,links)\n",
    "stochastic_optimization.visualize_three(tripid,line_dict,links,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_qgis(tripid,results_dict,geo_dict,config):\n",
    "    '''\n",
    "    Creates GeoJSON for viewing calibration results in QGIS. Set\n",
    "    colors to color column.\n",
    "    '''\n",
    "    \n",
    "    fields = ['matched_edges','shortest_edges','modeled_edges']\n",
    "    geos = [LineString(stochastic_optimization.get_route_line(results_dict[tripid][field].values,geo_dict)) for field in fields]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        data={\n",
    "            'type': ['chosen','shortest','modeled'],\n",
    "            'color': ['#fc8d62','#66c2a5','#8da0cb'],\n",
    "            'geometry': geos\n",
    "        },\n",
    "        crs=config['projected_crs_epsg']\n",
    "    )\n",
    "    gdf.to_file(config['calibration_fp']/'calibration_qaqc.gpkg',layer='calibration_results')\n",
    "    return gdf\n",
    "\n",
    "gdf = export_to_qgis(tripid,modeled_results,geo_dict,config)\n",
    "gdf.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "bbox = box(*gdf.total_bounds)\n",
    "bbox = bbox.buffer(5280*2)\n",
    "extract = links[links.geometry.intersects(bbox)].copy()\n",
    "extract['forward_cost'] = extract['link_cost']\n",
    "extract['backward_cost'] = extract['link_cost']\n",
    "extract = extract[extract['reverse_link']==False]\n",
    "extract = extract[['A','B','linkid','osmid','forward_cost','backward_cost','geometry']]\n",
    "extract.to_crs('epsg:4326',inplace=True)\n",
    "extract.to_file(Path.home()/'Downloads/test.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idenfity trips that pass through a circle\n",
    "One area with trouble is the Stone Mountain Trail because the map matched route often uses Dekalb instead. This leads to some trips having a lower than expected overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freedom_pkwy = (2237899.09,1372338.05)\n",
    "freedom_pkwy = stochastic_optimization.retrieve_geos(*freedom_pkwy,modeled_results,links)\n",
    "print(len(freedom_pkwy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = (2250499.40,1369121.80)\n",
    "smt = stochastic_optimization.retrieve_geos(*smt,modeled_results,links)\n",
    "print(len(smt))\n",
    "tenth_st = (2233722.10,1375729.08)\n",
    "tenth_st = stochastic_optimization.retrieve_geos(*tenth_st,modeled_results,links)\n",
    "print(len(tenth_st))\n",
    "wylie_st = (2237751.33,1365098.89)\n",
    "wylie_st = stochastic_optimization.retrieve_geos(*wylie_st,modeled_results,links)\n",
    "print(len(wylie_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = random.choice(freedom_pkwy)\n",
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.basic_three_viz(tripid,modeled_results,links.crs,length_dict,geo_dict,tile_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can calibrating by itself improve it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense it\n",
    "\n",
    "betas_links = {\n",
    "    0 : 'multi use path',\n",
    "    1 : 'bike lane',\n",
    "    2 : 'lanes',\n",
    "    3 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    4 : 'unsig_major_road_crossing'\n",
    "}\n",
    "\n",
    "with (config['calibration_fp']/'full_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "# train_set = train_set\n",
    "train_set = {tripid:train_set.get(tripid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "#loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    #loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled2 = full_results_dict[(8180621166, 68253267)]['edge_list']\n",
    "modeled2 = stochastic_optimization.get_route_line(modeled2,links)\n",
    "#modeled2 = LineString(modeled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "# mymap = stochastic_optimization.visualize_three(tripid,LineString(chosen),LineString(modeled2),LineString(modeled),links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# #mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "# print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "# mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see improvement! But how does it track with othere success measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_frechet = modeled_dist\n",
    "new_frechet = similaritymeasures.frechet_dist(chosen,modeled2)\n",
    "print(old_frechet,new_frechet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge reduction! Now what if we used frechet distance in the calibration for the objective function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True,drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.frechet_distance\n",
    "loss_function_kwargs = {'length_dict':length_dict,'links':links}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did using a different overlap function fix the issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "single_trip = stochastic_optimization.post_calibration_routing(links,turns,turn_G,\"travel_time_min\",\n",
    "                                                 betas,betas_links,betas_turns,train_ods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled3 = full_results_dict[(8180621166, 68253267)]['edge_list']\n",
    "modeled3 = stochastic_optimization.get_route_line(modeled3,links)\n",
    "#modeled2 = LineString(modeled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need something about the tootlip just so we can see what the different measurements are\n",
    "- jaccard (linkids + reverse)\n",
    "- frechet (coords)\n",
    "- maybe more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.basic_three_viz(243,modeled_results,links,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[122]['matched_edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dict = {\n",
    "    'Chosen': {'coords':chosen},\n",
    "    'Shortest': {'coords':shortest,'tooltip':0.5},\n",
    "    'Modeled (all trips)': {'coords':modeled,'tooltip':0.5},\n",
    "    'Modeled (trip only)': {'coords':modeled2,'tooltip':0.5},\n",
    "    'Modeled (new objective function)': {'coords':modeled3,'tooltip':0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "mymap = stochastic_optimization.visualize_three(tripid,line_dict,links,tile_info_dict)\n",
    "#mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think no but lets package these functions to make it easier to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect overlap values for trip to trip impedance\n",
    "(coefficients are incorrect right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"trip_specific.pkl\").open('rb') as fh:\n",
    "    trip_by_trip = pickle.load(fh)\n",
    "\n",
    "new_col = {tripid:item['loss'].min() * -1 for tripid, item in trip_by_trip.items()}\n",
    "new_col = pd.Series(new_col).reset_index()\n",
    "new_col.columns = ['tripid','new_impedance']\n",
    "test = pd.merge(full,new_col,on='tripid')\n",
    "print(test['new_impedance'].mean())\n",
    "(test['new_impedance'] - test['impedance']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the overlap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['new_impedance']<test['impedance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = 837\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "#mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links2 = links.reset_index().copy()\n",
    "# links2 = gpd.read_file(config['calibration_fp']/\"calibration_network.gpkg\",layer='links')\n",
    "# links2.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = full['impedance'] - full['shortest']\n",
    "differences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = full.loc[full['shortest']<full['impedance'],'tripid'].tolist()\n",
    "worse = full.loc[full['shortest']>full['impedance'],'tripid'].tolist()\n",
    "print(len(better))\n",
    "print(len(worse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Social Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "social = trips[trips['trip_type']=='Social']\n",
    "tripid = random.choice(social.index.tolist())\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[trips['description'].str.contains('ride') & trips['description'].notna(),'description'].head(50)#.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "social = trips[trips['description'].str.contains('ride') & trips['description'].notna()].index.tolist()\n",
    "tripid = random.choice(social)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the three lines into one gpkg file with pre-defined colors, so that we can update it on the fly in QGIS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Extract colors from a ColorBrewer scheme (e.g., 'Set2')\n",
    "# # Convert them to HEX format if needed\n",
    "colorbrewer_hex = [colors.to_hex(c) for c in plt.get_cmap('Set2').colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condense the network so that it is convenient to examine in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nonrev_cols = ['name','osmid','highway','year','geometry']\n",
    "rev_cols = ['multi use path','bike lane','lanes','above_4']\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "nonrev_links = links.loc[idx[:,False],idx[nonrev_cols+rev_cols]]\n",
    "nonrev_links.reset_index(inplace=True)\n",
    "nonrev_links.set_index('linkid',inplace=True)\n",
    "nonrev_links.drop(columns=['reverse_link'],inplace=True)\n",
    "\n",
    "rev_links = links.loc[idx[:,True],idx[rev_cols]]\n",
    "rev_links.reset_index(inplace=True)\n",
    "rev_links.set_index('linkid',inplace=True)\n",
    "rev_links.drop(columns=['reverse_link'],inplace=True)\n",
    "rev_links.columns = 'rev_' + rev_links.columns\n",
    "\n",
    "#combine\n",
    "condensed_network = pd.concat([nonrev_links,rev_links],ignore_index=False,axis=1)\n",
    "condensed_network = gpd.GeoDataFrame(condensed_network,crs=config['projected_crs_epsg'])\n",
    "\n",
    "import ast\n",
    "og_links = gpd.read_file(config['osmdwnld_fp']/'osm_2023.gpkg',layer='raw',ignore_geometry=True)\n",
    "og_links = dict(zip(og_links['osmid'],og_links['all_tags']))\n",
    "for key, item in og_links.items():\n",
    "    item = ast.literal_eval(item)\n",
    "    item.pop('@way_nodes')\n",
    "    item = str(item)\n",
    "    og_links[key] = item\n",
    "condensed_network['all_tags'] = condensed_network['osmid'].map(og_links)\n",
    "condensed_network.to_file(config['calibration_fp']/'calibration_qaqc.gpkg',layer='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can try viewing it in leaflet instead? might be slow because of all the links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense it\n",
    "\n",
    "betas_links = {\n",
    "    0 : 'multi use path',\n",
    "    1 : 'bike lane',\n",
    "    2 : 'lanes',\n",
    "    3 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    4 : 'unsig_major_road_crossing'\n",
    "}\n",
    "\n",
    "with (config['calibration_fp']/'full_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "# train_set = train_set\n",
    "train_set = {tripid:train_set.get(tripid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.reset_index(inplace=True)\n",
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "for tripid, item in full_set.items():\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled_edges = full_results_dict.get(od,0).get('edge_list',0)\n",
    "    if isinstance(modeled_edges,int):\n",
    "        print(modeled_edges)\n",
    "    #turn to dataframe\n",
    "    modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "    full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_links = links[links.intersects(box(*pd.concat([chosen_line,shortest_line,modeled_line]).total_bounds))].copy()\n",
    "# links.loc[idx[:,False],idx[rev_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_poor = full.loc[full['impedance']<0.1,'tripid'].tolist()\n",
    "tripid = random.choice(shortest_path_poor)\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where shortest path does poorly\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "shortest_path_poor = full.loc[full['shortest']<0.3,'tripid'].tolist()\n",
    "tripid = random.choice(shortest_path_poor)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/shortest_poor.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = random.choice(better)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/optim_results.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = random.choice(worse)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/optim_results2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[full['tripid']==tripid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_overlaps = [30845]\n",
    "needs_work = [13190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "# html = \"\"\n",
    "# nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "# nodes.to_crs('epsg:4236',inplace=True)\n",
    "# nodes['lon'] = nodes.geometry.x\n",
    "# nodes['lat'] = nodes.geometry.y\n",
    "# latlon = tuple(zip(nodes['lon'],nodes['lat']))\n",
    "# nodes = dict(zip(nodes['N'],latlon))\n",
    "# nodes.get(68196100,0)\n",
    "# htmls = []\n",
    "# for od in both_ods:\n",
    "#     start = od[0]\n",
    "#     end = od[1]\n",
    "#     start_lonlat = nodes.get(start,0)\n",
    "#     end_lonlat = nodes.get(end,0)\n",
    "#     html = f\"https://brouter.damsy.net/latest/#map=12/33.7522/-84.3892/standard&lonlats={start_lonlat[1]},{start_lonlat[0]};{end_lonlat[1]},{end_lonlat[0]}&profile=safety\"\n",
    "#     htmls.append(html)\n",
    "# with (config['calibration_fp']/\"brouter_links.txt\").open('w') as fh:\n",
    "#     for html in htmls:\n",
    "#         fh.write(f\"{html}\\n\")\n",
    "# with (config['calibration_fp']/\"brouter_ods.txt\").open('w') as fh:\n",
    "#     for od in both_ods:\n",
    "#         fh.write(f\"{od}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
