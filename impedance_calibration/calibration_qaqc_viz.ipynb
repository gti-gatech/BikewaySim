{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration QAQC\n",
    "- Visualize calibration routes and compare to the chosen and shortest routes\n",
    "- Trip-specific impedance routing to see if chosen route can be found\n",
    "- Test different objective functions\n",
    "- Try using coordinates in case the map matched trace is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import Point, MultiLineString, LineString\n",
    "from importlib import reload\n",
    "import datetime\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from bikewaysim.paths import config, stadia_toner, maptiler_streets\n",
    "from bikewaysim.impedance_calibration import stochastic_optimization, speedfactor\n",
    "from bikewaysim.network import modeling_turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('rb') as fh: # has loss values for shortest path\n",
    "    full_set = pickle.load(fh)\n",
    "full_ods = stochastic_optimization.match_results_to_ods_w_year(full_set)\n",
    "# for adding coordinates to the viz part\n",
    "with (config['cycleatl_fp']/\"rdp.pkl\").open('rb') as fh:\n",
    "    coords = pickle.load(fh)\n",
    "\n",
    "with (config['cycleatl_fp']/\"trips_2.pkl\").open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "with (config['cycleatl_fp']/\"users_2.pkl\").open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "trips.set_index('tripid',inplace=True)\n",
    "users.set_index('userid',inplace=True)\n",
    "trips = trips.loc[list(full_set.keys())]\n",
    "users = users.loc[users.index.isin(set(list(trips['userid'])))]\n",
    "user_map = trips['userid'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the calibration result for each model calibrated\n",
    "calibration_results_fps = (config['calibration_fp']/'user_calibration_results').glob('*.pkl')\n",
    "calibration_results = {}\n",
    "for calibration_results_fp in calibration_results_fps:\n",
    "    with calibration_results_fp.open('rb') as fh:\n",
    "        calibration_results[calibration_results_fp.stem] = pickle.load(fh)\n",
    "\n",
    "# retrieves post routing and loss values results for each model calibrated\n",
    "post_calibration_fps = (config['calibration_fp']/'user_post_calibration_loss').glob('*.pkl')\n",
    "post_calibration = {}\n",
    "for post_calibration_fp in post_calibration_fps:\n",
    "    with post_calibration_fp.open('rb') as fh:\n",
    "        post_calibration[post_calibration_fp.stem] = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# restrict to one user and model name for exploration\n",
    "userid = 21\n",
    "model_name = 'jaccard_buffer_mean '\n",
    "# model_name = 'break stuff'\n",
    "post_calibration = {key:item for key, item in post_calibration.items() if (int(key.split('_')[0]) == userid) & (model_name in key)}\n",
    "calibration_results = {key:item for key, item in calibration_results.items() if (int(key.split('_')[0]) == userid) & (model_name in key)}\n",
    "\n",
    "# retrieves the trips to look at so that we don't sample something out of range\n",
    "modeled_users = set([int(x.split('_')[0]) for x in post_calibration.keys()]) # checks to see model name co\n",
    "subset_trips = [x for x in trips.index if user_map[x] in modeled_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimums = [(item['results'].fun,item['results'].nfev,item['results'].nit,item['results'].nfev / item['results'].nit ) for _, item in calibration_results.items()]\n",
    "optimums = pd.DataFrame(optimums,columns=['obj','nfev','nit','particles'])\n",
    "optimums['obj'].abs().hist(color='grey',bins=np.arange(0, 1.05, 0.05))\n",
    "plt.xlabel('Objective Function Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([0, 1])\n",
    "plt.title(f'Objective Function Values for User {userid} (N={len(optimums)})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimums.sort_values('particles',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_optimization.post_calibration_loss(user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do the betas look like?\n",
    "betas_vals = stochastic_optimization.post_calibration_betas(user=True)\n",
    "aggregated_loss = stochastic_optimization.post_calibration_aggregated(user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(betas_vals,aggregated_loss,on=['userid','run_number','calibration'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = merged[merged['userid']==str(userid)]\n",
    "\n",
    "test['2lpd'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "# Assuming 'x' is your x-axis and the remaining columns are the y-axes\n",
    "# data = test\n",
    "\n",
    "# Extract x and y columns\n",
    "y = test['jaccard_buffer_mean']\n",
    "x_columns = ['2lpd', '3+lpd', '(30,40] mph',\n",
    "       '(40,inf) mph', '[4k,10k) aadt', '[10k,inf) aadt', '[4,6) grade',\n",
    "       '[6,inf) grade', 'bike lane', 'cycletrack', 'multi use path',\n",
    "       'unsig_crossing']\n",
    "\n",
    "# Set up the grid dimensions: 3 columns and as many rows as needed\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(len(x_columns) / n_cols)  # Dynamically calculates number of rows needed\n",
    "\n",
    "# Create a figure with subplots arranged in a grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10 * n_rows , 4 * n_cols))  # Adjust figure size\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Plot scatter plots for each y-column against the x-column\n",
    "for i, x_col in enumerate(x_columns):\n",
    "    axes[i].scatter(test[x_col], y, label=x_col)\n",
    "    axes[i].set_xlabel(x_col)\n",
    "    axes[i].set_ylabel('Objective Function')\n",
    "    # axes[i].set_title(f' vs {x_col}')\n",
    "    # axes[i].legend()\n",
    "\n",
    "# Remove any unused subplots if y_columns is not a multiple of 3\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Add layout adjustments\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (100)'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (100)']['betas_tup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First an overview of how to use the QAQC functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a random trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add route attributes and the betas used for each line\n",
    "reload(stochastic_optimization)\n",
    "pool = list(full_set.keys())\n",
    "tripid = random.choice(subset_trips)\n",
    "userid = user_map[tripid]\n",
    "print(tripid,userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (100)'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (30)']['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(len(item['past_vals']),item['results'].nfev,item['results'].success) for _, item in calibration_results.items()]\n",
    "# y = [ for _, item in calibration_results.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (100)']['past_vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results['21_jaccard_buffer_mean (30)']['past_vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "45/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ for model_name, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "# print(betas)\n",
    "# one_od = stochastic_optimization.match_results_to_ods(one_set)\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "#                         stochastic_optimization.link_impedance_function,\n",
    "#                         base_impedance_col,\n",
    "#                         stochastic_optimization.turn_impedance_function,\n",
    "#                         links,turns,turn_G)\n",
    "# modeled_results_sp = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in tqdm(one_od,total=len(one_od))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "subset_post_calibration = {key:item for key,item in post_calibration.items() if user_map[tripid] == int(key.split('_')[0])}\n",
    "print(trips.loc[tripid,['avg_speed_mph','trip_type','description']])\n",
    "print(users.loc[trips.at[tripid,'userid']])\n",
    "m = stochastic_optimization.visualize_three(tripid,full_set,subset_post_calibration,geo_dict,coords,config['projected_crs_epsg'],stadia_toner)\n",
    "m.save(Path.home()/'Downloads/test_viz.html')\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalibrate one trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # determine the ouput name of the calibration outputs\n",
    "# calibration_name = 'calibration2'\n",
    "\n",
    "# determine variables, impedance type, and search range\n",
    "betas_tup = (\n",
    "    {'col':'2lpd','type':'link','range':[0,3]},\n",
    "    {'col':'3+lpd','type':'link','range':[0,3]},\n",
    "    {'col':'(30,40] mph','type':'link','range':[0,3]},\n",
    "    {'col':'(40,inf) mph','type':'link','range':[0,3]},\n",
    "    {'col':'[4k,10k) aadt','type':'link','range':[0,3]},\n",
    "    {'col':'[10k,inf) aadt','type':'link','range':[0,3]},\n",
    "    {'col':'[4,6) grade','type':'link','range':[0,3]},\n",
    "    {'col':'[6,inf) grade','type':'link','range':[0,3]},\n",
    "    {'col':'bike lane','type':'link','range':[-1,0]},\n",
    "    {'col':'cycletrack','type':'link','range':[-1,0]},\n",
    "    {'col':'multi use path','type':'link','range':[-1,0]},\n",
    "    # {'col':'unsig_major_road_crossing','type':'turn','range':[0,2]}\n",
    ")\n",
    "\n",
    "# determine the objective function to use and other settings\n",
    "objective_function = stochastic_optimization.buffer_overlap\n",
    "batching = False\n",
    "stochastic_optimization_settings = {\n",
    "    'method':'pso',\n",
    "    'options': {'maxiter':100,'popsize':3}\n",
    "}\n",
    "\n",
    "# links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "\n",
    "one_set = {key:item for key, item in full_set.items() if key == tripid}\n",
    "\n",
    "args = (\n",
    "    [], # empty list for storing past calibration results\n",
    "    betas_tup, # tuple containing the impedance spec\n",
    "    stochastic_optimization.match_results_to_ods(one_set), # list of OD network node pairs needed for shortest path routing\n",
    "    one_set, # dict containing the origin/dest node and map matched edges\n",
    "    stochastic_optimization.link_impedance_function, # link impedance function to use\n",
    "    \"travel_time_min\", # column with the base the base impedance in travel time or distance\n",
    "    stochastic_optimization.turn_impedance_function, # turn impedance function to use\n",
    "    links,turns,turn_G, # network parts\n",
    "    objective_function, # loss function to use\n",
    "    {'length_dict':length_dict,'geo_dict':geo_dict},#,'trace_dict':traces}, # keyword arguments for loss function\n",
    "    True, #whether to print the results of each iteration\n",
    "    True, #whether to store calibration results\n",
    "    batching # whether to batch results to help speed up computation time, if yes input the number to batch with\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "print([x['col'] for x in betas_tup]+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration,\n",
    "             stochastic_optimization.extract_bounds(betas_tup),\n",
    "             args=args,\n",
    "             **stochastic_optimization_settings)\n",
    "end = time.time()\n",
    "print(f\"Took {str(pd.Timedelta(seconds=end-start).round('s'))} hours\")\n",
    "print(f\"{args[10].__name__}: {x.fun}\")\n",
    "print(x)\n",
    "\n",
    "calibration_result = {\n",
    "    'betas_tup': tuple({**item,'beta':x.x[idx].round(4)} for idx,item in enumerate(betas_tup)), # contains the betas\n",
    "    'settings': stochastic_optimization_settings, # contains the optimization settings\n",
    "    'objective_function': args[10].__name__, # objective function used\n",
    "    'results': x, # stochastic optimization outputs\n",
    "    'trips_calibrated': set(full_set.keys()), # saves which trips were calibrated\n",
    "    'past_vals': args[0], # all of the past values/guesses\n",
    "    'runtime': pd.Timedelta(end-start),\n",
    "    'time': datetime.datetime.now()\n",
    "}\n",
    "# #export but don't overwrite\n",
    "# export_fp = config['calibration_fp'] / f'calibration_results/{calibration_name}.pkl'\n",
    "# with stochastic_optimization.uniquify(export_fp).open('wb') as fh:\n",
    "#         pickle.dump(calibration_result,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_impedance_col = \"travel_time_min\"\n",
    "betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "print(betas)\n",
    "one_od = stochastic_optimization.match_results_to_ods(one_set)\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                        stochastic_optimization.link_impedance_function,\n",
    "                        base_impedance_col,\n",
    "                        stochastic_optimization.turn_impedance_function,\n",
    "                        links,turns,turn_G)\n",
    "modeled_results_sp = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in tqdm(one_od,total=len(one_od))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results_dict = {}\n",
    "for tripid, item in one_set.items():\n",
    "    chosen = item['matched_edges'].values\n",
    "    shortest = item['shortest_edges'].values\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled = modeled_results_sp[od]['edge_list']\n",
    "\n",
    "    modeled_results_dict[tripid] = {\n",
    "        'modeled_edges': pd.DataFrame(modeled,columns=['linkid','reverse_link']),\n",
    "        'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,1),\n",
    "        'modeled_detour': round(stochastic_optimization.detour_factor(modeled,shortest,length_dict),2),\n",
    "        'modeled_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,modeled,length_dict),2),\n",
    "        'modeled_buffer': round(stochastic_optimization.buffer_overlap(chosen,modeled,geo_dict),2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [('original',modeled_dict),('recalibrated',modeled_results_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.visualize_three(tripid,full_set,test,geo_dict,coords,config['projected_crs_epsg'],stadia_toner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_dict[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"calibration_results.pkl\").open('rb') as fh:\n",
    "#     calibration_results = pickle.load(fh)\n",
    "# calibration_result = caalibration_results[-1]\n",
    "# calibration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_trip = {tripid:modeled_results[tripid]}\n",
    "args = (\n",
    "    [], # empty list for storing past calibration results\n",
    "    calibration_result['betas_tup'], # tuple containing the impedance spec\n",
    "    stochastic_optimization.match_results_to_ods(one_trip), # list of OD network node pairs needed for shortest path routing\n",
    "    one_trip, # dict containing the origin/dest node and map matched edges\n",
    "    stochastic_optimization.link_impedance_function, # link impedance function to use\n",
    "    \"travel_time_min\", # column with the base the base impedance in travel time or distance\n",
    "    stochastic_optimization.turn_impedance_function, # turn impedance function to use\n",
    "    links,turns,turn_G, # network parts\n",
    "    stochastic_optimization.jaccard_index_func, # loss function to use\n",
    "    {'length_dict':length_dict,'geo_dict':geo_dict}, # keyword arguments for loss function\n",
    "    True, #whether to print the results of each iteration\n",
    "    False #whether to store calibration results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print([x['col'] for x in calibration_result['betas_tup']]+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration,\n",
    "             stochastic_optimization.extract_bounds(calibration_result['betas_tup']),\n",
    "             args=args,\n",
    "             method='pso',\n",
    "             options={'maxiter':20,\"popsize\":10})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reroute one trip after recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betas = [-0.184,-0.398,0.126,0.325,0.324]\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "betas = x.x\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "one_trip_od = stochastic_optimization.match_results_to_ods(one_trip)[0]\n",
    "new_result = stochastic_optimization.impedance_path(turns,turn_G,links,*one_trip_od) #for start_node, end_node in one_trip_od}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[tripid]['Recalibrated'] = pd.DataFrame(new_result['edge_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize new modeled one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[tripid].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "line_dict = stochastic_optimization.construct_line_dict(['matched_edges','shortest_edges','modeled_edges','Recalibrated'],modeled_results[tripid],geo_dict)\n",
    "line_dict = stochastic_optimization.add_metrics_to_tooltip(line_dict,length_dict,geo_dict)\n",
    "stochastic_optimization.visualize_three(tripid,line_dict,modeled_results[tripid]['coords'],links.crs,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the chosen, shortest, and modeled route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "tripid = 243\n",
    "print(trips.loc[tripid,['trip_type','description']])\n",
    "mymap = stochastic_optimization.basic_three_viz(tripid,modeled_results,links,tile_info_dict)\n",
    "mymap.save(Path.home()/'Downloads/troubleshooting.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to re-route or re-calibrate trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have more than one modeled route or other routes, then use this sequence of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dict = stochastic_optimization.construct_line_dict(['matched_edges','shortest_edges','modeled_edges'],modeled_results[tripid],geo_dict)\n",
    "line_dict = stochastic_optimization.add_metrics_to_tooltip(line_dict,links)\n",
    "stochastic_optimization.visualize_three(tripid,line_dict,links,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_qgis(tripid,results_dict,geo_dict,config):\n",
    "    '''\n",
    "    Creates GeoJSON for viewing calibration results in QGIS. Set\n",
    "    colors to color column.\n",
    "    '''\n",
    "    \n",
    "    fields = ['matched_edges','shortest_edges','modeled_edges']\n",
    "    geos = [LineString(stochastic_optimization.get_route_line(results_dict[tripid][field].values,geo_dict)) for field in fields]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        data={\n",
    "            'type': ['chosen','shortest','modeled'],\n",
    "            'color': ['#fc8d62','#66c2a5','#8da0cb'],\n",
    "            'geometry': geos\n",
    "        },\n",
    "        crs=config['projected_crs_epsg']\n",
    "    )\n",
    "    gdf.to_file(config['calibration_fp']/'calibration_qaqc.gpkg',layer='calibration_results')\n",
    "    return gdf\n",
    "\n",
    "gdf = export_to_qgis(tripid,modeled_results,geo_dict,config)\n",
    "gdf.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "bbox = box(*gdf.total_bounds)\n",
    "bbox = bbox.buffer(5280*2)\n",
    "extract = links[links.geometry.intersects(bbox)].copy()\n",
    "extract['forward_cost'] = extract['link_cost']\n",
    "extract['backward_cost'] = extract['link_cost']\n",
    "extract = extract[extract['reverse_link']==False]\n",
    "extract = extract[['A','B','linkid','osmid','forward_cost','backward_cost','geometry']]\n",
    "extract.to_crs('epsg:4326',inplace=True)\n",
    "extract.to_file(Path.home()/'Downloads/test.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idenfity trips that pass through a circle\n",
    "One area with trouble is the Stone Mountain Trail because the map matched route often uses Dekalb instead. This leads to some trips having a lower than expected overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freedom_pkwy = (2237899.09,1372338.05)\n",
    "freedom_pkwy = stochastic_optimization.retrieve_geos(*freedom_pkwy,modeled_results,links)\n",
    "print(len(freedom_pkwy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = (2250499.40,1369121.80)\n",
    "smt = stochastic_optimization.retrieve_geos(*smt,modeled_results,links)\n",
    "print(len(smt))\n",
    "tenth_st = (2233722.10,1375729.08)\n",
    "tenth_st = stochastic_optimization.retrieve_geos(*tenth_st,modeled_results,links)\n",
    "print(len(tenth_st))\n",
    "wylie_st = (2237751.33,1365098.89)\n",
    "wylie_st = stochastic_optimization.retrieve_geos(*wylie_st,modeled_results,links)\n",
    "print(len(wylie_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = random.choice(freedom_pkwy)\n",
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.basic_three_viz(tripid,modeled_results,links.crs,length_dict,geo_dict,tile_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can calibrating by itself improve it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense it\n",
    "\n",
    "betas_links = {\n",
    "    0 : 'multi use path',\n",
    "    1 : 'bike lane',\n",
    "    2 : 'lanes',\n",
    "    3 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    4 : 'unsig_major_road_crossing'\n",
    "}\n",
    "\n",
    "with (config['calibration_fp']/'full_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "# train_set = train_set\n",
    "train_set = {tripid:train_set.get(tripid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "#loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    #loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled2 = full_results_dict[(8180621166, 68253267)]['edge_list']\n",
    "modeled2 = stochastic_optimization.get_route_line(modeled2,links)\n",
    "#modeled2 = LineString(modeled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "# mymap = stochastic_optimization.visualize_three(tripid,LineString(chosen),LineString(modeled2),LineString(modeled),links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# #mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "# print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "# mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see improvement! But how does it track with othere success measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_frechet = modeled_dist\n",
    "new_frechet = similaritymeasures.frechet_dist(chosen,modeled2)\n",
    "print(old_frechet,new_frechet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge reduction! Now what if we used frechet distance in the calibration for the objective function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True,drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.frechet_distance\n",
    "loss_function_kwargs = {'length_dict':length_dict,'links':links}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did using a different overlap function fix the issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "single_trip = stochastic_optimization.post_calibration_routing(links,turns,turn_G,\"travel_time_min\",\n",
    "                                                 betas,betas_links,betas_turns,train_ods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled3 = full_results_dict[(8180621166, 68253267)]['edge_list']\n",
    "modeled3 = stochastic_optimization.get_route_line(modeled3,links)\n",
    "#modeled2 = LineString(modeled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need something about the tootlip just so we can see what the different measurements are\n",
    "- jaccard (linkids + reverse)\n",
    "- frechet (coords)\n",
    "- maybe more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.basic_three_viz(243,modeled_results,links,tile_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[122]['matched_edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dict = {\n",
    "    'Chosen': {'coords':chosen},\n",
    "    'Shortest': {'coords':shortest,'tooltip':0.5},\n",
    "    'Modeled (all trips)': {'coords':modeled,'tooltip':0.5},\n",
    "    'Modeled (trip only)': {'coords':modeled2,'tooltip':0.5},\n",
    "    'Modeled (new objective function)': {'coords':modeled3,'tooltip':0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results[122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "mymap = stochastic_optimization.visualize_three(tripid,line_dict,links,tile_info_dict)\n",
    "#mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think no but lets package these functions to make it easier to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect overlap values for trip to trip impedance\n",
    "(coefficients are incorrect right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"trip_specific.pkl\").open('rb') as fh:\n",
    "    trip_by_trip = pickle.load(fh)\n",
    "\n",
    "new_col = {tripid:item['loss'].min() * -1 for tripid, item in trip_by_trip.items()}\n",
    "new_col = pd.Series(new_col).reset_index()\n",
    "new_col.columns = ['tripid','new_impedance']\n",
    "test = pd.merge(full,new_col,on='tripid')\n",
    "print(test['new_impedance'].mean())\n",
    "(test['new_impedance'] - test['impedance']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the overlap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['new_impedance']<test['impedance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = 837\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "#mymap.save(Path.home()/'Downloads/troubleshooting.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links2 = links.reset_index().copy()\n",
    "# links2 = gpd.read_file(config['calibration_fp']/\"calibration_network.gpkg\",layer='links')\n",
    "# links2.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = full['impedance'] - full['shortest']\n",
    "differences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = full.loc[full['shortest']<full['impedance'],'tripid'].tolist()\n",
    "worse = full.loc[full['shortest']>full['impedance'],'tripid'].tolist()\n",
    "print(len(better))\n",
    "print(len(worse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Social Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "social = trips[trips['trip_type']=='Social']\n",
    "tripid = random.choice(social.index.tolist())\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[trips['description'].str.contains('ride') & trips['description'].notna(),'description'].head(50)#.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "social = trips[trips['description'].str.contains('ride') & trips['description'].notna()].index.tolist()\n",
    "tripid = random.choice(social)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the three lines into one gpkg file with pre-defined colors, so that we can update it on the fly in QGIS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Extract colors from a ColorBrewer scheme (e.g., 'Set2')\n",
    "# # Convert them to HEX format if needed\n",
    "colorbrewer_hex = [colors.to_hex(c) for c in plt.get_cmap('Set2').colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condense the network so that it is convenient to examine in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nonrev_cols = ['name','osmid','highway','year','geometry']\n",
    "rev_cols = ['multi use path','bike lane','lanes','above_4']\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "nonrev_links = links.loc[idx[:,False],idx[nonrev_cols+rev_cols]]\n",
    "nonrev_links.reset_index(inplace=True)\n",
    "nonrev_links.set_index('linkid',inplace=True)\n",
    "nonrev_links.drop(columns=['reverse_link'],inplace=True)\n",
    "\n",
    "rev_links = links.loc[idx[:,True],idx[rev_cols]]\n",
    "rev_links.reset_index(inplace=True)\n",
    "rev_links.set_index('linkid',inplace=True)\n",
    "rev_links.drop(columns=['reverse_link'],inplace=True)\n",
    "rev_links.columns = 'rev_' + rev_links.columns\n",
    "\n",
    "#combine\n",
    "condensed_network = pd.concat([nonrev_links,rev_links],ignore_index=False,axis=1)\n",
    "condensed_network = gpd.GeoDataFrame(condensed_network,crs=config['projected_crs_epsg'])\n",
    "\n",
    "import ast\n",
    "og_links = gpd.read_file(config['osmdwnld_fp']/'osm_2023.gpkg',layer='raw',ignore_geometry=True)\n",
    "og_links = dict(zip(og_links['osmid'],og_links['all_tags']))\n",
    "for key, item in og_links.items():\n",
    "    item = ast.literal_eval(item)\n",
    "    item.pop('@way_nodes')\n",
    "    item = str(item)\n",
    "    og_links[key] = item\n",
    "condensed_network['all_tags'] = condensed_network['osmid'].map(og_links)\n",
    "condensed_network.to_file(config['calibration_fp']/'calibration_qaqc.gpkg',layer='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can try viewing it in leaflet instead? might be slow because of all the links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense it\n",
    "\n",
    "betas_links = {\n",
    "    0 : 'multi use path',\n",
    "    1 : 'bike lane',\n",
    "    2 : 'lanes',\n",
    "    3 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    4 : 'unsig_major_road_crossing'\n",
    "}\n",
    "\n",
    "with (config['calibration_fp']/'full_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "# train_set = train_set\n",
    "train_set = {tripid:train_set.get(tripid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.reset_index(inplace=True)\n",
    "\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[-1,0],[-1,0],[0,4],[0,4]]\n",
    "#[[-1, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds\n",
    "\n",
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    stochastic_optimization.link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    stochastic_optimization.turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':50,\"popsize\":5})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(train_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "for tripid, item in full_set.items():\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled_edges = full_results_dict.get(od,0).get('edge_list',0)\n",
    "    if isinstance(modeled_edges,int):\n",
    "        print(modeled_edges)\n",
    "    #turn to dataframe\n",
    "    modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "    full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_links = links[links.intersects(box(*pd.concat([chosen_line,shortest_line,modeled_line]).total_bounds))].copy()\n",
    "# links.loc[idx[:,False],idx[rev_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_poor = full.loc[full['impedance']<0.1,'tripid'].tolist()\n",
    "tripid = random.choice(shortest_path_poor)\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "# mymap.save(Path.home()/'Downloads/shortest_poor.html')\n",
    "print(trips.loc[tripid,['start_time','trip_type','description']])\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where shortest path does poorly\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "shortest_path_poor = full.loc[full['shortest']<0.3,'tripid'].tolist()\n",
    "tripid = random.choice(shortest_path_poor)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/shortest_poor.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = random.choice(better)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/optim_results.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "tripid = random.choice(worse)\n",
    "shortest_overlap = full.loc[full['tripid']==tripid,'shortest'].item()\n",
    "impedance_overlap = full.loc[full['tripid']==tripid,'impedance'].item()\n",
    "mymap = stochastic_optimization.visualize_three_no_legend(tripid,modeled_results,links,tile_info_dict,shortest_overlap,impedance_overlap)\n",
    "mymap.save(Path.home()/'Downloads/optim_results2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[full['tripid']==tripid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_overlaps = [30845]\n",
    "needs_work = [13190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "# html = \"\"\n",
    "# nodes = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='nodes')\n",
    "# nodes.to_crs('epsg:4236',inplace=True)\n",
    "# nodes['lon'] = nodes.geometry.x\n",
    "# nodes['lat'] = nodes.geometry.y\n",
    "# latlon = tuple(zip(nodes['lon'],nodes['lat']))\n",
    "# nodes = dict(zip(nodes['N'],latlon))\n",
    "# nodes.get(68196100,0)\n",
    "# htmls = []\n",
    "# for od in both_ods:\n",
    "#     start = od[0]\n",
    "#     end = od[1]\n",
    "#     start_lonlat = nodes.get(start,0)\n",
    "#     end_lonlat = nodes.get(end,0)\n",
    "#     html = f\"https://brouter.damsy.net/latest/#map=12/33.7522/-84.3892/standard&lonlats={start_lonlat[1]},{start_lonlat[0]};{end_lonlat[1]},{end_lonlat[0]}&profile=safety\"\n",
    "#     htmls.append(html)\n",
    "# with (config['calibration_fp']/\"brouter_links.txt\").open('w') as fh:\n",
    "#     for html in htmls:\n",
    "#         fh.write(f\"{html}\\n\")\n",
    "# with (config['calibration_fp']/\"brouter_ods.txt\").open('w') as fh:\n",
    "#     for od in both_ods:\n",
    "#         fh.write(f\"{od}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
