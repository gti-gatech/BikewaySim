{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Route Attributes from List of Edges IDs and the Direction Travelled\n",
    "We have a list of edges or turns (depending on the settings) from Dijkstra, and we need to get the route attributes (how many turns, how much feet up, miles of bike facility, etc) to report the route characterstics of a trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from shapely.ops import MultiLineString\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import summarize_route\n",
    "import stochastic_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TEMP for GDOT report statistics\n",
    "# with (Path('D:\\PROJECTS\\GDOT\\GDOT\\Map_Matching\\matched_0.pkl')).open('rb') as fh:\n",
    "#     match_dict = pickle.load(fh)\n",
    "\n",
    "# cutoff = 0.90 # set pct of points that need to be matched\n",
    "\n",
    "# total = len(match_dict)\n",
    "# match_ratios = {tripid:item['match_ratio'] for tripid, item in match_dict.items() if isinstance(item,str)==False}\n",
    "# failed_matches = total - len(match_ratios)\n",
    "# match_ratios = pd.Series(match_ratios)\n",
    "# above_threshold = match_ratios[match_ratios > 0.90].index.tolist()\n",
    "# match_dict = {key:item for key, item in match_dict.items() if key in above_threshold}\n",
    "# below_threshold = total - failed_matches - len(above_threshold)\n",
    "\n",
    "# print(len(match_dict),'/',total,'successful matches')\n",
    "# print(failed_matches,'failed to match')\n",
    "# print(below_threshold,'partial match')\n",
    "\n",
    "# trips = pd.read_pickle(config['cycleatl_fp']/'trips_4.pkl')\n",
    "# trips = trips.loc[trips['tripid'].isin(list(match_dict.keys()))]#,'userid'].nunique()\n",
    "# users = pd.read_pickle(config['cycleatl_fp']/'users_4.pkl')\n",
    "# users = users[users['userid'].isin(set(trips['userid'].tolist()))]\n",
    "\n",
    "# #recalculate the number trips\n",
    "# users['matched_trips'] = users['userid'].map(trips.groupby('userid').size())\n",
    "\n",
    "# print(users.shape[0],'users')\n",
    "\n",
    "# # ready_for_calibration = {tripid:{'matched_edges':item['edges']} for tripid, item in match_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    ready_for_calibration = pickle.load(fh)\n",
    "print(len(ready_for_calibration),'trips')\n",
    "\n",
    "#new pickles\n",
    "with (config['cycleatl_fp']/'trips_4.pkl').open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "trips = trips[trips['tripid'].isin(ready_for_calibration.keys())]\n",
    "\n",
    "with (config['cycleatl_fp']/'users_4.pkl').open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "print(users.shape[0],'users')\n",
    "users = users[users['userid'].isin(trips['userid'])]\n",
    "print(users.shape[0],'users')\n",
    "\n",
    "#recalculate the number trips\n",
    "users['matched_trips'] = users['userid'].map(trips.groupby('userid').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barplot on trips per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((users['matched_trips'] > 10).sum(),'users had above 10 trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of users for each number of trips matched\n",
    "trip_counts = users['matched_trips'].value_counts().sort_index()\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(trip_counts.index, trip_counts.values, color='grey')\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel(f'Number of Trips (N={trips.shape[0]})')\n",
    "ax.set_ylabel(f'Number of Users (N={users.shape[0]})')\n",
    "\n",
    "# Set x-axis ticks every 5 bins\n",
    "#ax.set_xticks(range(trip_counts.index.min(), trip_counts.index.max() + 1, 5))\n",
    "ax.set_xticks(range(0, trip_counts.index.max() + 5, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Characterstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this one value\n",
    "users.loc[users['ethnicity'].astype(str) == \"['Hispanic / Mexican / Latino', 'Multi-racial']\",'ethnicity'] = 'Hispanic / Mexican / Latino'\n",
    "\n",
    "summary_cols = ['gender','age','income','ethnicity','cycling_freq','rider_history','rider_type']\n",
    "\n",
    "for col in summary_cols:\n",
    "    print(f\"------- {col} -------\")\n",
    "    counts = users[col].value_counts()\n",
    "    counts.name = 'counts'\n",
    "    pct = (counts / users.shape[0] * 100).round(0)\n",
    "    pct.name = 'percent'\n",
    "    print(pd.concat([counts,pct],axis=1,ignore_index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in summary_cols:\n",
    "    print(f\"------- {col} -------\")\n",
    "    counts = users.groupby(col)['matched_trips'].sum()\n",
    "    counts.name = 'counts'\n",
    "    # print(counts)\n",
    "    pct = (counts / users['matched_trips'].sum() * 100).round(0)\n",
    "    pct.name = 'percent'\n",
    "    print(pd.concat([counts,pct],axis=1,ignore_index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Characterstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['trip_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns_df, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "\n",
    "#set index for quick retrieval\n",
    "links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "turns_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Map Matched and Shortest Path Data (and impedance calibrated in the future)\n",
    "This is where we want to look at the makeup of the chosen routes to know what to include in the impedance function. Because route atttributes have to be aggregated from the links, continuous variables have to be averaged or split into ordinal variables in order to represented.\n",
    "\n",
    "In most cases, it seems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['name'].apply(lambda x: 'BeltLine' in x if x is not None else False),'name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links.loc[links['name'].isin(['Atlanta BeltLine Eastside Trail',\n",
    "#        'BeltLine Eastside Trail'])].explore()\n",
    "links['on_eastside_beltline'] = links['name'].isin(['Atlanta BeltLine Eastside Trail','BeltLine Eastside Trail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional columns to summarize\n",
    "links['length_mi'] = links['length_ft'] / 5280\n",
    "links['state_route'] = links['route_type'] == 'State Route'\n",
    "links['1lpd'] = (links['2lpd']==False)&(links['3+lpd']==False)\n",
    "links['[0,30] mph'] = (links['(30,40] mph']==False)&(links['(40,inf) mph']==False)\n",
    "links['[0,4k) aadt'] = (links['[10k,inf) aadt']==False)&(links['[4k,10k) aadt']==False)\n",
    "links['[0,4) grade'] = (links['[4,6) grade']==False)&(links['[6,inf) grade']==False)\n",
    "\n",
    "link_cols_to_summarize = {\n",
    "    'oneway':'bool',\n",
    "    'link_type':'category',\n",
    "    # 'highway':'category',\n",
    "    'state_route':'bool',\n",
    "    'ascent_ft':'sum',\n",
    "    # 'facility_fwd':'category', \n",
    "    'travel_time_min':'sum',\n",
    "    '1lpd':'bool',\n",
    "    '2lpd':'bool',\n",
    "    '3+lpd':'bool',\n",
    "    '[0,30] mph':'bool',\n",
    "    '(30,40] mph':'bool', \n",
    "    '(40,inf) mph':'bool',\n",
    "    '[0,4k) aadt':'bool',\n",
    "    '[4k,10k) aadt':'bool',\n",
    "    '[10k,inf) aadt':'bool', \n",
    "    '[0,4) grade':'bool',\n",
    "    '[4,6) grade':'bool', \n",
    "    '[6,inf) grade':'bool', \n",
    "    'bike lane':'bool',\n",
    "    'cycletrack':'bool', \n",
    "    'multi use path':'bool',\n",
    "    'on_eastside_beltline':'bool',\n",
    "    'length_mi':'sum'\n",
    "}\n",
    "restr_stats_to_roads = ['state_route','oneway','1lpd','2lpd','3+lpd','[0,30] mph','(30,40] mph','(40,inf) mph','[0,4k) aadt','[4k,10k) aadt','[10k,inf) aadt']\n",
    "turn_cols_to_summarize = {\n",
    "    'turn_type':'category',\n",
    "    'unsig_major_road_crossing':'bool'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(summarize_route)\n",
    "matched_summary = [summarize_route.route_attributes(key,item['matched_edges'],link_cols_to_summarize,turn_cols_to_summarize,links,turns_df,restr_stats_to_roads) for key, item in ready_for_calibration.items()]\n",
    "matched_summary = summarize_route.procees_summary_results(matched_summary,config['projected_crs_epsg'])\n",
    "reorder = ['length_mi', 'travel_time_min', 'ascent_ft', 'oneway_pct','state_route_pct',\n",
    "        'link_type_bike_pct','link_type_pedestrian_pct', 'link_type_road_pct','link_type_service_pct',\n",
    "        '[0,30] mph_pct','(30,40] mph_pct','(40,inf) mph_pct',\n",
    "        '1lpd_pct','2lpd_pct', '3+lpd_pct',\n",
    "        '[0,4k) aadt_pct','[4k,10k) aadt_pct','[10k,inf) aadt_pct',\n",
    "        '[0,4) grade_pct','[4,6) grade_pct',  '[6,inf) grade_pct',\n",
    "        'bike lane_pct', 'cycletrack_pct',  'multi use path_pct', 'on_eastside_beltline_pct'\n",
    "    ]\n",
    "df0 = matched_summary.drop(columns=['tripid','geometry']).describe().round(1).transpose().drop(columns='count').loc[reorder]\n",
    "df0.iloc[1:,:] = df0.iloc[1:,:].round(0)\n",
    "print(df0)\n",
    "df0.to_csv(Path.home()/'Downloads/route_attr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(summarize_route)\n",
    "shortest_summary = [summarize_route.route_attributes(key,item['shortest_edges'],link_cols_to_summarize,turn_cols_to_summarize,links,turns_df,restr_stats_to_roads) for key, item in ready_for_calibration.items()]\n",
    "shortest_summary = summarize_route.procees_summary_results(shortest_summary,config['projected_crs_epsg'])\n",
    "reorder = ['length_mi', 'travel_time_min', 'ascent_ft', 'oneway_pct','state_route_pct',\n",
    "        'link_type_bike_pct','link_type_pedestrian_pct', 'link_type_road_pct','link_type_service_pct',\n",
    "        '[0,30] mph_pct','(30,40] mph_pct','(40,inf) mph_pct',\n",
    "        '1lpd_pct','2lpd_pct', '3+lpd_pct',\n",
    "        '[0,4k) aadt_pct','[4k,10k) aadt_pct','[10k,inf) aadt_pct',\n",
    "        '[0,4) grade_pct','[4,6) grade_pct',  '[6,inf) grade_pct',\n",
    "        'bike lane_pct', 'cycletrack_pct',  'multi use path_pct', 'on_eastside_beltline_pct'\n",
    "    ]\n",
    "df1 = shortest_summary.drop(columns=['tripid','geometry']).describe().round(1).transpose().drop(columns='count').loc[reorder]\n",
    "df1.iloc[1:,:] = df1.iloc[1:,:].round(0)\n",
    "print(df1)\n",
    "df1.to_csv(Path.home()/'Downloads/route_attr_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = matched_summary.drop(columns=['geometry']).set_index('tripid')\n",
    "y = shortest_summary.drop(columns=['geometry']).set_index('tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (x - y).describe().round(1).transpose().drop(columns='count').loc[reorder]\n",
    "diff.iloc[1:,:] = diff.iloc[1:,:].round(0)\n",
    "diff.to_csv(Path.home()/'Downloads/diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = df0 - df1\n",
    "print(difference)\n",
    "difference.to_csv(Path.home()/'Downloads/difference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt. subplots()\n",
    "ax.hist(matched_summary['length_mi'],color='grey')\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel(f'Length in Miles')\n",
    "ax.set_ylabel(f'Number of Trips (N={trips.shape[0]})')\n",
    "\n",
    "# Set x-axis ticks every 5 bins\n",
    "#ax.set_xticks(range(trip_counts.index.min(), trip_counts.index.max() + 1, 5))\n",
    "#ax.set_xticks(range(0, int(matched_summary['length_mi'].max()) + 5, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest_summary = [summarize_route.route_attributes(key,item,'shortest_edges',cols_to_summarize,links,turns_df) for key, item in ready_for_calibration.items()]\n",
    "# shortest_summary = summarize_route.procees_summary_results(shortest_summary,config['projected_crs_epsg'])\n",
    "# shortest_summary.drop(columns=['tripid','geometry']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"matched\")\n",
    "shortest_summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"shortest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Chosen Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making graphs\n",
    "renaming_dict = {\n",
    "    '(0,2]_prop': \"0-2% grade\", \n",
    "    '(2,4]_prop': \"2-4% grade\", \n",
    "    '(4,6]_prop': \"4-6% grade\", \n",
    "    '(6,inf)_prop': \"> 6% grade\", \n",
    "    '(4,inf)_prop': \"> 4% grade\",\n",
    "    'ascent_ft': \"Ascent (ft)\",\n",
    "    'descent_ft': \"Descent (ft)\", \n",
    "    'beltline_prop': \"On BeltLine\", \n",
    "    'facility_fwd_bike lane_prop': \"Bike Lane\",\n",
    "    'facility_fwd_buffered bike lane_prop': \"Buffered Bike Lane\", \n",
    "    'facility_fwd_cycletrack_prop': \"Cycletrack\",\n",
    "    'facility_fwd_multi use path_prop': \"Multi-Use Path\", \n",
    "    'facility_fwd_sharrow_prop': \"Sharrow or Bike Route\", \n",
    "    'left': \"Left Turn (per mi)\",\n",
    "    'length_mi': \"Length (mi)\", \n",
    "    'right': \"Right Turn (per mi)\", \n",
    "    'straight': \"Straight\", \n",
    "    'uturn': \" U-Turn (per mi)\", \n",
    "    'vehicle_traffic_prop': \"Vehicle Traffic Allowed\",\n",
    "    'lts_0_prop': \"LTS Not Rated\",\n",
    "    'lts_1_prop': \"LTS 1\",\n",
    "    'lts_2_prop': \"LTS 2\",\n",
    "    'lts_3_prop': \"LTS 3\",\n",
    "    'lts_4_prop': \"LTS 4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axes_limits = {\n",
    "    # '(0,2]_prop': \"0-2% grade\", \n",
    "    # '(2,4]_prop': \"2-4% grade\", \n",
    "    # '(4,6]_prop': \"4-6% grade\", \n",
    "    # '(6,inf)_prop': \"> 6% grade\", \n",
    "    '(4,inf)_prop': (-0.2,0.2),\n",
    "    'ascent_ft': (-1000,1000),\n",
    "    #'descent_ft': \"Descent (ft)\", \n",
    "    'beltline_prop': (-0.6,0.6), \n",
    "    'facility_fwd_bike lane_prop': (-0.4,0.4),\n",
    "    'facility_fwd_buffered bike lane_prop': (-0.1,0.1), \n",
    "    'facility_fwd_cycletrack_prop': (-0.5,0.5),\n",
    "    'facility_fwd_multi use path_prop': (-0.6,0.6), \n",
    "    'facility_fwd_sharrow_prop': (-0.3,0.3), \n",
    "    #'left': \"Left Turn\",\n",
    "    'length_mi': (0,6), \n",
    "    #'right': \"Right Turn\", \n",
    "    #'straight': \"Straight\", \n",
    "    #'uturn': \" U-Turn\", \n",
    "    'vehicle_traffic_true_prop': (-0.75,0.75),\n",
    "    #'lts': \"LTS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select which differences to plot and what order to plot\n",
    "# cols_to_plot = ['length_mi', 'ascent_ft',\n",
    "#        '(4,inf)_prop', 'vehicle_traffic_prop', 'beltline_prop', \n",
    "#        'facility_fwd_sharrow_prop','facility_fwd_bike lane_prop',\n",
    "#        'facility_fwd_buffered bike lane_prop',\n",
    "#        'facility_fwd_cycletrack_prop', 'facility_fwd_multi use path_prop',\n",
    "#        'lts_1_prop','lts_2_prop','lts_3_prop','lts_4_prop',\n",
    "#        'uturn', 'straight', 'right', 'left','signalized'\n",
    "# ]\n",
    "\n",
    "cols_to_plot = ['facility_fwd_bike lane_prop','lanes','speed','above_4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the variables to plot\n",
    "variables = cols_to_plot\n",
    "\n",
    "# Number of variables\n",
    "num_vars = len(variables)\n",
    "\n",
    "# Determine grid size (e.g., 2x2)\n",
    "ncols = 3\n",
    "nrows = (num_vars // ncols) + (num_vars % ncols > 0)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 18), constrained_layout=True)\n",
    "\n",
    "# Set the background color of the figure\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each KDE plot on a separate subplot\n",
    "for ax, variable in zip(axes, variables):\n",
    "    sns.kdeplot(data=matched_summary, x=variable, fill=True, ax=ax, cut=0, bw_adjust=0.5)\n",
    "    #ax.set_title(renaming_dict.get(variable,variable))\n",
    "    ax.set_xlabel(renaming_dict.get(variable,variable))\n",
    "\n",
    "    # # Get the min and max values of the variable\n",
    "    # min_val = matched_summary[variable].min()\n",
    "    # max_val = matched_summary[variable].max()\n",
    "    \n",
    "    # # Calculate symmetric limits around zero\n",
    "    # max_abs_val = max(abs(min_val), abs(max_val))\n",
    "    # x_lim = (-max_abs_val, max_abs_val)\n",
    "\n",
    "    # # #set varaible specific limits\n",
    "    # # if x_axes_limits.get(variable,False) != False:\n",
    "    # #     x_lim = x_axes_limits.get(variable,x_lim)\n",
    "    \n",
    "    # ax.set_xlim(x_lim)\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha = 0.5)  # Optional: add a vertical line at zero for reference\n",
    "\n",
    "    # Set the background color of the axes\n",
    "    #ax.set_facecolor('grey')\n",
    "    #ax.grid(True, color='white')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for ax in axes[len(variables):]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Path Attribute Differences (Chosen - Shortest)\n",
    "Re-create the plots that were in Dillon's paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = matched_summary.iloc[:,2:] - shortest_summary.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the variables to plot\n",
    "variables = cols_to_plot\n",
    "\n",
    "# Number of variables\n",
    "num_vars = len(variables)\n",
    "\n",
    "# Determine grid size (e.g., 2x2)\n",
    "ncols = 3\n",
    "nrows = (num_vars // ncols) + (num_vars % ncols > 0)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 18), constrained_layout=True)\n",
    "\n",
    "# Set the background color of the figure\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each KDE plot on a separate subplot\n",
    "for ax, variable in zip(axes, variables):\n",
    "    sns.kdeplot(data=differences, x=variable, fill=True, ax=ax, cut=0, bw_adjust=0.5)\n",
    "    #ax.set_title(renaming_dict.get(variable,variable))\n",
    "    ax.set_xlabel(renaming_dict.get(variable,variable))\n",
    "\n",
    "    # Get the min and max values of the variable\n",
    "    min_val = differences[variable].min()\n",
    "    max_val = differences[variable].max()\n",
    "    \n",
    "    # Calculate symmetric limits around zero\n",
    "    max_abs_val = max(abs(min_val), abs(max_val))\n",
    "    x_lim = (-max_abs_val, max_abs_val)\n",
    "\n",
    "    #set varaible specific limits\n",
    "    if x_axes_limits.get(variable,False) != False:\n",
    "        x_lim = x_axes_limits.get(variable,x_lim)\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha = 0.5)  # Optional: add a vertical line at zero for reference\n",
    "\n",
    "    # Set the background color of the axes\n",
    "    #ax.set_facecolor('grey')\n",
    "    #ax.grid(True, color='white')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for ax in axes[len(variables):]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences.rename(columns=renaming_dict).describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (cycleatl_fp/'trips_3.pkl').open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "with (cycleatl_fp/'users_0.pkl').open('rb') as fh:\n",
    "    users = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretend they're not the same person for now and then later fix the cycleatl data processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences['tripid'] = matched_summary['tripid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_w_info = differences.merge(pd.merge(trips,users,on='userid'),on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_w_info['rider_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue = \"rider_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the variables to plot\n",
    "variables = cols_to_plot\n",
    "\n",
    "# Number of variables\n",
    "num_vars = len(variables)\n",
    "\n",
    "# Determine grid size (e.g., 2x2)\n",
    "ncols = 3\n",
    "nrows = (num_vars // ncols) + (num_vars % ncols > 0)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 20), constrained_layout=True)\n",
    "\n",
    "# Set the background color of the figure\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each KDE plot on a separate subplot\n",
    "i = 0\n",
    "for ax, variable in zip(axes, variables):\n",
    "    if i == 0:\n",
    "        sns.kdeplot(data=differences_w_info, x=variable, fill=False, ax=ax, cut=0, bw_adjust=0.5, hue=hue)\n",
    "        i += 1\n",
    "    else:\n",
    "        sns.kdeplot(data=differences_w_info, x=variable, fill=False, ax=ax, cut=0, bw_adjust=0.5, hue=hue, legend = False)\n",
    "    #ax.set_title(renaming_dict.get(variable,variable))\n",
    "    ax.set_xlabel(renaming_dict.get(variable,variable))\n",
    "\n",
    "    # Get the min and max values of the variable\n",
    "    min_val = differences_w_info[variable].min()\n",
    "    max_val = differences_w_info[variable].max()\n",
    "    \n",
    "    # Calculate symmetric limits around zero\n",
    "    max_abs_val = max(abs(min_val), abs(max_val))\n",
    "    x_lim = (-max_abs_val, max_abs_val)\n",
    "\n",
    "    #set varaible specific limits\n",
    "    if x_axes_limits.get(variable,False) != False:\n",
    "        x_lim = x_axes_limits.get(variable,x_lim)\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha = 0.5)  # Optional: add a vertical line at zero for reference\n",
    "\n",
    "# Remove any empty subplots\n",
    "for ax in axes[len(variables):]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_entries = users['userid'].apply(lambda x: isinstance(x,list))\n",
    "\n",
    "#users['rider_type'].apply()\n",
    "# def list_to_single(row):\n",
    "#     if isinstance(row['userid'],list) == False:\n",
    "#         return row\n",
    "    \n",
    "#     #remove nulls\n",
    "#     if isinstance(row['rider_type'],list):\n",
    "\n",
    "\n",
    "#     row[\"rider_type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a bad elevation link\n",
    "edges_w_attr.loc[edges_w_attr['ascent_ft'].sort_values(ascending=False).head(10).index,['name','ascent_ft','descent_ft','geometry']].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_summary.loc[[matched_summary['ascent_ft'].idxmax()]].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences.sort_values('ascent_ft',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=matched_summary[link_type_new],cut=0,bw_adjust=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated past here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = summary_df.copy()\n",
    "\n",
    "# Assuming your dataframe is named df\n",
    "# Drop any rows with missing values (if any)\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['tripid', 'geometry', 'length_ft'])\n",
    "y = df['length_ft']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(regressor, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(regressor.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "testtrip = random.choice(list(matched_traces_dict.keys()))\n",
    "testtrip = matched_traces_dict[testtrip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = {}\n",
    "\n",
    "#get edges\n",
    "route = testtrip['edges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get route and turns\n",
    "route = [tuple(x) for x in testtrip['edges'].values]\n",
    "turns = [(route[i][0],route[i][1],route[i+1][0],route[i+1][1]) for i in range(0,len(route)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Two different types of summarization:\n",
    "\n",
    "Instance based (turns, signals, bridges, etc)\n",
    "\n",
    "Length based on certain tag (bike facilities)\n",
    "\n",
    "Cumulative (length,elevation)\n",
    "\n",
    "'''\n",
    "\n",
    "summary_attributes = {}\n",
    "\n",
    "#get trip date for the bike facility check\n",
    "trip_date_year = testtrip['trace'].iloc[0,2].year\n",
    "\n",
    "#get route and turns\n",
    "route = testtrip['edges']\n",
    "turns = [(route.values[i][0],route.values[i][1],route.values[i+1][0],route.values[i+1][1]) for i in range(0,len(route.values)-1)]\n",
    "turns = pd.DataFrame(turns,columns=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#retrieve attributes\n",
    "route_w_attr = pd.merge(route,edges_w_attr,on='linkid')\n",
    "turns_w_attr = pd.merge(turns,turns_df,on=['source_linkid','source_reverse_link','target_linkid','target_reverse_link'])\n",
    "\n",
    "#turn to gdf\n",
    "route_w_attr = gpd.GeoDataFrame(route_w_attr,geometry='geometry',crs=config['projected_crs_epsg'])\n",
    "summary_attributes[\"geometry\"] = MultiLineString(route_w_attr['geometry'].tolist())\n",
    "\n",
    "#flip relevant attributes\n",
    "route_w_attr.loc[route_w_attr['reverse_link']==True,ascent_columns+descent_columns+bike_facils] = \\\n",
    "    route_w_attr.loc[route_w_attr['reverse_link']==True,descent_columns+ascent_columns+bike_facils[::-1]].values\n",
    "\n",
    "#set the bike facility to na if the trip date was before the bike facility\n",
    "route_w_attr.loc[route_w_attr['year'] > trip_date_year,bike_facils] = np.nan\n",
    "\n",
    "#summary columns\n",
    "summary_attributes[\"length_ft\"] = route_w_attr['length_ft'].sum().round(0)\n",
    "summary_attributes[\"ascent_m\"] = route_w_attr['ascent_m'].sum().round(0)\n",
    "summary_attributes[\"descent_m\"] = route_w_attr['descent_m'].sum().round(0)\n",
    "\n",
    "# average grade by category (from broach)\n",
    "zero_to_two = (route_w_attr['ascent_grade_%'] > 0) & (route_w_attr['ascent_grade_%'] <= 2)\n",
    "two_to_four = (route_w_attr['ascent_grade_%'] > 2) & (route_w_attr['ascent_grade_%'] <= 4)\n",
    "four_to_six = (route_w_attr['ascent_grade_%'] > 4) & (route_w_attr['ascent_grade_%'] <= 6)\n",
    "six_and_beyond = (route_w_attr['ascent_grade_%'] > 6)\n",
    "summary_attributes[\"zero_to_two_%_ft\"] = route_w_attr.loc[zero_to_two,'length_ft'].sum().round(0)\n",
    "summary_attributes[\"two_to_four_%_ft\"] = route_w_attr.loc[two_to_four,'length_ft'].sum().round(0)\n",
    "summary_attributes[\"four_to_six_%_ft\"] = route_w_attr.loc[four_to_six,'length_ft'].sum().round(0)\n",
    "summary_attributes[\"six_and_beyond_%_ft\"] = route_w_attr.loc[six_and_beyond,'length_ft'].sum().round(0)\n",
    "\n",
    "#TODO add this back in the elevation step and use the same limits?\n",
    "#add meters on grade segments (i.e. add all in length along x to x)\n",
    "#could possibly be a more accurate represntation of steep roads\n",
    "\n",
    "# #instance columns to summarize\n",
    "# count_cols = ['bridge','tunnel']\n",
    "# for count_col in count_cols:\n",
    "#     summary_attributes[count_col] = (route_w_attr[count_col]==True).sum().round(0)\n",
    "\n",
    "# length of route columns to summarize\n",
    "cols = ['link_type_new','facility_fwd']#['link_type','highway']#,'speedlimit_range_mph','lanes_per_direction']\n",
    "for col in cols:\n",
    "    #make a summary column for every unique value in that column\n",
    "    for unique_val in route_w_attr[col].unique():\n",
    "        #skip if nan\n",
    "        if isinstance(unique_val,str) == False:\n",
    "            continue\n",
    "        summary_attributes[col+'.'+unique_val+'_ft'] = route_w_attr.loc[route_w_attr[col]==unique_val,'length_ft'].sum().round(0)\n",
    "        \n",
    "# turns\n",
    "summary_attributes.update(turns_w_attr['turn_type'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges['tup'] = list(zip(df_edges['linkid'],df_edges['reverse_link']))\n",
    "chosen_links = df_edges.set_index('tup').loc[list_of_edges]\n",
    "list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "chosen_turns = pseudo_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link']).loc[list_of_turns]\n",
    "chosen_links.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize summary dict\n",
    "summary_attributes = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trip distance\n",
    "summary_attributes['trip_distance_ft'] = chosen_links['length_ft'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#instance columns to summarize\n",
    "count_cols = ['bridge','tunnel']\n",
    "for count_col in count_cols:\n",
    "    summary_attributes[count_col] = (chosen_links[count_col]==True).sum()\n",
    "\n",
    "#general elevation\n",
    "total_ascent = (chosen_links['ascent_m'].sum() / 3.28).round(0)\n",
    "summary_attributes['ascent_ft'] = total_ascent \n",
    "summary_attributes['avg_ascent_grade'] = (total_ascent / chosen_links['length_ft'].sum() * 100).round(1)\n",
    "\n",
    "#elevation broken by segment\n",
    "elev_cols = ['(0,2]_ascent','(2,4]_ascent', '(4,6]_ascent', '(6,10]_ascent', '(10,15]_ascent','(15,inf]_ascent']\n",
    "for elev_col in elev_cols:\n",
    "    total_length = (chosen_links[elev_col].sum() / 3.28).round(0)\n",
    "    summary_attributes[elev_col+'_ft'] = total_length\n",
    "\n",
    "#pct of route columns to summarize\n",
    "cols = ['link_type','highway','bike_facility_type','speedlimit_range_mph','lanes_per_direction']\n",
    "for col in cols:\n",
    "    #make a summary column for every unique value in that column\n",
    "    for unique_val in chosen_links[col].unique():\n",
    "        if (unique_val != None) | (unique_val == np.nan):\n",
    "            total_length = chosen_links[chosen_links[col] == unique_val]['length_ft'].sum()\n",
    "        else:\n",
    "            continue\n",
    "        if isinstance(unique_val,str) == False:\n",
    "            unique_val = str(unique_val)\n",
    "        summary_attributes[col+'.'+unique_val] = np.round(total_length/chosen_links['length_ft'].sum(),2)\n",
    "\n",
    "# signalized and turns\n",
    "summary_attributes['signalized'] = (chosen_turns['signalized']==True).sum()\n",
    "summary_attributes['unsignalized'] = (chosen_turns['unsignalized']==True).sum()\n",
    "turn_dict = chosen_turns['turn_type'].value_counts().to_dict()\n",
    "summary_attributes.update(turn_dict)\n",
    "\n",
    "summary_dict[tripid] = summary_attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into geodataframe\n",
    "trips_df_info = pd.DataFrame.from_dict(summary_dict,orient='index')\n",
    "trips_df_info.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = trips_df.merge(trips_df_info,left_on='tripid',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO find the visualiztion code that we had already made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_edges = list(zip(edges['linkid'],edges['reverse_link']))\n",
    "# list_of_turns = [(list_of_edges[i][0],list_of_edges[i][1],list_of_edges[i+1][0],list_of_edges[i+1][1]) for i in range(0,len(list_of_edges)-1)]\n",
    "\n",
    "# chosen_links = df_edges.set_index(['linkid','reverse_link'],drop=False).loc[list_of_edges]\n",
    "\n",
    "# chosen_links['bridge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add user info\n",
    "trip_and_user = pd.read_pickle(fp/'gps_traces/trip_and_user.pkl')\n",
    "\n",
    "trips_df = trips_df_info.merge(trip_and_user,left_index=True,right_on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv(fp/'all_attrs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of visualizing here visualize elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import stochastic_optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot'\n",
    "# #fp = Path.home() / 'Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/BikewaySim/Data'\n",
    "\n",
    "# with (fp / 'impedance_calibration.pkl').open('rb') as fh:\n",
    "#     (df_edges,pseudo_df,pseudo_G) = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve link/turn costs\n",
    "# default below is link distance\n",
    "# link_costs = dict(zip(list(zip(df_edges['source'],df_edges['target'],df_edges['linkid'])),df_edges['length_ft']))\n",
    "# tup = list(zip(pseudo_df['source_A'],pseudo_df['source_B'],pseudo_df['source_linkid']))\n",
    "# pseudo_df['source_cost'] = list(map(link_costs.get,tup))\n",
    "# tup = list(zip(pseudo_df['target_A'],pseudo_df['target_B'],pseudo_df['target_linkid']))\n",
    "\n",
    "# pseudo_df['target_cost'] = list(map(link_costs.get,tup))\n",
    "# pseudo_df['total_cost'] = pseudo_df['source_cost'] + pseudo_df['target_cost'] #+turn_cost\n",
    "\n",
    "# costs = pseudo_df.groupby(['source','target'])['total_cost'].min()\n",
    "# nx.set_edge_attributes(pseudo_G,values=costs,name='weight')\n",
    "# source = list(pseudo_G.nodes())[0]\n",
    "# target = list(pseudo_G.nodes())[420]\n",
    "# print(source,target)\n",
    "# import networkx as nx\n",
    "# length, edge_list = nx.single_source_dijkstra(pseudo_G,source,target,weight=\"weight\")\n",
    "# turn_list = [[edge_list[i][0],edge_list[i][1],edge_list[i+1][0],edge_list[i+1][1]] for i in range(len(edge_list)-1)]\n",
    "\n",
    "# turn_cols = ['turn_type','signalized_left_straight','unsignalized_left_straight_nonlocal']\n",
    "# linkid_cols = ['source_linkid','source_reverse_link','target_linkid','target_reverse_link']\n",
    "# chosen_turns = pseudo_df.set_index(['source_A','source_B','target_A','target_B'],drop=False).loc[turn_list,linkid_cols+turn_cols]\n",
    "\n",
    "# tripid = 302\n",
    "\n",
    "# #make a single row dataframe to attach to trips_df\n",
    "# stats_dict = {}\n",
    "# stats_dict[tripid] = {\n",
    "#     'tripid':tripid,\n",
    "#     'signalized_left_straight': chosen_turns['signalized_left_straight'].sum(),\n",
    "#     'unsignalized_left_straight_nonlocal': chosen_turns['unsignalized_left_straight_nonlocal'].sum()\n",
    "# }\n",
    "# turn_dict = chosen_turns['turn_type'].value_counts().to_dict()\n",
    "# stats_dict[tripid].update(turn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Need to run shortest paths to create link sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_links = chosen_turns[['source_linkid','source_reverse_link']]\n",
    "# target_links = chosen_turns[['target_linkid','target_reverse_link']]\n",
    "# source_links.columns = ['linkid','reverse_link']\n",
    "# target_links.columns = ['linkid','reverse_link']\n",
    "# linkids = pd.concat([source_links,target_links],ignore_index=True).drop_duplicates()\n",
    "# chosen_links = df_edges.merge(linkids,on=['linkid','reverse_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO recalculate bearing\n",
    "#create pseudo graph for modeling turns\n",
    "df_edges, pseudo_links, pseudo_G = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = list(pseudo_G.nodes())[0]\n",
    "target = list(pseudo_G.nodes())[420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (68209677, 68209675)\n",
    "target = (69200243, 69465418)\n",
    "\n",
    "import networkx as nx\n",
    "length, path = nx.single_source_dijkstra(pseudo_G,source,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [(linkids[i],linkids[i+1]) for i in range(len(linkids)-1)]\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [(*path[i],*path[i+1]) for i in range(len(path)-1)]\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_links.set_index(['source_A','source_B','target_A','target_B']).loc[edge_list,'turn_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
