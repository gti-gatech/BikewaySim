{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Calibration\n",
    "In this we look at the quality of the calibrated impedance functions.\n",
    "---\n",
    "1. Recalculate shortest path results using the calibrated coefficients\n",
    "1. Calculate objective functions and other performance metrics\n",
    "1. Get route attribute summary for the chosen/shortest/modeled routes (right now)\n",
    "\n",
    "\n",
    "Still Working On\n",
    "1. Look at where calibrated function did the best/worst job for both the training/testing set\n",
    "1. Cluster/segment results based on loss function value?\n",
    "4. Export for application in BikewaySim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "from importlib import reload\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import modeling_turns\n",
    "from bikewaysim.impedance_calibration import stochastic_optimization, speedfactor\n",
    "\n",
    "from step_1_calibration_experiments import all_calibrations, full_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run post calibration for all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUG instead of using the calibration network for these processes, use the full network\n",
    "stochastic_optimization.post_calibration_loss(False) # for general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_optimization.post_calibration_loss(True) # for user specific results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "beta_vals = stochastic_optimization.post_calibration_betas(True)\n",
    "full_model_cols = [item['col'] for item in full_model]\n",
    "beta_vals = beta_vals[beta_vals[full_model_cols].notna().all(axis=1)].dropna(axis=1)\n",
    "beta_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disaggregate only really makes sense for all trips calibrations or testing\n",
    "# reload(stochastic_optimization)\n",
    "# disaggregated_loss = stochastic_optimization.post_calibration_disaggregate(True)\n",
    "# disaggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "aggregated_loss = stochastic_optimization.post_calibration_aggregated(True)\n",
    "aggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add\n",
    "merged = pd.merge(beta_vals,aggregated_loss,on=['userid','run_number','calibration'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which calibration method generally resulted in the best outcomes?\n",
    "merged.groupby('calibration')['jaccard_exact_mean','jaccard_exact_total','jaccard_buffer_mean','jaccard_buffer_total'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_optimization.shortest_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('rb') as fh:\n",
    "    full_set = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['origin_node','destination_node','trip_start_time','match_ratio','matched_edges','shortest_edges']:\n",
    "    [item.pop(x) for tripid, item in full_set.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(full_set,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stochastic_optimization)\n",
    "stochastic_optimization.shortest_aggregated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_shortest = stochastic_optimization.shortest_aggregated(True)\n",
    "user_shortest.set_index('userid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby('userid')['jaccard_exact_mean','jaccard_exact_total','jaccard_buffer_mean','jaccard_buffer_total'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby(['userid','calibration']).std().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = '48_gdot (1)'.split('_',maxsplit=1)[0]\n",
    "calibration_name = '48_gdot (1)'.split('_',maxsplit=1)[1].split('(')[0]\n",
    "run_number = '48_gdot (1)'.split('_',maxsplit=1)[1]\n",
    "test = '48_gdot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\((\\d+)\\)'\n",
    "re.findall(pattern,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_loss = stochastic_optimization.post_calibration_aggregated()\n",
    "beta_vals = stochastic_optimization.post_calibration_betas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaggregated_loss = stochastic_optimization.post_calibration_disaggregate(True)\n",
    "disaggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relevant Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "# with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "#     full_set = pickle.load(fh)\n",
    "# full_ods = stochastic_optimization.match_results_to_ods_w_year(full_set)\n",
    "# Retreive shortest and chosen stats first (already calculated the shortest paths)\n",
    "# for key, item in full_set.items():\n",
    "#     # extract chosen and shortest routes\n",
    "#     chosen = item['matched_edges'].values\n",
    "#     shortest = item['shortest_edges'].values\n",
    "\n",
    "#     #compute the loss values (store the intermediates too so total vs mean methods can be compared)\n",
    "#     shortest_jaccard_exact_intersection, shortest_jaccard_exact_union =  stochastic_optimization.jaccard_exact(chosen,shortest,length_dict)\n",
    "#     shortest_jaccard_exact = shortest_jaccard_exact_intersection / shortest_jaccard_exact_union\n",
    "#     shortest_jaccard_buffer_intersection, shortest_jaccard_buffer_union =  stochastic_optimization.jaccard_buffer(chosen,shortest,geo_dict)\n",
    "#     shortest_jaccard_buffer = shortest_jaccard_buffer_intersection / shortest_jaccard_buffer_union\n",
    "\n",
    "#     # add to full set in additon to what's already there\n",
    "#     full_set[key].update({\n",
    "#         'chosen_length': round(np.array([length_dict.get(tripid[0],False) for tripid in chosen]).sum()/5280,2),\n",
    "#         'shortest_length': round(np.array([length_dict.get(tripid[0],False) for tripid in shortest]).sum()/5280,2),\n",
    "#         'chosen_detour': round(stochastic_optimization.detour_factor(chosen,shortest,length_dict),2),\n",
    "#         'shortest_jaccard_exact': round(shortest_jaccard_exact,2),\n",
    "#         'shortest_jaccard_exact_intersection': round(shortest_jaccard_exact_intersection,2),\n",
    "#         'shortest_jaccard_exact_union': round(shortest_jaccard_exact_union,2),\n",
    "#         'shortest_jaccard_buffer': round(shortest_jaccard_buffer,2),\n",
    "#         'shortest_jaccard_buffer_intersection': round(shortest_jaccard_buffer_intersection,2),\n",
    "#         'shortest_jaccard_buffer_union': round(shortest_jaccard_buffer_union,2),\n",
    "#     })\n",
    "\n",
    "# # export new version\n",
    "# with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('wb') as fh:\n",
    "#     pickle.dump(full_set,fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post process calibration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all of the current calibration results\n",
    "# calibration_result_fps = list((config['calibration_fp']/\"calibration_results\").glob('*.pkl'))\n",
    "\n",
    "# # pick a specific model\n",
    "# # specific_model = 'jaccard_'\n",
    "# # calibration_result_fps = [x for x in calibration_result_fps if specific_model in x.stem.split('(')[0].strip()]\n",
    "\n",
    "# Get dataframe of calibrated betas (fast)\n",
    "# beta_vals = {}\n",
    "# for idx, calibration_result_fp in enumerate(calibration_result_fps):\n",
    "#     with calibration_result_fp.open('rb') as fh:\n",
    "#         calibration_result = pickle.load(fh)\n",
    "#     beta_vals[calibration_result_fp.stem] = {x['col']:x['beta'] for x in calibration_result['betas_tup']}\n",
    "# beta_vals = pd.DataFrame().from_dict(beta_vals,orient='index')\n",
    "# # beta_vals.std()\n",
    "# beta_vals.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the betas, calculate all of the shortest paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_vals = {}\n",
    "\n",
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "\n",
    "# #NOTE TEMP\n",
    "# # calibration_result_fps = [calibration_result_fps[0]]\n",
    "# set_to_zero = []\n",
    "# set_to_inf = []\n",
    "# # full_ods = full_ods[0:10]\n",
    "\n",
    "# modeled_paths_dicts = {}\n",
    "# for calibration_result_fp in tqdm(calibration_result_fps):\n",
    "    \n",
    "#     with calibration_result_fp.open('rb') as fh:\n",
    "#         calibration_result = pickle.load(fh)\n",
    "\n",
    "#     beta_vals[calibration_result_fp.stem] = {x['col']:x['beta'] for x in calibration_result['betas_tup']}\n",
    "\n",
    "#     base_impedance_col = \"travel_time_min\" # set the base impedance (default is travel time)\n",
    "#     betas = [x['beta'] for x in calibration_result['betas_tup']] # get betas\n",
    "\n",
    "#     # create a copy of links so we don't mutate it\n",
    "#     links0 = links.copy()\n",
    "    \n",
    "#     # reset the link costs\n",
    "#     stochastic_optimization.back_to_base_impedance(base_impedance_col,links0,turns,turn_G)\n",
    "\n",
    "#     # do initial impedance update\n",
    "#     # if infra is off street (i.e., the link should no longer be traversable)\n",
    "#     links0['link_cost_override'] = False\n",
    "#     stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "#                         stochastic_optimization.link_impedance_function,\n",
    "#                         base_impedance_col,\n",
    "#                         stochastic_optimization.turn_impedance_function,\n",
    "#                         links0,turns,turn_G)\n",
    "\n",
    "#     trips_years = set()\n",
    "#     results_dict = {}\n",
    "#     for start_node, end_node, year in full_ods:\n",
    "#         if year not in trips_years:\n",
    "#             # print('Remaking network for',year)\n",
    "#             trips_years.add(year) # add it to the years already looked at\n",
    "#             if (links0['year'] > year).any(): # only then should we run this\n",
    "#                 # print('Re-making network to year',year)\n",
    "                \n",
    "#                 # if infra is on street (i.e., the link is still traversable but the impedance doesn't apply)\n",
    "#                 links0.loc[links0['year']>year,set_to_zero] = 0 \n",
    "#                 links0.loc[(links0['year']>year) & (links0.loc[:,set_to_inf]==1).any(axis=1),'link_cost_override'] = True\n",
    "                \n",
    "#                 # re-run network update\n",
    "#                 updated_edge_costs = stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "#                         stochastic_optimization.link_impedance_function,\n",
    "#                         base_impedance_col,\n",
    "#                         stochastic_optimization.turn_impedance_function,\n",
    "#                         links0,turns,turn_G)\n",
    "            \n",
    "#         results_dict[(start_node,end_node)] = stochastic_optimization.impedance_path(turns,turn_G,links0,start_node,end_node)\n",
    "\n",
    "#     # before this, retrieve the tripid?\n",
    "\n",
    "#     # export\n",
    "#     with (config['calibration_fp']/'post_calibration_routing'/(calibration_result_fp.stem+'.pkl')).open('wb') as fh:\n",
    "#         pickle.dump(results_dict,fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate loss and objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_calibration_routing_fps = list((config['calibration_fp']/\"post_calibration_routing\").glob('*.pkl'))\n",
    "# print([post_calibration_routing_fp.stem for post_calibration_routing_fp in post_calibration_routing_fps])\n",
    "# #export modeled_results_sp so the next step can compute objective functions\n",
    "\n",
    "# for post_calibration_routing_fp in tqdm(post_calibration_routing_fps):\n",
    "    \n",
    "#     # #skip if this has already been performed?\n",
    "#     # if (config['calibration_fp']/'post_calibration_loss'/(post_calibration_routing_fp.stem+'.pkl')).exists():\n",
    "#     #     continue\n",
    "    \n",
    "#     with post_calibration_routing_fp.open('rb') as fh:\n",
    "#         results_dict = pickle.load(fh)\n",
    "    \n",
    "#     modeled_results_dict = {}\n",
    "#     # we could try storing these\n",
    "#     for tripid, item in full_set.items(): # make sure you import this\n",
    "#         chosen = item['matched_edges'].values\n",
    "#         shortest = item['shortest_edges'].values\n",
    "#         od = (item['origin_node'],item['destination_node'])\n",
    "#         modeled = results_dict[od]['edge_list']\n",
    "    \n",
    "#         #compute the loss values (store the intermediates too so total vs mean methods can be compared)\n",
    "#         modeled_jaccard_exact_intersection, modeled_jaccard_exact_union =  stochastic_optimization.jaccard_exact(chosen,modeled,length_dict)\n",
    "#         modeled_jaccard_exact = modeled_jaccard_exact_intersection / modeled_jaccard_exact_union\n",
    "#         modeled_jaccard_buffer_intersection, modeled_jaccard_buffer_union =  stochastic_optimization.jaccard_buffer(chosen,modeled,geo_dict)\n",
    "#         modeled_jaccard_buffer = modeled_jaccard_buffer_intersection / modeled_jaccard_buffer_union\n",
    "\n",
    "#         modeled_results_dict[tripid] = {\n",
    "#             'modeled_edges': pd.DataFrame(modeled,columns=['linkid','reverse_link']),\n",
    "#             'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,1),\n",
    "#             'modeled_detour': round(stochastic_optimization.detour_factor(modeled,shortest,length_dict),2),\n",
    "#             'modeled_jaccard_exact': round(modeled_jaccard_exact,2),\n",
    "#             'modeled_jaccard_exact_intersection': round(modeled_jaccard_exact_intersection,2),\n",
    "#             'modeled_jaccard_exact_union': round(modeled_jaccard_exact_union,2),\n",
    "#             'modeled_jaccard_buffer': round(modeled_jaccard_buffer,2),\n",
    "#             'modeled_jaccard_buffer_intersection': round(modeled_jaccard_buffer_intersection,2),\n",
    "#             'modeled_jaccard_buffer_union': round(modeled_jaccard_buffer_union,2),\n",
    "#         }\n",
    "    \n",
    "#     # print('Mean Jaccard Index',round(jaccard_mean,2),'Mean Buffer',round(buffer_mean,2))\n",
    "#     with (config['calibration_fp']/'post_calibration_loss'/(post_calibration_routing_fp.stem+'.pkl')).open('wb') as fh:\n",
    "#         pickle.dump(modeled_results_dict,fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a function that gathers the loss function value for each trip, and one for aggregating them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_calibration_loss_fps = list((config['calibration_fp']/\"post_calibration_loss\").glob('*.pkl'))\n",
    "# print([post_calibration_loss_fp.stem for post_calibration_loss_fp in post_calibration_loss_fps])\n",
    "# from collections import defaultdict\n",
    "# all_loss_stats = defaultdict(dict)\n",
    "# for post_calibration_loss_fp in tqdm(post_calibration_loss_fps):\n",
    "#     with post_calibration_loss_fp.open('rb') as fh:\n",
    "#         loss_dict = pickle.load(fh)\n",
    "#     #remove the edges\n",
    "#     for tripid, item in loss_dict.items():\n",
    "#         #remove certain fields\n",
    "#         for key in list(item.keys()):\n",
    "#             if ('_intersection' in key) | ('_union' in key) | (key=='modeled_edges'):\n",
    "#                 item.pop(key)\n",
    "#         renamed = {post_calibration_loss_fp.stem+'_'+key.removeprefix('modeled_'):sub_item for key, sub_item in item.items()}\n",
    "#         all_loss_stats[tripid].update(renamed)\n",
    "# all_loss_stats = pd.DataFrame.from_dict(all_loss_stats,orient='index')\n",
    "# all_loss_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # disaggregated\n",
    "# aggregated_loss = {}\n",
    "# for post_calibration_loss_fp in tqdm(post_calibration_loss_fps):\n",
    "#     with post_calibration_loss_fp.open('rb') as fh:\n",
    "#         loss_dict = pickle.load(fh)\n",
    "    \n",
    "#     jaccard_exact_mean = np.array([item['modeled_jaccard_exact'] for tripid, item in loss_dict.items()]).mean()\n",
    "#     jaccard_exact_total = np.array([(item['modeled_jaccard_exact_intersection'],item['modeled_jaccard_exact_union']) for tripid, item in loss_dict.items()])\n",
    "#     jaccard_exact_total = jaccard_exact_total[:,0].sum() / jaccard_exact_total[:,1].sum()\n",
    "\n",
    "#     jaccard_buffer_mean = np.array([item['modeled_jaccard_buffer'] for tripid, item in loss_dict.items()]).mean()\n",
    "#     jaccard_buffer_total = np.array([(item['modeled_jaccard_buffer_intersection'],item['modeled_jaccard_buffer_union']) for tripid, item in loss_dict.items()])\n",
    "#     jaccard_buffer_total = jaccard_buffer_total[:,0].sum() / jaccard_buffer_total[:,1].sum()\n",
    "\n",
    "#     aggregated_loss[post_calibration_loss_fp.stem] = {\n",
    "#         'jaccard_exact_mean': jaccard_buffer_mean,\n",
    "#         'jaccard_exact_total': jaccard_exact_total,\n",
    "#         'jaccard_buffer_mean': jaccard_buffer_mean,\n",
    "#         'jaccard_buffer_total': jaccard_buffer_total, \n",
    "#     }\n",
    "# aggregated_loss = pd.DataFrame.from_dict(aggregated_loss,orient='index').round(2)\n",
    "# aggregated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([loss_df,betas_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fit stats\n",
    "# TODO get the length weighted versions\n",
    "shortest_jaccard_mean = np.array([item['shortest_jaccard'] for tripid, item in full_set.items()]).mean()\n",
    "shortest_buffer_mean = np.array([item['shortest_buffer'] for tripid, item in full_set.items()]).mean()\n",
    "print('Mean Jaccard Index',round(shortest_jaccard_mean,2),'Mean Buffer',round(shortest_buffer_mean,2))\n",
    "\n",
    "shortest_jaccard = {tripid:item['shortest_jaccard'] for tripid, item in full_set.items()}\n",
    "shortest_jaccard = pd.Series(shortest_jaccard)\n",
    "shortest_jaccard.name = 'shortest_jaccard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test[post_calibration_loss_fp.stem] = {\n",
    "    'modeled_jaccard_exact_mean': modeled_jaccard_buffer_mean,\n",
    "    'modeled_jaccard_exact_total': modeled_jaccard_exact_total,\n",
    "    'modeled_jaccard_buffer_mean': modeled_jaccard_buffer_mean,\n",
    "    'modeled_jaccard_buffer_total': modeled_jaccard_buffer_total, \n",
    "}\n",
    "# get fit stats\n",
    "# TODO get the length weighted versions\n",
    "shortest_jaccard_mean = np.array([item['shortest_jaccard'] for tripid, item in full_set.items()]).mean()\n",
    "shortest_buffer_mean = np.array([item['shortest_buffer'] for tripid, item in full_set.items()]).mean()\n",
    "print('Mean Jaccard Index',round(shortest_jaccard_mean,2),'Mean Buffer',round(shortest_buffer_mean,2))\n",
    "\n",
    "shortest_jaccard = {tripid:item['shortest_jaccard'] for tripid, item in full_set.items()}\n",
    "shortest_jaccard = pd.Series(shortest_jaccard)\n",
    "shortest_jaccard.name = 'shortest_jaccard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccrd_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([(3,4),(3,4)])\n",
    "x[:,0].sum() / x[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all of the intersects intersect of chosen and modeled / sum of all of the unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_calibration_result_fps = list((config['calibration_fp']/\"post_calibration\").glob('*.pkl'))\n",
    "\n",
    "# pick a specific model\n",
    "specific_model = 'calibration2_new'\n",
    "calibration_result_fps = [x for x in calibration_result_fps if specific_model == x.stem.split('(')[0].strip()]\n",
    "post_calibration_result_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make this into a function\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#aggregated results and overlap figures\n",
    "mean_values = []\n",
    "for idx, post_calibration_result_fp in enumerate(post_calibration_result_fps):\n",
    "    print('Calibration result',post_calibration_result_fp.stem)\n",
    "    with post_calibration_result_fp.open('rb') as fh:\n",
    "        post_calibration_result = pickle.load(fh)\n",
    "\n",
    "    jaccard_mean = np.array([item['modeled_jaccard'] for tripid, item in post_calibration_result.items()]).mean()\n",
    "    buffer_mean = np.array([item['modeled_buffer'] for tripid, item in post_calibration_result.items()]).mean()\n",
    "    mean_values.append((post_calibration_result_fp.stem,round(jaccard_mean,2),round(buffer_mean,2)))\n",
    "\n",
    "    print('Mean Jaccard Index',round(jaccard_mean,2),'Mean Buffer',round(buffer_mean,2))\n",
    "    # with (config['calibration_fp']/'post_calibration'/(calibration_result_fp.stem+'.pkl')).open('wb') as fh:\n",
    "    #     pickle.dump(modeled_results_dict,fh)\n",
    "\n",
    "    #get just jaccard values\n",
    "    modeled_jaccard = {tripid:item['modeled_jaccard'] for tripid, item in post_calibration_result.items()}\n",
    "    modeled_jaccard = pd.Series(modeled_jaccard)\n",
    "    modeled_jaccard.name = 'modeled_jaccard'\n",
    "    df = pd.concat([shortest_jaccard,modeled_jaccard],axis=1,ignore_index=False)\n",
    "\n",
    "    # make figures\n",
    "    # Create the histogram\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.hist(df['shortest_jaccard'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "    plt.hist(df['modeled_jaccard'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "    # Adding labels, title, and legend with font size adjustments\n",
    "    plt.xlabel('Overlap', fontsize=22)\n",
    "    plt.ylabel(f'Frequency (N={df.shape[0]})', fontsize=22)\n",
    "    plt.title(post_calibration_result_fp.stem, fontsize=16)\n",
    "    plt.legend(title='Jaccard Index', fontsize=22, title_fontsize=22)\n",
    "    plt.ylim([0,700])\n",
    "\n",
    "    # Adjusting the font size of the tick labels\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(config['calibration_fp']/'calibration_performance'/(post_calibration_result_fp.stem + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_result['betas_tup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(mean_values,columns=['calibration_name','jaccard_mean','buffer_mean'])\n",
    "metrics.set_index('calibration_name',inplace=True)\n",
    "metrics.sort_values('jaccard_mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort_values('buffer_mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate all the possible overlap metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import impedance_calibration.src.summarize_route as summarize_route\n",
    "reload(summarize_route)\n",
    "\n",
    "chosen_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['matched_edges'].values,links,turns) for tripid in full_set.keys()}\n",
    "shortest_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['shortest_edges'].values,links,turns) for tripid in full_set.keys()} \n",
    "modeled_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['modeled_edges'].values,links,turns) for tripid in full_set.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_attr = pd.DataFrame.from_dict(chosen_attr,orient='index')\n",
    "shortest_attr = pd.DataFrame.from_dict(shortest_attr,orient='index')\n",
    "modeled_attr = pd.DataFrame.from_dict(modeled_attr,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.reset_index().to_csv(config['calibration_fp']/'objective_functions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(config['calibration_fp']/'objective_functions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.mean().drop('index').to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting/labeling trips\n",
    "Want to know which attributes help lead to a loss function value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree #1\n",
    "Want to see if percent detour or if any of the chosen route characterstics (that were accounted for in the calibration process) contributed to the overlap value (modeled_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = pd.concat([results_df[['chosen_length','chosen_detour','modeled_jaccard']],chosen_attr],axis=1)\n",
    "\n",
    "tree_df['lanes_above_1'] = tree_df['lane_2'] + tree_df['lane_3']\n",
    "tree_df.drop(columns=['lane_0','lane_1','lane_2','lane_3'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First split is the chosen detour rate. 1,377 trips (over half) have a detour rate above 10.5% and this is associated with a bigger reduction in overlap. Past this it appears that trips that took a lot \n",
    "\n",
    "Second split is on chosen length and chosen detour rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree\n",
    "\n",
    "X, y = tree_df.drop(columns=['modeled_jaccard']).values, tree_df['modeled_jaccard'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=tree_df.drop(columns=['modeled_jaccard']).columns, filled=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X, y = tree_df.drop(columns=['modeled_jaccard']), tree_df['modeled_jaccard']\n",
    "X = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X).fit()\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df.sort_values('unsig_major_road_crossing',ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = one_hot_data.values, merged['impedance'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=5)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "plt.show()\n",
    "how to compare predicted values vs actual?\n",
    "SS_res = ((y - clf.predict(X))**2).sum()\n",
    "SS_tot = ((y - y.mean())**2).sum()\n",
    "R2 = 1 - (SS_res/SS_tot)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"full_modeled_results.pkl\").open('rb') as fh:\n",
    "#     modeled_results = pickle.load(fh)\n",
    "## Add Route Attributes\n",
    "import impedance_calibration.src.summarize_route as summarize_route\n",
    "cols_to_summarize = {\n",
    "    'facility_fwd': \"category\",\n",
    "    'AADT': (\"threshold\",[10000]),\n",
    "    'truck_pct': (\"threshold\",[5]),\n",
    "    'speed': \"category\",\n",
    "    'lanes': \"category\",\n",
    "    'mixed_traffic_no_facil': \"boolean\",\n",
    "    'mixed_traffic_w_facil': \"boolean\"\n",
    "}\n",
    "links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "turns.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "links.columns\n",
    "# #unit conversions\n",
    "#links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "#links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "#links.drop(columns=['length_ft','ascent_m'],inplace=True)\n",
    "test_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in full_set.items()]\n",
    "test_summary = summarize_route.procees_summary_results(test_summary,config['projected_crs_epsg'])\n",
    "test_summary.drop(columns=['tripid','geometry']).describe()\n",
    "train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the percent change in impedance at the link level for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change = links.copy()\n",
    "impedance_change['imp_prop'] = (impedance_change['link_cost'] - impedance_change['travel_time_min']) / impedance_change['travel_time_min']\n",
    "impedance_change['imp_prop'] = impedance_change['imp_prop'].round(3)\n",
    "impedance_change = impedance_change[impedance_change['reverse_link']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo automate the plot generation for when qgis isn't available\n",
    "impedance_change.plot('imp_prop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change.to_file(config['calibration_fp']/\"network_impedance_change.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change['imp_prop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(impedance_change['imp_prop'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(impedance_change['imp_prop']==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change.imp_prop.round(3).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# train_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_train = loss_function(train_set,train_results_dict,**loss_function_kwargs)\n",
    "# loss_train[:,1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# test_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_test = loss_function(test_set,test_results_dict,**loss_function_kwargs)\n",
    "# loss_test[:,1].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test0 = pd.DataFrame(loss_shortest_test,columns=['tripid','shortest'])\n",
    "# test1 = pd.DataFrame(loss_test,columns=['tripid','impedance'])\n",
    "# testing = pd.concat([test0,test1])\n",
    "\n",
    "# train0 = pd.DataFrame(loss_shortest_train,columns=['tripid','shortest'])\n",
    "# train1 = pd.DataFrame(loss_train,columns=['tripid','impedance'])\n",
    "# training = pd.concat([train0,train1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make dataframe and export results\n",
    "# testing = pd.DataFrame({'tripid':list(test_set.keys()),'shortest':loss_shortest_test[:,1],'impedance':loss_test})\n",
    "# testing.to_csv(config['calibration_fp']/'testing_results.csv',index=False)\n",
    "# training = pd.DataFrame({'tripid':list(train_set.keys()),'shortest':loss_shortest_train[:,1],'impedance':loss_train})\n",
    "# training.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble dataframe of overlap metrics\n",
    "Dataframe that adds in jaccard index, frechet dist, detour percent, etc into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set[71].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "#calulate objective function\n",
    "test = stochastic_optimization.general_objective_function(\n",
    "    stochastic_optimization.frechet_distance,\n",
    "    full_set,\n",
    "    results_dict,\n",
    "    links)\n",
    "test#print(loss_full[:,1].mean().round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.DataFrame({'tripid':list(full_set.keys()),'shortest':loss_shortest_full[:,1],'impedance':loss_full[:,1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of overlap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#loss_data = pd.DataFrame({'loss_shortest_full':loss_shortest_full,'loss_full':loss_full})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Create the histogram\n",
    "#ax = loss_full_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.hist(full['shortest'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "plt.hist(full['impedance'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# Adding labels, title, and legend with font size adjustments\n",
    "plt.xlabel('Overlap', fontsize=22)\n",
    "plt.ylabel(f'Frequency (N={full.shape[0]})', fontsize=22)\n",
    "#plt.title('Histogram of Training Losses', fontsize=16)\n",
    "#plt.legend(title='Tra Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# Adjusting the font size of the tick labels\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# loss_data = pd.DataFrame({'loss_shortest_train':loss_shortest_train,'loss_train':loss_train})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_train'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_train'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Training Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_data = pd.DataFrame({'loss_shortest_test':loss_shortest_test,'loss_test':loss_test})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_test'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_test'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Testing Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add modeled geometry to results dict for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "for tripid, item in full_set.items():\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled_edges = full_results_dict.get(od,0).get('edge_list',0)\n",
    "    if isinstance(modeled_edges,int):\n",
    "        print(modeled_edges)\n",
    "    #turn to dataframe\n",
    "    modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "    full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the test and train set dictionaries\n",
    "modeled_results = {}\n",
    "# modeled_results.update(train_set)\n",
    "# modeled_results.update(test_set)\n",
    "modeled_results.update(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"full_modeled_results.pkl\").open('wb') as fh:\n",
    "    pickle.dump(modeled_results,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAQC (separate into a separate notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"full_modeled_results.pkl\").open('rb') as fh:\n",
    "#     modeled_results = pickle.load(fh)\n",
    "# ## Add Route Attributes\n",
    "# import summarize_route\n",
    "# cols_to_summarize = {\n",
    "#     'facility_fwd': \"category\",\n",
    "#     'AADT': (\"threshold\",[10000]),\n",
    "#     'truck_pct': (\"threshold\",[5]),\n",
    "#     'here_speed': \"category\",\n",
    "#     'lanes': \"category\",\n",
    "#     'mixed_traffic_no_facil': \"boolean\",\n",
    "#     'mixed_traffic_w_facil': \"boolean\"\n",
    "# }\n",
    "# links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "# turns.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "# links.columns\n",
    "# # #unit conversions\n",
    "# #links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "# #links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "# #links.drop(columns=['length_ft','ascent_m'],inplace=True)\n",
    "# test_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in full_set.items()]\n",
    "# test_summary = summarize_route.procees_summary_results(test_summary,config['projected_crs_epsg'])\n",
    "# test_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "# train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "# train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "# train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "# train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')\n",
    "# summary.columns\n",
    "# summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Regression Trees\n",
    "# from sklearn import tree\n",
    "\n",
    "# testing = pd.read_csv(config['calibration_fp']/'testing_results.csv')\n",
    "# training = pd.read_csv(config['calibration_fp']/'training_results.csv')\n",
    "\n",
    "# #assume that keys are in the right order?\n",
    "# loss_df = pd.concat([testing,training],ignore_index=True)\n",
    "# #import trip and user characteristics\n",
    "# trips_df = pd.read_pickle(cycleatl_fp/\"trips_3.pkl\")\n",
    "# users_df = pd.read_pickle(cycleatl_fp/\"users_1.pkl\")\n",
    "# trips_df.reset_index(drop=True,inplace=True)\n",
    "# #import route attributes\n",
    "# matched_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"matched\")\n",
    "# shortest_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"shortest\")\n",
    "# #consolidate trip types\n",
    "# trips_df.loc[trips_df['trip_type']=='other','trip_type'] = 'Other'\n",
    "# trips_df.loc[trips_df['trip_type']=='Work-related','trip_type'] = 'Work-Related'\n",
    "# trips_df['trip_type'].value_counts()\n",
    "# #replace userid with just the first one\n",
    "# def take_first(x):\n",
    "#     if isinstance(x,list):\n",
    "#         return x[0]\n",
    "#     return x\n",
    "# users_df['userid'] = users_df['userid'].apply(take_first)\n",
    "# #consolidate trip types\n",
    "# trips_df.loc[trips_df['trip_type']=='other','trip_type'] = 'Other'\n",
    "# trips_df.loc[trips_df['trip_type']=='Work-related','trip_type'] = 'Work-Related'\n",
    "# trips_df['trip_type'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Tree #1\n",
    "# - First tree is on the non-null variables\n",
    "# - The dist. between shortest and impedance were similar and so are the trees\n",
    "# - Shorter trips better explained by impedance/shortest path which makes sense\n",
    "#     - Use this to split longer trips? and retrain?\n",
    "# - Shopping is the only significant trip type variable\n",
    "# - Speed above 9 mph is usually better explained by impedance\n",
    "# ## Tree #1\n",
    "# - First tree is on the non-null variables\n",
    "# - The dist. between shortest and impedance were similar and so are the trees\n",
    "# - Shorter trips better explained by impedance/shortest path which makes sense\n",
    "#     - Use this to split longer trips? and retrain?\n",
    "# - Shopping is the only significant trip type variable\n",
    "# - Speed above 9 mph is usually better explained by impedance\n",
    "# nonulls = ['trip_type','length_mi','avg_speed_mph','(0,4]_prop', '(4,8]_prop',\n",
    "#        '(8,inf]_prop', 'AADT_10000_prop', 'facility_fwd_bike lane_prop',\n",
    "#        'facility_fwd_cycletrack_prop', 'facility_fwd_multi use path_prop',\n",
    "#        'facility_fwd_sharrow_prop', 'here_speed_1_prop', 'here_speed_2_prop',\n",
    "#        'here_speed_3_prop', 'here_speed_4_prop', 'lanes_1_prop',\n",
    "#        'lanes_2_prop', 'lanes_3_prop', 'left', 'right', 'signalized',\n",
    "#        'straight', 'truck_pct_5_prop', 'uturn']\n",
    "# nonulls_tree_df = merged[nonulls]\n",
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# #convert nominal categorical to numeric\n",
    "# one_hot_data = pd.get_dummies(nonulls_tree_df,drop_first=True)\n",
    "# one_hot_data.columns\n",
    "# X, y = one_hot_data.values, merged['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "# clf = clf.fit(X, y)\n",
    "# fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "# plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "# plt.show()\n",
    "# X, y = one_hot_data.values, merged['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=5)\n",
    "# clf = clf.fit(X, y)\n",
    "# fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "# plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "# plt.show()\n",
    "# how to compare predicted values vs actual?\n",
    "# SS_res = ((y - clf.predict(X))**2).sum()\n",
    "# SS_tot = ((y - y.mean())**2).sum()\n",
    "# R2 = 1 - (SS_res/SS_tot)\n",
    "# R2\n",
    "# ## Tree #2\n",
    "# This one takes the previous variables and adds the user characterstics. Sample size is smaller due to null values\n",
    "\n",
    "# - Looks like trip distance is still the dominant one here, really think i should start there\n",
    "# - When removing trip distance and avg speed, trip type and age 55+ are the best\n",
    "\n",
    "# **NOTE:** just noticed that age should not be dummies, need to fix that and try again\n",
    "# import json\n",
    "# user_data_definitions = json.load((Path.home()/'Documents/GitHub/cycleatlanta/user_data_definition.json').open('rb'))\n",
    "\n",
    "# #add the 55+ column\n",
    "# user_data_definitions['age']['6'] = '55+'\n",
    "# #income has too many nulls\n",
    "# tree_cols = ['age','gender','rider_history','rider_type'] + nonulls #,'total_distance_ft','avg_speed_mph','count']#,'count']#[,'cycling_freq'\n",
    "# tree_df = merged[tree_cols]\n",
    "\n",
    "# #use to detect null values\n",
    "# isnull = ((tree_df == -1) | (tree_df == 'NULL'))\n",
    "\n",
    "# #TODO do cross-sectionals to see which combination results in the most retained entries\n",
    "# #remove rows with null values\n",
    "# tree_df = tree_df[(isnull==False).all(axis=1)]\n",
    "\n",
    "# loss_vals = merged.loc[tree_df.index]\n",
    "# get_factor = ['age','rider_history','rider_type']\n",
    "# # just fyi\n",
    "# # select_max_cols = ['age','income','cycling_freq']\n",
    "# # #select the min for these (i.e. strong and fearless over interested but...)\n",
    "# # select_min_cols = ['rider_type','rider_history']\n",
    "\n",
    "# for col in get_factor:\n",
    "#     ivd = {v:k for k, v in user_data_definitions[col].items()}\n",
    "#     tree_df[col] = tree_df[col].map(ivd)\n",
    "# tree_df\n",
    "# #this is where i left off\n",
    "# #convert nominal categorical to numeric\n",
    "# dummy_cols = ['gender','trip_type']\n",
    "# one_hot_data = pd.get_dummies(tree_df[dummy_cols],drop_first=True)\n",
    "# comb = pd.concat([tree_df.drop(columns=dummy_cols),one_hot_data],ignore_index=False,axis=1)\n",
    "# comb\n",
    "# X, y = comb.values, loss_vals['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "# clf = clf.fit(X, y)\n",
    "# #tree.plot_tree(clf,feature_names=one_hot_data.columns)\n",
    "# # Visualize the tree with higher resolution\n",
    "# plt.figure(figsize=(20, 10), dpi=300)\n",
    "# from sklearn.tree import plot_tree\n",
    "# plot_tree(clf, feature_names=comb.columns, filled=True)\n",
    "# plt.show()\n",
    "# # how to compare predicted values vs actual?\n",
    "# SS_res = ((y - clf.predict(X))**2).sum()\n",
    "# SS_tot = ((y - y.mean())**2).sum()\n",
    "# R2 = 1 - (SS_res/SS_tot)\n",
    "# R2\n",
    "# What we actually want to know, is what variables help increase the overlap? So wouldn't that be more of an application for linear regression?\n",
    "\n",
    "# clf\n",
    "# Since the squared error is already pretty high and our histogram tells us, most of these trips are not currently well predicted with the current impedances. The idea behind using regression trees here is can we figure out if attributes help exmplain the bad overlap?\n",
    "\n",
    "# Or we could just try knocking off \n",
    "# #correlation matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Calculate the correlation matrix\n",
    "# correlation_matrix = one_hot_data.corr()\n",
    "\n",
    "# # Display the correlation matrix\n",
    "# print(\"Correlation Matrix:\")\n",
    "# print(correlation_matrix)\n",
    "\n",
    "# # Plot the correlation matrix using seaborn heatmap\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "# one_hot_data.corr()\n",
    "# # Distribution of Loss Function\n",
    "# # Export to get route attributes\n",
    "# # Using BRouter Results\n",
    "# To compare across we'll use Frechet distance. Will need to use next time.\n",
    "# with (config['calibration_fp']/'brouter_links.txt').open('r') as file:\n",
    "#     my_list = file.readlines()\n",
    "#     # Remove any extra whitespace or newline characters\n",
    "#     my_list = [line.strip() for line in my_list]\n",
    "# len(my_list)\n",
    "# geojsons = list((config['calibration_fp']/'GeoJSON_Out').glob('*.geojson'))\n",
    "# both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "# len(both_ods)\n",
    "# test_ods\n",
    "# len(geojsons)\n",
    "# #use the results dict combined with the geo dict one\n",
    "# results_dict[(68166811, 8789832117)]\n",
    "# #\n",
    "# geojson_geos = []\n",
    "# for geojson in geojsons:\n",
    "#     geojson_geo = gpd.read_file(geojson).to_crs(config['projected_crs_epsg'])\n",
    "#     geojson_geo = np.array(geojson_geo.geometry.item().coords)\n",
    "#     # geojson_geo = [(x, y) for x, y, z in geojson_geo.coords]\n",
    "#     # geojson_geo = LineString(geojson_geo)\n",
    "#     geojson_geos.append(geojson_geo)\n",
    "# frechet_distance = similaritymeasures.frechet_dist(chosen_coords,modeled_coords)\n",
    "# #import and compare frechet distance across them with geodict?\n",
    "# list(geojson_geo.coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
