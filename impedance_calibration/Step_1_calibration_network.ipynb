{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Preparation\n",
    "- Determine which links should be included for routing\n",
    "- Create directed edge dataframe\n",
    "- Format edge and turn attribute variables\n",
    "- Prepare dictionaries for quick edge attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths()\n",
    "\n",
    "from network.src import modeling_turns\n",
    "import speedfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = pd.read_parquet(config['network_fp']/'turns_df.parquet')\n",
    "links = gpd.read_file(config['network_fp']/'final_network.gpkg',layer='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #unit conversions\n",
    "links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "#links.drop(columns=['length_ft','ascent_m'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicts for referencing certain link attributes quickly\n",
    "length_dict = dict(zip(links['linkid'],links['length_ft'])) # need this for loss function\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define which links are permitted for routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only allow these types for routing\n",
    "link_types_allowed = ['bike','pedestrian','road']\n",
    "links['link_type'].unique()\n",
    "links = links[links['link_type'].isin(link_types_allowed)]\n",
    "\n",
    "# trim the turns dataframe too\n",
    "highway_dict = dict(zip(links['linkid'],links['link_type']))\n",
    "turns['source_link_type'] = turns['source_linkid'].map(highway_dict)\n",
    "turns['target_link_type'] = turns['target_linkid'].map(highway_dict)\n",
    "del highway_dict\n",
    "turns = turns[turns['source_link_type'].isin(link_types_allowed) & turns['target_link_type'].isin(link_types_allowed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUTURE: ADD LINKS USED IN MAP MATCHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Attribute Cleaning\n",
    "We have these attributes:\n",
    "- Length\n",
    "- Grade/Elevation\n",
    "- Bike Facility\n",
    "- Oneway\n",
    "- Signals\n",
    "- AADT\n",
    "- Truck %\n",
    "- Lanes\n",
    "- Speed Category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Facilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[['facility_fwd','facility_rev']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set no facility values to null\n",
    "links.loc[links['facility_fwd'] == 'no facility','facility_fwd'] = None\n",
    "links.loc[links['facility_rev'] == 'no facility','facility_rev'] = None\n",
    "\n",
    "# set sharrow to none\n",
    "links.loc[links['facility_fwd']=='sharrow','facility_fwd'] = None\n",
    "links.loc[links['facility_rev']=='sharrow','facility_rev'] = None\n",
    "\n",
    "# create a single column version for correlation matrix\n",
    "protection = {\n",
    "    \"cycletrack\": 3,\n",
    "    \"buffered bike lane\": 2,\n",
    "    \"bike lane\": 1,\n",
    "    \"sharrow\": 0\n",
    "}\n",
    "cond = links['facility_fwd'].map(protection) >= links['facility_rev'].map(protection)\n",
    "links['bike_facility'] = pd.Series(np.where(cond,links['facility_fwd'],links['facility_rev']))\n",
    "links.loc[links['bike_facility'].isna(),'bike_facility'] = None\n",
    "links['bike_facility'].value_counts()\n",
    "#for correlation testing turn into oridinal variable (increasing protection)\n",
    "links['bike_facility'] = links['bike_facility'].map(protection)\n",
    "links.loc[links['bike_facility'].isna(),'bike_facility'] = 0\n",
    "links['bike_facility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for right now, just treat multi-use paths and cycletracks as the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanes\n",
    "- All non-road links get a 1 (doing this so lanes attribute isn't being confounded with vehicle access)\n",
    "- By direction is too detailed, use a per direction estimate (i.e. treat a 5 lane oneway road the same as a 10 lane twoway road or a 5 lane per direction)\n",
    "- Simplify to:\n",
    "    - 1 lane per direction\n",
    "    - 2 lanes per direction\n",
    "    - 3+ lanes per direction\n",
    "- If unequal number of lanes use direction that would result in the higher category\n",
    "    - Example: 10th Street NE would be 2 lanes per direction because it has 2/1 lanes by direction\n",
    "- Turn lanes (middle, right, etc) are NOT counted in HERE or GDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give every road link a base value of 1\n",
    "links['lanes'] = 0\n",
    "links.loc[links['link_type']=='road','lanes'] = 1\n",
    "\n",
    "#if one is null take the null value\n",
    "links.loc[links['here_lanes'].isna() & links['gdot_lanes'].notna(),'lanes'] = links['gdot_lanes']\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].isna(),'lanes'] = links['here_lanes']\n",
    "\n",
    "#otherwise choose whichever is smaller\n",
    "links.loc[links['here_lanes'].notna() & links['gdot_lanes'].notna(),'lanes'] = links[['here_lanes','gdot_lanes']].min(axis=1)\n",
    "\n",
    "#TODO figure out what to do when there is a disrepency between the lanes\n",
    "## Examine where there's a big mismatch between HERE and GDOT\n",
    "# - There are a couple of cases where GDOT will be way off, like North Highland Ave NE which shows up as having four lanes when it's mostly 2 lanes for most of its length.\n",
    "# - Memorial Drive is also marked as having four lanes but it was road dieted post 2016, so just use the old value.\n",
    "# - Unless it's a residential street or a few cases that were identified, use the GDOT values.\n",
    "#links.loc[links['here_lanes'] != links['gdot_lanes'],['here_lanes','gdot_lanes']].value_counts()\n",
    "#links.loc[links['here_lanes'] != links['gdot_lanes'],['here_lanes','gdot_lanes','geometry']].explore(style_kwds=style_kwds,**tile_dict)\n",
    "#links.loc[(links['here_lanes']=='1') & (links['lanes']==4),['highway','name','lanes','here_lanes','geometry']].explore(**tile_dict,style_kwds=style_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dict = {\n",
    "    \"tiles\": \"https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}\",\n",
    "    \"attr\": \"Google\"\n",
    "}\n",
    "style_kwds = {\n",
    "    \"weight\": 6,\n",
    "    \"color\": \"white\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all na values to 1 as the base\n",
    "links['speed'] = 0\n",
    "links.loc[links['here_speed'].notna(),'speed'] = links.loc[links['here_speed'].notna()]\n",
    "links.loc[links['here_speed'].isna() & (links['link_type']=='road'),'speed'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set nulls to zero\n",
    "links.loc[links['AADT'].isna(),'AADT'] = 0\n",
    "links.loc[links['truck_pct'].isna(),'truck_pct'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get absolute value\n",
    "links['descent_grade_%'] = links['descent_grade_%'].abs()\n",
    "\n",
    "# set maximum possible grade to 30%\n",
    "links.loc[(links['ascent_grade_%'] > 30),'ascent_grade_%'] = 30\n",
    "links.loc[(links['descent_grade_%'] > 30),'descent_grade_%'] = 30\n",
    "\n",
    "#take the max value for the correlation matrix\n",
    "links['maxgrade_%'] = links[['ascent_grade_%','descent_grade_%']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Attribute Analysis\n",
    "Just apply this to road links for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_variables = ['bike_facility','AADT','truck_pct','lanes','speed','maxgrade_%','length_ft']\n",
    "test = links.loc[links['link_type']=='road',correlation_variables]\n",
    "test\n",
    "#links[network_variables].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.groupby(['lanes','here_speed']).apply(lambda x: np.round(x.length.sum() / 5280,1)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = test.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix for roads with bicycle facilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a random 80000x3 matrix\n",
    "# For a real scenario, you would load your data here\n",
    "#data = links[categorical_variables].values #np.random.rand(80000, 3)\n",
    "\n",
    "# Convert the data to a pandas DataFrame for easier manipulation\n",
    "#df = links[['lanes','here_speed']]#pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "df = test[test['bike_facility']>0]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Generate a random 80000x3 matrix\n",
    "# # For a real scenario, you would load your data here\n",
    "# data = np.random.rand(80000, 3)\n",
    "\n",
    "# # Initialize PCA\n",
    "# pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization purposes\n",
    "\n",
    "# # Fit PCA on the data\n",
    "# principal_components = pca.fit_transform(data)\n",
    "\n",
    "# # Display the explained variance ratio\n",
    "# print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# # Display the principal components\n",
    "# print(\"Principal components shape:\", principal_components.shape)\n",
    "\n",
    "# # Optionally, save the principal components to a file\n",
    "# np.savetxt(\"principal_components.csv\", principal_components, delimiter=\",\")\n",
    "\n",
    "# # Plot the first two principal components if you want to visualize\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(principal_components[:, 0], principal_components[:, 1], alpha=0.5)\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.title('PCA of 80000x3 matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wasn't able to get major/minor to be significant\n",
    "#Major/minor road classification to create high traffic stress variable\n",
    "major_road = ['primary','secondary']\n",
    "major_road = major_road + [item + '_link' for item in major_road]\n",
    "minor_road = ['tertiary','unclassified','residential','service','trunk','living_street']\n",
    "major_road = major_road + [item + '_link' for item in minor_road]\n",
    "links.loc[links['highway'].isin(major_road),'link_type_new'] = 'major_road'\n",
    "links.loc[links['highway'].isin(minor_road),'link_type_new'] = 'minor_road'\n",
    "links.loc[links['link_type_new'].isna(),'link_type_new'] = links.loc[links['link_type_new'].isna(),'link_type']\n",
    "\n",
    "# links['high_traffic_stress'] = links['link_type_new'] == 'major_road'\n",
    "links['motorized'] = links['link_type_new'].isin(['major_road','minor_road'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format turn attributes\n",
    "Only count left and right turns if going from one road to another road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets turns that are not from road to road to None, effectively ignoring them\n",
    "turns.loc[(turns['source_link_type']!='road') & (turns['target_link_type']!='road'),'turn_type'] = None\n",
    "\n",
    "#create boolean turn type columns\n",
    "turns['left'] = turns['turn_type'] == 'left'\n",
    "turns['right'] = turns['turn_type'] == 'right'\n",
    "turns['straight'] = turns['turn_type'] == 'straight'\n",
    "\n",
    "#unsignalized straight/left turn where crossing street is a major road\n",
    "highway_dict = dict(zip(links['linkid'],links['link_type_new']))\n",
    "turns['source_link_type'] = turns['source_linkid'].map(highway_dict)\n",
    "turns['target_link_type'] = turns['target_linkid'].map(highway_dict)\n",
    "del highway_dict\n",
    "turns['unsig_major_road_crossing'] = (turns['signalized']==False) & (turns['target_link_type']=='major_road') & (turns['source_link_type']=='minor_road')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import directed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links = pd.read_parquet(config['network_fp']/'directed_edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with links\n",
    "link_cols_drop = ['ascent_m', 'ascent_grade_%', 'descent_m', 'descent_grade_%']\n",
    "links.drop(columns=link_cols_drop,inplace=True)\n",
    "directed_cols_to_add = ['linkid','reverse_link','ascent_m','ascent_grade_%']\n",
    "links = pd.merge(links,directed_links[directed_cols_to_add])\n",
    "del directed_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse bike facilities\n",
    "links['facility_fwd'] = np.where(links['reverse_link']==True,links['facility_fwd'],links['facility_rev'])\n",
    "links.drop(columns=['facility_rev'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove wrongway\n",
    "oneway_dict = dict(zip(links['linkid'],links['oneway']))\n",
    "turns['source_oneway'] = turns['source_linkid'].map(oneway_dict)\n",
    "turns['target_oneway'] = turns['target_linkid'].map(oneway_dict)\n",
    "del oneway_dict\n",
    "source_wrongway = ((turns['source_oneway'] == True) & (turns['source_reverse_link'] == True)) == False\n",
    "target_wrongway = ((turns['target_oneway'] == True) & (turns['target_reverse_link'] == True)) == False\n",
    "turns = turns[source_wrongway & target_wrongway]\n",
    "\n",
    "#remove wrongway links\n",
    "#TODO did we remove these in the export network step too?\n",
    "links = links.loc[((links['oneway']==True) & (links['reverse_link']==True)) == False]#,'reverse_link'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format directed link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing NAs for grade\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].fillna(0)\n",
    "#TODO remove negative values from grade %\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].abs()\n",
    "#set any values above X to blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links['ascent_grade_%'].describe()\n",
    "links['above_4'] = links['ascent_grade_%'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['facility_fwd'].isna() | (links['facility_fwd']=='no facility'),'facility_fwd'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links['major_road_w_class_2'] = links['facility_fwd'].isin(['bike lane','buffered bike lane']) & (links['link_type_new'] == 'major road')\n",
    "# links['minor_road_w_class_2'] = links['facility_fwd'].isin(['bike lane','buffered bike lane']) & (links['link_type_new'] == 'minor road')\n",
    "# links['major_road_no_facil'] = (links['major_road_w_class_2'] == False) & (links['link_type_new'] == 'major road')\n",
    "# links['minor_road_no_facil'] = (links['minor_road_w_class_2'] == False) & (links['link_type_new'] == 'minor road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed traffic, no bike lanes\n",
    "#take sharrow out\n",
    "links['mixed_traffic_no_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path','buffered bike lane','cycletrack']) == False)\n",
    "links['mixed_traffic_w_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path','buffered bike lane','cycletrack']) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['mixed_traffic_w_facil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO post GDOT\n",
    "#add elevation adjusted travel times based on assumed speed on flat ground\n",
    "speedfactor.calculate_adjusted_speed(links,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use these, you'll just get the shortest path back\n",
    "links['test_column'] = 0\n",
    "turns['test_column'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_links = links[['A', 'B', 'linkid', 'reverse_link', 'link_type', 'osmid',\n",
    "       'highway', 'oneway', 'name', 'year',\n",
    "       'AADT', 'truck_pct', 'speed', 'length_ft',\n",
    "       'lanes', 'link_type_new', 'motorized', 'facility_fwd', 'improvement', 'ascent_ft',\n",
    "       'ascent_grade_%', 'above_4','mixed_traffic_no_facil', 'mixed_traffic_w_facil',\n",
    "       'travel_time_min',\n",
    "       'test_column','length_mi','geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form the turn graph needed for routing from the turns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = set(export_links['linkid'].tolist())\n",
    "# turns[(turns['source_linkid'].isin(test) == False)|(turns['target_linkid'].isin(test) == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn_G = modeling_turns.make_turn_graph(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export calibration network\n",
    "with (config['calibration_fp']/\"calibration_network.pkl\").open('wb') as fh:\n",
    "    pickle.dump((export_links,turns),fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
