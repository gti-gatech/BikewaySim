{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Post Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "from network.src import modeling_turns\n",
    "import speedfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo, see if there's a way to just have this auto import\n",
    "import json\n",
    "config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "calibration_fp = Path(config['project_directory']) / 'Calibration'\n",
    "cycleatl_fp = Path(config['project_directory']) / 'CycleAtlanta'\n",
    "matching_fp = Path(config['project_directory']) / 'Map_Matching'\n",
    "network_fp = Path(config['project_directory']) / 'Network'\n",
    "if calibration_fp.exists() == False:\n",
    "    calibration_fp.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the impedance calibration results\n",
    "with (calibration_fp/'trip_specific.pkl').open('rb') as fh:\n",
    "    results = pickle.load(fh)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have position of beta next to name of variable\n",
    "#NOTE: keys must be in the currect order used\n",
    "betas_links = {\n",
    "    0 : 'mixed_traffic_no_facil',\n",
    "    1 : 'mixed_traffic_w_facil',\n",
    "    2 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    3 : 'unsig_major_road_crossing'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the network and perform shortest path routing using the impedance coefficients\n",
    "with (calibration_fp/\"calibration_network.pkl\").open('rb') as fh:\n",
    "    links, turns = pickle.load(fh)\n",
    "turn_G = modeling_turns.make_turn_graph(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to add an additional key for the impedance result\n",
    "with (calibration_fp/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    ready_for_calibration = pickle.load(fh)\n",
    "#add user id?\n",
    "ready_for_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.read_pickle(cycleatl_fp/\"trips_3.pkl\")\n",
    "trips_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripids_by_user = pd.read_pickle(calibration_fp/'tripids_by_user.pkl')\n",
    "tripids_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (calibration_fp/'test_set.pkl').open('rb') as fh:\n",
    "    test_set = pickle.load(fh)\n",
    "with (calibration_fp/'train_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve impedance routes\n",
    "#each user has a seperate set and x\n",
    "\n",
    "users_dict = {}\n",
    "\n",
    "for user, item in tqdm(results.items()):\n",
    "\n",
    "    tripids = tripids_by_user.loc[user]\n",
    "    train_set = { key : item0 for key, item0 in train_set.items() if key in tripids}\n",
    "    train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "\n",
    "    betas = item['betas']\n",
    "\n",
    "    base_impedance_col = \"travel_time_min\"\n",
    "    stochastic_optimization.post_calibration_routing(\n",
    "        links, turns, turn_G, base_impedance_col, betas, betas_links, betas_turns,\n",
    "        train_ods, users_dict\n",
    "    )\n",
    "\n",
    "\n",
    "    # base_impedance_col = \"travel_time_min\"\n",
    "    # stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "    # stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "    #                         stochastic_optimization.link_impedance_function,\n",
    "    #                         base_impedance_col,\n",
    "    #                         stochastic_optimization.turn_impedance_function,\n",
    "    #                         links,turns,turn_G)\n",
    "\n",
    "    #find shortest path\n",
    "    #results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "    #add to final dict?\n",
    "    #users_dict.update(results_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (calibration_fp/\"\")\n",
    "users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn dict into dataframe\n",
    "labels = ['userid','Loss'] + list(betas_links.values()) + list(betas_turns.values())\n",
    "loss = [tuple([key,item['loss'],*item['betas']]) for key, item in results.items()]\n",
    "loss = pd.DataFrame.from_records(loss,columns=labels)\n",
    "loss['Loss'] = loss['Loss'].abs()\n",
    "loss.set_index('userid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the impedance routes to the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_test = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "loss_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import user characteristics\n",
    "users_df = pd.read_pickle(cycleatl_fp/\"users_1.pkl\")\n",
    "\n",
    "#replace userid with just the first one\n",
    "def take_first(x):\n",
    "    if isinstance(x,list):\n",
    "        return x[0]\n",
    "    return x\n",
    "users_df['userid'] = users_df['userid'].apply(take_first)\n",
    "\n",
    "#combine data\n",
    "merged = pd.merge(loss,users_df,on='userid')\n",
    "\n",
    "#merged = pd.merge(merged.drop(columns=['userid']),users_df,left_on='remapped_userid',right_on='userid')\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = loss.hist(figsize=(12,12),bins=20,color='grey')\n",
    "\n",
    "# Add a title for the entire figure\n",
    "plt.suptitle(f'User by User Impedance Calibration (n=500)')\n",
    "plt.subplots_adjust(top=0.925)\n",
    "\n",
    "#x_labels = ['(Intersection of Modeled and Chosen) / (Union of Modeled and Chosen)','Distance Proportion Change','Distance Proportion Change','Added Minutes Per Instance','Added Minutes Per Instance','Added Minutes Per Instance']\n",
    "x_lims = [(0,1),(0,9),(0,9),(0,9),(0,9),(0,9)]\n",
    "for i, sub_ax in enumerate(ax.flatten()):\n",
    "    #sub_ax.set_xlabel(x_labels[i])\n",
    "    sub_ax.set_ylabel('Frequency')\n",
    "    #sub_ax.set_xlim(x_lims[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter-intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss['counter'] = loss['mixed_traffic_no_facil'] < loss['mixed_traffic_w_facil']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12, 12), constrained_layout=True)\n",
    "\n",
    "# Add a title for the entire figure\n",
    "fig.suptitle(f'User by User Impedance Calibration')\n",
    "fig.subplots_adjust(top=0.925)\n",
    "\n",
    "categories = [True, False]\n",
    "colors = ['orange','skyblue']\n",
    "\n",
    "# Iterate over features to create stacked histograms\n",
    "for i, feature in enumerate(['mixed_traffic_no_facil', 'mixed_traffic_w_facil', 'above_4','unsig_major_road_crossing']):\n",
    "    ax = axs[i]\n",
    "    for category, color in zip(categories, colors):\n",
    "        ax.hist(\n",
    "            loss[loss['counter'] == category][feature],\n",
    "            bins=20,\n",
    "            stacked=True,\n",
    "            label=category,\n",
    "            alpha=0.5,\n",
    "            color=color,\n",
    "            density=True\n",
    "        )\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(feature)\n",
    "    ax.legend(labels=[f\"True ({(loss['counter']==True).sum()})\",f\"False ({(loss['counter']==False).sum()})\"])\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like people with a higher impedance for roads with bike infrastructure don't differ much on the other characterstics. Next, we should check these users to see what the distribution of roate attributes was like. Maybe these people still avoided major streets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the attribute values vary by the overlap amt?\n",
    "Does not appear to for the coefficients selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.loc[loss['Loss'] > loss['Loss'].mean(),'loss_value'] = \"Above Mean\"\n",
    "loss.loc[loss['loss_value'].isna(),'loss_value'] = \"Below Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12, 12), constrained_layout=True)\n",
    "\n",
    "# Add a title for the entire figure\n",
    "fig.suptitle(f'User by User Impedance Calibration')\n",
    "fig.subplots_adjust(top=0.925)\n",
    "\n",
    "categories = ['Above Mean', 'Below Mean']\n",
    "colors = ['orange','skyblue']\n",
    "\n",
    "# Iterate over features to create stacked histograms\n",
    "for i, feature in enumerate(['mixed_traffic_no_facil', 'mixed_traffic_w_facil', 'above_4','unsig_major_road_crossing']):\n",
    "    ax = axs[i]\n",
    "    for category, color in zip(categories, colors):\n",
    "        ax.hist(\n",
    "            loss[loss['loss_value'] == category][feature],\n",
    "            bins=20,\n",
    "            stacked=True,\n",
    "            label=category,\n",
    "            alpha=0.5,\n",
    "            color=color,\n",
    "            density=True\n",
    "        )\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(feature)\n",
    "    ax.legend()\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "user_data_definitions = json.load((Path.home()/'Documents/GitHub/cycleatlanta/user_data_definition.json').open('rb'))\n",
    "\n",
    "#add the 55+ column\n",
    "user_data_definitions['age']['6'] = '55+'\n",
    "\n",
    "#income has too many nulls\n",
    "tree_cols = ['age','gender','rider_history','rider_type','trip_type','total_distance_ft','avg_speed_mph','count']#,'count']#[,'cycling_freq'\n",
    "tree_df = merged[tree_cols]\n",
    "\n",
    "#use to detect null values\n",
    "isnull = ((tree_df == -1) | (tree_df == 'NULL'))\n",
    "\n",
    "#TODO do cross-sectionals to see which combination results in the most retained entries\n",
    "\n",
    "#remove rows with null values\n",
    "tree_df = tree_df[(isnull==False).all(axis=1)]\n",
    "\n",
    "loss_vals = merged.loc[tree_df.index]\n",
    "\n",
    "get_factor = ['age','rider_history','rider_type']\n",
    "# just fyi\n",
    "# select_max_cols = ['age','income','cycling_freq']\n",
    "# #select the min for these (i.e. strong and fearless over interested but...)\n",
    "# select_min_cols = ['rider_type','rider_history']\n",
    "\n",
    "for col in get_factor:\n",
    "    ivd = {v:k for k, v in user_data_definitions[col].items()}\n",
    "    tree_df[col] = tree_df[col].map(ivd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
