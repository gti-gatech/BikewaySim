{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Calibration\n",
    "1. Assess Results\n",
    "    - Recalculate results for training set using best coefficients\n",
    "    - Use best coefficients to calculate objective function for the test set\n",
    "    - Compare against the shortest path results (with and without the elevation correction) using both training and testing sets\n",
    "1. Look at where calibrated function did the best/worst job for both the training/testing set\n",
    "1. Cluster/segment results based on loss function value?\n",
    "4. Export for application in BikewaySim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "import file_structure_setup\n",
    "config = file_structure_setup.filepaths()\n",
    "\n",
    "from network.src import modeling_turns\n",
    "import speedfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "# calibration_fp = Path(config['project_directory']) / 'Calibration'\n",
    "# cycleatl_fp = Path(config['project_directory']) / 'CycleAtlanta'\n",
    "# matching_fp = Path(config['project_directory']) / 'Map_Matching'\n",
    "# network_fp = Path(config['project_directory']) / 'Network'\n",
    "# if calibration_fp.exists() == False:\n",
    "#     calibration_fp.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Calibration Results and Calibration Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"calibration_network.pkl\").open('rb') as fh:\n",
    "    links,turns = pickle.load(fh)\n",
    "with (config['calibration_fp']/\"calibration_results.pkl\").open('rb') as fh:\n",
    "    calibration_results = pickle.load(fh)\n",
    "turn_G = modeling_turns.make_turn_graph(turns)\n",
    "\n",
    "links['multi use path'] = links['facility_fwd'].isin(['multi use path','cycletrack']).astype(int)\n",
    "links.loc[links['multi use path']==True,'lanes'] = 0\n",
    "\n",
    "links['bike lane'] = links['facility_fwd'].isin(['bike lane','bufferred bike lane']).astype(int)\n",
    "#links.loc[links['bike lane']==True,'']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicts for referencing certain link attributes quickly\n",
    "length_dict = dict(zip(links['linkid'],links['length_ft'])) # need this for loss function\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/'test_set.pkl').open('rb') as fh:\n",
    "#     test_set = pickle.load(fh)\n",
    "# with (config['calibration_fp']/'train_set.pkl').open('rb') as fh:\n",
    "#     train_set = pickle.load(fh)\n",
    "with (config['calibration_fp']/'full_set.pkl').open('rb') as fh:\n",
    "    full_set = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update\n",
    "with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    match_results = pickle.load(fh)\n",
    "\n",
    "# test_set = {key:match_results.get(key,False) for key, item in test_set.items()}\n",
    "# train_set = {key:match_results.get(key,False) for key, item in train_set.items()}\n",
    "# test_set = {key:item for key, item in test_set.items() if item != False}\n",
    "# train_set = {key:item for key, item in train_set.items() if item != False}\n",
    "full_set = {key:match_results.get(key,False) for key, item in full_set.items()}\n",
    "full_set = {key:item for key, item in full_set.items() if item != False}\n",
    "del match_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the ods to the network\n",
    "# train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "# test_ods = stochastic_optimization.match_results_to_ods(test_set)\n",
    "full_ods = stochastic_optimization.match_results_to_ods(full_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path Comparison\n",
    "Not super neccessary becuase we already have these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = stochastic_optimization.jaccard_index\n",
    "loss_function_kwargs = {'length_dict':length_dict}\n",
    "base_impedance_col = \"travel_time_min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shortest path results here for comparison\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "# loss_shortest_train = loss_function(train_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_shortest_train[:,1].mean().round(5))\n",
    "# # 0.29911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in test_ods}\n",
    "# loss_shortest_test = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_shortest_test[:,1].mean().round(5))\n",
    "# # 0.3053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in full_ods}\n",
    "loss_shortest_full = loss_function(full_set,results_dict,**loss_function_kwargs)\n",
    "print(loss_shortest_full[:,1].mean().round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Generate Shortest Paths from Calibrated Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_result = calibration_results[-1]\n",
    "calibration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = list(calibration_result.values())[0:-3]\n",
    "betas_links = calibration_result['beta_links']\n",
    "betas_turns = calibration_result['beta_turns']\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "#betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          stochastic_optimization.link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          stochastic_optimization.turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "full_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in full_ods}\n",
    "\n",
    "#calulate objective function\n",
    "loss_full = loss_function(full_set,full_results_dict,**loss_function_kwargs)\n",
    "loss_full[:,1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the percent change in impedance at the link level for visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check status\n",
    "# didn't work for some reason, go back and check tomorrowa\n",
    "impedance_change = links.copy()\n",
    "impedance_change['imp_prop'] = (impedance_change['link_cost'] - impedance_change['travel_time_min']) / impedance_change['travel_time_min']\n",
    "impedance_change['imp_prop'] = impedance_change['imp_prop'].round(3)\n",
    "impedance_change = impedance_change[impedance_change['reverse_link']==False]\n",
    "impedance_change.to_file(config['calibration_fp']/\"scratch.gpkg\",layer=\"impedance_change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change['imp_prop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change.imp_prop.round(3).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# train_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_train = loss_function(train_set,train_results_dict,**loss_function_kwargs)\n",
    "# loss_train[:,1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# test_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_test = loss_function(test_set,test_results_dict,**loss_function_kwargs)\n",
    "# loss_test[:,1].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test0 = pd.DataFrame(loss_shortest_test,columns=['tripid','shortest'])\n",
    "# test1 = pd.DataFrame(loss_test,columns=['tripid','impedance'])\n",
    "# testing = pd.concat([test0,test1])\n",
    "\n",
    "# train0 = pd.DataFrame(loss_shortest_train,columns=['tripid','shortest'])\n",
    "# train1 = pd.DataFrame(loss_train,columns=['tripid','impedance'])\n",
    "# training = pd.concat([train0,train1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make dataframe and export results\n",
    "# testing = pd.DataFrame({'tripid':list(test_set.keys()),'shortest':loss_shortest_test[:,1],'impedance':loss_test})\n",
    "# testing.to_csv(config['calibration_fp']/'testing_results.csv',index=False)\n",
    "# training = pd.DataFrame({'tripid':list(train_set.keys()),'shortest':loss_shortest_train[:,1],'impedance':loss_train})\n",
    "# training.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.DataFrame({'tripid':list(full_set.keys()),'shortest':loss_shortest_full[:,1],'impedance':loss_full[:,1]})\n",
    "full.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of overlap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#loss_data = pd.DataFrame({'loss_shortest_full':loss_shortest_full,'loss_full':loss_full})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Create the histogram\n",
    "#ax = loss_full_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.hist(full['shortest'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "plt.hist(full['impedance'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# Adding labels, title, and legend with font size adjustments\n",
    "plt.xlabel('Overlap', fontsize=22)\n",
    "plt.ylabel(f'Frequency (N={full.shape[0]})', fontsize=22)\n",
    "#plt.title('Histogram of Training Losses', fontsize=16)\n",
    "#plt.legend(title='Tra Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# Adjusting the font size of the tick labels\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# loss_data = pd.DataFrame({'loss_shortest_train':loss_shortest_train,'loss_train':loss_train})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_train'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_train'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Training Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_data = pd.DataFrame({'loss_shortest_test':loss_shortest_test,'loss_test':loss_test})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_test'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_test'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Testing Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add modeled geometry to results dict for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "for tripid, item in full_set.items():\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled_edges = full_results_dict.get(od,0).get('edge_list',0)\n",
    "    if isinstance(modeled_edges,int):\n",
    "        print(modeled_edges)\n",
    "    #turn to dataframe\n",
    "    modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "    full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the test and train set dictionaries\n",
    "modeled_results = {}\n",
    "# modeled_results.update(train_set)\n",
    "# modeled_results.update(test_set)\n",
    "modeled_results.update(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"full_modeled_results.pkl\").open('wb') as fh:\n",
    "    pickle.dump(modeled_results,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Route Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import summarize_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_summarize = {\n",
    "    'facility_fwd': \"category\",\n",
    "    'AADT': (\"threshold\",[10000]),\n",
    "    'truck_pct': (\"threshold\",[5]),\n",
    "    'here_speed': \"category\",\n",
    "    'lanes': \"category\",\n",
    "    'mixed_traffic_no_facil': \"boolean\",\n",
    "    'mixed_traffic_w_facil': \"boolean\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "turns.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #unit conversions\n",
    "links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "#links.drop(columns=['length_ft','ascent_m'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in test_set.items()]\n",
    "test_summary = summarize_route.procees_summary_results(test_summary,config['projected_crs_epsg'])\n",
    "test_summary.drop(columns=['tripid','geometry']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "train_summary.drop(columns=['tripid','geometry']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and export route attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "testing = pd.read_csv(config['calibration_fp']/'testing_results.csv')\n",
    "training = pd.read_csv(config['calibration_fp']/'training_results.csv')\n",
    "\n",
    "#assume that keys are in the right order?\n",
    "loss_df = pd.concat([testing,training],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trip and user characteristics\n",
    "trips_df = pd.read_pickle(cycleatl_fp/\"trips_3.pkl\")\n",
    "users_df = pd.read_pickle(cycleatl_fp/\"users_1.pkl\")\n",
    "trips_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import route attributes\n",
    "matched_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"matched\")\n",
    "shortest_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"shortest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidate trip types\n",
    "trips_df.loc[trips_df['trip_type']=='other','trip_type'] = 'Other'\n",
    "trips_df.loc[trips_df['trip_type']=='Work-related','trip_type'] = 'Work-Related'\n",
    "trips_df['trip_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace userid with just the first one\n",
    "def take_first(x):\n",
    "    if isinstance(x,list):\n",
    "        return x[0]\n",
    "    return x\n",
    "users_df['userid'] = users_df['userid'].apply(take_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data\n",
    "merged = pd.merge(loss_df,trips_df,on='tripid')\n",
    "merged = pd.merge(merged.drop(columns=['userid']),users_df,left_on='remapped_userid',right_on='userid')\n",
    "merged = pd.merge(merged, summary, on='tripid')\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree #1\n",
    "- First tree is on the non-null variables\n",
    "- The dist. between shortest and impedance were similar and so are the trees\n",
    "- Shorter trips better explained by impedance/shortest path which makes sense\n",
    "    - Use this to split longer trips? and retrain?\n",
    "- Shopping is the only significant trip type variable\n",
    "- Speed above 9 mph is usually better explained by impedance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonulls = ['trip_type','length_mi','avg_speed_mph','(0,4]_prop', '(4,8]_prop',\n",
    "       '(8,inf]_prop', 'AADT_10000_prop', 'facility_fwd_bike lane_prop',\n",
    "       'facility_fwd_cycletrack_prop', 'facility_fwd_multi use path_prop',\n",
    "       'facility_fwd_sharrow_prop', 'here_speed_1_prop', 'here_speed_2_prop',\n",
    "       'here_speed_3_prop', 'here_speed_4_prop', 'lanes_1_prop',\n",
    "       'lanes_2_prop', 'lanes_3_prop', 'left', 'right', 'signalized',\n",
    "       'straight', 'truck_pct_5_prop', 'uturn']\n",
    "nonulls_tree_df = merged[nonulls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "#convert nominal categorical to numeric\n",
    "one_hot_data = pd.get_dummies(nonulls_tree_df,drop_first=True)\n",
    "one_hot_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = one_hot_data.values, merged['impedance'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = one_hot_data.values, merged['impedance'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=5)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to compare predicted values vs actual?\n",
    "SS_res = ((y - clf.predict(X))**2).sum()\n",
    "SS_tot = ((y - y.mean())**2).sum()\n",
    "R2 = 1 - (SS_res/SS_tot)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree #2\n",
    "This one takes the previous variables and adds the user characterstics. Sample size is smaller due to null values\n",
    "\n",
    "- Looks like trip distance is still the dominant one here, really think i should start there\n",
    "- When removing trip distance and avg speed, trip type and age 55+ are the best\n",
    "\n",
    "**NOTE:** just noticed that age should not be dummies, need to fix that and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "user_data_definitions = json.load((Path.home()/'Documents/GitHub/cycleatlanta/user_data_definition.json').open('rb'))\n",
    "\n",
    "#add the 55+ column\n",
    "user_data_definitions['age']['6'] = '55+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#income has too many nulls\n",
    "tree_cols = ['age','gender','rider_history','rider_type'] + nonulls #,'total_distance_ft','avg_speed_mph','count']#,'count']#[,'cycling_freq'\n",
    "tree_df = merged[tree_cols]\n",
    "\n",
    "#use to detect null values\n",
    "isnull = ((tree_df == -1) | (tree_df == 'NULL'))\n",
    "\n",
    "#TODO do cross-sectionals to see which combination results in the most retained entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with null values\n",
    "tree_df = tree_df[(isnull==False).all(axis=1)]\n",
    "\n",
    "loss_vals = merged.loc[tree_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_factor = ['age','rider_history','rider_type']\n",
    "# just fyi\n",
    "# select_max_cols = ['age','income','cycling_freq']\n",
    "# #select the min for these (i.e. strong and fearless over interested but...)\n",
    "# select_min_cols = ['rider_type','rider_history']\n",
    "\n",
    "for col in get_factor:\n",
    "    ivd = {v:k for k, v in user_data_definitions[col].items()}\n",
    "    tree_df[col] = tree_df[col].map(ivd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where i left off\n",
    "#convert nominal categorical to numeric\n",
    "dummy_cols = ['gender','trip_type']\n",
    "one_hot_data = pd.get_dummies(tree_df[dummy_cols],drop_first=True)\n",
    "comb = pd.concat([tree_df.drop(columns=dummy_cols),one_hot_data],ignore_index=False,axis=1)\n",
    "comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = comb.values, loss_vals['impedance'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "clf = clf.fit(X, y)\n",
    "#tree.plot_tree(clf,feature_names=one_hot_data.columns)\n",
    "# Visualize the tree with higher resolution\n",
    "plt.figure(figsize=(20, 10), dpi=300)\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(clf, feature_names=comb.columns, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to compare predicted values vs actual?\n",
    "SS_res = ((y - clf.predict(X))**2).sum()\n",
    "SS_tot = ((y - y.mean())**2).sum()\n",
    "R2 = 1 - (SS_res/SS_tot)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we actually want to know, is what variables help increase the overlap? So wouldn't that be more of an application for linear regression?\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the squared error is already pretty high and our histogram tells us, most of these trips are not currently well predicted with the current impedances. The idea behind using regression trees here is can we figure out if attributes help exmplain the bad overlap?\n",
    "\n",
    "Or we could just try knocking off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = one_hot_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "one_hot_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Distribution of Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Export to get route attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BRouter Results\n",
    "To compare across we'll use Frechet distance. Will need to use next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/'brouter_links.txt').open('r') as file:\n",
    "    my_list = file.readlines()\n",
    "    # Remove any extra whitespace or newline characters\n",
    "    my_list = [line.strip() for line in my_list]\n",
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojsons = list((config['calibration_fp']/'GeoJSON_Out').glob('*.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "len(both_ods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geojsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the results dict combined with the geo dict one\n",
    "results_dict[(68166811, 8789832117)]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_geos = []\n",
    "for geojson in geojsons:\n",
    "    geojson_geo = gpd.read_file(geojson).to_crs(config['projected_crs_epsg'])\n",
    "    geojson_geo = np.array(geojson_geo.geometry.item().coords)\n",
    "    # geojson_geo = [(x, y) for x, y, z in geojson_geo.coords]\n",
    "    # geojson_geo = LineString(geojson_geo)\n",
    "    geojson_geos.append(geojson_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frechet_distance = similaritymeasures.frechet_dist(chosen_coords,modeled_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and compare frechet distance across them with geodict?\n",
    "list(geojson_geo.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_gdf = gpd.read_file(config['calibration_fp']/'route_attributes.gpkg',layer=\"matched\")\n",
    "modeled_gdf = gpd.read_file(config['calibration_fp']/'route_attributes.gpkg',layer=\"modeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
