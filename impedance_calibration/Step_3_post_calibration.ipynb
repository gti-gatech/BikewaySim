{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Calibration\n",
    "In this we look at the quality of the calibrated impedance functions.\n",
    "---\n",
    "1. Recalculate shortest path results using the calibrated coefficients\n",
    "1. Calculate objective functions and other performance metrics\n",
    "1. Get route attribute summary for the chosen/shortest/modeled routes (right now)\n",
    "\n",
    "\n",
    "Still Working On\n",
    "1. Look at where calibrated function did the best/worst job for both the training/testing set\n",
    "1. Cluster/segment results based on loss function value?\n",
    "4. Export for application in BikewaySim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.network import modeling_turns\n",
    "from bikewaysim.impedance_calibration import stochastic_optimization, speedfactor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relevant Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns, length_dict, geo_dict, turn_G = stochastic_optimization.import_calibration_network(config)\n",
    "with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    full_set = pickle.load(fh)\n",
    "full_ods = stochastic_optimization.match_results_to_ods(full_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get shortest and chosen stats first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in full_set.items():\n",
    "    \n",
    "    chosen = item['matched_edges'].values\n",
    "    shortest = item['shortest_edges'].values\n",
    "\n",
    "    test0 = {\n",
    "        'chosen_length': round(np.array([length_dict.get(tripid[0],0) for tripid in chosen]).sum()/5280,2),\n",
    "        'shortest_length': round(np.array([length_dict.get(tripid[0],0) for tripid in shortest]).sum()/5280,2),\n",
    "        'chosen_detour': round(stochastic_optimization.detour_factor(chosen,shortest,length_dict),2),\n",
    "        'shortest_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,shortest,length_dict),2),\n",
    "        'shortest_buffer': round(stochastic_optimization.buffer_overlap(chosen,shortest,geo_dict),2),\n",
    "    }\n",
    "    full_set[key].update(test0)\n",
    "\n",
    "# export new version\n",
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('wb') as fh:\n",
    "    pickle.dump(full_set,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the current calibration results\n",
    "calibration_result_fps = list((config['calibration_fp']/\"calibration_results\").glob('*.pkl'))\n",
    "\n",
    "# pick a specific model\n",
    "specific_model = 'calibration2_new'\n",
    "calibration_result_fps = [x for x in calibration_result_fps if specific_model == x.stem.split('(')[0].strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals = {}\n",
    "for idx, calibration_result_fp in enumerate(calibration_result_fps):\n",
    "    with calibration_result_fp.open('rb') as fh:\n",
    "        calibration_result = pickle.load(fh)\n",
    "    beta_vals[calibration_result_fp.stem] = {x['col']:x['beta'] for x in calibration_result['betas_tup']}\n",
    "beta_vals = pd.DataFrame().from_dict(beta_vals,orient='index')\n",
    "# beta_vals.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals = {}\n",
    "\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "#NOTE TEMP\n",
    "calibration_result_fps = [calibration_result_fps[0]]\n",
    "\n",
    "for idx, calibration_result_fp in enumerate(calibration_result_fps):\n",
    "    print('Calibration result',idx+1,'out of',len(calibration_result_fps))\n",
    "    with calibration_result_fp.open('rb') as fh:\n",
    "        calibration_result = pickle.load(fh)\n",
    "\n",
    "    beta_vals[calibration_result_fp.stem] = {x['col']:x['beta'] for x in calibration_result['betas_tup']}\n",
    "\n",
    "    base_impedance_col = \"travel_time_min\"\n",
    "    betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "    print(betas)\n",
    "    stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "    stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                            stochastic_optimization.link_impedance_function,\n",
    "                            base_impedance_col,\n",
    "                            stochastic_optimization.turn_impedance_function,\n",
    "                            links,turns,turn_G)\n",
    "    modeled_results_sp = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in tqdm(full_ods,total=len(full_ods))}\n",
    "    modeled_results_dict = {}\n",
    "    for tripid, item in full_set.items():\n",
    "        chosen = item['matched_edges'].values\n",
    "        shortest = item['shortest_edges'].values\n",
    "        od = (item['origin_node'],item['destination_node'])\n",
    "        modeled = modeled_results_sp[od]['edge_list']\n",
    "    \n",
    "        modeled_results_dict[tripid] = {\n",
    "            'modeled_edges': pd.DataFrame(modeled,columns=['linkid','reverse_link']),\n",
    "            'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,1),\n",
    "            'modeled_detour': round(stochastic_optimization.detour_factor(modeled,shortest,length_dict),2),\n",
    "            'modeled_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,modeled,length_dict),2),\n",
    "            'modeled_buffer': round(stochastic_optimization.buffer_overlap(chosen,modeled,geo_dict),2),\n",
    "            'test': stochastic_optimization.jaccard_index_total(chosen,modeled,length_dict) # returns tuple\n",
    "        }\n",
    "    \n",
    "    jaccard_mean = np.array([item['modeled_jaccard'] for tripid, item in modeled_results_dict.items()]).mean()\n",
    "    buffer_mean = np.array([item['modeled_buffer'] for tripid, item in modeled_results_dict.items()]).mean()\n",
    "    jaccrd_total = np.array([item['test'] for tripid, item in modeled_results_dict.items()])\n",
    "    jaccrd_total = jaccrd_total[:,0].sum() / jaccrd_total[:,1].sum()\n",
    "    jaccard_mean2 = np.sum(jaccrd_total[:,0] / jaccrd_total[:,1]) / jaccrd_total.shape[0]\n",
    "    print(jaccard_mean,jaccard_mean2)\n",
    "    \n",
    "    print('Mean Jaccard Index',round(jaccard_mean,2),'Mean Buffer',round(buffer_mean,2))\n",
    "    with (config['calibration_fp']/'post_calibration'/(calibration_result_fp.stem+'.pkl')).open('wb') as fh:\n",
    "        pickle.dump(modeled_results_dict,fh)\n",
    "\n",
    "# get fit stats\n",
    "# TODO get the length weighted versions\n",
    "shortest_jaccard_mean = np.array([item['shortest_jaccard'] for tripid, item in full_set.items()]).mean()\n",
    "shortest_buffer_mean = np.array([item['shortest_buffer'] for tripid, item in full_set.items()]).mean()\n",
    "print('Mean Jaccard Index',round(shortest_jaccard_mean,2),'Mean Buffer',round(shortest_buffer_mean,2))\n",
    "\n",
    "shortest_jaccard = {tripid:item['shortest_jaccard'] for tripid, item in full_set.items()}\n",
    "shortest_jaccard = pd.Series(shortest_jaccard)\n",
    "shortest_jaccard.name = 'shortest_jaccard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccrd_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([(3,4),(3,4)])\n",
    "x[:,0].sum() / x[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all of the intersects intersect of chosen and modeled / sum of all of the unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_calibration_result_fps = list((config['calibration_fp']/\"post_calibration\").glob('*.pkl'))\n",
    "\n",
    "# pick a specific model\n",
    "specific_model = 'calibration2_new'\n",
    "calibration_result_fps = [x for x in calibration_result_fps if specific_model == x.stem.split('(')[0].strip()]\n",
    "post_calibration_result_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#aggregated results and overlap figures\n",
    "mean_values = []\n",
    "for idx, post_calibration_result_fp in enumerate(post_calibration_result_fps):\n",
    "    print('Calibration result',post_calibration_result_fp.stem)\n",
    "    with post_calibration_result_fp.open('rb') as fh:\n",
    "        post_calibration_result = pickle.load(fh)\n",
    "\n",
    "    jaccard_mean = np.array([item['modeled_jaccard'] for tripid, item in post_calibration_result.items()]).mean()\n",
    "    buffer_mean = np.array([item['modeled_buffer'] for tripid, item in post_calibration_result.items()]).mean()\n",
    "    mean_values.append((post_calibration_result_fp.stem,round(jaccard_mean,2),round(buffer_mean,2)))\n",
    "\n",
    "    print('Mean Jaccard Index',round(jaccard_mean,2),'Mean Buffer',round(buffer_mean,2))\n",
    "    # with (config['calibration_fp']/'post_calibration'/(calibration_result_fp.stem+'.pkl')).open('wb') as fh:\n",
    "    #     pickle.dump(modeled_results_dict,fh)\n",
    "\n",
    "    #get just jaccard values\n",
    "    modeled_jaccard = {tripid:item['modeled_jaccard'] for tripid, item in post_calibration_result.items()}\n",
    "    modeled_jaccard = pd.Series(modeled_jaccard)\n",
    "    modeled_jaccard.name = 'modeled_jaccard'\n",
    "    df = pd.concat([shortest_jaccard,modeled_jaccard],axis=1,ignore_index=False)\n",
    "\n",
    "    # make figures\n",
    "    # Create the histogram\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.hist(df['shortest_jaccard'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "    plt.hist(df['modeled_jaccard'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "    # Adding labels, title, and legend with font size adjustments\n",
    "    plt.xlabel('Overlap', fontsize=22)\n",
    "    plt.ylabel(f'Frequency (N={df.shape[0]})', fontsize=22)\n",
    "    plt.title(post_calibration_result_fp.stem, fontsize=16)\n",
    "    plt.legend(title='Jaccard Index', fontsize=22, title_fontsize=22)\n",
    "    plt.ylim([0,700])\n",
    "\n",
    "    # Adjusting the font size of the tick labels\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(config['calibration_fp']/'calibration_performance'/(post_calibration_result_fp.stem + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_result['betas_tup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(mean_values,columns=['calibration_name','jaccard_mean','buffer_mean'])\n",
    "metrics.set_index('calibration_name',inplace=True)\n",
    "metrics.sort_values('jaccard_mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort_values('buffer_mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff past here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the betas too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# #loss_data = pd.DataFrame({'loss_shortest_full':loss_shortest_full,'loss_full':loss_full})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_full_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# #get just jaccard values\n",
    "# shortest_jaccard = {tripid:item['shortest_jaccard'] for tripid, item in full_set.items()}\n",
    "# modeled_jaccard = {tripid:item['modeled_jaccard'] for tripid, item in post_calibration_result.items()}\n",
    "# shortest_jaccard = pd.Series(shortest_jaccard)\n",
    "# shortest_jaccard.name = 'shortest_jaccard'\n",
    "# modeled_jaccard = pd.Series(modeled_jaccard)\n",
    "# modeled_jaccard.name = 'modeled_jaccard'\n",
    "\n",
    "# df = pd.concat([shortest_jaccard,modeled_jaccard],axis=1,ignore_index=False)\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(df['shortest_jaccard'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(df['modeled_jaccard'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel(f'Frequency (N={df.shape[0]})', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Jaccard Index', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get all the coefficient values in one dataframe that have\n",
    "# cols = ['multi use path','bike lane','lanes','above_4','unsig_major_road_crossing']\n",
    "\n",
    "# # each row is a calibration result, each column corresponds to a beta\n",
    "# constr = []\n",
    "# for idx, results in enumerate(calibration_result):\n",
    "#     results = {x['col']:x['beta'] for x in results['betas_tup']}\n",
    "#     x = set(list(results.keys()))\n",
    "#     y = set(cols)\n",
    "#     cond1 = len(set.union(x,y)) == len(cols)\n",
    "#     cond2 = len(set.intersection(x,y)) == len(cols)\n",
    "#     if cond1 & cond2:\n",
    "#         results['idx'] = idx\n",
    "#         constr.append(results)\n",
    "# beta_vals = pd.DataFrame.from_records(constr)\n",
    "# beta_vals.set_index('idx',inplace=True)\n",
    "# beta_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUG the calibration process is not retrieving the correct coefficients anymore\n",
    "# betas = [-0.184,-0.398,0.126,0.325,0.324]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-calculate shortest path results for all the modeleling attempts so that we can get standardized performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = {}\n",
    "\n",
    "for idx,calibration_result in enumerate(calibration_results):\n",
    "\n",
    "    base_impedance_col = \"travel_time_min\"\n",
    "    betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "    print(betas)\n",
    "    stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "    stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "                            stochastic_optimization.link_impedance_function,\n",
    "                            base_impedance_col,\n",
    "                            stochastic_optimization.turn_impedance_function,\n",
    "                            links,turns,turn_G)\n",
    "    modeled_results = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in full_ods}\n",
    "\n",
    "    #TODO so can this\n",
    "    #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "    for tripid, item in full_set.items():\n",
    "        od = (item['origin_node'],item['destination_node'])\n",
    "        modeled_edges = modeled_results[od]['edge_list']\n",
    "        #turn to dataframe\n",
    "        modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "        full_set[tripid].update({f\"modeled_edges_{idx}\":modeled_edges})\n",
    "\n",
    "    #TODO can also probably be a function\n",
    "    from importlib import reload\n",
    "    reload(stochastic_optimization)\n",
    "    test = {}\n",
    "\n",
    "    geo_dict = dict(zip(links['linkid'],links.geometry))\n",
    "    length_dict = dict(zip(links['linkid'],links.length))\n",
    "\n",
    "    for key, item in full_set.items():\n",
    "        \n",
    "        chosen = item['matched_edges'].values\n",
    "        shortest = item['shortest_edges'].values\n",
    "        modeled = item[f\"modeled_edges_{idx}\"].values\n",
    "\n",
    "        test0 = {\n",
    "            #lengths\n",
    "            'chosen_length': round(np.array([length_dict.get(tripid[0],0) for tripid in chosen]).sum()/5280,2),\n",
    "            'shortest_length': round(np.array([length_dict.get(tripid[0],0) for tripid in shortest]).sum()/5280,2),\n",
    "            'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,2),\n",
    "            # detour\n",
    "            'chosen_detour': round(stochastic_optimization.detour_factor(chosen,shortest,length_dict),2),\n",
    "            'modeled_detour': round(stochastic_optimization.detour_factor(modeled,shortest,length_dict),2),\n",
    "            # jaccard\n",
    "            'shortest_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,shortest,length_dict),2),\n",
    "            'modeled_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,modeled,length_dict),2),\n",
    "            # buffer\n",
    "            'shortest_buffer': round(stochastic_optimization.buffer_overlap(chosen,shortest,geo_dict),2),\n",
    "            'modeled_buffer': round(stochastic_optimization.buffer_overlap(chosen,modeled,geo_dict),2),\n",
    "            # frechet\n",
    "            'shortest_frechet': round(stochastic_optimization.frechet_distance(chosen,shortest,geo_dict),2),\n",
    "            'modeled_frechet': round(stochastic_optimization.frechet_distance(chosen,modeled,geo_dict),2)\n",
    "        }\n",
    "        test[key] = test0\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict(test,orient='index')\n",
    "    \n",
    "    to_add[idx] = results_df.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(to_add,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_impedance_col = \"travel_time_min\"\n",
    "# betas = [x['beta'] for x in calibration_result['betas_tup']]\n",
    "# print(betas)\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# stochastic_optimization.impedance_update(betas,calibration_result['betas_tup'],\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "# modeled_results = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in full_ods}\n",
    "\n",
    "# #TODO so can this\n",
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in full_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = modeled_results[od]['edge_list']\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"full_modeled_results.pkl\").open('wb') as fh:\n",
    "    pickle.dump(full_set,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate all the possible overlap metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"full_modeled_results.pkl\").open('rb') as fh:\n",
    "    full_set = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO can also probably be a function\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "test = {}\n",
    "\n",
    "geo_dict = dict(zip(links['linkid'],links.geometry))\n",
    "length_dict = dict(zip(links['linkid'],links.length))\n",
    "\n",
    "for key, item in full_set.items():\n",
    "    \n",
    "    chosen = item['matched_edges'].values\n",
    "    shortest = item['shortest_edges'].values\n",
    "    modeled = item['modeled_edges'].values\n",
    "\n",
    "    test0 = {\n",
    "        #lengths\n",
    "        'chosen_length': round(np.array([length_dict.get(tripid[0],0) for tripid in chosen]).sum()/5280,2),\n",
    "        'shortest_length': round(np.array([length_dict.get(tripid[0],0) for tripid in shortest]).sum()/5280,2),\n",
    "        'modeled_length': round(np.array([length_dict.get(tripid[0],0) for tripid in modeled]).sum()/5280,2),\n",
    "        # detour\n",
    "        'chosen_detour': round(stochastic_optimization.detour_factor(chosen,shortest,length_dict),2),\n",
    "        'modeled_detour': round(stochastic_optimization.detour_factor(chosen,modeled,length_dict),2),\n",
    "        # jaccard\n",
    "        'shortest_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,shortest,length_dict),2),\n",
    "        'modeled_jaccard': round(stochastic_optimization.jaccard_index_func(chosen,modeled,length_dict),2),\n",
    "        # buffer\n",
    "        'shortest_buffer': round(stochastic_optimization.buffer_overlap(chosen,shortest,geo_dict),2),\n",
    "        'modeled_buffer': round(stochastic_optimization.buffer_overlap(chosen,modeled,geo_dict),2),\n",
    "        # frechet\n",
    "        'shortest_frechet': round(stochastic_optimization.frechet_distance(chosen,shortest,geo_dict),2),\n",
    "        'modeled_frechet': round(stochastic_optimization.frechet_distance(chosen,modeled,geo_dict),2)\n",
    "    }\n",
    "    test[key] = test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(test,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['chosen_detour']<1].hist('chosen_detour',bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 5 mins/first 30%\n",
    "If you deviate from the shortest path do you eventually come back or not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['chosen_detour']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to add additional rows to find where they performed best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add route attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import impedance_calibration.src.summarize_route as summarize_route\n",
    "reload(summarize_route)\n",
    "\n",
    "chosen_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['matched_edges'].values,links,turns) for tripid in full_set.keys()}\n",
    "shortest_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['shortest_edges'].values,links,turns) for tripid in full_set.keys()} \n",
    "modeled_attr = {tripid:summarize_route.route_attributes1(tripid,full_set[tripid]['modeled_edges'].values,links,turns) for tripid in full_set.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_attr = pd.DataFrame.from_dict(chosen_attr,orient='index')\n",
    "shortest_attr = pd.DataFrame.from_dict(shortest_attr,orient='index')\n",
    "modeled_attr = pd.DataFrame.from_dict(modeled_attr,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.reset_index().to_csv(config['calibration_fp']/'objective_functions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(config['calibration_fp']/'objective_functions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.mean().drop('index').to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting/labeling trips\n",
    "Want to know which attributes help lead to a loss function value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree #1\n",
    "Want to see if percent detour or if any of the chosen route characterstics (that were accounted for in the calibration process) contributed to the overlap value (modeled_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = pd.concat([results_df[['chosen_length','chosen_detour','modeled_jaccard']],chosen_attr],axis=1)\n",
    "\n",
    "tree_df['lanes_above_1'] = tree_df['lane_2'] + tree_df['lane_3']\n",
    "tree_df.drop(columns=['lane_0','lane_1','lane_2','lane_3'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First split is the chosen detour rate. 1,377 trips (over half) have a detour rate above 10.5% and this is associated with a bigger reduction in overlap. Past this it appears that trips that took a lot \n",
    "\n",
    "Second split is on chosen length and chosen detour rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree\n",
    "\n",
    "X, y = tree_df.drop(columns=['modeled_jaccard']).values, tree_df['modeled_jaccard'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=tree_df.drop(columns=['modeled_jaccard']).columns, filled=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X, y = tree_df.drop(columns=['modeled_jaccard']), tree_df['modeled_jaccard']\n",
    "X = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X).fit()\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df.sort_values('unsig_major_road_crossing',ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = one_hot_data.values, merged['impedance'].values\n",
    "clf = tree.DecisionTreeRegressor(max_depth=5)\n",
    "clf = clf.fit(X, y)\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "plt.show()\n",
    "how to compare predicted values vs actual?\n",
    "SS_res = ((y - clf.predict(X))**2).sum()\n",
    "SS_tot = ((y - y.mean())**2).sum()\n",
    "R2 = 1 - (SS_res/SS_tot)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"full_modeled_results.pkl\").open('rb') as fh:\n",
    "#     modeled_results = pickle.load(fh)\n",
    "## Add Route Attributes\n",
    "import impedance_calibration.src.summarize_route as summarize_route\n",
    "cols_to_summarize = {\n",
    "    'facility_fwd': \"category\",\n",
    "    'AADT': (\"threshold\",[10000]),\n",
    "    'truck_pct': (\"threshold\",[5]),\n",
    "    'speed': \"category\",\n",
    "    'lanes': \"category\",\n",
    "    'mixed_traffic_no_facil': \"boolean\",\n",
    "    'mixed_traffic_w_facil': \"boolean\"\n",
    "}\n",
    "links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "turns.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "links.columns\n",
    "# #unit conversions\n",
    "#links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "#links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "#links.drop(columns=['length_ft','ascent_m'],inplace=True)\n",
    "test_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in full_set.items()]\n",
    "test_summary = summarize_route.procees_summary_results(test_summary,config['projected_crs_epsg'])\n",
    "test_summary.drop(columns=['tripid','geometry']).describe()\n",
    "train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the percent change in impedance at the link level for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change = links.copy()\n",
    "impedance_change['imp_prop'] = (impedance_change['link_cost'] - impedance_change['travel_time_min']) / impedance_change['travel_time_min']\n",
    "impedance_change['imp_prop'] = impedance_change['imp_prop'].round(3)\n",
    "impedance_change = impedance_change[impedance_change['reverse_link']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo automate the plot generation for when qgis isn't available\n",
    "impedance_change.plot('imp_prop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change.to_file(config['calibration_fp']/\"network_impedance_change.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change['imp_prop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(impedance_change['imp_prop'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(impedance_change['imp_prop']==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance_change.imp_prop.round(3).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# train_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,links,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_train = loss_function(train_set,train_results_dict,**loss_function_kwargs)\n",
    "# loss_train[:,1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# base_impedance_col = \"travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# #betas = #past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           stochastic_optimization.link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           stochastic_optimization.turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# test_results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# loss_test = loss_function(test_set,test_results_dict,**loss_function_kwargs)\n",
    "# loss_test[:,1].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test0 = pd.DataFrame(loss_shortest_test,columns=['tripid','shortest'])\n",
    "# test1 = pd.DataFrame(loss_test,columns=['tripid','impedance'])\n",
    "# testing = pd.concat([test0,test1])\n",
    "\n",
    "# train0 = pd.DataFrame(loss_shortest_train,columns=['tripid','shortest'])\n",
    "# train1 = pd.DataFrame(loss_train,columns=['tripid','impedance'])\n",
    "# training = pd.concat([train0,train1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make dataframe and export results\n",
    "# testing = pd.DataFrame({'tripid':list(test_set.keys()),'shortest':loss_shortest_test[:,1],'impedance':loss_test})\n",
    "# testing.to_csv(config['calibration_fp']/'testing_results.csv',index=False)\n",
    "# training = pd.DataFrame({'tripid':list(train_set.keys()),'shortest':loss_shortest_train[:,1],'impedance':loss_train})\n",
    "# training.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble dataframe of overlap metrics\n",
    "Dataframe that adds in jaccard index, frechet dist, detour percent, etc into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set[71].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "#calulate objective function\n",
    "test = stochastic_optimization.general_objective_function(\n",
    "    stochastic_optimization.frechet_distance,\n",
    "    full_set,\n",
    "    results_dict,\n",
    "    links)\n",
    "test#print(loss_full[:,1].mean().round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.DataFrame({'tripid':list(full_set.keys()),'shortest':loss_shortest_full[:,1],'impedance':loss_full[:,1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv(config['calibration_fp']/'training_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of overlap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#loss_data = pd.DataFrame({'loss_shortest_full':loss_shortest_full,'loss_full':loss_full})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Create the histogram\n",
    "#ax = loss_full_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.hist(full['shortest'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "plt.hist(full['impedance'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# Adding labels, title, and legend with font size adjustments\n",
    "plt.xlabel('Overlap', fontsize=22)\n",
    "plt.ylabel(f'Frequency (N={full.shape[0]})', fontsize=22)\n",
    "#plt.title('Histogram of Training Losses', fontsize=16)\n",
    "#plt.legend(title='Tra Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# Adjusting the font size of the tick labels\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# loss_data = pd.DataFrame({'loss_shortest_train':loss_shortest_train,'loss_train':loss_train})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_train'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_train'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Training Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_data = pd.DataFrame({'loss_shortest_test':loss_shortest_test,'loss_test':loss_test})\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Create the histogram\n",
    "# #ax = loss_train_df.plot.hist(stacked=True, bins=20, figsize=(12, 12), color=['grey', 'lightgrey'])\n",
    "\n",
    "# # Create the histogram\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.hist(loss_data['loss_shortest_test'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "# plt.hist(loss_data['loss_test'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# # Adding labels, title, and legend with font size adjustments\n",
    "# plt.xlabel('Overlap', fontsize=22)\n",
    "# plt.ylabel('Frequency', fontsize=22)\n",
    "# #plt.title('Histogram of Training Losses', fontsize=16)\n",
    "# plt.legend(title='Testing Overlap', fontsize=22, title_fontsize=22)\n",
    "\n",
    "# # Adjusting the font size of the tick labels\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add modeled geometry to results dict for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "for tripid, item in full_set.items():\n",
    "    od = (item['origin_node'],item['destination_node'])\n",
    "    modeled_edges = full_results_dict.get(od,0).get('edge_list',0)\n",
    "    if isinstance(modeled_edges,int):\n",
    "        print(modeled_edges)\n",
    "    #turn to dataframe\n",
    "    modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "    full_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add a new modeled edges field so that we can calculate the modeled edges entry\n",
    "# for tripid, item in test_set.items():\n",
    "#     od = (item['origin_node'],item['destination_node'])\n",
    "#     modeled_edges = test_results_dict.get(od,0).get('edge_list',0)\n",
    "#     if isinstance(modeled_edges,int):\n",
    "#         print(modeled_edges)\n",
    "#     #turn to dataframe\n",
    "#     modeled_edges = pd.DataFrame(modeled_edges,columns=['linkid','reverse_link'])\n",
    "#     test_set[tripid].update({'modeled_edges':modeled_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the test and train set dictionaries\n",
    "modeled_results = {}\n",
    "# modeled_results.update(train_set)\n",
    "# modeled_results.update(test_set)\n",
    "modeled_results.update(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (config['calibration_fp']/\"full_modeled_results.pkl\").open('wb') as fh:\n",
    "    pickle.dump(modeled_results,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAQC (separate into a separate notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/\"full_modeled_results.pkl\").open('rb') as fh:\n",
    "#     modeled_results = pickle.load(fh)\n",
    "# ## Add Route Attributes\n",
    "# import summarize_route\n",
    "# cols_to_summarize = {\n",
    "#     'facility_fwd': \"category\",\n",
    "#     'AADT': (\"threshold\",[10000]),\n",
    "#     'truck_pct': (\"threshold\",[5]),\n",
    "#     'here_speed': \"category\",\n",
    "#     'lanes': \"category\",\n",
    "#     'mixed_traffic_no_facil': \"boolean\",\n",
    "#     'mixed_traffic_w_facil': \"boolean\"\n",
    "# }\n",
    "# links.set_index(['linkid','reverse_link'],inplace=True)\n",
    "# turns.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "# links.columns\n",
    "# # #unit conversions\n",
    "# #links['length_mi'] = (links['length_ft'] / 5280).round(2)\n",
    "# #links['ascent_ft'] = (links['ascent_m'] * 3.28084).round(0)\n",
    "# #links.drop(columns=['length_ft','ascent_m'],inplace=True)\n",
    "# test_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in full_set.items()]\n",
    "# test_summary = summarize_route.procees_summary_results(test_summary,config['projected_crs_epsg'])\n",
    "# test_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "# train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "# train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# train_summary = [summarize_route.route_attributes(key,item,'modeled_edges',cols_to_summarize,links,turns) for key, item in train_set.items()]\n",
    "# train_summary = summarize_route.procees_summary_results(train_summary,config['projected_crs_epsg'])\n",
    "# train_summary.drop(columns=['tripid','geometry']).describe()\n",
    "# summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')\n",
    "# summary.columns\n",
    "# summary = pd.concat([test_summary,train_summary],ignore_index=True)\n",
    "# summary.to_file(config['calibration_fp']/\"route_attributes.gpkg\",layer='modeled')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Regression Trees\n",
    "# from sklearn import tree\n",
    "\n",
    "# testing = pd.read_csv(config['calibration_fp']/'testing_results.csv')\n",
    "# training = pd.read_csv(config['calibration_fp']/'training_results.csv')\n",
    "\n",
    "# #assume that keys are in the right order?\n",
    "# loss_df = pd.concat([testing,training],ignore_index=True)\n",
    "# #import trip and user characteristics\n",
    "# trips_df = pd.read_pickle(cycleatl_fp/\"trips_3.pkl\")\n",
    "# users_df = pd.read_pickle(cycleatl_fp/\"users_1.pkl\")\n",
    "# trips_df.reset_index(drop=True,inplace=True)\n",
    "# #import route attributes\n",
    "# matched_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"matched\")\n",
    "# shortest_summary = gpd.read_file(config['calibration_fp']/\"route_attributes.gpkg\",layer=\"shortest\")\n",
    "# #consolidate trip types\n",
    "# trips_df.loc[trips_df['trip_type']=='other','trip_type'] = 'Other'\n",
    "# trips_df.loc[trips_df['trip_type']=='Work-related','trip_type'] = 'Work-Related'\n",
    "# trips_df['trip_type'].value_counts()\n",
    "# #replace userid with just the first one\n",
    "# def take_first(x):\n",
    "#     if isinstance(x,list):\n",
    "#         return x[0]\n",
    "#     return x\n",
    "# users_df['userid'] = users_df['userid'].apply(take_first)\n",
    "# #consolidate trip types\n",
    "# trips_df.loc[trips_df['trip_type']=='other','trip_type'] = 'Other'\n",
    "# trips_df.loc[trips_df['trip_type']=='Work-related','trip_type'] = 'Work-Related'\n",
    "# trips_df['trip_type'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Tree #1\n",
    "# - First tree is on the non-null variables\n",
    "# - The dist. between shortest and impedance were similar and so are the trees\n",
    "# - Shorter trips better explained by impedance/shortest path which makes sense\n",
    "#     - Use this to split longer trips? and retrain?\n",
    "# - Shopping is the only significant trip type variable\n",
    "# - Speed above 9 mph is usually better explained by impedance\n",
    "# ## Tree #1\n",
    "# - First tree is on the non-null variables\n",
    "# - The dist. between shortest and impedance were similar and so are the trees\n",
    "# - Shorter trips better explained by impedance/shortest path which makes sense\n",
    "#     - Use this to split longer trips? and retrain?\n",
    "# - Shopping is the only significant trip type variable\n",
    "# - Speed above 9 mph is usually better explained by impedance\n",
    "# nonulls = ['trip_type','length_mi','avg_speed_mph','(0,4]_prop', '(4,8]_prop',\n",
    "#        '(8,inf]_prop', 'AADT_10000_prop', 'facility_fwd_bike lane_prop',\n",
    "#        'facility_fwd_cycletrack_prop', 'facility_fwd_multi use path_prop',\n",
    "#        'facility_fwd_sharrow_prop', 'here_speed_1_prop', 'here_speed_2_prop',\n",
    "#        'here_speed_3_prop', 'here_speed_4_prop', 'lanes_1_prop',\n",
    "#        'lanes_2_prop', 'lanes_3_prop', 'left', 'right', 'signalized',\n",
    "#        'straight', 'truck_pct_5_prop', 'uturn']\n",
    "# nonulls_tree_df = merged[nonulls]\n",
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# #convert nominal categorical to numeric\n",
    "# one_hot_data = pd.get_dummies(nonulls_tree_df,drop_first=True)\n",
    "# one_hot_data.columns\n",
    "# X, y = one_hot_data.values, merged['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "# clf = clf.fit(X, y)\n",
    "# fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "# plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "# plt.show()\n",
    "# X, y = one_hot_data.values, merged['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=5)\n",
    "# clf = clf.fit(X, y)\n",
    "# fig, ax = plt.subplots(figsize=(20, 10), dpi=300)\n",
    "# plot_tree(clf, feature_names=one_hot_data.columns, filled=True, ax=ax)\n",
    "# plt.show()\n",
    "# how to compare predicted values vs actual?\n",
    "# SS_res = ((y - clf.predict(X))**2).sum()\n",
    "# SS_tot = ((y - y.mean())**2).sum()\n",
    "# R2 = 1 - (SS_res/SS_tot)\n",
    "# R2\n",
    "# ## Tree #2\n",
    "# This one takes the previous variables and adds the user characterstics. Sample size is smaller due to null values\n",
    "\n",
    "# - Looks like trip distance is still the dominant one here, really think i should start there\n",
    "# - When removing trip distance and avg speed, trip type and age 55+ are the best\n",
    "\n",
    "# **NOTE:** just noticed that age should not be dummies, need to fix that and try again\n",
    "# import json\n",
    "# user_data_definitions = json.load((Path.home()/'Documents/GitHub/cycleatlanta/user_data_definition.json').open('rb'))\n",
    "\n",
    "# #add the 55+ column\n",
    "# user_data_definitions['age']['6'] = '55+'\n",
    "# #income has too many nulls\n",
    "# tree_cols = ['age','gender','rider_history','rider_type'] + nonulls #,'total_distance_ft','avg_speed_mph','count']#,'count']#[,'cycling_freq'\n",
    "# tree_df = merged[tree_cols]\n",
    "\n",
    "# #use to detect null values\n",
    "# isnull = ((tree_df == -1) | (tree_df == 'NULL'))\n",
    "\n",
    "# #TODO do cross-sectionals to see which combination results in the most retained entries\n",
    "# #remove rows with null values\n",
    "# tree_df = tree_df[(isnull==False).all(axis=1)]\n",
    "\n",
    "# loss_vals = merged.loc[tree_df.index]\n",
    "# get_factor = ['age','rider_history','rider_type']\n",
    "# # just fyi\n",
    "# # select_max_cols = ['age','income','cycling_freq']\n",
    "# # #select the min for these (i.e. strong and fearless over interested but...)\n",
    "# # select_min_cols = ['rider_type','rider_history']\n",
    "\n",
    "# for col in get_factor:\n",
    "#     ivd = {v:k for k, v in user_data_definitions[col].items()}\n",
    "#     tree_df[col] = tree_df[col].map(ivd)\n",
    "# tree_df\n",
    "# #this is where i left off\n",
    "# #convert nominal categorical to numeric\n",
    "# dummy_cols = ['gender','trip_type']\n",
    "# one_hot_data = pd.get_dummies(tree_df[dummy_cols],drop_first=True)\n",
    "# comb = pd.concat([tree_df.drop(columns=dummy_cols),one_hot_data],ignore_index=False,axis=1)\n",
    "# comb\n",
    "# X, y = comb.values, loss_vals['impedance'].values\n",
    "# clf = tree.DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "# clf = clf.fit(X, y)\n",
    "# #tree.plot_tree(clf,feature_names=one_hot_data.columns)\n",
    "# # Visualize the tree with higher resolution\n",
    "# plt.figure(figsize=(20, 10), dpi=300)\n",
    "# from sklearn.tree import plot_tree\n",
    "# plot_tree(clf, feature_names=comb.columns, filled=True)\n",
    "# plt.show()\n",
    "# # how to compare predicted values vs actual?\n",
    "# SS_res = ((y - clf.predict(X))**2).sum()\n",
    "# SS_tot = ((y - y.mean())**2).sum()\n",
    "# R2 = 1 - (SS_res/SS_tot)\n",
    "# R2\n",
    "# What we actually want to know, is what variables help increase the overlap? So wouldn't that be more of an application for linear regression?\n",
    "\n",
    "# clf\n",
    "# Since the squared error is already pretty high and our histogram tells us, most of these trips are not currently well predicted with the current impedances. The idea behind using regression trees here is can we figure out if attributes help exmplain the bad overlap?\n",
    "\n",
    "# Or we could just try knocking off \n",
    "# #correlation matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Calculate the correlation matrix\n",
    "# correlation_matrix = one_hot_data.corr()\n",
    "\n",
    "# # Display the correlation matrix\n",
    "# print(\"Correlation Matrix:\")\n",
    "# print(correlation_matrix)\n",
    "\n",
    "# # Plot the correlation matrix using seaborn heatmap\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "# one_hot_data.corr()\n",
    "# # Distribution of Loss Function\n",
    "# # Export to get route attributes\n",
    "# # Using BRouter Results\n",
    "# To compare across we'll use Frechet distance. Will need to use next time.\n",
    "# with (config['calibration_fp']/'brouter_links.txt').open('r') as file:\n",
    "#     my_list = file.readlines()\n",
    "#     # Remove any extra whitespace or newline characters\n",
    "#     my_list = [line.strip() for line in my_list]\n",
    "# len(my_list)\n",
    "# geojsons = list((config['calibration_fp']/'GeoJSON_Out').glob('*.geojson'))\n",
    "# both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "# len(both_ods)\n",
    "# test_ods\n",
    "# len(geojsons)\n",
    "# #use the results dict combined with the geo dict one\n",
    "# results_dict[(68166811, 8789832117)]\n",
    "# #\n",
    "# geojson_geos = []\n",
    "# for geojson in geojsons:\n",
    "#     geojson_geo = gpd.read_file(geojson).to_crs(config['projected_crs_epsg'])\n",
    "#     geojson_geo = np.array(geojson_geo.geometry.item().coords)\n",
    "#     # geojson_geo = [(x, y) for x, y, z in geojson_geo.coords]\n",
    "#     # geojson_geo = LineString(geojson_geo)\n",
    "#     geojson_geos.append(geojson_geo)\n",
    "# frechet_distance = similaritymeasures.frechet_dist(chosen_coords,modeled_coords)\n",
    "# #import and compare frechet distance across them with geodict?\n",
    "# list(geojson_geo.coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
