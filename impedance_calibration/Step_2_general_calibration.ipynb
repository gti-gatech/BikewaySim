{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration Test Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "1. Network Preparation\n",
    "1. Import Train and Test Sets\n",
    "2. Specify Calibration Parameters\n",
    "    - Link Impedance Function\n",
    "    - Turn Impedance Function\n",
    "    - Objective/Loss Function\n",
    "        - First Preference Recovery\n",
    "        - Exact Overlap\n",
    "        - Buffer Overlap (in development)\n",
    "        - Frechet Distance/Area (in development)\n",
    "3. Run Calibration\n",
    "    - Particle Swarm Optimization (constrained & non-probabilistic)\n",
    "    - Maximum likelihood estimation (unconstrained & probabilistic, in development)\n",
    "4. Export and Run Post Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "from network.src import modeling_turns\n",
    "import speedfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "calibration_fp = Path(config['project_directory']) / 'Calibration'\n",
    "cycleatl_fp = Path(config['project_directory']) / 'CycleAtlanta'\n",
    "matching_fp = Path(config['project_directory']) / 'Map_Matching'\n",
    "network_fp = Path(config['project_directory']) / 'Network'\n",
    "if calibration_fp.exists() == False:\n",
    "    calibration_fp.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Preparation\n",
    "- Determine which links should be included for routing\n",
    "- Create directed edge dataframe\n",
    "- Format edge and turn attribute variables\n",
    "- Prepare dictionaries for quick edge attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = pd.read_parquet(network_fp/'turns_df.parquet')\n",
    "links = gpd.read_file(network_fp/'final_network.gpkg',layer='edges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicts for referencing certain link attributes quickly\n",
    "length_dict = dict(zip(links['linkid'],links['length_ft'])) # need this for loss function\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define which links are permitted for routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove these types of links from routing\n",
    "link_types_allowed = ['bike','pedestrian','road']\n",
    "links['link_type'].unique()\n",
    "links = links[links['link_type'].isin(link_types_allowed)]\n",
    "\n",
    "highway_dict = dict(zip(links['linkid'],links['link_type']))\n",
    "turns['source_link_type'] = turns['source_linkid'].map(highway_dict)\n",
    "turns['target_link_type'] = turns['target_linkid'].map(highway_dict)\n",
    "del highway_dict\n",
    "turns = turns[turns['source_link_type'].isin(link_types_allowed) & turns['target_link_type'].isin(link_types_allowed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Major/minor road classification to create high traffic stress variable\n",
    "major_road = ['primary','secondary']\n",
    "major_road = major_road + [item + '_link' for item in major_road]\n",
    "minor_road = ['tertiary','unclassified','residential','service','trunk','living_street']\n",
    "major_road = major_road + [item + '_link' for item in minor_road]\n",
    "links.loc[links['highway'].isin(major_road),'link_type_new'] = 'major_road'\n",
    "links.loc[links['highway'].isin(minor_road),'link_type_new'] = 'minor_road'\n",
    "links.loc[links['link_type_new'].isna(),'link_type_new'] = links.loc[links['link_type_new'].isna(),'link_type']\n",
    "\n",
    "links['high_traffic_stress'] = links['link_type_new'] == 'major_road'\n",
    "links['motorized'] = links['link_type_new'].isin(['major_road','minor_road'])\n",
    "\n",
    "# #Format variables (in progress)\n",
    "# #HERE variables have error because of the conflation process\n",
    "# above_30 = links['speedlimit_range_mph'].isin(['31-40 MPH','41-54 MPH','55-64 MPH'])\n",
    "# more_than_1_lpd = links['lanes_per_direction'].isin(['2-3','> 4'])\n",
    "# no_bike_infra = links['bike_facility_type'].isna()\n",
    "# links['NACTO'] = 1\n",
    "# links.loc[(above_30 | more_than_1_lpd) & no_bike_infra,'NACTO'] = 0\n",
    "# links_geo = links['linkid'].map(geo_dict)\n",
    "# links.reset_index(drop=True,inplace=True)\n",
    "# links = gpd.GeoDataFrame(links,geometry=links_geo,crs='epsg:2240')\n",
    "# links[links['NACTO']==0].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format turn attributes\n",
    "Only count left and right turns if going from one road to another road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets turns that are not from road to road to None, effectively ignoring them\n",
    "turns.loc[(turns['source_link_type']!='road') & (turns['target_link_type']!='road'),'turn_type'] = None\n",
    "\n",
    "#create boolean turn type columns\n",
    "turns['left'] = turns['turn_type'] == 'left'\n",
    "turns['right'] = turns['turn_type'] == 'right'\n",
    "turns['straight'] = turns['turn_type'] == 'straight'\n",
    "\n",
    "#unsignalized straight/left turn where crossing street is a major road\n",
    "highway_dict = dict(zip(links['linkid'],links['link_type_new']))\n",
    "turns['source_link_type'] = turns['source_linkid'].map(highway_dict)\n",
    "turns['target_link_type'] = turns['target_linkid'].map(highway_dict)\n",
    "del highway_dict\n",
    "turns['unsig_major_road_crossing'] = (turns['signalized']==False) & (turns['target_link_type']=='major_road') & (turns['source_link_type']=='minor_road')\n",
    "\n",
    "#((turns['left']==True) | (turns['straight']==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    240924\n",
       "True       6808\n",
       "Name: unsig_major_road_crossing, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns['unsig_major_road_crossing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    236026\n",
       "True      11706\n",
       "Name: signalized, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it looks like there are fewer signals than expected\n",
    "turns['signalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import directed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links = pd.read_parquet(network_fp/'directed_edges.parquet')\n",
    "\n",
    "#merge with links\n",
    "link_cols_drop = ['facility_fwd','facility_rev','reverse_geometry','ascent_m', 'ascent_grade_%', 'descent_m', 'descent_grade_%']\n",
    "links.drop(columns=link_cols_drop,inplace=True)\n",
    "directed_cols_to_add = ['linkid','reverse_link','facility_fwd','ascent_m','ascent_grade_%']\n",
    "links = pd.merge(links,directed_links[directed_cols_to_add])\n",
    "del directed_links\n",
    "\n",
    "# Remove wrongway\n",
    "oneway_dict = dict(zip(links['linkid'],links['oneway']))\n",
    "turns['source_oneway'] = turns['source_linkid'].map(oneway_dict)\n",
    "turns['target_oneway'] = turns['target_linkid'].map(oneway_dict)\n",
    "del oneway_dict\n",
    "source_wrongway = ((turns['source_oneway'] == True) & (turns['source_reverse_link'] == True)) == False\n",
    "target_wrongway = ((turns['target_oneway'] == True) & (turns['target_reverse_link'] == True)) == False\n",
    "turns = turns[source_wrongway & target_wrongway]\n",
    "\n",
    "#remove wrongway links\n",
    "#TODO did we remove these in the export network step too?\n",
    "links = links.loc[((links['oneway']==True) & (links['reverse_link']==True)) == False]#,'reverse_link'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format directed link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing NAs for grade\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].fillna(0)\n",
    "#TODO remove negative values from grade %\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].abs()\n",
    "#set any values above X to blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links['ascent_grade_%'].describe()\n",
    "links['above_4'] = links['ascent_grade_%'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'bike lane', 'multi use path', 'sharrow',\n",
       "       'buffered bike lane', 'no facility', 'cycletrack'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['facility_fwd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['major_road_w_class_2'] = links['facility_fwd'].isin(['bike lane','buffered bike lane']) & (links['link_type_new'] == 'major road')\n",
    "links['minor_road_w_class_2'] = links['facility_fwd'].isin(['bike lane','buffered bike lane']) & (links['link_type_new'] == 'minor road')\n",
    "links['major_road_no_facil'] = (links['major_road_w_class_2'] == False) & (links['link_type_new'] == 'major road')\n",
    "links['minor_road_no_facil'] = (links['minor_road_w_class_2'] == False) & (links['link_type_new'] == 'minor road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed traffic, no bike lanes\n",
    "links['mixed_traffic_no_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path', 'sharrow','buffered bike lane','cycletrack']) == False)\n",
    "links['mixed_traffic_w_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path', 'sharrow','buffered bike lane','cycletrack']) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add elevation adjusted travel times based on assumed speed on flat ground\n",
    "speedfactor.calculate_adjusted_speed(links,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use these, you'll just get the shortest path back everytime\n",
    "links['test_column'] = 0\n",
    "turns['test_column'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form the turn graph needed for routing from the turns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G = modeling_turns.make_turn_graph(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export calibration network\n",
    "with (calibration_fp/\"calibration_network.pkl\").open('wb') as fh:\n",
    "    pickle.dump((links,turns),fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Link Impedance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     114671\n",
       "False     33078\n",
       "Name: mixed_traffic_no_facil, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['mixed_traffic_no_facil'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    141389\n",
       "True       6360\n",
       "Name: mixed_traffic_w_facil, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['mixed_traffic_w_facil'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have position of beta next to name of variable\n",
    "#NOTE: keys must be in the currect order used\n",
    "betas_links = {\n",
    "    0 : 'mixed_traffic_no_facil',\n",
    "    1 : 'mixed_traffic_w_facil',\n",
    "    #0 : 'major_road_w_class_2',\n",
    "    # 1 : 'minor_road_w_class_2',\n",
    "    # 2 : 'major_road_no_facil',\n",
    "    # 3 : 'minor_road_no_facil',\n",
    "    2 : 'above_4'\n",
    "    #1 : 'motorized'\n",
    "    #1 : 'ascent_grade_%'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    3 : 'unsig_major_road_crossing'\n",
    "    #1 : 'left',\n",
    "    #2 : 'right',\n",
    "    #3 : 'signalized'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Currently works with binary and numeric variables. Categorical data will have to be\n",
    "cast into a different format for now.\n",
    "\n",
    "Link impedance is weighted by the length of the link, turns are just the impedance associated\n",
    "'''\n",
    "\n",
    "#customize this function to change impedance formula\n",
    "#TODO streamline process of trying out new impedance functions\n",
    "def link_impedance_function(betas,beta_links,links,base_impedance_col):\n",
    "    #prevent mutating the original links gdf\n",
    "    links = links.copy()\n",
    "    \n",
    "    multiplier = np.zeros(links.shape[0])\n",
    "    \n",
    "    if len(beta_links) > 0:\n",
    "        #assumes that these effects are additive\n",
    "        #TODO i think this can be done as a matrix product\n",
    "        for key, item in beta_links.items():\n",
    "            multiplier = multiplier + (betas[key] * links[item].values)\n",
    "    \n",
    "        links['link_cost'] = links[base_impedance_col] * (1 + multiplier) #removeing the + 1 for now\n",
    "\n",
    "    else:\n",
    "        links['link_cost'] = links[base_impedance_col]\n",
    "\n",
    "    return links\n",
    "\n",
    "def turn_impedance_function(betas,beta_turns,turns):\n",
    "    #use beta coefficient to calculate turn cost\n",
    "    # base_turn_cost = 30 # from Lowry et al 2016 DOI: http://dx.doi.org/10.1016/j.tra.2016.02.003\n",
    "    # turn_costs = {\n",
    "    #     'left': betas[1] * base_turn_cost,\n",
    "    #     'right': betas[1] * base_turn_cost,\n",
    "    #     'straight': betas[1] * base_turn_cost\n",
    "    # }\n",
    "    #turns['turn_cost'] = turns['turn_type'].map(turn_costs)\n",
    "\n",
    "    turns = turns.copy()\n",
    "    turns['turn_cost'] = 0\n",
    "\n",
    "    if len(beta_turns) > 0:\n",
    "        #instance impedance\n",
    "        for key, item in beta_turns.items():\n",
    "            turns['turn_cost'] = turns['turn_cost'] + (betas[key] * turns[item])\n",
    "\n",
    "    #not sure if needed\n",
    "    turns['turn_cost'] = turns['turn_cost'].astype(float)\n",
    "\n",
    "    return turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (calibration_fp/'test_set.pkl').open('rb') as fh:\n",
    "    test_set = pickle.load(fh)\n",
    "with (calibration_fp/'train_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "\n",
    "# import random\n",
    "# random_trip = 1797#random.choice(list(train_set.keys()))\n",
    "# train_set = {random_trip:train_set[random_trip]}\n",
    "\n",
    "#match the ods to the network\n",
    "train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "test_ods = stochastic_optimization.match_results_to_ods(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both_ods = list(set.union(set(train_ods),set(test_ods)))\n",
    "# html = \"\"\n",
    "\n",
    "# nodes = gpd.read_file(network_fp/'final_network.gpkg',layer='nodes')\n",
    "# nodes.to_crs('epsg:4236',inplace=True)\n",
    "# nodes['lon'] = nodes.geometry.x\n",
    "# nodes['lat'] = nodes.geometry.y\n",
    "# latlon = tuple(zip(nodes['lon'],nodes['lat']))\n",
    "# nodes = dict(zip(nodes['N'],latlon))\n",
    "# nodes.get(68196100,0)\n",
    "# htmls = []\n",
    "# for od in both_ods:\n",
    "#     start = od[0]\n",
    "#     end = od[1]\n",
    "#     start_lonlat = nodes.get(start,0)\n",
    "#     end_lonlat = nodes.get(end,0)\n",
    "#     html = f\"https://brouter.damsy.net/latest/#map=12/33.7522/-84.3892/standard&lonlats={start_lonlat[1]},{start_lonlat[0]};{end_lonlat[1]},{end_lonlat[0]}&profile=safety\"\n",
    "#     htmls.append(html)\n",
    "# with (calibration_fp/\"brouter_links.txt\").open('w') as fh:\n",
    "#     for html in htmls:\n",
    "#         fh.write(f\"{html}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = train_set[random_trip]['matched_edges']\n",
    "# gdf['geometry'] = gdf['linkid'].map(geo_dict)\n",
    "# gdf = gpd.GeoDataFrame(gdf,crs=config['projected_crs_epsg'])\n",
    "# gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[0, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 4] for _ in range(0, len(betas_turns))]\n",
    "if (len(betas_links) > 0) & (len(betas_turns) > 0):\n",
    "    bounds = np.vstack([link_bounds,turn_bounds])\n",
    "elif (len(betas_links) > 0):\n",
    "    bounds = link_bounds\n",
    "elif (len(betas_turns) > 0):\n",
    "    bounds = turn_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_betas = []\n",
    "past_vals = []\n",
    "args = (\n",
    "    past_betas,\n",
    "    past_vals,\n",
    "    betas_links,betas_turns,\n",
    "    train_ods,train_set,\n",
    "    link_impedance_function,\n",
    "    base_impedance_col,\n",
    "    turn_impedance_function,\n",
    "    links,turns,turn_G,\n",
    "    loss_function,\n",
    "    loss_function_kwargs,\n",
    "    True #whether to print the results of each iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mixed_traffic_no_facil', 'mixed_traffic_w_facil', 'above_4', 'unsig_major_road_crossing', 'objective_function']\n",
      "[1.85, 0.81, 0.01, 1.7, -0.2524]\n",
      "[0.24, 0.09, 1.3, 1.34, -0.3017]\n",
      "[0.84, 0.6, 0.84, 2.93, -0.2836]\n",
      "[1.05, 1.88, 0.41, 2.47, -0.2379]\n",
      "[0.69, 1.25, 0.25, 0.95, -0.2405]\n",
      "[1.43, 1.02, 1.03, 3.4, -0.2703]\n",
      "[1.62, 0.47, 0.61, 3.71, -0.2629]\n",
      "[1.24, 0.25, 1.62, 0.02, -0.2791]\n",
      "[0.47, 1.41, 1.42, 0.41, -0.2325]\n",
      "[0.06, 1.67, 1.86, 2.15, -0.2059]\n",
      "[0.94, 0.24, 1.01, 1.37, -0.2909]\n",
      "[0.24, 0.09, 1.3, 1.34, -0.3017]\n",
      "[0.68, 0.08, 1.01, 2.86, -0.2958]\n",
      "[0.04, 0.5, 0.9, 1.6, -0.2392]\n",
      "[0.35, 0.11, 1.65, 1.34, -0.3111]\n",
      "[1.35, 0.06, 1.33, 1.58, -0.2756]\n",
      "[1.56, 0.07, 1.47, 1.37, -0.2664]\n",
      "[1.09, 0.25, 1.65, 0.05, -0.2897]\n",
      "[0.35, 0.45, 1.51, 1.75, -0.2846]\n",
      "[0.31, 0.62, 1.55, 1.14, -0.2645]\n",
      "[0.46, 0.27, 2.06, 1.08, -0.3028]\n",
      "[0.38, 0.11, 1.31, 1.34, -0.3082]\n",
      "[0.42, 0.34, 1.47, 1.7, -0.2997]\n",
      "[0.67, 1.44, 1.67, 0.8, -0.2409]\n",
      "[0.1, 0.72, 2.68, 1.63, -0.2176]\n",
      "[0.61, 0.58, 1.55, 0.15, -0.2977]\n",
      "[1.32, 0.17, 2.25, 0.34, -0.2805]\n",
      "[0.43, 0.12, 1.67, 0.14, -0.3068]\n",
      "[0.26, 1.73, 1.59, 2.28, -0.2177]\n",
      "[0.54, 0.39, 1.47, 0.6, -0.3036]\n",
      "[1.27, 0.11, 2.44, 0.97, -0.283]\n",
      "[0.46, 0.12, 1.56, 1.34, -0.3142]\n",
      "[0.28, 0.21, 1.93, 0.74, -0.2962]\n",
      "[0.84, 0.67, 2.13, 0.54, -0.2981]\n",
      "[0.4, 0.8, 2.57, 1.38, -0.2471]\n",
      "[0.1, 0.29, 1.73, 0.38, -0.2703]\n",
      "[0.95, 0.05, 2.35, 0.08, -0.2923]\n",
      "[0.06, 0.02, 1.62, 0.53, -0.307]\n",
      "[0.3, 0.11, 1.52, 1.9, -0.3022]\n",
      "[0.59, 0.95, 1.51, 0.21, -0.2616]\n",
      "[0.36, 0.15, 2.29, 1.17, -0.3008]\n",
      "[0.51, 0.13, 1.75, 1.34, -0.3056]\n",
      "[0.2, 0.24, 1.58, 0.19, -0.2944]\n",
      "[0.32, 0.09, 1.83, 0.6, -0.3036]\n",
      "[0.66, 0.17, 1.79, 1.16, -0.3013]\n",
      "[0.43, 0.1, 1.58, 0.26, -0.3062]\n",
      "[0.36, 0.3, 1.87, 1.82, -0.299]\n",
      "[0.04, 0.01, 1.52, 1.29, -0.2959]\n",
      "[0.38, 1.24, 1.5, 0.9, -0.2362]\n",
      "[0.56, 0.31, 1.6, 1.06, -0.3088]\n",
      "[0.89, 0.15, 1.95, 1.48, -0.2983]\n",
      "[0.48, 0.12, 1.71, 1.34, -0.3062]\n",
      "[0.38, 0.09, 1.15, 1.6, -0.3061]\n",
      "[0.74, 0.65, 1.31, 1.51, -0.2906]\n",
      "[0.44, 0.41, 0.85, 1.21, -0.2986]\n",
      "[0.85, 0.41, 1.45, 1.05, -0.2947]\n",
      "[0.02, 0.23, 1.13, 3.02, -0.2556]\n",
      "[0.04, 0.03, 1.55, 1.77, -0.2901]\n",
      "[0.48, 1.53, 1.61, 1.68, -0.2301]\n",
      "[0.47, 0.69, 1.62, 2.06, -0.272]\n",
      "[0.04, 0.22, 1.28, 1.14, -0.2692]\n",
      "[0.42, 0.11, 1.5, 1.34, -0.3099]\n",
      "[0.51, 0.01, 1.38, 2.46, -0.3017]\n",
      "[0.6, 0.3, 1.03, 1.29, -0.3026]\n",
      "[0.18, 0.39, 1.07, 1.52, -0.2705]\n",
      "[0.45, 0.56, 1.54, 1.57, -0.2826]\n",
      "[0.4, 0.1, 1.47, 0.7, -0.3106]\n",
      "[0.54, 0.07, 1.58, 0.04, -0.3013]\n",
      "[0.48, 0.37, 1.68, 2.14, -0.2981]\n",
      "[0.5, 0.19, 1.59, 0.73, -0.3094]\n",
      "[0.83, 0.29, 1.34, 1.09, -0.2944]\n",
      "[0.41, 0.12, 1.44, 1.34, -0.312]\n",
      "[0.44, 0.06, 1.48, 2.26, -0.2966]\n",
      "[0.02, 0.27, 2.15, 1.05, -0.2445]\n",
      "[0.45, 0.41, 1.94, 1.49, -0.2924]\n",
      "[0.14, 0.06, 1.65, 0.46, -0.3029]\n",
      "[0.76, 0.03, 1.86, 0.16, -0.3026]\n",
      "[0.17, 0.11, 1.64, 0.4, -0.2999]\n",
      "[0.34, 0.75, 1.53, 1.95, -0.255]\n",
      "[0.47, 0.19, 1.56, 0.12, -0.3054]\n",
      "[0.54, 0.04, 1.93, 1.2, -0.3002]\n",
      "[0.46, 0.12, 1.53, 1.34, -0.3151]\n",
      "[0.37, 0.23, 1.43, 0.34, -0.3024]\n",
      "[0.1, 0.06, 2.3, 0.61, -0.2985]\n",
      "[0.51, 0.78, 2.03, 1.42, -0.2717]\n",
      "[0.48, 0.35, 1.67, 0.22, -0.3001]\n",
      "[0.53, 0.0, 1.48, 1.77, -0.2982]\n",
      "[0.21, 0.09, 1.59, 1.67, -0.2945]\n",
      "[0.23, 0.23, 1.41, 1.48, -0.2917]\n",
      "[0.48, 0.11, 1.54, 2.36, -0.303]\n",
      "[0.67, 0.08, 2.33, 1.27, -0.3024]\n",
      "[0.5, 0.13, 1.6, 1.34, -0.3084]\n",
      "[0.4, 0.12, 1.26, 0.82, -0.309]\n",
      "[0.18, 0.31, 1.25, 0.95, -0.2878]\n",
      "[0.52, 0.7, 1.13, 1.22, -0.2767]\n",
      "[0.7, 0.06, 1.48, 0.19, -0.3021]\n",
      "[0.16, 0.22, 1.24, 2.68, -0.2868]\n",
      "[0.1, 0.1, 1.56, 1.66, -0.2917]\n",
      "[0.51, 0.76, 1.5, 1.63, -0.2684]\n",
      "[0.48, 0.36, 1.53, 1.05, -0.3049]\n",
      "[0.85, 0.12, 1.45, 1.32, -0.2977]\n",
      "[0.48, 0.13, 1.55, 1.34, -0.3097]\n",
      "[0.49, 0.04, 1.22, 1.49, -0.2973]\n",
      "[0.24, 0.2, 1.06, 1.28, -0.2958]\n",
      "[0.37, 0.17, 0.91, 1.29, -0.3062]\n",
      "[0.66, 0.39, 1.46, 1.52, -0.3057]\n",
      "[0.17, 0.18, 1.28, 0.36, -0.3012]\n",
      "[0.74, 0.05, 1.55, 0.2, -0.3006]\n",
      "[0.52, 0.19, 1.62, 1.93, -0.3038]\n",
      "[0.47, 0.2, 1.6, 0.13, -0.3039]\n",
      "[0.96, 0.1, 1.55, 1.05, -0.2902]\n",
      "[0.45, 0.12, 1.51, 1.34, -0.314]\n",
      "[0.43, 0.1, 1.62, 1.72, -0.3072]\n",
      "[0.08, 0.05, 2.0, 1.09, -0.2972]\n",
      "[0.29, 0.82, 1.19, 1.35, -0.2391]\n",
      "[0.52, 0.1, 1.61, 0.3, -0.3041]\n",
      "[0.62, 0.03, 1.85, 0.23, -0.3008]\n",
      "[1.06, 0.08, 1.6, 0.43, -0.2858]\n",
      "[0.5, 0.32, 1.58, 1.37, -0.3049]\n",
      "[0.48, 0.03, 1.55, 1.8, -0.2984]\n",
      "[0.37, 0.46, 2.17, 1.18, -0.2835]\n",
      "[0.45, 0.12, 1.51, 1.34, -0.3144]\n",
      "[0.4, 0.19, 1.75, 0.97, -0.3076]\n",
      "[0.15, 0.08, 1.92, 0.61, -0.2983]\n",
      "[0.39, 0.46, 2.03, 1.38, -0.2904]\n",
      "[0.27, 0.09, 1.64, 1.49, -0.3048]\n",
      "[0.71, 0.03, 1.49, 0.92, -0.2975]\n",
      "[0.29, 0.07, 1.58, 1.25, -0.3065]\n",
      "[0.45, 0.6, 1.51, 0.94, -0.2818]\n",
      "[0.5, 0.07, 1.57, 2.49, -0.3028]\n",
      "[0.53, 0.32, 2.09, 1.42, -0.303]\n",
      "[0.46, 0.12, 1.54, 1.34, -0.3137]\n",
      "[0.41, 0.21, 1.37, 0.38, -0.3087]\n",
      "[0.69, 0.33, 1.59, 0.33, -0.305]\n",
      "[0.49, 0.11, 1.92, 1.31, -0.3055]\n",
      "[0.54, 0.14, 1.47, 1.68, -0.3044]\n",
      "[0.4, 0.12, 1.23, 1.8, -0.306]\n",
      "[0.49, 0.06, 1.52, 2.08, -0.3003]\n",
      "[0.45, 0.17, 1.46, 1.23, -0.3118]\n",
      "[0.48, 0.19, 1.57, 0.15, -0.3053]\n",
      "[1.12, 0.33, 1.22, 1.48, -0.2854]\n",
      "[0.48, 0.13, 1.56, 1.34, -0.3103]\n",
      "[0.44, 0.14, 1.08, 0.46, -0.3103]\n",
      "[1.13, 0.44, 1.3, 0.38, -0.2895]\n",
      "[0.5, 0.09, 1.22, 1.32, -0.3056]\n",
      "[0.61, 0.26, 1.46, 3.52, -0.3019]\n",
      "[0.21, 0.18, 1.54, 2.12, -0.2886]\n",
      "[0.26, 0.03, 1.58, 0.06, -0.3042]\n",
      "[0.47, 0.42, 1.5, 1.59, -0.2955]\n",
      "[0.46, 0.27, 1.56, 0.94, -0.3051]\n",
      "Took 2.62 hours\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':15})\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLE version to try out\n",
    "# # Optimization to find the optimal beta coefficients\n",
    "# result = minimize(loss_function, initial_beta, args=(G, observed_paths), method='BFGS')\n",
    "# optimal_beta = result.x\n",
    "\n",
    "# print(f\"Optimal coefficients: {optimal_beta.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -0.31513428304183927\n",
       " message: 'maximum number of iterations is reached'\n",
       "    nfev: 150\n",
       "     nit: 15\n",
       "  status: -1\n",
       " success: False\n",
       "       x: array([0.46263004, 0.12362448, 1.53117212, 1.34265007])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mixed_traffic_no_facil', 'mixed_traffic_w_facil', 'above_4', 'unsig_major_road_crossing', 'objective_function']\n",
      "(0.46263003513032264, 0.12362448102583937, 1.5311721170426633, 1.3426500745160708) -0.315\n"
     ]
    }
   ],
   "source": [
    "#print('high stress,','ascent grade %,','left,','right,','signalized,','val')\n",
    "print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "print(past_betas[np.array(past_vals).argmin()],np.array(past_vals).min().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of loss function values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed_traffic_no_facil': 0.46263003513032264,\n",
       " 'mixed_traffic_w_facil': 0.12362448102583937,\n",
       " 'above_4': 1.5311721170426633,\n",
       " 'unsig_major_road_crossing': 1.3426500745160708,\n",
       " 'loss': -0.31513428304183927,\n",
       " 'beta_links': {0: 'mixed_traffic_no_facil',\n",
       "  1: 'mixed_traffic_w_facil',\n",
       "  2: 'above_4'},\n",
       " 'beta_turns': {3: 'unsig_major_road_crossing'}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_betas = {**betas_links, **betas_turns}\n",
    "calibration_result = {}\n",
    "#get the best betas\n",
    "best_coefs = past_betas[np.array(past_vals).argmin()]\n",
    "for key, item in combined_betas.items():\n",
    "    calibration_result[item] = best_coefs[key]\n",
    "\n",
    "calibration_result['loss'] = np.array(past_vals).min()\n",
    "calibration_result['beta_links'] = betas_links\n",
    "calibration_result['beta_turns'] = betas_turns\n",
    "calibration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export coefficents\n",
    "if (calibration_fp/\"calibration_results.pkl\").exists():\n",
    "    with (calibration_fp/\"calibration_results.pkl\").open('rb') as fh:\n",
    "        calibration_results = pickle.load(fh)\n",
    "else:\n",
    "    calibration_results = []\n",
    "calibration_results.append(calibration_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'high_traffic_stress': 0.0661610119497198,\n",
       "  'left': 2.363333949708205,\n",
       "  'right': 2.875007430851495,\n",
       "  'signalized': 1.0893697547325298,\n",
       "  'loss': -0.31058206517829084},\n",
       " {'class_1': 0.2308230358521835,\n",
       "  'class_2': 1.2595525736224469,\n",
       "  'class_3': 1.6777012261955218,\n",
       "  'high_traffic_stress': 1.3901822221263547,\n",
       "  'loss': -0.058962721570665844},\n",
       " {'major_road_w_class_2': 0.009352298764821576,\n",
       "  'minor_road_w_class_2': 0.7192848670201979,\n",
       "  'major_road_no_facil': 1.0242846535338108,\n",
       "  'minor_road_no_facil': 1.4280555289480468,\n",
       "  'above_4': 1.5152250035581623,\n",
       "  'unsig_major_road_crossing': 0.012773275662048,\n",
       "  'loss': -0.2903367458779148,\n",
       "  'beta_links': {0: 'major_road_w_class_2',\n",
       "   1: 'minor_road_w_class_2',\n",
       "   2: 'major_road_no_facil',\n",
       "   3: 'minor_road_no_facil',\n",
       "   4: 'above_4'},\n",
       "  'beta_turns': {5: 'unsig_major_road_crossing'}},\n",
       " {'mixed_traffic_no_facil': 0.46263003513032264,\n",
       "  'mixed_traffic_w_facil': 0.12362448102583937,\n",
       "  'above_4': 1.5311721170426633,\n",
       "  'unsig_major_road_crossing': 1.3426500745160708,\n",
       "  'loss': -0.31513428304183927,\n",
       "  'beta_links': {0: 'mixed_traffic_no_facil',\n",
       "   1: 'mixed_traffic_w_facil',\n",
       "   2: 'above_4'},\n",
       "  'beta_turns': {3: 'unsig_major_road_crossing'}}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del calibration_results[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'high_traffic_stress': 0.0661610119497198,\n",
       "  'left': 2.363333949708205,\n",
       "  'right': 2.875007430851495,\n",
       "  'signalized': 1.0893697547325298,\n",
       "  'loss': -0.31058206517829084},\n",
       " {'class_1': 0.2308230358521835,\n",
       "  'class_2': 1.2595525736224469,\n",
       "  'class_3': 1.6777012261955218,\n",
       "  'high_traffic_stress': 1.3901822221263547,\n",
       "  'loss': -0.058962721570665844},\n",
       " {'major_road_w_class_2': 0.009352298764821576,\n",
       "  'minor_road_w_class_2': 0.7192848670201979,\n",
       "  'major_road_no_facil': 1.0242846535338108,\n",
       "  'minor_road_no_facil': 1.4280555289480468,\n",
       "  'above_4': 1.5152250035581623,\n",
       "  'unsig_major_road_crossing': 0.012773275662048,\n",
       "  'loss': -0.2903367458779148,\n",
       "  'beta_links': {0: 'major_road_w_class_2',\n",
       "   1: 'minor_road_w_class_2',\n",
       "   2: 'major_road_no_facil',\n",
       "   3: 'minor_road_no_facil',\n",
       "   4: 'above_4'},\n",
       "  'beta_turns': {5: 'unsig_major_road_crossing'}},\n",
       " {'mixed_traffic_no_facil': 0.46263003513032264,\n",
       "  'mixed_traffic_w_facil': 0.12362448102583937,\n",
       "  'above_4': 1.5311721170426633,\n",
       "  'unsig_major_road_crossing': 1.3426500745160708,\n",
       "  'loss': -0.31513428304183927,\n",
       "  'beta_links': {0: 'mixed_traffic_no_facil',\n",
       "   1: 'mixed_traffic_w_facil',\n",
       "   2: 'above_4'},\n",
       "  'beta_turns': {3: 'unsig_major_road_crossing'}}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with (calibration_fp/\"calibration_results.pkl\").open('wb') as fh:\n",
    "        pickle.dump(calibration_results,fh)\n",
    "calibration_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to plot a GeoSeries and save the plot\n",
    "def plot_geoseries(geoseries,other_geoseries,i,past_val):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    #cx.add_basemap(ax)\n",
    "    other_geoseries.plot(ax=ax,color='blue',style_kwds={'linewidth':2})\n",
    "    geoseries.plot(ax=ax,color='red')\n",
    "    ax.set_title(f\"Iter:{i} Overlap Function:{past_val}\")\n",
    "    ax.set_axis_off()\n",
    "    img_bytes = BytesIO()\n",
    "    plt.savefig(img_bytes, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return img_bytes.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trips = 10\n",
    "\n",
    "# for z in range(0,num_trips):\n",
    "\n",
    "#     #choose a random tripid\n",
    "#     tripid = random.choice(list(train_set.keys()))\n",
    "#     start_node = train_set[tripid]['start_node']\n",
    "#     end_node = train_set[tripid]['end_node']\n",
    "\n",
    "#     matched_edges = train_set[tripid]['matched_edges']\n",
    "#     matched_edges = np.array(matched_edges)\n",
    "#     matched_line = MultiLineString([geo_dict[linkid] for linkid, reverse_link in matched_edges])\n",
    "#     matched_line = gpd.GeoSeries(matched_line,crs='epsg:2240')\n",
    "#     matched_line = matched_line.to_crs('epsg:4326')\n",
    "\n",
    "#     modeled_lines = []\n",
    "\n",
    "#     for betas in past_betas:\n",
    "#         #update network with the correct impedances\n",
    "#         stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                                 link_impedance_function,\n",
    "#                                 turn_impedance_function,\n",
    "#                                 links,turns,turn_G)\n",
    "#         #find shortest path\n",
    "#         modeled_edges = stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node)['edge_list']\n",
    "#         modeled_line = MultiLineString([geo_dict[linkid] for linkid, reverse_link in modeled_edges])\n",
    "#         modeled_line = gpd.GeoSeries(modeled_line,crs='epsg:2240')\n",
    "#         modeled_line = modeled_line.to_crs('epsg:4326')\n",
    "#         modeled_lines.append(modeled_line)\n",
    "\n",
    "#     # List of GeoSeries (Replace this with your own GeoSeries list)\n",
    "#     geoseries_list = modeled_lines\n",
    "\n",
    "#     # Loop through the list of GeoSeries, plot each one, and save the plot\n",
    "#     images = []\n",
    "#     for i, geoseries in enumerate(geoseries_list):\n",
    "#         past_val = past_vals[i]\n",
    "#         image_bytes = plot_geoseries(geoseries,matched_line,i,past_val)\n",
    "#         images.append(imageio.imread(BytesIO(image_bytes)))\n",
    "\n",
    "#     # Path for saving the GIF\n",
    "#     gif_path = f\"animations/stress_animation_{z}.gif\"\n",
    "\n",
    "#     # Save the images as a GIF\n",
    "#     imageio.mimsave(Path.cwd()/gif_path, images, format='gif', duration=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "with (calibration_fp/\"calibration_results.pkl\").open('rb') as fh:\n",
    "    calibration_results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# betas = past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# val_to_minimize = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "# val_to_minimize.mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "base_impedance_col = \"travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "betas = past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "val_to_minimize = loss_function(train_set,results_dict,**loss_function_kwargs)\n",
    "val_to_minimize.mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize random trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These did well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_results = stochastic_optimization.first_preference_recovery(train_set,results_dict,**{'length_dict':length_dict,'overlap_threshold':0.7})\n",
    "fpr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tripid = random.choice(fpr_results)\n",
    "tripid\n",
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in train_set[tripid]['matched_edges'].to_numpy()]\n",
    "shortest = [tuple(row) for row in train_set[tripid]['shortest_edges'].to_numpy()]\n",
    "\n",
    "#retrieve modeled path linkids\n",
    "start_node = train_set[tripid]['origin_node']\n",
    "end_node = train_set[tripid]['destination_node']\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "chosen_lines = gpd.GeoSeries(chosen_geo,crs='epsg:2240')\n",
    "shortest_lines = gpd.GeoSeries(shortest_geo,crs='epsg:2240')\n",
    "modeled_lines = gpd.GeoSeries(modeled_geo,crs='epsg:2240')\n",
    "\n",
    "stochastic_optimization.visualize_three_no_legend(chosen_lines,shortest_lines,modeled_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and these not so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "not_good = list(set(test_set.keys()) - set(fpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = random.choice(not_good)\n",
    "tripid\n",
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in test_set[tripid]['matched_edges'].to_numpy()]\n",
    "shortest = [tuple(row) for row in test_set[tripid]['shortest_edges'].to_numpy()]\n",
    "\n",
    "#retrieve modeled path linkids\n",
    "start_node = test_set[tripid]['origin_node']\n",
    "end_node = test_set[tripid]['destination_node']\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "chosen_lines = gpd.GeoSeries(chosen_geo,crs='epsg:2240')\n",
    "shortest_lines = gpd.GeoSeries(shortest_geo,crs='epsg:2240')\n",
    "modeled_lines = gpd.GeoSeries(modeled_geo,crs='epsg:2240')\n",
    "\n",
    "stochastic_optimization.visualize_three_no_legend(chosen_lines,shortest_lines,modeled_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
