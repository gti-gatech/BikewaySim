{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining route attributes\n",
    "Before, I had been only considering how these attributes can be compared across route alternatives, but instead of doing that, let's just look at the distance travelled on high stress facilities as this gives some evidence on people's willingness to travel on these facilities.\n",
    "\n",
    "Look at distance rather than percent of route because a short trip with only a brief two block strech on a busy road is different than someone biking several miles on a stressful road that ends up being a smaller portion of the trip. Essentially, tolerance to stress from motor vehicles should in theory not vary with the distance of the trip. We're trying to find user profiles by acutally looking at the composition of links that they actually put themselves on.\n",
    "\n",
    "However, it should be noted that distance will be limited in that there are only so many of a facility. Also, because sidewalks exist, this approach may run into issues in the case that someone is matched to a highstress road but they were actually on a sidewalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from shapely.ops import MultiLineString\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.impedance_calibration import summarize_route, stochastic_optimization, post_calibration\n",
    "from bikewaysim.routing import rustworkx_routing_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns_df, length_dict, geo_dict, turn_G = rustworkx_routing_funcs.import_calibration_network(config)\n",
    "\n",
    "# just make this a function\n",
    "with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "    ready_for_calibration = pickle.load(fh)\n",
    "print(len(ready_for_calibration),'trips')\n",
    "\n",
    "# get the best performing full model so far\n",
    "best_model = 'bootstrap_final,validation,0'\n",
    "with (config['calibration_fp']/f'loss/{best_model}.pkl').open('rb') as fh:\n",
    "    best_model = pickle.load(fh)\n",
    "\n",
    "# reduce size ofready for calibration\n",
    "ready_for_calibration = {key:item for key,item in ready_for_calibration.items() if key in best_model.keys()}\n",
    "print(len(ready_for_calibration),'trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new pickles\n",
    "with (config['cycleatl_fp']/'trips_4.pkl').open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "trips.reset_index(drop=True,inplace=True)\n",
    "trips = trips[trips['tripid'].isin(ready_for_calibration.keys())]\n",
    "with (config['cycleatl_fp']/'users_4.pkl').open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "users = users[users['userid'].isin(trips['userid'])]\n",
    "\n",
    "#recalculate the number trips\n",
    "users['matched_trips'] = users['userid'].map(trips.groupby('userid').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with cycletracks and multi-use path sidepaths.\n",
    "Problem is that when two links are parallel and close together, the map matching algorithm may not route on the parallel bike infrastructure. Especially true when the infrastructure doesn't have good network connectivity. In this case, we want to acknowledge that there was a bicycle facility that they could have been on.\n",
    "\n",
    "This happens in two instances:\n",
    "1. Cycletracks\n",
    "1. Mutli-Use Paths that are essentially wide sidewalks\n",
    "\n",
    "Some trips may be matched to these features still so I think it's important that not only it be acknowledge that the road had an adjacent cycletrack/multi-use path but that the adjacent cycletrack/multi-use path also takes on the features of the adjacent road. That way, it won't matter how the trip was matched.\n",
    "\n",
    "For an LTS style analysis, we want to know "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidepaths = gpd.read_file(config['bicycle_facilities_fp']/'sidepaths.gpkg',layer='sidepaths',ignore_geometry=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, add cycletrack / multi-use path attributes to streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.merge(links,sidepaths,on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the roads with sidepath variables but no bicycle facility variables\n",
    "cond = links['sidepath_linkid'].notna() & links['facility_fwd'].isna()\n",
    "\n",
    "# assign sidepath to the road if it doesn't already have a facility\n",
    "links.loc[cond,'facility_fwd'] = links.loc[cond,'sidepath']\n",
    "\n",
    "# assign sidepath year if there is one\n",
    "links.loc[cond & links['sidepath_year'].notna(),'year'] = links['sidepath_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add street attributes to cycletracks / multi-use paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the street attributes that we care about and then drop duplicates\n",
    "# assign the highest value for each (NOTE: these sidepaths prolly need to be split up in OSM)\n",
    "cols = ['AADT','speed','lanes']\n",
    "to_add = links.loc[links['linkid'].isin(set(list(sidepaths['linkid']))),['sidepath_linkid']+cols].drop_duplicates()\n",
    "# retrieve the highest value present\n",
    "to_add = to_add.groupby('sidepath_linkid').max()\n",
    "to_add['link_type'] = 'road'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.merge(to_add,left_on='linkid',right_index=True,how='left',suffixes=(None,'_new'))\n",
    "# replaces na values in the to_add column with the links data\n",
    "for col in to_add.columns:\n",
    "    links[col] = links[f'{col}_new'].fillna(links[col])\n",
    "links.drop(columns=[x for x in links.columns if '_new' in x],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting route attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode the attributes\n",
    "links['speed'] = links['speed'].astype(str)\n",
    "links.loc[links['speed'].isin(['(30,40]', '(40,inf)']),'speed'] = '(30,inf)'\n",
    "links['speed'] = pd.Categorical(links['speed'],categories=['[0,30]','(30,inf)'],ordered=True)\n",
    "\n",
    "links['lanes'] = links['lanes'].astype(int).astype(str)\n",
    "links.loc[links['lanes']=='3','lanes'] = '3+'\n",
    "links['lanes'] = pd.Categorical(links['lanes'],categories=['1','2','3+'],ordered=True)\n",
    "\n",
    "links.loc[links['facility_fwd']=='buffered bike lane','facility_fwd'] = 'bike lane'\n",
    "\n",
    "links['grade_cat'] = pd.Categorical(links['ascent_grade_cat'],categories=['[0,4)', '[4,6)', '[6,inf)'],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index for quick retrieval\n",
    "links.set_index(['linkid'],inplace=True)\n",
    "turns_df.set_index(['source_linkid','source_reverse_link','target_linkid','target_reverse_link'],inplace=True)\n",
    "\n",
    "links['length_mi'] = links['length_ft'] / 5280 \n",
    "links['facility_fwd'] = links['facility_fwd'].fillna('No facility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much on the base case?\n",
    "links['base_case'] = (links['facility_fwd'] == 'No facility') & (links['grade_cat'] == '[0,4)') & (links['speed'] == '[0,30]') & (links['lanes'] == '1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = ready_for_calibration[tripid]\n",
    "# matched_edges = item['matched_edges']\n",
    "\n",
    "def route_attributes(tripid,edge_list):\n",
    "\n",
    "    record = {}\n",
    "\n",
    "    record['tripid'] = tripid\n",
    "\n",
    "    # get links traversed\n",
    "    trip_links = links.loc[edge_list['linkid']] \n",
    "    route = [tuple(x) for x in edge_list.values]\n",
    "\n",
    "    # get the turn movements\n",
    "    trip_turns = [(route[i][0],route[i][1],route[i+1][0],route[i+1][1]) for i in range(0,len(route)-1)]\n",
    "    trip_turns = [x for x in trip_turns if x[0] != x[2]]\n",
    "    trip_turns = turns_df.loc[trip_turns]\n",
    "\n",
    "    #general stats\n",
    "    record['Length (miles)'] = trip_links['length_mi'].sum().round(1)\n",
    "    record['Ascent (feet)'] = trip_links['ascent_ft'].sum() # ascent seems a little high\n",
    "    record['Not on Road'] = trip_links.loc[trip_links['link_type']!='road','length_mi'].sum()\n",
    "    record['Base Case'] = trip_links.loc[trip_links['base_case']==True,'length_mi'].sum()\n",
    "\n",
    "    # turn stats\n",
    "    record['Left Turns'] = trip_turns['left_turn'].sum()\n",
    "    record['Right Turns'] = trip_turns['right_turn'].sum()\n",
    "    record['Unsignalized Crossing'] = trip_turns['unsig_crossing'].sum()  # these appear to match up to real world\n",
    "    record['Signalized Crossing'] = trip_turns['signalized'].sum()\n",
    "\n",
    "    #bike facilities\n",
    "    bike_attrs = trip_links[trip_links['facility_fwd'].isin(['multi use path', 'bike lane', 'cycletrack'])]\n",
    "    bike_attrs = bike_attrs.groupby('facility_fwd')['length_mi'].sum().to_dict()\n",
    "    bike_attrs = {f\"{key.title()}\":item for key, item in bike_attrs.items()}\n",
    "    record.update(bike_attrs)\n",
    "\n",
    "    # road variables\n",
    "    road_attrs = trip_links[(trip_links['link_type']=='road')].copy()\n",
    "    aadt = {f'AADT: {key}':item for key, item in road_attrs.groupby('AADT')['length_mi'].sum().to_dict().items()}\n",
    "    lanes = {f'Lanes: {key}':item for key, item in road_attrs.groupby('lanes')['length_mi'].sum().to_dict().items()}\n",
    "    speed = {f'Speed: {key}':item for key, item in road_attrs.groupby('speed')['length_mi'].sum().to_dict().items()}\n",
    "    grade = {f'Grade: {key}':item for key, item in road_attrs.groupby('grade_cat')['length_mi'].sum().to_dict().items()}\n",
    "\n",
    "    record.update(aadt)\n",
    "    record.update(lanes)\n",
    "    record.update(speed)\n",
    "    record.update(grade)\n",
    "\n",
    "    # # road variables (no bike facilities)\n",
    "    # # remove if there's a bicycle facility\n",
    "    # road_attrs = trip_links[(trip_links['link_type']=='road') & (trip_links['facility_fwd'].isin(['multi use path', 'bike lane', 'cycletrack', 'buffered bike lane'])==False)].copy()\n",
    "    \n",
    "    # aadt = {('aadt',str(key)+'_mi'):item for key, item in road_attrs.groupby('AADT')['length_mi'].sum().to_dict().items()}\n",
    "    # lanes = {('lanes',str(key)+'_mi'):item for key, item in road_attrs.groupby('lanes')['length_mi'].sum().to_dict().items()}\n",
    "    # speed = {('speed',str(key)+'_mi'):item for key, item in road_attrs.groupby('speed')['length_mi'].sum().to_dict().items()}\n",
    "\n",
    "    # record.update(aadt)\n",
    "    # record.update(lanes)\n",
    "    # record.update(speed)\n",
    "\n",
    "    # # road variables (w bike faciliies)\n",
    "    # road_attrs_w_bikeaccom = trip_links[(trip_links['link_type']=='road') & (trip_links['facility_fwd'].isin(['multi use path', 'bike lane', 'cycletrack', 'buffered bike lane']))].copy()\n",
    "\n",
    "    # aadt_bike = {('bike_aadt',str(key)+'_mi'):item for key, item in road_attrs_w_bikeaccom.groupby('AADT')['length_mi'].sum().to_dict().items()}\n",
    "    # lanes_bike = {('bike_lanes',str(key)+'_mi'):item for key, item in road_attrs_w_bikeaccom.groupby('lanes')['length_mi'].sum().to_dict().items()}\n",
    "    # speed_bike = {('bike_speed',str(key)+'_mi'):item for key, item in road_attrs_w_bikeaccom.groupby('speed')['length_mi'].sum().to_dict().items()}\n",
    "\n",
    "    # record.update(aadt_bike)\n",
    "    # record.update(lanes_bike)\n",
    "    # record.update(speed_bike)\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to think of why "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate chosen route attributes\n",
    "chosen_route_attr = [route_attributes(key,item['matched_edges']) for key, item in ready_for_calibration.items()]\n",
    "chosen_route_attr = pd.DataFrame.from_records(chosen_route_attr).fillna(0).round(2)\n",
    "chosen_route_attr.set_index('tripid',inplace=True)\n",
    "\n",
    "# calculate shortest route attributes\n",
    "shortest_route_attr = [route_attributes(key,item['shortest_edges']) for key, item in ready_for_calibration.items()]\n",
    "shortest_route_attr = pd.DataFrame.from_records(shortest_route_attr).fillna(0).round(2)\n",
    "shortest_route_attr.set_index('tripid',inplace=True)\n",
    "\n",
    "# calculate modeled route attributes\n",
    "modeled_route_attr = [route_attributes(key,item['modeled_edges']) for key, item in best_model.items()]\n",
    "modeled_route_attr = pd.DataFrame.from_records(modeled_route_attr).fillna(0).round(2)\n",
    "modeled_route_attr.set_index('tripid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize route attributes by the length of the trip\n",
    "chosen_route_attr_norm = chosen_route_attr.drop(columns=['Length (miles)']).div(chosen_route_attr['Length (miles)'],axis=0)\n",
    "shortest_route_attr_norm = shortest_route_attr.drop(columns=['Length (miles)']).div(shortest_route_attr['Length (miles)'],axis=0)\n",
    "modeled_route_attr_norm = modeled_route_attr.drop(columns=['Length (miles)']).div(modeled_route_attr['Length (miles)'],axis=0)\n",
    "\n",
    "# add the length back in\n",
    "chosen_route_attr_norm['Length (miles)'] = chosen_route_attr_norm.index.map(chosen_route_attr['Length (miles)'])\n",
    "shortest_route_attr_norm['Length (miles)'] = shortest_route_attr_norm.index.map(shortest_route_attr['Length (miles)'])\n",
    "modeled_route_attr_norm['Length (miles)'] = modeled_route_attr_norm.index.map(modeled_route_attr['Length (miles)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find difference in percentage\n",
    "chosen_aligned, shortest_aligned = chosen_route_attr_norm.align(shortest_route_attr_norm, fill_value=0)\n",
    "chosen_minus_shortest = chosen_aligned - shortest_aligned\n",
    "\n",
    "chosen_aligned, modeled_aligned = chosen_route_attr_norm.align(modeled_route_attr_norm, fill_value=0)\n",
    "chosen_minus_modeled = chosen_aligned - modeled_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate sum of squared differences for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = (chosen_minus_modeled ** 2).sum()\n",
    "test1.name = 'chosen_minus_modeled'\n",
    "test2 = (chosen_minus_shortest ** 2).sum()\n",
    "test2.name = 'chsoen_minus_shortest'\n",
    "test3 = pd.concat([test1,test2],axis=1,ignore_index=False).round(1)\n",
    "test3.to_csv(config['scratch_fp']/'sum_of_squared_difference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_minus_modeled['Signalized Crossing'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO Find squared difference for each attribute\n",
    "# chosen_minus_modeled\n",
    "# (chosen_minus_modeled ** 2).sum(axis=1).mean()\n",
    "# (chosen_minus_shortest ** 2).sum(axis=1).mean()\n",
    "# chosen_minus_shortest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create chosen route attributes plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link_pct_cols = [\n",
    "#     'Lanes: 1',\n",
    "#     'Lanes: 2',\n",
    "#     'Lanes: 3+',\n",
    "#     'Speed: [0,30]', \n",
    "#     'Speed: (30,inf)',\n",
    "#     'AADT: [0,4k)',\n",
    "#     'AADT: [4k,10k)', \n",
    "#     'AADT: [10k,inf)',\n",
    "#     'Bike Lane',\n",
    "#     'Cycletrack',\n",
    "#     'Multi Use Path',\n",
    "#     'Not on Road', \n",
    "#     'Base Case',\n",
    "# ]\n",
    "\n",
    "# # Loop through each column and create a histogram\n",
    "# for column in link_pct_cols:\n",
    "    \n",
    "#     # Set up the figure and subplots\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     # Center the histograms around zero by setting limits\n",
    "#     max_val = max(chosen_route_attr[column].max(), chosen_minus_shortest[column].max())\n",
    "#     min_val = min(chosen_route_attr[column].min(), chosen_minus_shortest[column].min())\n",
    "#     val = np.ceil(max(abs(max_val),abs(min_val)))\n",
    "\n",
    "#     bins = np.arange(0,val,0.5)\n",
    "#     # Set major ticks every 0.5 and minor ticks every 0.1\n",
    "#     ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "#     ax.xaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "#     ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "#     ax.yaxis.set_minor_locator(MultipleLocator(10))   \n",
    "    \n",
    "#     # Plot histogram for chosen_route_attr\n",
    "#     ax.hist(chosen_route_attr[column], bins=bins, alpha=0.3, color='blue', edgecolor='black')\n",
    "    \n",
    "#     ax.set_title(column)\n",
    "#     ax.set_ylabel(f'Frequency (N={chosen_route_attr.shape[0]})')\n",
    "#     ax.set_xlim(0, val)\n",
    "#     # ax.legend()\n",
    "\n",
    "#     # Set a common xlabel\n",
    "#     ax.set_xlabel('Miles')\n",
    "\n",
    "#     #save the figure\n",
    "#     plt.savefig(config['figures_fp']/f\"{column.replace(' ','_').replace(':','_')}_chosenattrs.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create difference in route attributes plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_pct_cols = [\n",
    "    'Lanes: 1',\n",
    "    'Lanes: 2',\n",
    "    'Lanes: 3+',\n",
    "    'Speed: [0,30]', \n",
    "    'Speed: (30,inf)',\n",
    "    'AADT: [0,4k)',\n",
    "    'AADT: [4k,10k)', \n",
    "    'AADT: [10k,inf)',\n",
    "    'Grade: [0,4)',\n",
    "    'Grade: [4,6)',\n",
    "    'Grade: [6,inf)',\n",
    "    'Bike Lane',\n",
    "    'Cycletrack',\n",
    "    'Multi Use Path',\n",
    "    'Not on Road', \n",
    "    'Base Case',\n",
    "]\n",
    "\n",
    "# Loop through each column and create a histogram\n",
    "for column in link_pct_cols:\n",
    "    \n",
    "    # Set up the figure and subplots\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Center the histograms around zero by setting limits\n",
    "    max_val = max(chosen_minus_modeled[column].max(), chosen_minus_shortest[column].max())\n",
    "    min_val = min(chosen_minus_modeled[column].min(), chosen_minus_shortest[column].min())\n",
    "    val = np.ceil(max(abs(max_val),abs(min_val)))\n",
    "\n",
    "    bins = np.arange(-1,1,0.05)\n",
    "    # Set major ticks every 0.5 and minor ticks every 0.1\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(0.25))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(10))   \n",
    "    \n",
    "    # Plot histogram for chosen_minus_modeled\n",
    "    ax.hist(chosen_minus_modeled[column], bins=bins, alpha=0.3, color='blue', label='Chosen Minus Modeled', edgecolor='black')\n",
    "\n",
    "    # Plot histogram for chosen_minus_shortest\n",
    "    ax.hist(chosen_minus_shortest[column], bins=bins, alpha=0.3, color='grey', label='Chosen Minus Shortest', edgecolor='black')\n",
    "    \n",
    "    ax.set_title(column + ' (%)')\n",
    "    ax.set_ylabel(f'Frequency (N={chosen_minus_modeled.shape[0]})')\n",
    "    ax.set_xlim(min(val * -1, -1), max(val, 1))\n",
    "    ax.legend()\n",
    "\n",
    "    # Set a common xlabel\n",
    "    ax.set_xlabel('Difference')\n",
    "\n",
    "    #save the figure\n",
    "    plt.savefig(config['figures_fp']/f\"{column.replace(' ','_').replace(':','_')}_routeattrs.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_cols = [\n",
    "    'Left Turns', \n",
    "    'Right Turns',\n",
    "    'Unsignalized Crossing',\n",
    "    'Signalized Crossing',\n",
    "]\n",
    "\n",
    "# Loop through each column and create a histogram\n",
    "for column in turn_cols:\n",
    "    \n",
    "    # Set up the figure and subplots\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Center the histograms around zero by setting limits\n",
    "    max_val = max(chosen_minus_modeled[column].max(), chosen_minus_shortest[column].max())\n",
    "    min_val = min(chosen_minus_modeled[column].min(), chosen_minus_shortest[column].min())\n",
    "    val = np.ceil(max(abs(max_val),abs(min_val)))\n",
    "\n",
    "    bin_size = 0.25\n",
    "    bins = np.arange(-1*val,val+bin_size,bin_size)\n",
    "    # Set major ticks every 0.5 and minor ticks every 0.1\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(0.25))\n",
    "\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(10))   \n",
    "    \n",
    "    # Plot histogram for chosen_minus_modeled\n",
    "    ax.hist(chosen_minus_modeled[column], bins=bins, alpha=0.3, color='blue', label='Chosen Minus Modeled', edgecolor='black')\n",
    "\n",
    "    # Plot histogram for chosen_minus_shortest\n",
    "    ax.hist(chosen_minus_shortest[column], bins=bins, alpha=0.3, color='grey', label='Chosen Minus Shortest', edgecolor='black')\n",
    "\n",
    "    # Set the title and labels for each subplot\n",
    "    ax.set_title(column + ' Per Mile')\n",
    "    ax.set_ylabel(f'Frequency (N={chosen_minus_modeled.shape[0]})')\n",
    "    ax.set_xlim(min(val * -1, -1), max(val, 1))  # Adjust these limits based on your data\n",
    "    ax.legend()\n",
    "\n",
    "    # Set a common xlabel\n",
    "    ax.set_xlabel(f'Difference (Bin Size = {bin_size})')\n",
    "\n",
    "    #save the figure\n",
    "    plt.savefig(config['figures_fp']/f\"{column.replace(' ','_')}_routeattrs.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Length (miles)'\n",
    "\n",
    "# Set up the figure and subplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Center the histograms around zero by setting limits\n",
    "max_val = max(chosen_minus_modeled[column].max(), chosen_minus_shortest[column].max())\n",
    "min_val = min(chosen_minus_modeled[column].min(), chosen_minus_shortest[column].min())\n",
    "val = np.ceil(max(abs(max_val),abs(min_val)))\n",
    "\n",
    "bin_size = 0.5\n",
    "bins = np.arange(-1*val,val+bin_size,bin_size)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(10))   \n",
    "\n",
    "# Plot histogram for chosen_minus_modeled\n",
    "ax.hist(chosen_minus_modeled[column], bins=bins, alpha=0.3, color='blue', label='Chosen Minus Modeled', edgecolor='black')\n",
    "\n",
    "# Plot histogram for chosen_minus_shortest\n",
    "ax.hist(chosen_minus_shortest[column], bins=bins, alpha=0.3, color='grey', label='Chosen Minus Shortest', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for each subplot\n",
    "ax.set_title(column)\n",
    "ax.set_ylabel(f'Frequency (N={chosen_minus_modeled.shape[0]})')\n",
    "ax.set_xlim(min(val * -1, -1), max(val, 1))  # Adjust these limits based on your data\n",
    "ax.legend()\n",
    "\n",
    "# Set a common xlabel\n",
    "ax.set_xlabel(f'Difference (Bin Size = {bin_size})')\n",
    "\n",
    "#save the figure\n",
    "plt.savefig(config['figures_fp']/f\"{column.replace(' ','_')}_routeattrs.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Ascent (feet)'\n",
    "\n",
    "# Set up the figure and subplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Center the histograms around zero by setting limits\n",
    "max_val = max(chosen_minus_modeled[column].max(), chosen_minus_shortest[column].max())\n",
    "min_val = min(chosen_minus_modeled[column].min(), chosen_minus_shortest[column].min())\n",
    "val = np.ceil(max(abs(max_val),abs(min_val)))\n",
    "\n",
    "bin_size = 5\n",
    "bins = np.arange(-1*val,val+bin_size,bin_size)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(15))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(10))   \n",
    "\n",
    "# Plot histogram for chosen_minus_modeled\n",
    "ax.hist(chosen_minus_modeled[column], bins=bins, alpha=0.3, color='blue', label='Chosen Minus Modeled', edgecolor='black')\n",
    "\n",
    "# Plot histogram for chosen_minus_shortest\n",
    "ax.hist(chosen_minus_shortest[column], bins=bins, alpha=0.3, color='grey', label='Chosen Minus Shortest', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for each subplot\n",
    "ax.set_title(\"Ascent (feet per mile)\")\n",
    "ax.set_ylabel(f'Frequency (N={chosen_minus_modeled.shape[0]})')\n",
    "ax.set_xlim(min(val * -1, -1), max(val, 1))  # Adjust these limits based on your data\n",
    "ax.legend()\n",
    "\n",
    "# Set a common xlabel\n",
    "ax.set_xlabel(f'Difference (Bin Size = {bin_size})')\n",
    "\n",
    "#save the figure\n",
    "plt.savefig(config['figures_fp']/f\"{column.replace(' ','_')}_routeattrs.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# test = []\n",
    "# for tripid, item in tqdm(ready_for_calibration.items()):\n",
    "#     trip = item['matched_edges']\n",
    "\n",
    "#     # get links traversed\n",
    "#     trip_links = links.loc[trip['linkid']] \n",
    "#     route = [tuple(x) for x in trip.values]\n",
    "\n",
    "#     # get the turn movements\n",
    "#     trip_turns = [(route[i][0],route[i][1],route[i+1][0],route[i+1][1]) for i in range(0,len(route)-1)]\n",
    "#     trip_turns = [x for x in trip_turns if x[0] != x[2]]\n",
    "#     trip_turns = turns_df.loc[trip_turns]\n",
    "\n",
    "#     #general stats\n",
    "#     general_stats = pd.Series({\n",
    "#         'length_mi': trip_links['length_mi'].sum().round(1),\n",
    "#         'ascent_ft': trip_links['ascent_ft'].sum(), # ascent seems a little high\n",
    "#     })\n",
    "#     general_stats.index.name = 'general stats'\n",
    "#     turn_stats = pd.Series({\n",
    "#         'left_turns': trip_turns['left_turn'].sum(),\n",
    "#         'right_turns': trip_turns['right_turn'].sum(),\n",
    "#         'unsig_crossing': trip_turns['unsig_crossing'].sum(),  # these appear to match up to real world\n",
    "#         'sig_crossings': trip_turns['signalized'].sum()\n",
    "#     })\n",
    "#     turn_stats.index.name = 'turn stats'\n",
    "\n",
    "#     #bike facilities\n",
    "#     bike_attrs = trip_links[trip_links['facility_fwd'].isin(['multi use path', 'bike lane', 'cycletrack', 'buffered bike lane'])]\n",
    "#     bike_attrs = bike_attrs.groupby('facility_fwd')['length_mi'].sum()\n",
    "\n",
    "#     # road variables (no bike facilities)\n",
    "#     # remove if there's a bicycle facility\n",
    "#     road_attrs = trip_links[(trip_links['link_type']=='road') & (trip_links['facility_fwd'].isin(['multi use path', 'bike lane', 'cycletrack', 'buffered bike lane'])==False)].copy()\n",
    "#     # route_attrs = trip_links[trip_links['link_type']=='road'].groupby(['AADT','lanes','speed'])['length_mi'].sum()\n",
    "#     aadt = road_attrs.groupby('AADT')['length_mi'].sum()\n",
    "#     lanes = road_attrs.groupby('lanes')['length_mi'].sum()\n",
    "#     speed = road_attrs.groupby('speed')['length_mi'].sum()\n",
    "\n",
    "#     #group these\n",
    "#     concat = [general_stats,bike_attrs,aadt,lanes,speed,turn_stats]\n",
    "#     concat = pd.concat(concat,keys=[x.index.name for x in concat])\n",
    "\n",
    "#     test.append(concat)\n",
    "# # Define the number of columns to plot\n",
    "# columns = chosen_minus_modeled.columns  # Assuming both DataFrames have the same columns\n",
    "# num_columns = len(columns)\n",
    "\n",
    "# # Set up the figure and subplots\n",
    "# fig, axes = plt.subplots(num_columns, 1, figsize=(10, 100))\n",
    "\n",
    "# # Loop through each column and create a histogram\n",
    "# for i, column in enumerate(columns):\n",
    "    \n",
    "#     # Center the histograms around zero by setting limits\n",
    "#     max_val = max(chosen_minus_modeled[column].max(), chosen_minus_shortest[column].max())\n",
    "#     min_val = min(chosen_minus_modeled[column].min(), chosen_minus_shortest[column].min())\n",
    "#     val = max(abs(max_val),abs(min_val))\n",
    "\n",
    "#     bins = np.arange(-1,1,0.05)\n",
    "    \n",
    "#     # Plot histogram for chosen_minus_shortest\n",
    "#     axes[i].hist(chosen_minus_shortest[column].round(2), bins=bins, alpha=0.5, color='grey', label='Chosen Minus Shortest', edgecolor='black')\n",
    "    \n",
    "#     # Plot histogram for chosen_minus_modeled\n",
    "#     axes[i].hist(chosen_minus_modeled[column].round(2), bins=bins, alpha=0.5, color='blue', label='Chosen Minus Modeled', edgecolor='black')\n",
    "\n",
    "#     # Set the title and labels for each subplot\n",
    "#     axes[i].set_title(f'Histogram for {column}')\n",
    "#     axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "#     axes[i].set_xlim(min(val * -1, -1), max(val, 1))  # Adjust these limits based on your data\n",
    "\n",
    "#     # Set major ticks every 0.5 and minor ticks every 0.1\n",
    "#     axes[i].xaxis.set_major_locator(MultipleLocator(0.25))\n",
    "#     axes[i].xaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "#     axes[i].legend()\n",
    "\n",
    "# # Set a common xlabel\n",
    "# axes[-1].set_xlabel('Value')\n",
    "\n",
    "# # Add a legend to the last subplot\n",
    "# # axes[-1].legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()  # Adjust subplots to fit in the figure area.\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
