{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration QAQC\n",
    "- Visualize calibration routes and compare to the chosen and shortest routes\n",
    "- Trip-specific impedance routing to see if chosen route can be found\n",
    "- Test different objective functions\n",
    "- Try using coordinates in case the map matched trace is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import Point, MultiLineString, LineString\n",
    "from importlib import reload\n",
    "import datetime\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from bikewaysim.paths import config, stadia_toner, maptiler_streets\n",
    "from bikewaysim.impedance_calibration import stochastic_optimization, speedfactor\n",
    "from bikewaysim.network import modeling_turns\n",
    "from bikewaysim.routing import rustworkx_routing_funcs\n",
    "\n",
    "# from step_1_calibration_experiments import all_calibrations, full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links, turns, length_dict, geo_dict, turn_G = rustworkx_routing_funcs.import_calibration_network(config)\n",
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('rb') as fh: # has loss values for shortest path\n",
    "    full_set = pickle.load(fh)\n",
    "full_ods = stochastic_optimization.match_results_to_ods_w_year(full_set)\n",
    "# for adding coordinates to the viz part\n",
    "with (config['cycleatl_fp']/\"rdp.pkl\").open('rb') as fh:\n",
    "    coords = pickle.load(fh)\n",
    "\n",
    "with (config['cycleatl_fp']/\"trips_2.pkl\").open('rb') as fh:\n",
    "    trips = pickle.load(fh)\n",
    "with (config['cycleatl_fp']/\"users_2.pkl\").open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "trips.set_index('tripid',inplace=True)\n",
    "users.set_index('userid',inplace=True)\n",
    "trips = trips.loc[list(full_set.keys())]\n",
    "users = users.loc[users.index.isin(set(list(trips['userid'])))]\n",
    "user_map = trips['userid'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the calibration result for each model calibrated\n",
    "calibration_results_fps = (config['calibration_fp']/'user_calibration_results').glob('*.pkl')\n",
    "calibration_results = {}\n",
    "for calibration_results_fp in calibration_results_fps:\n",
    "    with calibration_results_fp.open('rb') as fh:\n",
    "        calibration_results[calibration_results_fp.stem] = pickle.load(fh)\n",
    "\n",
    "# retrieves post routing and loss values results for each model calibrated\n",
    "post_calibration_fps = (config['calibration_fp']/'user_post_calibration_loss').glob('*.pkl')\n",
    "post_calibration = {}\n",
    "for post_calibration_fp in post_calibration_fps:\n",
    "    with post_calibration_fp.open('rb') as fh:\n",
    "        post_calibration[post_calibration_fp.stem] = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do the betas look like?\n",
    "betas_vals = stochastic_optimization.post_calibration_betas(user=True)\n",
    "aggregated_loss = stochastic_optimization.post_calibration_aggregated(user=True)\n",
    "merged = pd.merge(betas_vals,aggregated_loss,on=['userid','run_number','calibration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the calibration results for a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# restrict to one user and model name for exploration\n",
    "userid = 21\n",
    "model_name = 'jaccard_buffer_mean '\n",
    "# model_name = 'break stuff'\n",
    "post_calibration_subset = {key:item for key, item in post_calibration.items() if (key.split('_')[0] == str(userid)) & (model_name in key)}\n",
    "calibration_results_subset = {key:item for key, item in calibration_results.items() if (key.split('_')[0] == str(userid)) & (model_name in key)}\n",
    "\n",
    "# retrieves the trips to look at so that we don't sample something out of range\n",
    "modeled_users = set([x.split('_')[0] for x in post_calibration.keys()]) # checks to see model name co\n",
    "subset_trips = [x for x in trips.index if user_map[x] in modeled_users]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective value variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimums = [(item['results'].fun,item['results'].nfev,item['results'].nit,item['results'].nfev / item['results'].nit ) for _, item in calibration_results_subset.items()]\n",
    "optimums = pd.DataFrame(optimums,columns=['obj','nfev','nit','particles'])\n",
    "optimums['obj'].abs().hist(color='grey',bins=np.arange(0, 1.05, 0.05))\n",
    "plt.xlabel('Objective Function Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([0, 1])\n",
    "plt.title(f'Objective Function Values for User {userid} (N={len(optimums)})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function against particle size\n",
    "Larger the particle size, the better chance it will find a high objective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimums['obj'] = optimums['obj'].abs()\n",
    "optimums.plot.scatter(x='particles',y='obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot of coefficient values vs optimization results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# TODO make the x axis the same\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "# Assuming 'x' is your x-axis and the remaining columns are the y-axes\n",
    "# data = test\n",
    "\n",
    "# Extract x and y columns\n",
    "y = merged.loc[merged['userid']==f\"{userid}\",'jaccard_buffer_mean']\n",
    "x_columns = ['2lpd', '3+lpd', '(30,40] mph',\n",
    "       '(40,inf) mph', '[4k,10k) aadt', '[10k,inf) aadt', '[4,6) grade',\n",
    "       '[6,inf) grade', 'bike lane', 'cycletrack', 'multi use path',\n",
    "       'unsig_crossing']\n",
    "\n",
    "# Set up the grid dimensions: 3 columns and as many rows as needed\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(len(x_columns) / n_cols)  # Dynamically calculates number of rows needed\n",
    "\n",
    "# Create a figure with subplots arranged in a grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10 * n_rows , 4 * n_cols))  # Adjust figure size\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Plot scatter plots for each y-column against the x-column\n",
    "for i, x_col in enumerate(x_columns):\n",
    "    axes[i].scatter(merged.loc[merged['userid']==f\"{userid}\",x_col], y, label=x_col)\n",
    "    axes[i].set_xlabel(x_col)\n",
    "    axes[i].set_ylabel('Objective Function')\n",
    "    # axes[i].set_title(f' vs {x_col}')\n",
    "    # axes[i].legend()\n",
    "\n",
    "# Remove any unused subplots if y_columns is not a multiple of 3\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Add layout adjustments\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining across users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function value and coefficient varation across users for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to the full model\n",
    "cols = [\n",
    "    '2lpd',\n",
    "    '3+lpd',\n",
    "    '(30,40] mph',\n",
    "    '(40,inf) mph',\n",
    "    '[4k,10k) aadt',\n",
    "    '[10k,inf) aadt',\n",
    "    '[4,6) grade',\n",
    "    '[6,inf) grade',\n",
    "    'bike lane',\n",
    "    'cycletrack',\n",
    "    'multi use path',\n",
    "    'unsig_crossing',\n",
    "]\n",
    "merged = merged[merged[cols].notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmax = merged.groupby('userid')['jaccard_buffer_mean'].idxmax()\n",
    "best_model = merged.loc[idxmax]\n",
    "best_model['n_runs'] = best_model['userid'].map(merged.groupby('userid').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering based on calibrated coefficients for each user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future work, these results seem pretty meaningless right now\n",
    "# #DBSCAN\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# X = best_model[cols].values\n",
    "# clustering = DBSCAN(eps=2, min_samples=2).fit(X)\n",
    "# best_model['label'] = clustering.labels_\n",
    "# print(len(set(clustering.labels_)),'clusters')\n",
    "# print(best_model['label'].value_counts())\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "# # Calculate the silhouette score (higher is better)\n",
    "# sil_score = silhouette_score(X, clustering.labels_)\n",
    "# print(f'Silhouette Score: {sil_score}')\n",
    "\n",
    "\n",
    "# #K-MEANS\n",
    "# #Set number of clusters (this can be tuned or determined using methods like the elbow method)\n",
    "# n_clusters = 5\n",
    "\n",
    "# # Apply KMeans clustering\n",
    "# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# clusters = kmeans.fit_predict(X)\n",
    "# best_model['label'] = clusters\n",
    "# print(len(set(clusters)),'clusters')\n",
    "# print(best_model['label'].value_counts())\n",
    "\n",
    "\n",
    "# #Hierarchical Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of User Coefficients (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shortest path ones\n",
    "with (config['calibration_fp']/'ready_for_calibration_stats.pkl').open('rb') as fh:\n",
    "    full_set = pickle.load(fh)\n",
    "shortest = [[trips['userid'].loc[tripid],item['shortest_jaccard_buffer']] for tripid, item in full_set.items()]\n",
    "shortest = pd.DataFrame(shortest,columns=['userid','jaccard_buffer'])\n",
    "shortest = shortest.groupby('userid')['jaccard_buffer'].mean()\n",
    "shortest.name = 'shortest_jaccard_buffer_mean'\n",
    "shortest.index = [str(int(x)) for x in shortest.index]\n",
    "best_model = best_model.merge(shortest,left_on='userid',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make this into a function\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#aggregated results and overlap figures\n",
    "mean_values = []\n",
    "\n",
    "# make figures\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.hist(best_model['shortest_jaccard_buffer_mean'], bins=20, alpha=0.5, label='Shortest Path Overlap', color='grey')\n",
    "plt.hist(best_model['jaccard_buffer_mean'], bins=20, alpha=0.3, label='Calibrated Overlap', color='blue')\n",
    "\n",
    "# Adding labels, title, and legend with font size adjustments\n",
    "plt.xlabel('Overlap', fontsize=22)\n",
    "plt.ylabel(f'Frequency (N={best_model.shape[0]})', fontsize=22)\n",
    "plt.title('User by User (best result)', fontsize=16)\n",
    "plt.legend(title='Jaccard Index', fontsize=22, title_fontsize=22)\n",
    "plt.ylim([0,100])\n",
    "\n",
    "# Adjusting the font size of the tick labels\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Show the plot\n",
    "# plt.savefig(config['calibration_fp']/'calibration_performance'/(post_calibration_result_fp.stem + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#TODO make bin sizes equal\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "# Assuming 'x' is your x-axis and the remaining columns are the y-axes\n",
    "# data = test\n",
    "\n",
    "# Extract x and y columns\n",
    "\n",
    "# min_x = best_model[cols].min().min()\n",
    "# max_x = best_model[cols].max().max()\n",
    "min_x = -1\n",
    "max_x = 5\n",
    "\n",
    "# Set up the grid dimensions: 3 columns and as many rows as needed\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(len(cols) / n_cols)  # Dynamically calculates number of rows needed\n",
    "\n",
    "# Create a figure with subplots arranged in a grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10 * n_rows , 4 * n_cols))  # Adjust figure size\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Plot scatter plots for each y-column against the x-column\n",
    "multiplier = 10\n",
    "start = int(-1 * multiplier)\n",
    "increment = int(0.1 * multiplier)\n",
    "end = int((5 + increment) * multiplier)\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    axes[i].hist(best_model[col], label=col, bins =[x/multiplier for x in range(start,end,increment)], color = 'grey')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(f'Frequency (N={best_model.shape[0]})')\n",
    "    axes[i].set_xlim(min_x,max_x)\n",
    "    axes[i].set_ylim(0,300)\n",
    "\n",
    "# Remove any unused subplots if y_columns is not a multiple of 3\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Add layout adjustments\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
