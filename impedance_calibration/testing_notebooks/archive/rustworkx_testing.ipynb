{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shapely.ops import MultiLineString, LineString\n",
    "import geopandas as gpd\n",
    "\n",
    "from bikewaysim.paths import config\n",
    "from bikewaysim.impedance_calibration import speedfactor, stochastic_optimization\n",
    "from bikewaysim.map_matching import map_match, post_process\n",
    "from bikewaysim.network import prepare_network, modeling_turns\n",
    "from bikewaysim.routing import rustworkx_routing_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (config['calibration_fp']/'ready_for_calibration.pkl').open('rb') as fh:\n",
    "#     match_results = pickle.load(fh)\n",
    "with (config['matching_fp'] / f'match_dict_full_5.pkl').open('rb') as fh:\n",
    "    match_dict = pickle.load(fh)\n",
    "\n",
    "cutoff = 0.90 # set pct of points that need to be matched\n",
    "above_threshold, below_threshold, failed_matches, match_ratios = post_process.mapmatch_results(match_dict,cutoff)\n",
    "match_dict = {key:item for key,item in match_dict.items() if key in above_threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try doing this in rustworkx and time the difference\n",
    "import rustworkx as rx\n",
    "\n",
    "links, turns, length_dict, geo_dict, turn_G = rustworkx_routing_funcs.import_calibration_network(config)\n",
    "base_impedance_col = \"travel_time_min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rustworkx_routing_funcs.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "links.set_index(['linkid','reverse_link'],inplace=True,drop=False)\n",
    "match_results = {}\n",
    "#shortest_results = {}\n",
    "failed_shortest_path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of ods from match_dict?\n",
    "# match_results\n",
    "keys = list(match_dict.keys())[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(rustworkx_routing_funcs)\n",
    "starts, ends = post_process.get_ods_from_match_dict(match_dict,links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_nodes = rustworkx_routing_funcs.add_virtual_edges(starts,ends,links,turns,turn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_paths = rustworkx_routing_funcs.rx_shortest_paths(list(zip(starts,ends)),turn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the connecting links\n",
    "starting_edges = turns.loc[turns['source_A'].isin(set(starts)),['source_A','source_linkid','source_reverse_link']].drop_duplicates().values\n",
    "ending_edges = turns.loc[turns['target_B'].isin(set(ends)),['target_linkid','target_reverse_link','target_B']].drop_duplicates().values\n",
    "\n",
    "# get tuples of the edges we need to add\n",
    "starting_edges = [(int(x[0]),(int(x[1]),bool(x[2])),link_costs.get((x[1],x[2]))) for x in starting_edges]\n",
    "ending_edges = [((int(x[0]),bool(x[1])),int(x[2]),0) for x in ending_edges]\n",
    "\n",
    "# this makes sure we don't add any duplicate nodes to the graph\n",
    "new_nodes = list(set(starts + ends) - set(turn_rx.nodes()))\n",
    "turn_rx.add_nodes_from(new_nodes)\n",
    "\n",
    "# create a dict for mapping back and forth (only valid if we're positive that each node value is unique)\n",
    "node_to_idx = dict(zip(turn_rx.nodes(),turn_rx.node_indices()))\n",
    "idx_to_node = dict(zip(turn_rx.node_indices(),turn_rx.nodes()))\n",
    "\n",
    "# get idx edges\n",
    "starting_virtual_edges = [(node_to_idx[a],node_to_idx[b],{'weight':weight}) for a, b, weight in starting_edges] \n",
    "ending_virtual_edges = [(node_to_idx[a],node_to_idx[b],{'weight':weight}) for a, b, weight in ending_edges] \n",
    "\n",
    "# add these to graph\n",
    "turn_rx.add_edges_from(starting_virtual_edges + ending_virtual_edges)\n",
    "\n",
    "\n",
    "ods = [(node_to_idx[start],node_to_idx[end]) for start, end in zip(starts,ends)]\n",
    "results_rx = [rx.dijkstra_shortest_paths(turn_rx,start,end,weight_fn=lambda x: x['weight']) for start, end in ods]\n",
    "converted = [[idx_to_node[x] for x in i[1:-1]] for sublist in results_rx for i in sublist.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(results_rx[0].values())\n",
    "turn_rx.get_all_edge_data(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [-0.5]\n",
    "betas_tup = (\n",
    "    {'col':'bike lane','type':'link','range':[-1,0]},\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#update link costs (in the 'link_cost' column)\n",
    "stochastic_optimization.link_impedance_function(betas, betas_tup, links, base_impedance_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['link_cost_override'] = False\n",
    "\n",
    "# override the cost with 9e9 if feature is a future off-street facility\n",
    "# this effectively prevents routing w/o messing around with the network structure\n",
    "links.loc[links['link_cost_override']==True,'link_cost'] = 9e9\n",
    "\n",
    "#create cost dict (i think this is the fastest python way to do this?)\n",
    "tuple_index = tuple(zip(links['linkid'],links['reverse_link']))\n",
    "cost_dict = dict(zip(tuple_index,links['link_cost']))\n",
    "\n",
    "#costs are stored in the turn graph (only target matters, initial link cost is added during routing)\n",
    "turns['target_link_cost'] = turns[['target_linkid','target_reverse_link']].apply(lambda x: cost_dict.get(tuple(x.values),False),axis=1)\n",
    "\n",
    "#update turn costs\n",
    "stochastic_optimization.turn_impedance_function(betas, betas_tup, turns)\n",
    "\n",
    "#cacluate new total cost\n",
    "turns['total_cost'] = (turns['target_link_cost'] + turns['turn_cost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if turns['total_cost'].isna().any():\n",
    "    raise Exception(\"There are nan edge costs, exiting\")\n",
    "\n",
    "#check for negative link impedance\n",
    "if (links['link_cost'] < 0).any() | (turns['total_cost'] < 0).any():\n",
    "    return False\n",
    "\n",
    "#update turn network graph with final cost\n",
    "cols = ['source_linkid','source_reverse_link','target_linkid','target_reverse_link','total_cost']\n",
    "# updated_edge_costs = {((row[0],row[1]),(row[2],row[3])):row[4] for row in turns[cols].itertuples(index=False)}\n",
    "\n",
    "updated_edge_costs = [((row[0],row[1]),(row[2],row[3]),row[4]) for row in turns[cols].values]\n",
    "\n",
    "updated_edge_costs = [(node_to_idx[x[0]],node_to_idx[x[1]],{'weight':x[2]}) for x in updated_edge_costs] \n",
    "\n",
    "# updates the edges\n",
    "_ = [turn_rx.update_edge(*x) for x in updated_edge_costs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_rx.edges()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_edge_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_rx.get_edge_data(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to assign edges new weights\n",
    "turn_rx.edges()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_rx[turn_rx.edge_indices_from_endpoints(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`#get length\n",
    "results_nx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [other_way.get(x) for x in list(first_path)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(results_nx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "results_nx = []\n",
    "for start, end in zip(start_nodes,end_nodes):\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    results_nx.append(nx.single_source_dijkstra(turn_G,start,end,weight='weigth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nx = {}\n",
    "for tripid, items in tqdm(match_dict.items()):\n",
    "\n",
    "    #get start and end linkid\n",
    "    start = tuple(match_dict[tripid]['edges'].iloc[0,:].values)\n",
    "    end = tuple(match_dict[tripid]['edges'].iloc[-1,:].values)\n",
    "\n",
    "    #get start and end node for shortest and impedance routing\n",
    "    # #TODO change this to be live so we don't run into errors when the matching network is different\n",
    "    # start = links.loc[start,'A']\n",
    "    # end = links.loc[end,'B']\n",
    "\n",
    "    results_nx[tripid] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
