{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration Test Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "1. Network Preparation\n",
    "1. Import Matched Trace Data\n",
    "2. Specify Calibration Parameters\n",
    "    - Link Impedance Function\n",
    "    - Turn Impedance Function\n",
    "    - Objective/Loss Function\n",
    "        - First Preference Recovery\n",
    "        - Exact Overlap\n",
    "        - Buffer Overlap (in development)\n",
    "        - Frechet Distance/Area (in development)\n",
    "3. Run Calibration\n",
    "    - Particle Swarm Optimization (constrained & non-probabilistic)\n",
    "    - Maximum likelihood estimation (unconstrained & probabilistic, in development)\n",
    "1. Assess Results\n",
    "    - Recalculate results for training set using best coefficients\n",
    "    - Use best coefficients to calculate objective function for the test set\n",
    "    - Compare against the shortest path results (with and without the elevation correction) using both training and testing sets\n",
    "1. Look at where calibrated function did the best/worst job for both the training/testing set\n",
    "1. Cluster/segment results based on loss function value?\n",
    "4. Export for application in BikewaySim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from stochopy.optimize import minimize\n",
    "import stochastic_optimization\n",
    "from tqdm import tqdm\n",
    "import similaritymeasures\n",
    "import random\n",
    "\n",
    "from shapely.ops import LineString, MultiLineString\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,str(Path.cwd().parent))\n",
    "from network.src import modeling_turns\n",
    "import speedfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load((Path.cwd().parent / 'config.json').open('rb'))\n",
    "calibration_fp = Path(config['project_directory']) / 'Calibration'\n",
    "cycleatl_fp = Path(config['project_directory']) / 'CycleAtlanta'\n",
    "matching_fp = Path(config['project_directory']) / 'Map_Matching'\n",
    "network_fp = Path(config['project_directory']) / 'Network'\n",
    "if calibration_fp.exists() == False:\n",
    "    calibration_fp.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Preparation\n",
    "- Determine which links should be included for routing\n",
    "- Create directed edge dataframe\n",
    "- Format edge and turn attribute variables\n",
    "- Prepare dictionaries for quick edge attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = pd.read_parquet(network_fp/'turns_df.parquet')\n",
    "links = gpd.read_file(network_fp/'final_network.gpkg',layer='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicts for referencing certain link attributes quickly\n",
    "geo_dict = dict(zip(links['linkid'],links['geometry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define which links are permitted for routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add highway into turns (need this for later steps)\n",
    "highway_dict = dict(zip(links['linkid'],links['link_type']))\n",
    "turns['source_link_type'] = turns['source_linkid'].map(highway_dict)\n",
    "turns['target_link_type'] = turns['target_linkid'].map(highway_dict)\n",
    "del highway_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove these types of links from routing\n",
    "link_types_allowed = ['bike','pedestrian','road']\n",
    "links['link_type'].unique()\n",
    "links = links[links['link_type'].isin(link_types_allowed)]\n",
    "turns = turns[turns['source_link_type'].isin(link_types_allowed) & turns['target_link_type'].isin(link_types_allowed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major/minor road classification to create high traffic stress variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_road = ['primary','secondary']\n",
    "major_road = major_road + [item + '_link' for item in major_road]\n",
    "minor_road = ['tertiary','unclassified','residential','service','trunk','living_street']\n",
    "major_road = major_road + [item + '_link' for item in minor_road]\n",
    "links.loc[links['highway'].isin(major_road),'link_type_new'] = 'major_road'\n",
    "links.loc[links['highway'].isin(minor_road),'link_type_new'] = 'minor_road'\n",
    "links.loc[links['link_type_new'].isna(),'link_type_new'] = links.loc[links['link_type_new'].isna(),'link_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['high_traffic_stress'] = links['link_type_new'] == 'major_road'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['motorized'] = links['link_type_new'].isin(['major_road','minor_road'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format variables (in progress)\n",
    "HERE variables have error because of the conflation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above_30 = links['speedlimit_range_mph'].isin(['31-40 MPH','41-54 MPH','55-64 MPH'])\n",
    "# more_than_1_lpd = links['lanes_per_direction'].isin(['2-3','> 4'])\n",
    "# no_bike_infra = links['bike_facility_type'].isna()\n",
    "# links['NACTO'] = 1\n",
    "# links.loc[(above_30 | more_than_1_lpd) & no_bike_infra,'NACTO'] = 0\n",
    "# links_geo = links['linkid'].map(geo_dict)\n",
    "# links.reset_index(drop=True,inplace=True)\n",
    "# links = gpd.GeoDataFrame(links,geometry=links_geo,crs='epsg:2240')\n",
    "# links[links['NACTO']==0].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format turn variables\n",
    "Only count left and right turns if going from one road to another road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets turns that are not from road to road to None, effectively ignoring them\n",
    "turns.loc[(turns['source_link_type']!='road') & (turns['target_link_type']!='road'),'turn_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns['left'] = turns['turn_type'] == 'left'\n",
    "turns['right'] = turns['turn_type'] == 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_links = pd.read_parquet(network_fp/'directed_edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_cols_drop = ['facility_fwd','facility_rev','reverse_geometry','ascent_m', 'ascent_grade_%', 'descent_m', 'descent_grade_%']\n",
    "links.drop(columns=link_cols_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the appropriate directed columns (should only be one step)\n",
    "directed_cols_to_add = ['linkid','reverse_link','facility_fwd','ascent_m','ascent_grade_%']\n",
    "links = pd.merge(links,directed_links[directed_cols_to_add])\n",
    "del directed_cols_to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove wrongway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add highway into turns (need this for later steps)\n",
    "oneway_dict = dict(zip(links['linkid'],links['oneway']))\n",
    "turns['source_oneway'] = turns['source_linkid'].map(oneway_dict)\n",
    "turns['target_oneway'] = turns['target_linkid'].map(oneway_dict)\n",
    "del oneway_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_wrongway = ((turns['source_oneway'] == True) & (turns['source_reverse_link'] == True)) == False\n",
    "target_wrongway = ((turns['target_oneway'] == True) & (turns['target_reverse_link'] == True)) == False\n",
    "turns = turns[source_wrongway & target_wrongway]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove wrongway links\n",
    "#TODO did we remove these in the export network step too?\n",
    "links = links.loc[((links['oneway']==True) & (links['reverse_link']==True)) == False]#,'reverse_link'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing NAs\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO remove negative values from grade %\n",
    "links['ascent_grade_%'] = links['ascent_grade_%'].abs()\n",
    "links['above_4'] = links['ascent_grade_%'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed traffic, no bike lanes\n",
    "links['mixed_traffic_no_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path', 'sharrow','buffered bike lane','cycletrack']) == False)\n",
    "links['mixed_traffic_w_facil'] = links['motorized'] & (links['facility_fwd'].isin(['bike lane', 'multi use path', 'sharrow','buffered bike lane','cycletrack']) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add elevation adjusted travel times based on assumed speed on flat ground\n",
    "speedfactor.calculate_adjusted_speed(links,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use these, you'll just get the shortest path back everytime\n",
    "links['test_column'] = 1\n",
    "turns['test_column'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form the turn graph needed for routing from the turns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_G = modeling_turns.make_turn_graph(turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Link Impedance Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BicyclingPlus Demo Impedance Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn + Stress Impedance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO allow for certain impedance functions to be left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_links = {\n",
    "    0 : 'multi use path',\n",
    "    1 : 'bike lane',\n",
    "    2 : 'lanes',\n",
    "    3 : 'above_4'\n",
    "} \n",
    "\n",
    "betas_turns = {\n",
    "    4 : 'unsig_major_road_crossing'\n",
    "}\n",
    "\n",
    "# #this was only .14 overlap\n",
    "# betas_links = {\n",
    "#     0 : 'multi use path',\n",
    "#     1 : 'bike lane',\n",
    "#     2 : 'AADT',\n",
    "#     3 : 'above_4'\n",
    "# } \n",
    "\n",
    "# betas_turns = {\n",
    "#     4 : 'unsig_major_road_crossing'\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# #have position of beta next to name of variable\n",
    "# #NOTE: keys must be in the currect order used\n",
    "# betas_links = {\n",
    "#     0 : 'mixed_traffic_no_facil',\n",
    "#     1 : 'mixed_traffic_w_facil',\n",
    "#     #0 : 'major_road_w_class_2',\n",
    "#     # 1 : 'minor_road_w_class_2',\n",
    "#     # 2 : 'major_road_no_facil',\n",
    "#     # 3 : 'minor_road_no_facil',\n",
    "#     2 : 'above_4'\n",
    "#     #1 : 'motorized'\n",
    "#     #1 : 'ascent_grade_%'\n",
    "# } \n",
    "\n",
    "# betas_turns = {\n",
    "#     3 : 'unsig_major_road_crossing'\n",
    "#     #1 : 'left',\n",
    "#     #2 : 'right',\n",
    "#     #3 : 'signalized'\n",
    "# }\n",
    "\n",
    "\n",
    "# #have position of beta next to name of variable\n",
    "# #NOTE: keys must be in the currect order used\n",
    "# #TODO have this be named tuples or something similar\n",
    "# # (name=var_name,type,position=position,bounds=[0,3])\n",
    "# betas_links = {\n",
    "#     0 : 'AADT',\n",
    "#     1 : 'lanes',\n",
    "#     2 : 'here_speed',\n",
    "#     3 : 'above_4'\n",
    "# } \n",
    "\n",
    "# betas_turns = {\n",
    "#     4 : 'unsig_major_road_crossing',\n",
    "#     5 : 'signalized'\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Currently works with binary and numeric variables. Categorical data will have to be\n",
    "cast into a different format for now.\n",
    "\n",
    "Link impedance is weighted by the length of the link, turns are just the impedance associated\n",
    "'''\n",
    "\n",
    "#customize this function to change impedance formula\n",
    "#TODO streamline process of trying out new impedance functions\n",
    "def link_impedance_function(betas,beta_links,links,base_impedance_col):\n",
    "    #prevent mutating the original links gdf\n",
    "    links = links.copy()\n",
    "    \n",
    "    multiplier = np.zeros(links.shape[0])\n",
    "    \n",
    "    #assumes that these effects are additive\n",
    "    for key, item in beta_links.items():\n",
    "        multiplier = multiplier + (betas[key] * links[item].values)\n",
    "    #final multplier is a proportion increase to the base impedance\n",
    "    #ex: a value 0f 0.5 would mean a 50 increase to the link impedance\n",
    "    links['link_cost'] = links[base_impedance_col] * (1+multiplier)\n",
    "\n",
    "    return links\n",
    "\n",
    "def turn_impedance_function(betas,beta_turns,turns):\n",
    "    #use beta coefficient to calculate turn cost\n",
    "    # base_turn_cost = 30 # from Lowry et al 2016 DOI: http://dx.doi.org/10.1016/j.tra.2016.02.003\n",
    "    # turn_costs = {\n",
    "    #     'left': betas[1] * base_turn_cost,\n",
    "    #     'right': betas[1] * base_turn_cost,\n",
    "    #     'straight': betas[1] * base_turn_cost\n",
    "    # }\n",
    "    #turns['turn_cost'] = turns['turn_type'].map(turn_costs)\n",
    "\n",
    "    turns = turns.copy()\n",
    "\n",
    "    turns['turn_cost'] = 0\n",
    "    #instance impedance\n",
    "    for key, item in beta_turns.items():\n",
    "        turns['turn_cost'] = turns['turn_cost'] + (betas[key] * turns[item])\n",
    "\n",
    "    #not sure if needed\n",
    "    turns['turn_cost'] = turns['turn_cost'].astype(float)\n",
    "\n",
    "    return turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = train_set[random_trip]['matched_edges']\n",
    "# gdf['geometry'] = gdf['linkid'].map(geo_dict)\n",
    "# gdf = gpd.GeoDataFrame(gdf,crs=config['projected_crs_epsg'])\n",
    "# gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO put the loss/objective functions in a class for documentation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_impedance_col = \"travel_time_min\"\n",
    "loss_function = stochastic_optimization.jaccard_index\n",
    "length_dict = dict(zip(links['linkid'],links['length_ft'])) # need this for loss function\n",
    "loss_function_kwargs = {'length_dict':length_dict}#,'overlap_threshold':0.80}\n",
    "\n",
    "# loss_function = stochastic_optimization.buffer_overlap\n",
    "# loss_function_kwargs = {'geo_dict':geo_dict,'buffer_ft':100,'standardize':True}\n",
    "\n",
    "# link coefficients control the % increase in link travel time (units don't matter)\n",
    "# turn coefficients control the amount of seconds added from the turn (units matter)\n",
    "link_bounds = [[0, 2] for _ in range(0, len(betas_links))]\n",
    "turn_bounds = [[0, 2] for _ in range(0, len(betas_turns))]\n",
    "bounds = np.vstack([link_bounds,turn_bounds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (calibration_fp/'test_set.pkl').open('rb') as fh:\n",
    "    test_set = pickle.load(fh)\n",
    "with (calibration_fp/'train_set.pkl').open('rb') as fh:\n",
    "    train_set = pickle.load(fh)\n",
    "\n",
    "# import random\n",
    "# random_trip = 1797#random.choice(list(train_set.keys()))\n",
    "# train_set = {random_trip:train_set[random_trip]}\n",
    "\n",
    "# #match the ods to the network\n",
    "# train_ods = stochastic_optimization.match_results_to_ods(train_set)\n",
    "# test_ods = stochastic_optimization.match_results_to_ods(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes about 14 hours for 500 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for tripid, item in tqdm(train_set.items()):\n",
    "    one_set = {tripid:item}\n",
    "    one_ods = stochastic_optimization.match_results_to_ods(one_set)\n",
    "\n",
    "    past_betas = []\n",
    "    past_vals = []\n",
    "    args = (\n",
    "        past_betas,\n",
    "        past_vals,\n",
    "        betas_links,betas_turns,\n",
    "        one_ods,one_set,\n",
    "        link_impedance_function,\n",
    "        base_impedance_col,\n",
    "        turn_impedance_function,\n",
    "        links,turns,turn_G,\n",
    "        loss_function,\n",
    "        loss_function_kwargs,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    # args = (df_edges,turns,turn_G,matched_traces,False)\n",
    "    #print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "    x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':5})\n",
    "    end = time.time()\n",
    "    #print(f'Took {(end-start)/60/60:.2f} hours')\n",
    "    \n",
    "    results[tripid] = {\n",
    "        'betas': past_betas[np.array(past_vals).argmin()],\n",
    "        'loss': np.array(past_vals).min().round(3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [tuple([key,item['loss'],*item['betas']]) for key, item in results.items()]\n",
    "labels = ['tripid','Loss Function','High Traffic Stress', 'Motorized','Left Turn','Right Turn','Signalized']\n",
    "loss = pd.DataFrame.from_records(loss,columns=labels)\n",
    "#coef = [(key,key:item['betas'] for key, item in results.items()]\n",
    "loss['Loss Function'] = loss['Loss Function'].abs()\n",
    "loss.set_index('tripid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add trip info?\n",
    "with (calibration_fp/'trip_specific.pkl').open('wb') as fh:\n",
    "    pickle.dump(results,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = loss.hist(figsize=(12,12),bins=20,color='grey')\n",
    "\n",
    "# Add a title for the entire figure\n",
    "plt.suptitle('Trip by Trip Impedance Calibration (n=500)')\n",
    "plt.subplots_adjust(top=0.925)\n",
    "\n",
    "x_labels = ['(Intersection of Modeled and Chosen) / (Union of Modeled and Chosen)','Distance Proportion Change','Distance Proportion Change','Added Minutes Per Instance','Added Minutes Per Instance','Added Minutes Per Instance']\n",
    "x_lims = [(0,1),(0,9),(0,9),(0,9),(0,9),(0,9)]\n",
    "for i, sub_ax in enumerate(ax.flatten()):\n",
    "    sub_ax.set_xlabel(x_labels[i])\n",
    "    sub_ax.set_ylabel('Frequency')\n",
    "    sub_ax.set_xlim(x_lims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame.from_dict(loss,orient='index')\n",
    "coef = pd.DataFrame.from_dict(coef)\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (calibration_fp/'imp_cal_ind.pkl').open('wb') as fh:\n",
    "#     pickle.dump(results,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shortest path results here for comparison\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in train_ods}\n",
    "# loss_values = loss_function(train_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_values.mean().round(5))\n",
    "# # 0.3102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "# loss_values = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_values.mean().round(5))\n",
    "# # 0.3034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path with Elevation Adjustment\n",
    "Redo these later because nothing seems to have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shortest path results here for comparison\n",
    "# stochastic_optimization.back_to_base_impedance(\"adj_travel_time_min\",links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in train_ods}\n",
    "# loss_values = loss_function(train_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_values.mean().round(5))\n",
    "# # 0.31022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic_optimization.back_to_base_impedance(\"adj_travel_time_min\",links,turns,turn_G)\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "# loss_values = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "# print(loss_values.mean().round(5))\n",
    "# # 0.30337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "\n",
    "# start = time.time()\n",
    "# # args = (df_edges,turns,turn_G,matched_traces,False)\n",
    "# print(list(betas_links.values())+list(betas_turns.values())+['objective_function'])\n",
    "# x = minimize(stochastic_optimization.impedance_calibration, bounds, args=args, method='pso', options={'maxiter':5})\n",
    "# end = time.time()\n",
    "# print(f'Took {(end-start)/60/60:.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLE version to try out\n",
    "# # Optimization to find the optimal beta coefficients\n",
    "# result = minimize(loss_function, initial_beta, args=(G, observed_paths), method='BFGS')\n",
    "# optimal_beta = result.x\n",
    "\n",
    "# print(f\"Optimal coefficients: {optimal_beta.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('high stress,','ascent grade %,','left,','right,','signalized,','val')\n",
    "print(past_betas[np.array(past_vals).argmin()],np.array(past_vals).min().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to plot a GeoSeries and save the plot\n",
    "def plot_geoseries(geoseries,other_geoseries,i,past_val):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    #cx.add_basemap(ax)\n",
    "    other_geoseries.plot(ax=ax,color='blue',style_kwds={'linewidth':2})\n",
    "    geoseries.plot(ax=ax,color='red')\n",
    "    ax.set_title(f\"Iter:{i} Overlap Function:{past_val}\")\n",
    "    ax.set_axis_off()\n",
    "    img_bytes = BytesIO()\n",
    "    plt.savefig(img_bytes, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return img_bytes.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trips = 10\n",
    "\n",
    "# for z in range(0,num_trips):\n",
    "\n",
    "#     #choose a random tripid\n",
    "#     tripid = random.choice(list(train_set.keys()))\n",
    "#     start_node = train_set[tripid]['start_node']\n",
    "#     end_node = train_set[tripid]['end_node']\n",
    "\n",
    "#     matched_edges = train_set[tripid]['matched_edges']\n",
    "#     matched_edges = np.array(matched_edges)\n",
    "#     matched_line = MultiLineString([geo_dict[linkid] for linkid, reverse_link in matched_edges])\n",
    "#     matched_line = gpd.GeoSeries(matched_line,crs='epsg:2240')\n",
    "#     matched_line = matched_line.to_crs('epsg:4326')\n",
    "\n",
    "#     modeled_lines = []\n",
    "\n",
    "#     for betas in past_betas:\n",
    "#         #update network with the correct impedances\n",
    "#         stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                                 link_impedance_function,\n",
    "#                                 turn_impedance_function,\n",
    "#                                 links,turns,turn_G)\n",
    "#         #find shortest path\n",
    "#         modeled_edges = stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node)['edge_list']\n",
    "#         modeled_line = MultiLineString([geo_dict[linkid] for linkid, reverse_link in modeled_edges])\n",
    "#         modeled_line = gpd.GeoSeries(modeled_line,crs='epsg:2240')\n",
    "#         modeled_line = modeled_line.to_crs('epsg:4326')\n",
    "#         modeled_lines.append(modeled_line)\n",
    "\n",
    "#     # List of GeoSeries (Replace this with your own GeoSeries list)\n",
    "#     geoseries_list = modeled_lines\n",
    "\n",
    "#     # Loop through the list of GeoSeries, plot each one, and save the plot\n",
    "#     images = []\n",
    "#     for i, geoseries in enumerate(geoseries_list):\n",
    "#         past_val = past_vals[i]\n",
    "#         image_bytes = plot_geoseries(geoseries,matched_line,i,past_val)\n",
    "#         images.append(imageio.imread(BytesIO(image_bytes)))\n",
    "\n",
    "#     # Path for saving the GIF\n",
    "#     gif_path = f\"animations/stress_animation_{z}.gif\"\n",
    "\n",
    "#     # Save the images as a GIF\n",
    "#     imageio.mimsave(Path.cwd()/gif_path, images, format='gif', duration=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #link_impedance_col = \"adj_travel_time_min\"\n",
    "# stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "# #update impedances\n",
    "# betas = past_betas[np.array(past_vals).argmin()]#x.x\n",
    "# print(betas)\n",
    "# stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "#                           link_impedance_function,\n",
    "#                           base_impedance_col,\n",
    "#                           turn_impedance_function,\n",
    "#                           links,turns,turn_G)\n",
    "\n",
    "# #find shortest path\n",
    "# results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in test_ods}\n",
    "\n",
    "# #calulate objective function\n",
    "# val_to_minimize = loss_function(test_set,results_dict,**loss_function_kwargs)\n",
    "# val_to_minimize.mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_impedance_col = \"adj_travel_time_min\"\n",
    "stochastic_optimization.back_to_base_impedance(base_impedance_col,links,turns,turn_G)\n",
    "\n",
    "#update impedances\n",
    "betas = past_betas[np.array(past_vals).argmin()]#x.x\n",
    "print(betas)\n",
    "stochastic_optimization.impedance_update(betas,betas_links,betas_turns,\n",
    "                          link_impedance_function,\n",
    "                          base_impedance_col,\n",
    "                          turn_impedance_function,\n",
    "                          links,turns,turn_G)\n",
    "\n",
    "#find shortest path\n",
    "results_dict = {(start_node,end_node):stochastic_optimization.impedance_path(turns,turn_G,start_node,end_node) for start_node, end_node in train_ods}\n",
    "\n",
    "#calulate objective function\n",
    "val_to_minimize = loss_function(train_set,results_dict,**loss_function_kwargs)\n",
    "val_to_minimize.mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize random trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These did well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_results = stochastic_optimization.first_preference_recovery(train_set,results_dict,**{'length_dict':length_dict,'overlap_threshold':0.7})\n",
    "fpr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tripid = random.choice(fpr_results)\n",
    "tripid\n",
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in train_set[tripid]['matched_edges'].to_numpy()]\n",
    "shortest = [tuple(row) for row in train_set[tripid]['shortest_edges'].to_numpy()]\n",
    "\n",
    "#retrieve modeled path linkids\n",
    "start_node = train_set[tripid]['origin_node']\n",
    "end_node = train_set[tripid]['destination_node']\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "chosen_lines = gpd.GeoSeries(chosen_geo,crs='epsg:2240')\n",
    "shortest_lines = gpd.GeoSeries(shortest_geo,crs='epsg:2240')\n",
    "modeled_lines = gpd.GeoSeries(modeled_geo,crs='epsg:2240')\n",
    "\n",
    "stochastic_optimization.visualize_three_no_legend(chosen_lines,shortest_lines,modeled_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and these not so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "not_good = list(set(test_set.keys()) - set(fpr_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = random.choice(not_good)\n",
    "tripid\n",
    "#retrieve chosen path linkids and convert them to tuple\n",
    "chosen = [tuple(row) for row in test_set[tripid]['matched_edges'].to_numpy()]\n",
    "shortest = [tuple(row) for row in test_set[tripid]['shortest_edges'].to_numpy()]\n",
    "\n",
    "#retrieve modeled path linkids\n",
    "start_node = test_set[tripid]['origin_node']\n",
    "end_node = test_set[tripid]['destination_node']\n",
    "modeled_edges = results_dict[(start_node,end_node)]['edge_list']\n",
    "\n",
    "#get geos (non-directional)\n",
    "chosen_geo = [geo_dict[linkid[0]] for linkid in chosen]\n",
    "shortest_geo = [geo_dict[linkid[0]] for linkid in shortest]\n",
    "modeled_geo = [geo_dict[linkid[0]] for linkid in modeled_edges]\n",
    "\n",
    "chosen_lines = gpd.GeoSeries(chosen_geo,crs='epsg:2240')\n",
    "shortest_lines = gpd.GeoSeries(shortest_geo,crs='epsg:2240')\n",
    "modeled_lines = gpd.GeoSeries(modeled_geo,crs='epsg:2240')\n",
    "\n",
    "stochastic_optimization.visualize_three_no_legend(chosen_lines,shortest_lines,modeled_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
