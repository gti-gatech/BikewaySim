{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a0e84c",
   "metadata": {},
   "source": [
    "## Step 2 Network Reconciliation\n",
    "---\n",
    "### This the second of five steps to running BikewaySim\n",
    "1. Process network spatial data into a routable network graph format\n",
    "2. __Reconcile networks into one through node and link overlap conflation__\n",
    "3. Create final network graph and calculate link costs\n",
    "4. Create OD tables\n",
    "5. Run BikewaySim\n",
    "\n",
    "In this step, the networks are conflated to each other by utilizing functions in the network_conflation.py module. \n",
    "\n",
    "There are five main functions in the conflation tools module:\n",
    "1. Match nearest points between base and join networks\n",
    "1. Split base links by joining network node\n",
    "1. Add network attributes by link overlap\n",
    "1. Add join links/nodes that aren't in base network\n",
    "1. Resolve reference IDs\n",
    "\n",
    "The final step combines the different types of networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b74c49",
   "metadata": {},
   "source": [
    "## Import/install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7001d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb08fa6",
   "metadata": {},
   "source": [
    "## Import Conflation Tools Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43df411d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (conflation_tools.py, line 159)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\TPASSM~1\\AppData\\Local\\Temp/ipykernel_140900/860695893.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from conflation_tools import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\tpassmore6\\Documents\\GitHub\\BikewaySimDev\\conflation_tools.py\"\u001b[1;36m, line \u001b[1;32m159\u001b[0m\n\u001b[1;33m    already_matched = base_nodes[base_nodes[f'{network_name}_ID'] not None]\u001b[0m\n\u001b[1;37m                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from conflation_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d770e2a",
   "metadata": {},
   "source": [
    "## Set Directory:\n",
    "Modify this directory to where you stored your network shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51410106",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_directory = os.fspath(Path.home()) #get home directory and convert to path string\n",
    "file_directory = r\"/Documents/BikewaySimData\" #directory of bikewaysim outputs\n",
    "os.chdir(user_directory+file_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60519e7",
   "metadata": {},
   "source": [
    "### Links and Nodes to Conflate\n",
    "Determine what you want the base and join network to be. All of the links and nodes from the base network will be present in the final network.\n",
    "\n",
    "For this project, OSM served as the base followed by HERE and ABM as the joining. Only the road + bike networks created in the first step was used for conflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d93693",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'osm'\n",
    "join_name = 'here'\n",
    "study_area = 'bikewaysim'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b15922",
   "metadata": {},
   "source": [
    "### Road Link Conflation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e8ed2",
   "metadata": {},
   "source": [
    "I like to remove all of the columns that aren't related to node_id or geometry for this step. To make sure we preserve link information I also make a A_B column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_links, base_nodes = import_network(base_name,'road',study_area)\n",
    "join_links, join_nodes = import_network(join_name,'road',study_area)\n",
    "\n",
    "#initialize the base network\n",
    "base_links, base_nodes = initialize_base(base_links, base_nodes, join_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3665c6",
   "metadata": {},
   "source": [
    "### Node Matching\n",
    "This function matches nodes within a set tolerence (in CRS units) that are likely to be the same nodes. This function is intended for matching road intersections or road termini since these are likely to be in both networks. This function can be applied with an iteratively increasing tolerance if you're not sure what's a good tolerance. At some point, the number of matched nodes will not increase by much.\n",
    "\n",
    "The match results will get printed out.\n",
    "\n",
    "#### NOTE: This function handles duplicate matches (i.e. when two or more nodes share a nearest node in the other network) by selecting the one with the shorter match distance. The duplicates won't be rematched unless you run the matching process again.\n",
    "\n",
    "#### When looping match function, feed outputs from previous\n",
    "\n",
    "### Function Inputs\n",
    "- base_nodes, base_name, join_nodes, join_name # self explanatory\n",
    "- tolerance_ft: the match tolerance in units of feet\n",
    "- prev_matched_nodes: geodataframe of the list of currently matched nodes, set to none for first run\n",
    "- remove_duplicates: if set to 'True' (default), then remove duplicate matches. If set to false, duplicate matches will be returned in the matched_nodes gdf.\n",
    "- export_error_lines: if set to 'False', a geojson of linestrings visualizing the matches will be written.\n",
    "- export_unmatched: if you want a geojson of the nodes that didn't match in each network set this to true (False by default).\n",
    "\n",
    "### Function Outputs\n",
    "- matched_nodes: a df of matched nodes, just the node ids.\n",
    "- unmatched_base_nodes: a gdf of the base nodes that weren't matched.\n",
    "- unmatched_join_nodes: a gdf of the join nodes that weren't matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "tolerance_ft = 25\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second iteration example with same tolerance\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)\n",
    "\n",
    "#third iteration example wiht larger tolerance\n",
    "tolerance_ft = 30\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe76125",
   "metadata": {},
   "source": [
    "### Link Splitting and Add New Links and Nodes\n",
    "This function will split links in the base network if there's a node in the join network that is within a certain tolerance. This creates new nodes and links on the base network. The original base links are then replaced with these new links/nodes.\n",
    "\n",
    "#### NOTE: This may create way more links/nodes than neccessary.\n",
    "\n",
    "It may be wise to consider limiting the kind of join nodes that can split a base link. For instance, OSM has lots of additional links and nodes because there are sidewalks. The nodes used to access these sidewalks will split the base link, which creates additional link where there otherwise would be none. These added links/nodes can slow down computational time for shortest path calculation. However, it could be adventageous in the attribute transfer process.\n",
    "\n",
    "#### Looping\n",
    "This function can be looped if unsure what tolerance or nodes to use. \n",
    "\n",
    "### Function Inputs\n",
    "- unmatched_join_nodes: These are the join nodes that weren't matched to base nodes in the previous step\n",
    "- join_name, base_links, base_name: self-explanatory\n",
    "- tolerance_ft: the matching tolerance in feet\n",
    "- export: set to 'True' to get a GeoJSON of new links and nodes that were created\n",
    "\n",
    "### Function Outputs\n",
    "- split_lines: a gdf of just the new base links\n",
    "- split_nodes: a gdf of jsut the new base nodes\n",
    "- unmathced_join_nodes: a gdf of the join nodes that didn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c76ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_join_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "tolerance_ft = 25\n",
    "split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "                                                                           join_name,\n",
    "                                                                           base_links,\n",
    "                                                                           base_name,\n",
    "                                                                           tolerance_ft,\n",
    "                                                                           export = False)\n",
    "split_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "new_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931b59f",
   "metadata": {},
   "source": [
    "### Attribute Transfer\n",
    "In the previous steps, we found geometric commonalties between the networks. In this step, we want to transfer attribute information from the join network into the base network. Link attributes are based on a link's reference ids, but the current set of links may not have reference ids that correspond to a join network link.\n",
    "\n",
    "To address this, we buffer the base links and intersect them with the join links. We then measure the length of the resulting linestrings. The attribute information from the join links that have the maximum length (i.e. the maximum amount of overlap with the base link) is tranferred. This ensures that each base link is associated with only one join link's attributes.\n",
    "\n",
    "### NOTE: The buffer here needs to be smaller\n",
    "If it's larger, then a longer join node could be selected as the join link with most overlap.\n",
    "\n",
    "This process will likely change in the future. A different approach might be to look at all the base links with at least one join node in the reference id column, and then look up all the links in the join network associated with that node (there should only be a few). Using other reference node that doesn't have a join node id, the nearest node in that lookup table could be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match attribute information with greatest overlap from joining links\n",
    "buffer_ft = 30\n",
    "new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "new_base_links_w_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b03124",
   "metadata": {},
   "source": [
    "### Add rest of features\n",
    "Now that we've settled the geometric and attribute commonalities between the base and join networks, we can add in the join network features that aren't represented in the base network. This is done using a buffer. If a join link is covered at least 95% by a base link, then it is left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce23175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "#create new abmhere column with id and geo\n",
    "final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)\n",
    "\n",
    "final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d7fc5",
   "metadata": {},
   "source": [
    "### Save as pickle, this is more of a progress save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9278388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(added_base_links, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))\n",
    "#pickle.dump(added_base_nodes, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a709e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Repeat for OSM\n",
    "Now that we've resovled ABM and HERE, we can add the second join network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b47e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"abmhere\"\n",
    "base_links = final_links\n",
    "base_nodes = final_nodes\n",
    "\n",
    "join_name = \"osm\"\n",
    "join_links = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_links.geojson\")\n",
    "join_nodes = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_nodes.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean join links (no need to clean base links)\n",
    "join_links, join_nodes = cleaning_process(join_links,join_nodes,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ffb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "tolerance_ft = 25\n",
    "matched_nodes, unmatched_base_nodes, unmatched_join_nodes = match_nodes(base_nodes, base_name, join_nodes, join_name, tolerance_ft, prev_matched_nodes=None)\n",
    "\n",
    "#join the matched nodes to the base nodes once done with matching\n",
    "matched_nodes_final = pd.merge(base_nodes, matched_nodes, on = f'{base_name}_ID', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "tolerance_ft = 25\n",
    "split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "                                                                           join_name,\n",
    "                                                                           base_links,\n",
    "                                                                           base_name,\n",
    "                                                                           tolerance_ft,\n",
    "                                                                           export = False)\n",
    "split_lines.head()\n",
    "split_lines.to_file('processed_shapefiles/conflation/split_lines.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "new_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b96068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match attribute information with greatest overlap from joining links\n",
    "buffer_ft = 30\n",
    "new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "new_base_links_w_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "#create new abmhere column with id and geo\n",
    "final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df29cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike Subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bike layers\n",
    "bike_links = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_links.geojson')\n",
    "bike_nodes = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_nodes.geojson')\n",
    "bike_name = 'here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean excess columns\n",
    "bike_links, bike_nodes = cleaning_process(bike_links,bike_nodes,bike_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e26f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge with other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance_ft = 25\n",
    "merged_links, merged_nodes = merge_diff_networks(added_base_links, added_base_nodes, 'road', bike_links, bike_nodes, 'bike', tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add reference IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match reference IDs based on all the id in the nodes\n",
    "refid_base_links = add_reference_ids(merged_links, merged_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "refid_base_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97216bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "refid_base_links.to_file(r'processed_shapefiles\\conflation\\final_links.geojson', driver = 'GeoJSON')\n",
    "merged_nodes.to_file(r'processed_shapefiles\\conflation\\final_nodes.geojson', driver = 'GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert for use in BikewaySim\n",
    "\n",
    "This last section focusses on making sure that the conflated network is readable by BikewaySim. After this is completed, you can run the Running BikwaySim notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "#make directory/pathing more intuitive later\n",
    "file_dir = r\"C:\\Users\\tpassmore6\\Documents\\BikewaySimData\" #directory of bikewaysim network processing code\n",
    "\n",
    "#change this to where you stored this folder\n",
    "os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8139fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for just OSM network\n",
    "conflated_linksfp\n",
    "conflated_nodesfp\n",
    "\n",
    "#filepath for conflated network\n",
    "#conflated_linksfp = r'processed_shapefiles\\conflation\\final_links.geojson'\n",
    "#conflated_nodesfp = r'processed_shapefiles\\conflation\\final_nodes.geojson'\n",
    "\n",
    "#filepaths for network attribute data (doesn't have to be a shapefile)\n",
    "abm_linksfp = r'processed_shapefiles\\abm\\abm_bikewaysim_base_links.geojson'\n",
    "here_linksfp = r'processed_shapefiles\\here\\here_bikewaysim_base_links.geojson'\n",
    "osm_linksfp = r'base_shapefiles\\osm\\osm_links_attr.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Node cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conflated nodes\n",
    "conflated_nodes = gpd.read_file(conflated_nodesfp)\n",
    "\n",
    "#drop the num links columns\n",
    "conflated_nodes = conflated_nodes.drop(columns=['abm_num_links','here_num_links'])\n",
    "\n",
    "#create an N column that takes the abm_id if avaiable followed by the here_id\n",
    "func = lambda row: row['here_ID'] if row['abm_ID'] == None else row['abm_ID']\n",
    "conflated_nodes['N'] = conflated_nodes.apply(func,axis=1)\n",
    "\n",
    "#create UTM coords columns\n",
    "conflated_nodes['X'] = conflated_nodes.geometry.x\n",
    "conflated_nodes['Y'] = conflated_nodes.geometry.y\n",
    "\n",
    "#reproject and find latlon\n",
    "conflated_nodes = conflated_nodes.to_crs(epsg=4326)\n",
    "conflated_nodes['lon'] = conflated_nodes.geometry.x\n",
    "conflated_nodes['lat'] = conflated_nodes.geometry.y\n",
    "\n",
    "#filter\n",
    "conflated_nodes = conflated_nodes[['N','X','Y','lon','lat','geometry']]\n",
    "\n",
    "#export\n",
    "conflated_nodes.to_file(r'processed_shapefiles\\prepared_network\\nodes\\nodes.geojson',driver='GeoJSON')\n",
    "conlfated_nodes = conflated_nodes.drop(columns=['geometry'])\n",
    "conflated_nodes.to_csv(r'processed_shapefiles\\prepared_network\\nodes\\nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa581937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conflated network\n",
    "conflated_links = gpd.read_file(conflated_linksfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e350bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c268eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_network_and_attributes(conflated_links,attr_network,cols_to_keep):\n",
    "    #find the shared columns between conflated network and attribute network\n",
    "    shared_cols = list(conflated_links.columns[conflated_links.columns.isin(attr_network.columns)])\n",
    "\n",
    "    if len(shared_cols) > 2:\n",
    "        #merge based on shared columns\n",
    "        conflated_links = pd.merge(conflated_links,attr_network[cols_to_keep + shared_cols],on=shared_cols,how='left')\n",
    "        print(conflated_links.head(20))\n",
    "    else:\n",
    "        print(f'Attr_network columns not in conflated network')\n",
    "    return conflated_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb472443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data with attributes, don't bring in geometry\n",
    "abm_links = gpd.read_file(abm_linksfp,ignore_geometry=True)\n",
    "\n",
    "#specify which columns you need\n",
    "cols_to_keep = ['NAME','SPEEDLIMIT','two_way']\n",
    "\n",
    "#perform the merge\n",
    "conflated_links = merge_network_and_attributes(conflated_links,abm_links,cols_to_keep)\n",
    "\n",
    "#delete data with attributes to free up memory\n",
    "del(abm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "here_links = gpd.read_file(here_linksfp,ignore_geometry=True)\n",
    "\n",
    "cols_to_keep = ['ST_NAME','DIR_TRAVEL']\n",
    "\n",
    "conflated_links = merge_network_and_attributes(conflated_links,here_links,cols_to_keep)\n",
    "del(here_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31888f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links = pickle.load(open(osm_linksfp,\"rb\"))\n",
    "\n",
    "cols_to_keep = ['name']\n",
    "\n",
    "conflated_links = merge_network_and_attributes(conflated_links,osm_links,cols_to_keep)\n",
    "del(osm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflated_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd48c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff058c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
