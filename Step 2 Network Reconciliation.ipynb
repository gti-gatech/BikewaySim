{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a0e84c",
   "metadata": {},
   "source": [
    "## Step 2 Network Reconciliation\n",
    "---\n",
    "### This the second of five steps to running BikewaySim\n",
    "1. Process network spatial data into a routable network graph format\n",
    "2. __Reconcile networks into one through node and link overlap conflation__\n",
    "3. Create final network graph and calculate link costs\n",
    "4. Create OD tables\n",
    "5. Run BikewaySim\n",
    "\n",
    "In this step, the networks are conflated to each other by utilizing functions in the network_conflation.py module. \n",
    "\n",
    "There are five main functions in the conflation tools module:\n",
    "1. Match nearest points between base and join networks\n",
    "1. Split base links by joining network node\n",
    "1. Add network attributes by link overlap\n",
    "1. Add join links/nodes that aren't in base network\n",
    "1. Resolve reference IDs\n",
    "\n",
    "The final step combines the different types of networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b74c49",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7001d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "#from conflation_tools import *\n",
    "from network_reconcile import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "090d6051",
   "metadata": {},
   "source": [
    "### Quick Method (just use overlap)\n",
    "For a quick reconcile, just run the add_attributes function. For this example, the osm network will serve as the base network, and the here road network will be used to add additional road attributes on speed, the number of lanes, etc. The HERE attributes will only be added to the OSM road layer to minimize incorrect matches. (NOTE: attribute matches will need to be QA/QC'd, this function just serves to populate a base network with the most likely match)\n",
    "   \n",
    "In addition, a non-network geojson file of the Atlanta Regional Comission's Regional Bikeway Inventory 2022 will be used to add additional info to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64fa1a49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Null layer: 'here_links_road'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/Step 2 Network Reconciliation.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/Step%202%20Network%20Reconciliation.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m osm \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(working_dir \u001b[39m/\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstudyarea_name\u001b[39m}\u001b[39;00m\u001b[39m/filtered.gpkg\u001b[39m\u001b[39m'\u001b[39m),layer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mosm_links_road\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/Step%202%20Network%20Reconciliation.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m osm_bike \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(working_dir \u001b[39m/\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstudyarea_name\u001b[39m}\u001b[39;00m\u001b[39m/filtered.gpkg\u001b[39m\u001b[39m'\u001b[39m),layer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mosm_links_bike\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/Step%202%20Network%20Reconciliation.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m here \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_file(working_dir \u001b[39m/\u001b[39;49m Path(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mstudyarea_name\u001b[39m}\u001b[39;49;00m\u001b[39m/filtered.gpkg\u001b[39;49m\u001b[39m'\u001b[39;49m),layer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhere_links_road\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tannerpassmore/Documents/GitHub/BikewaySimDev/Step%202%20Network%20Reconciliation.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m arc_bike \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(working_dir \u001b[39m/\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39mData/ARC/Regional_Bikeway_Inventory_2022.geojson\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mto_crs(\u001b[39m'\u001b[39m\u001b[39mepsg:2240\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/geopandas/io/file.py:201\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     reader \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mopen\n\u001b[1;32m    200\u001b[0m \u001b[39mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mwith\u001b[39;00m reader(path_or_bytes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m features:\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m         \u001b[39m# In a future Fiona release the crs attribute of features will\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39m# no longer be a dict, but will behave like a dict. So this should\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[39m# be forwards compatible\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         crs \u001b[39m=\u001b[39m (\n\u001b[1;32m    207\u001b[0m             features\u001b[39m.\u001b[39mcrs[\u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    208\u001b[0m             \u001b[39mif\u001b[39;00m features\u001b[39m.\u001b[39mcrs \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features\u001b[39m.\u001b[39mcrs\n\u001b[1;32m    209\u001b[0m             \u001b[39melse\u001b[39;00m features\u001b[39m.\u001b[39mcrs_wkt\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    212\u001b[0m         \u001b[39m# handle loading the bounding box\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/fiona/env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m local\u001b[39m.\u001b[39m_env:\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    409\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/fiona/__init__.py:256\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     path \u001b[39m=\u001b[39m parse_path(fp)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 256\u001b[0m     c \u001b[39m=\u001b[39m Collection(path, mode, driver\u001b[39m=\u001b[39;49mdriver, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    257\u001b[0m                    layer\u001b[39m=\u001b[39;49mlayer, enabled_drivers\u001b[39m=\u001b[39;49menabled_drivers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    258\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m schema:\n\u001b[1;32m    260\u001b[0m         \u001b[39m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/fiona/collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m Session()\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mstart(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:553\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Null layer: 'here_links_road'"
     ]
    }
   ],
   "source": [
    "studyarea_name = 'bikewaysim'\n",
    "working_dir = Path.home() / Path(f'Documents/NewBikewaySimData')\n",
    "\n",
    "#import\n",
    "osm = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_links_road')\n",
    "osm_bike = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_links_bike')\n",
    "here = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='here_links_road')\n",
    "arc_bike = gpd.read_file(working_dir / Path('Data/ARC/Regional_Bikeway_Inventory_2022.geojson')).to_crs('epsg:2240')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a93df53",
   "metadata": {},
   "source": [
    "## Merge attribute data\n",
    "These are custom functions made for each network that sort and re-fine the columns to avoid adding excess columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43f9da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\geopandas\\geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\Users\\tpassmore6\\Anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "osm = add_osm_attr(osm,working_dir / Path(f'{studyarea_name}/osm.pkl'))\n",
    "osm_bike = add_osm_attr(osm_bike,working_dir / Path(f'{studyarea_name}/osm.pkl'))\n",
    "here = add_here_attr(here,working_dir / Path(f'{studyarea_name}/here.pkl'))\n",
    "arc_bike = add_arc_bike(arc_bike)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14e803",
   "metadata": {},
   "source": [
    "## transfer attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd382a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissolving by 5 columns\n"
     ]
    }
   ],
   "source": [
    "#add here road attributes to osm road\n",
    "outputs = add_attributes(osm, here, 'here', 25, .9)\n",
    "\n",
    "#add back in osm bike\n",
    "combined = pd.concat([osm_bike,outputs])\n",
    "\n",
    "#add arc bike attributes to osm\n",
    "final = add_attributes(combined, arc_bike, 'arc_bike', 50, .9, dissolve=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59ddeb",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b31c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_file(Path.home() / 'Downloads/test.gpkg',layer='comb_test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e9b18d2",
   "metadata": {},
   "source": [
    "# Lab 9 Conflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "176cc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_dir = Path.home() / Path(\"Downloads/Shortest Path Lab\")\n",
    "# sidewalk_links = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/sidewalks.shp')).to_crs('epsg:2240')\n",
    "# crosswalks = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/crosswalks.shp')).to_crs('epsg:2240')\n",
    "# sidewalk_connectors = gpd.read_file(working_dir / Path('Lab Files/lab_9.gpkg'),layer='sidewalk_connectors')\n",
    "# #sidewalk_nodes = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/sidewalk_nodes.shp')).to_crs('epsg:2240')\n",
    "\n",
    "# osm_links = gpd.read_file(working_dir / Path('Lab Files/networks.gpkg'),layer='osm links')\n",
    "# #osm_nodes = gpd.read_file(working_dir / Path('Lab Files/networks.gpkg'),layer='osm nodes')\n",
    "# #osm_nodes = osm_nodes[osm_nodes['osm_A'].append(osm_nodes['osm_B'].dropna().drop_duplicates().to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "addceabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sidewalk_nodes['id'] = 'SD' + sidewalk_nodes['ID'].astype(str)\n",
    "#sidewalk_nodes[['id','geometry']].to_file(working_dir / Path('lab9.gpkg'),layer='sidewalk_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "afaff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_nodes = osm_nodes[osm_nodes['osm_N'].isin(osm_links['osm_A'].append(osm_links['osm_B']).dropna().drop_duplicates().to_list())]\n",
    "#osm_links.loc[osm_links['type'].isna(),'type'] = \"connector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7f5c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_nodes['id'] = 'OSM' + osm_nodes['osm_N'].astype(str)\n",
    "#osm_nodes[['id','geometry']].to_file(working_dir / Path('lab9.gpkg'),layer='osm_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4bc92447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import\n",
    "# sidewalk_nodes = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='sidewalk_nodes')\n",
    "groceries = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='groceries')\n",
    "origins = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='origins')\n",
    "# osm_nodes = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='osm_nodes')\n",
    "\n",
    "# all_nodes = pd.concat([sidewalk_nodes,osm_nodes,origins,groceries])\n",
    "# all_nodes['lab9_N'] = all_nodes['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f833b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #add ref ids to sidewalk connectors from sidewalk nodes\n",
    "# from network_filter import add_ref_ids\n",
    "# sidewalk_links = add_ref_ids(sidewalk_links,all_nodes,'lab9')\n",
    "# crosswalks = add_ref_ids(crosswalks,all_nodes,'lab9')\n",
    "# sidewalk_connectors = add_ref_ids(sidewalk_connectors,all_nodes,'lab9')\n",
    "# osm_links = add_ref_ids(osm_links,all_nodes,'lab9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7f17d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n",
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference IDs successfully added to links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n",
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference IDs successfully added to links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n",
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference IDs successfully added to links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n",
      "/Users/tannerpassmore/opt/anaconda3/envs/geo-env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference IDs successfully added to links.\n"
     ]
    }
   ],
   "source": [
    "# from network_filter import add_ref_ids\n",
    "# dfs = {\n",
    "#     'sidewalk_links':sidewalk_links,\n",
    "#     'crosswalks':crosswalks,\n",
    "#     'sidewalk_connectors':sidewalk_connectors,\n",
    "#     'osm_links':osm_links\n",
    "# }\n",
    "\n",
    "# for key in dfs.keys():\n",
    "#     df = dfs[key]\n",
    "#     df = add_ref_ids(df,all_nodes,'lab9')\n",
    "#     df['A'] = df['lab9_A']\n",
    "#     df['B'] = df['lab9_B']\n",
    "#     df['A_B'] = df['A'] + '_' + df['B']\n",
    "#     df.to_file(working_dir / Path('lab9.gpkg'),layer=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "34c28861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "combs = list(itertools.product(origins['id'],groceries['id']))\n",
    "df = pd.DataFrame.from_records(combs,columns=['ori','dest'])\n",
    "df = pd.merge(df,origins,left_on='ori',right_on='id')\n",
    "df = gpd.GeoDataFrame(df,geometry='geometry',crs='epsg:2240').to_crs('epsg:4326')\n",
    "df['ori_lat'] = df.geometry.y\n",
    "df['ori_lon'] = df.geometry.x\n",
    "df.drop(columns=['id','geometry'],inplace=True)\n",
    "\n",
    "df = pd.merge(df,groceries,left_on='dest',right_on='id')\n",
    "df = gpd.GeoDataFrame(df,geometry='geometry',crs='epsg:2240').to_crs('epsg:4326')\n",
    "df['dest_lat'] = df.geometry.y\n",
    "df['dest_lon'] = df.geometry.x\n",
    "df.drop(columns=['id','geometry'],inplace=True)\n",
    "\n",
    "df['trip_id'] = df['ori'] + '_' + df['dest']\n",
    "\n",
    "df.to_csv(working_dir / Path('trips.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60519e7",
   "metadata": {},
   "source": [
    "### Links and Nodes to Conflate\n",
    "Determine what you want the base and join network to be. All of the links and nodes from the base network will be present in the final network.\n",
    "\n",
    "For this project, OSM served as the base followed by HERE and ABM as the joining. Only the road + bike networks created in the first step was used for conflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d93693",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'osm'\n",
    "join_name = 'here'\n",
    "study_area = 'bikewaysim'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b15922",
   "metadata": {},
   "source": [
    "### Road Link Conflation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e8ed2",
   "metadata": {},
   "source": [
    "I like to remove all of the columns that aren't related to node_id or geometry for this step. To make sure we preserve link information I also make a A_B column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_links, base_nodes = import_network(base_name,'road',study_area)\n",
    "join_links, join_nodes = import_network(join_name,'road',study_area)\n",
    "\n",
    "#initialize the base network\n",
    "base_links, base_nodes = initialize_base(base_links, base_nodes, join_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3665c6",
   "metadata": {},
   "source": [
    "### Node Matching\n",
    "This function matches nodes within a set tolerence (in CRS units) that are likely to be the same nodes. This function is intended for matching road intersections or road termini since these are likely to be in both networks. This function can be applied with an iteratively increasing tolerance if you're not sure what's a good tolerance. At some point, the number of matched nodes will not increase by much.\n",
    "\n",
    "The match results will get printed out.\n",
    "\n",
    "#### NOTE: This function handles duplicate matches (i.e. when two or more nodes share a nearest node in the other network) by selecting the one with the shorter match distance. The duplicates won't be rematched unless you run the matching process again.\n",
    "\n",
    "#### When looping match function, feed outputs from previous\n",
    "\n",
    "### Function Inputs\n",
    "- base_nodes, base_name, join_nodes, join_name # self explanatory\n",
    "- tolerance_ft: the match tolerance in units of feet\n",
    "- prev_matched_nodes: geodataframe of the list of currently matched nodes, set to none for first run\n",
    "- remove_duplicates: if set to 'True' (default), then remove duplicate matches. If set to false, duplicate matches will be returned in the matched_nodes gdf.\n",
    "- export_error_lines: if set to 'False', a geojson of linestrings visualizing the matches will be written.\n",
    "- export_unmatched: if you want a geojson of the nodes that didn't match in each network set this to true (False by default).\n",
    "\n",
    "### Function Outputs\n",
    "- matched_nodes: a df of matched nodes, just the node ids.\n",
    "- unmatched_base_nodes: a gdf of the base nodes that weren't matched.\n",
    "- unmatched_join_nodes: a gdf of the join nodes that weren't matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "tolerance_ft = 25\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second iteration example with same tolerance\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)\n",
    "\n",
    "#third iteration example wiht larger tolerance\n",
    "tolerance_ft = 30\n",
    "base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe76125",
   "metadata": {},
   "source": [
    "### Link Splitting and Add New Links and Nodes\n",
    "This function will split links in the base network if there's a node in the join network that is within a certain tolerance. This creates new nodes and links on the base network. The original base links are then replaced with these new links/nodes.\n",
    "\n",
    "#### NOTE: This may create way more links/nodes than neccessary.\n",
    "\n",
    "It may be wise to consider limiting the kind of join nodes that can split a base link. For instance, OSM has lots of additional links and nodes because there are sidewalks. The nodes used to access these sidewalks will split the base link, which creates additional link where there otherwise would be none. These added links/nodes can slow down computational time for shortest path calculation. However, it could be adventageous in the attribute transfer process.\n",
    "\n",
    "#### Looping\n",
    "This function can be looped if unsure what tolerance or nodes to use. \n",
    "\n",
    "### Function Inputs\n",
    "- unmatched_join_nodes: These are the join nodes that weren't matched to base nodes in the previous step\n",
    "- join_name, base_links, base_name: self-explanatory\n",
    "- tolerance_ft: the matching tolerance in feet\n",
    "- export: set to 'True' to get a GeoJSON of new links and nodes that were created\n",
    "\n",
    "### Function Outputs\n",
    "- split_lines: a gdf of just the new base links\n",
    "- split_nodes: a gdf of jsut the new base nodes\n",
    "- unmathced_join_nodes: a gdf of the join nodes that didn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c76ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_join_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "tolerance_ft = 25\n",
    "split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "                                                                           join_name,\n",
    "                                                                           base_links,\n",
    "                                                                           base_name,\n",
    "                                                                           tolerance_ft,\n",
    "                                                                           export = False)\n",
    "split_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "new_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931b59f",
   "metadata": {},
   "source": [
    "### Attribute Transfer\n",
    "In the previous steps, we found geometric commonalties between the networks. In this step, we want to transfer attribute information from the join network into the base network. Link attributes are based on a link's reference ids, but the current set of links may not have reference ids that correspond to a join network link.\n",
    "\n",
    "To address this, we buffer the base links and intersect them with the join links. We then measure the length of the resulting linestrings. The attribute information from the join links that have the maximum length (i.e. the maximum amount of overlap with the base link) is tranferred. This ensures that each base link is associated with only one join link's attributes.\n",
    "\n",
    "### NOTE: The buffer here needs to be smaller\n",
    "If it's larger, then a longer join node could be selected as the join link with most overlap.\n",
    "\n",
    "This process will likely change in the future. A different approach might be to look at all the base links with at least one join node in the reference id column, and then look up all the links in the join network associated with that node (there should only be a few). Using other reference node that doesn't have a join node id, the nearest node in that lookup table could be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match attribute information with greatest overlap from joining links\n",
    "buffer_ft = 30\n",
    "new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "new_base_links_w_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b03124",
   "metadata": {},
   "source": [
    "### Add rest of features\n",
    "Now that we've settled the geometric and attribute commonalities between the base and join networks, we can add in the join network features that aren't represented in the base network. This is done using a buffer. If a join link is covered at least 95% by a base link, then it is left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce23175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "#create new abmhere column with id and geo\n",
    "final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)\n",
    "\n",
    "final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d7fc5",
   "metadata": {},
   "source": [
    "### Save as pickle, this is more of a progress save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9278388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(added_base_links, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))\n",
    "#pickle.dump(added_base_nodes, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a709e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Repeat for OSM\n",
    "Now that we've resovled ABM and HERE, we can add the second join network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b47e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"abmhere\"\n",
    "base_links = final_links\n",
    "base_nodes = final_nodes\n",
    "\n",
    "join_name = \"osm\"\n",
    "join_links = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_links.geojson\")\n",
    "join_nodes = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_nodes.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean join links (no need to clean base links)\n",
    "join_links, join_nodes = cleaning_process(join_links,join_nodes,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ffb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "tolerance_ft = 25\n",
    "matched_nodes, unmatched_base_nodes, unmatched_join_nodes = match_nodes(base_nodes, base_name, join_nodes, join_name, tolerance_ft, prev_matched_nodes=None)\n",
    "\n",
    "#join the matched nodes to the base nodes once done with matching\n",
    "matched_nodes_final = pd.merge(base_nodes, matched_nodes, on = f'{base_name}_ID', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "tolerance_ft = 25\n",
    "split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "                                                                           join_name,\n",
    "                                                                           base_links,\n",
    "                                                                           base_name,\n",
    "                                                                           tolerance_ft,\n",
    "                                                                           export = False)\n",
    "split_lines.head()\n",
    "split_lines.to_file('processed_shapefiles/conflation/split_lines.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "new_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b96068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match attribute information with greatest overlap from joining links\n",
    "buffer_ft = 30\n",
    "new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "new_base_links_w_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "#create new abmhere column with id and geo\n",
    "final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df29cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike Subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bike layers\n",
    "bike_links = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_links.geojson')\n",
    "bike_nodes = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_nodes.geojson')\n",
    "bike_name = 'here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean excess columns\n",
    "bike_links, bike_nodes = cleaning_process(bike_links,bike_nodes,bike_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e26f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge with other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance_ft = 25\n",
    "merged_links, merged_nodes = merge_diff_networks(added_base_links, added_base_nodes, 'road', bike_links, bike_nodes, 'bike', tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add reference IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match reference IDs based on all the id in the nodes\n",
    "refid_base_links = add_reference_ids(merged_links, merged_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "refid_base_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97216bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "refid_base_links.to_file(r'processed_shapefiles\\conflation\\final_links.geojson', driver = 'GeoJSON')\n",
    "merged_nodes.to_file(r'processed_shapefiles\\conflation\\final_nodes.geojson', driver = 'GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert for use in BikewaySim\n",
    "\n",
    "This last section focusses on making sure that the conflated network is readable by BikewaySim. After this is completed, you can run the Running BikwaySim notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "#make directory/pathing more intuitive later\n",
    "file_dir = r\"C:\\Users\\tpassmore6\\Documents\\BikewaySimData\" #directory of bikewaysim network processing code\n",
    "\n",
    "#change this to where you stored this folder\n",
    "os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8139fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for just OSM network\n",
    "conflated_linksfp\n",
    "conflated_nodesfp\n",
    "\n",
    "#filepath for conflated network\n",
    "#conflated_linksfp = r'processed_shapefiles\\conflation\\final_links.geojson'\n",
    "#conflated_nodesfp = r'processed_shapefiles\\conflation\\final_nodes.geojson'\n",
    "\n",
    "#filepaths for network attribute data (doesn't have to be a shapefile)\n",
    "abm_linksfp = r'processed_shapefiles\\abm\\abm_bikewaysim_base_links.geojson'\n",
    "here_linksfp = r'processed_shapefiles\\here\\here_bikewaysim_base_links.geojson'\n",
    "osm_linksfp = r'base_shapefiles\\osm\\osm_links_attr.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Node cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conflated nodes\n",
    "conflated_nodes = gpd.read_file(conflated_nodesfp)\n",
    "\n",
    "#drop the num links columns\n",
    "conflated_nodes = conflated_nodes.drop(columns=['abm_num_links','here_num_links'])\n",
    "\n",
    "#create an N column that takes the abm_id if avaiable followed by the here_id\n",
    "func = lambda row: row['here_ID'] if row['abm_ID'] == None else row['abm_ID']\n",
    "conflated_nodes['N'] = conflated_nodes.apply(func,axis=1)\n",
    "\n",
    "#create UTM coords columns\n",
    "conflated_nodes['X'] = conflated_nodes.geometry.x\n",
    "conflated_nodes['Y'] = conflated_nodes.geometry.y\n",
    "\n",
    "#reproject and find latlon\n",
    "conflated_nodes = conflated_nodes.to_crs(epsg=4326)\n",
    "conflated_nodes['lon'] = conflated_nodes.geometry.x\n",
    "conflated_nodes['lat'] = conflated_nodes.geometry.y\n",
    "\n",
    "#filter\n",
    "conflated_nodes = conflated_nodes[['N','X','Y','lon','lat','geometry']]\n",
    "\n",
    "#export\n",
    "conflated_nodes.to_file(r'processed_shapefiles\\prepared_network\\nodes\\nodes.geojson',driver='GeoJSON')\n",
    "conlfated_nodes = conflated_nodes.drop(columns=['geometry'])\n",
    "conflated_nodes.to_csv(r'processed_shapefiles\\prepared_network\\nodes\\nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa581937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conflated network\n",
    "conflated_links = gpd.read_file(conflated_linksfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e350bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c268eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_network_and_attributes(conflated_links,attr_network,cols_to_keep):\n",
    "    #find the shared columns between conflated network and attribute network\n",
    "    shared_cols = list(conflated_links.columns[conflated_links.columns.isin(attr_network.columns)])\n",
    "\n",
    "    if len(shared_cols) > 2:\n",
    "        #merge based on shared columns\n",
    "        conflated_links = pd.merge(conflated_links,attr_network[cols_to_keep + shared_cols],on=shared_cols,how='left')\n",
    "        print(conflated_links.head(20))\n",
    "    else:\n",
    "        print(f'Attr_network columns not in conflated network')\n",
    "    return conflated_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb472443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data with attributes, don't bring in geometry\n",
    "abm_links = gpd.read_file(abm_linksfp,ignore_geometry=True)\n",
    "\n",
    "#specify which columns you need\n",
    "cols_to_keep = ['NAME','SPEEDLIMIT','two_way']\n",
    "\n",
    "#perform the merge\n",
    "conflated_links = merge_network_and_attributes(conflated_links,abm_links,cols_to_keep)\n",
    "\n",
    "#delete data with attributes to free up memory\n",
    "del(abm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "here_links = gpd.read_file(here_linksfp,ignore_geometry=True)\n",
    "\n",
    "cols_to_keep = ['ST_NAME','DIR_TRAVEL']\n",
    "\n",
    "conflated_links = merge_network_and_attributes(conflated_links,here_links,cols_to_keep)\n",
    "del(here_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31888f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_links = pickle.load(open(osm_linksfp,\"rb\"))\n",
    "\n",
    "cols_to_keep = ['name']\n",
    "\n",
    "conflated_links = merge_network_and_attributes(conflated_links,osm_links,cols_to_keep)\n",
    "del(osm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflated_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd48c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff058c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
