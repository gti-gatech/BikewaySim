{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a0e84c",
   "metadata": {},
   "source": [
    "## Step 2 Network Reconciliation\n",
    "---\n",
    "### This the second of five steps to running BikewaySim\n",
    "1. Process network spatial data into a routable network graph format\n",
    "2. __Reconcile networks into one through node and link overlap conflation__\n",
    "3. Create final network graph and calculate link costs\n",
    "4. Create OD tables\n",
    "5. Run BikewaySim\n",
    "\n",
    "In this step, the networks are conflated to each other by utilizing functions in the network_conflation.py module. \n",
    "\n",
    "There are five main functions in the conflation tools module:\n",
    "1. Match nearest points between base and join networks\n",
    "1. Split base final by joining network node\n",
    "1. Add network attributes by link overlap\n",
    "1. Add join final/nodes that aren't in base network\n",
    "1. Resolve reference IDs\n",
    "\n",
    "The final step combines the different types of networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b74c49",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7001d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from conflation_tools import *\n",
    "from network_filter import *\n",
    "from network_reconcile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7617b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO turn this into a function\n",
    "\n",
    "#transitsim quick\n",
    "filepath = Path.home() / 'Documents/TransitSimData/networks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ada00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import road layer\n",
    "road_links = gpd.read_file(filepath / 'filtered.gpkg',layer='osm_links_road')\n",
    "road_nodes = gpd.read_file(filepath / 'filtered.gpkg',layer='osm_nodes_road')\n",
    "\n",
    "#import bike layer\n",
    "bike_links = gpd.read_file(filepath / 'filtered.gpkg',layer='osm_links_bike')\n",
    "bike_nodes = gpd.read_file(filepath / 'filtered.gpkg',layer='osm_nodes_bike')\n",
    "\n",
    "#get node count to find dead ends\n",
    "bike_nodes['num_links'] = bike_nodes['osm_N'].map(bike_links['osm_A'].append(bike_links['osm_B']).value_counts())\n",
    "dead_ends = bike_nodes[bike_nodes['num_links']==1]\n",
    "\n",
    "#remove dead ends already connected to road network\n",
    "dead_ends = dead_ends[-dead_ends['osm_N'].isin(road_nodes['osm_N'])]\n",
    "\n",
    "#split osm road links\n",
    "split_lines, split_points, unmatched_join_nodes = split_lines_create_points(dead_ends, 'osm', road_links, 'osm', 40)\n",
    "\n",
    "#add nodes\n",
    "road_nodes = pd.concat([road_nodes,split_points,bike_nodes],ignore_index=True).reset_index().drop_duplicates()\n",
    "\n",
    "#add ref ids to split links\n",
    "split_lines = add_ref_ids(split_lines,road_nodes,'osm')\n",
    "\n",
    "road_links= add_split_links(road_links,split_lines,'osm')\n",
    "\n",
    "road_links= pd.concat([road_links,bike_links])\n",
    "\n",
    "#add attributes back\n",
    "osm = add_osm_attr(road_links, filepath / 'osm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7a38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_links = gpd.read_file(filepath / 'reconciled_network.gpkg',layer='links')\n",
    "road_nodes = gpd.read_file(filepath / 'reconciled_network.gpkg',layer='nodes')\n",
    "\n",
    "#add attributes back\n",
    "osm = add_osm_attr(road_links, filepath / 'osm.pkl')\n",
    "\n",
    "osm.to_file(filepath / 'reconciled_network.gpkg',layer='links')\n",
    "road_nodes.to_file(filepath / 'reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02bf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export plain version\n",
    "road_links.to_file(filepath / 'reconciled_network.gpkg',layer='links')\n",
    "road_nodes.to_file(filepath / 'reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6697e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add attributes back\n",
    "osm = add_osm_attr(road_links, filepath / 'osm.pkl')\n",
    "\n",
    "#drop stressfull links unless they have bike infra\n",
    "stressful = osm['highway'].isin(['primary','primary_link','secondary','secondary_link','tertiary_link','trunk','trunk_link'])\n",
    "bike_infra = osm[['osm_pbl','osm_mu','osm_bl']].sum(axis=1) > 0\n",
    "\n",
    "new_osm = osm[-stressful | bike_infra]\n",
    "\n",
    "new_nodes = road_nodes[road_nodes['osm_N'].isin(new_osm['osm_A'].append(new_osm['osm_B']).drop_duplicates())]\n",
    "\n",
    "#exports\n",
    "new_osm.to_file(filepath / 'lowstress_reconciled_network.gpkg',layer='links')\n",
    "new_nodes.to_file(filepath / 'lowstress_reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "090d6051",
   "metadata": {},
   "source": [
    "### Quick Method (split osm final and use overlap to add here attributes)\n",
    "For a quick reconcile, just run the add_attributes function. For this example, the osm network will serve as the base network, and the here road network will be used to add additional road attributes on speed, the number of lanes, etc. The HERE attributes will only be added to the OSM road layer to minimize incorrect matches. (NOTE: attribute matches will need to be QA/QC'd, this function just serves to populate a base network with the most likely match)\n",
    "   \n",
    "In addition, a non-network geojson file of the Atlanta Regional Comission's Regional Bikeway Inventory 2022 will be used to add additional info to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyarea_name = 'bikewaysim'\n",
    "working_dir = Path.home() / Path(f'Documents/NewBikewaySimData')\n",
    "\n",
    "#import links\n",
    "osm = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_links_road')\n",
    "osm_bike = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_links_bike')\n",
    "here = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='here_links_road')\n",
    "\n",
    "#import osm nodes for line splitting and layer merging\n",
    "osm_n = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_nodes_road')\n",
    "osm_bike_n = gpd.read_file(working_dir / Path(f'{studyarea_name}/filtered.gpkg'),layer='osm_nodes_bike')\n",
    "\n",
    "# import supplemental data\n",
    "arc_bike = gpd.read_file(working_dir / Path('Data/ARC/Regional_Bikeway_Inventory_2022.geojson')).to_crs('epsg:2240')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a81466ba",
   "metadata": {},
   "source": [
    "# Combine OSM road and bike layers\n",
    "In this cell, the OSM road and bike layers are reconnected to form one network. To do this, dead end nodes on the bike layer are used to split osm final and create new nodes if no node is near."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get node count to find dead ends\n",
    "osm_bike_n['num_links'] = osm_bike_n['osm_N'].map(osm_bike['osm_A'].append(osm_bike['osm_B']).value_counts())\n",
    "dead_ends = osm_bike_n[osm_bike_n['num_links']==1]\n",
    "\n",
    "#remove dead ends already connected to road network\n",
    "dead_ends = dead_ends[-dead_ends['osm_N'].isin(osm_n['osm_N'])]\n",
    "\n",
    "#split osm road links\n",
    "split_lines, split_points, unmatched_join_nodes = split_lines_create_points(dead_ends, 'osm', osm, 'osm', 40)\n",
    "\n",
    "#add nodes\n",
    "osm_n = pd.concat([osm_n,split_points,osm_bike_n],ignore_index=True).reset_index().drop_duplicates()\n",
    "\n",
    "#add ref ids to split links\n",
    "split_lines = add_ref_ids(split_lines,osm_n,'osm')\n",
    "\n",
    "osm = add_split_links(osm,split_lines,'osm')\n",
    "\n",
    "osm = pd.concat([osm,osm_bike])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a93df53",
   "metadata": {},
   "source": [
    "# Merge attribute data\n",
    "These are custom functions made for each network that sort and re-fine the columns to avoid adding excess columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm = add_osm_attr(osm,working_dir / Path(f'{studyarea_name}/osm.pkl'))\n",
    "here = add_here_attr(here,working_dir / Path(f'{studyarea_name}/here.pkl'))\n",
    "arc_bike = add_arc_bike(arc_bike)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c14e803",
   "metadata": {},
   "source": [
    "## transfer attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd382a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add here road attributes to osm road\n",
    "outputs = add_attributes(osm, here, 'here', 25, .9)\n",
    "\n",
    "#add arc bike attributes to osm\n",
    "final = add_attributes(outputs, arc_bike, 'arc_bike', 50, .9, dissolve=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ad4bd2",
   "metadata": {},
   "source": [
    "Reconcile Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ['osm','here','arc']\n",
    "cols = ['bl','pbl','mu','<25mph','25-30mph','>30mph','1lpd','2-3lpd','>4lpd']\n",
    "\n",
    "for col in cols:\n",
    "    final[col] = 0\n",
    "    final[col+'_check'] = final[[ x for x in final.columns.tolist() if col in x]].sum(axis=1)\n",
    "\n",
    "#bike facil (go with osm values for multi-use)\n",
    "final.loc[final['osm_mu'] == 1, 'mu'] = 1\n",
    "final.loc[final['pbl_check'] > 0,'pbl'] = 1\n",
    "final.loc[final['bl_check'] > 0,'bl'] = 1\n",
    "\n",
    "#get bike facilites and export\n",
    "final['bike_facil'] = None\n",
    "final.loc[final['mu'] == 1, 'bike_facil'] = 'Multi-Use Path'\n",
    "final.loc[final['bl'] == 1, 'bike_facil'] = 'Bike Lane'\n",
    "final.loc[final['pbl'] == 1, 'bike_facil'] = 'Protected Bike Lane'\n",
    "\n",
    "#speed (go with here values)\n",
    "final.loc[final['here_<25mph'] == 1, '<25mph'] = 1\n",
    "final.loc[final['here_25-30mph'] == 1, '25-30mph'] = 1\n",
    "final.loc[final['here_>30mph'] == 1, '>30mph'] = 1\n",
    "\n",
    "#lanes (go with here values)\n",
    "final.loc[final['here_1lpd'] == 1, '1lpd'] = 1\n",
    "final.loc[final['here_2-3lpd'] == 1, '2-3lpd'] = 1\n",
    "final.loc[final['here_>4lpd'] == 1, '>4lpd'] = 1\n",
    "\n",
    "#make all other 0 if mu\n",
    "new_cols = ['bl','pbl','<25mph','25-30mph','>30mph','1lpd','2-3lpd','>4lpd']\n",
    "final.loc[final['mu']==1,new_cols] = 0\n",
    "\n",
    "#have pbl over bl\n",
    "final.loc[(final['bl']==1) & (final['pbl']==1),'bl'] = 0\n",
    "\n",
    "#links with no attributes (use highway tag to impute)\n",
    "no_values = final[cols].sum(axis=1) == 0\n",
    "final.loc[no_values & (final['highway']=='residential'),'25-30mph'] = 1\n",
    "final.loc[no_values & (final['highway']=='residential'),'1lpd'] = 1\n",
    "\n",
    "final.loc[no_values & (final['highway']=='service'),'<25mph'] = 1\n",
    "final.loc[no_values & (final['highway']=='service'),'1lpd'] = 1\n",
    "\n",
    "#make this more advanced later\n",
    "others = ['secondary','trunk','trunk_link','tertiary','tertiary_link','primary','secondary_link','primary_link']\n",
    "final.loc[no_values & (final['highway'].isin(others)),'25-30mph'] = 1\n",
    "final.loc[no_values & (final['highway'].isin(others)),'2-3lpd'] = 1\n",
    "\n",
    "final = final[['osm_A','osm_B','osm_A_B','name','highway','oneway','ST_NAME','FUNC_CLASS','DIR_TRAVEL','bike_facil','geometry']+cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caa85ea9",
   "metadata": {},
   "source": [
    "Handle wrongways (future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e2b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf59ddeb",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_file(working_dir / studyarea_name / 'reconciled_network.gpkg',layer='links')\n",
    "osm_n.to_file(working_dir / studyarea_name / 'reconciled_network.gpkg',layer='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.value_counts(subset=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.explore('bike_facil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(final['>4lpd'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6655ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final[final[cols].sum(axis=1) ==0].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_dir = Path.home() / Path(\"Downloads/Shortest Path Lab\")\n",
    "# sidewalk_final = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/sidewalks.shp')).to_crs('epsg:2240')\n",
    "# crosswalks = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/crosswalks.shp')).to_crs('epsg:2240')\n",
    "# sidewalk_connectors = gpd.read_file(working_dir / Path('Lab Files/lab_9.gpkg'),layer='sidewalk_connectors')\n",
    "# #sidewalk_nodes = gpd.read_file(working_dir / Path('lab_files/sidewalk_network/sidewalk_nodes.shp')).to_crs('epsg:2240')\n",
    "\n",
    "# osm_final = gpd.read_file(working_dir / Path('Lab Files/networks.gpkg'),layer='osm final')\n",
    "# #osm_nodes = gpd.read_file(working_dir / Path('Lab Files/networks.gpkg'),layer='osm nodes')\n",
    "# #osm_nodes = osm_nodes[osm_nodes['osm_A'].append(osm_nodes['osm_B'].dropna().drop_duplicates().to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addceabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sidewalk_nodes['id'] = 'SD' + sidewalk_nodes['ID'].astype(str)\n",
    "#sidewalk_nodes[['id','geometry']].to_file(working_dir / Path('lab9.gpkg'),layer='sidewalk_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_nodes = osm_nodes[osm_nodes['osm_N'].isin(osm_final['osm_A'].append(osm_final['osm_B']).dropna().drop_duplicates().to_list())]\n",
    "#osm_final.loc[osm_final['type'].isna(),'type'] = \"connector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_nodes['id'] = 'OSM' + osm_nodes['osm_N'].astype(str)\n",
    "#osm_nodes[['id','geometry']].to_file(working_dir / Path('lab9.gpkg'),layer='osm_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc92447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import\n",
    "# sidewalk_nodes = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='sidewalk_nodes')\n",
    "#groceries = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='groceries')\n",
    "#origins = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='origins')\n",
    "# osm_nodes = gpd.read_file(working_dir / Path('lab9.gpkg'),layer='osm_nodes')\n",
    "\n",
    "# all_nodes = pd.concat([sidewalk_nodes,osm_nodes,origins,groceries])\n",
    "# all_nodes['lab9_N'] = all_nodes['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #add ref ids to sidewalk connectors from sidewalk nodes\n",
    "# from network_filter import add_ref_ids\n",
    "# sidewalk_final = add_ref_ids(sidewalk_final,all_nodes,'lab9')\n",
    "# crosswalks = add_ref_ids(crosswalks,all_nodes,'lab9')\n",
    "# sidewalk_connectors = add_ref_ids(sidewalk_connectors,all_nodes,'lab9')\n",
    "# osm_final = add_ref_ids(osm_final,all_nodes,'lab9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from network_filter import add_ref_ids\n",
    "# dfs = {\n",
    "#     'sidewalk_final':sidewalk_final,\n",
    "#     'crosswalks':crosswalks,\n",
    "#     'sidewalk_connectors':sidewalk_connectors,\n",
    "#     'osm_final':osm_final\n",
    "# }\n",
    "\n",
    "# for key in dfs.keys():\n",
    "#     df = dfs[key]\n",
    "#     df = add_ref_ids(df,all_nodes,'lab9')\n",
    "#     df['A'] = df['lab9_A']\n",
    "#     df['B'] = df['lab9_B']\n",
    "#     df['A_B'] = df['A'] + '_' + df['B']\n",
    "#     df.to_file(working_dir / Path('lab9.gpkg'),layer=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c28861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# combs = list(itertools.product(origins['id'],groceries['id']))\n",
    "# df = pd.DataFrame.from_records(combs,columns=['ori','dest'])\n",
    "# df = pd.merge(df,origins,left_on='ori',right_on='id')\n",
    "# df = gpd.GeoDataFrame(df,geometry='geometry',crs='epsg:2240').to_crs('epsg:4326')\n",
    "# df['ori_lat'] = df.geometry.y\n",
    "# df['ori_lon'] = df.geometry.x\n",
    "# df.drop(columns=['id','geometry'],inplace=True)\n",
    "\n",
    "# df = pd.merge(df,groceries,left_on='dest',right_on='id')\n",
    "# df = gpd.GeoDataFrame(df,geometry='geometry',crs='epsg:2240').to_crs('epsg:4326')\n",
    "# df['dest_lat'] = df.geometry.y\n",
    "# df['dest_lon'] = df.geometry.x\n",
    "# df.drop(columns=['id','geometry'],inplace=True)\n",
    "\n",
    "# df['trip_id'] = df['ori'] + '_' + df['dest']\n",
    "\n",
    "# df.to_csv(working_dir / Path('trips.csv'),index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b60519e7",
   "metadata": {},
   "source": [
    "### final and Nodes to Conflate\n",
    "Determine what you want the base and join network to be. All of the final and nodes from the base network will be present in the final network.\n",
    "\n",
    "For this project, OSM served as the base followed by HERE and ABM as the joining. Only the road + bike networks created in the first step was used for conflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d93693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_name = 'osm'\n",
    "# join_name = 'here'\n",
    "# study_area = 'bikewaysim'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05b15922",
   "metadata": {},
   "source": [
    "### Road Link Conflation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a46e8ed2",
   "metadata": {},
   "source": [
    "I like to remove all of the columns that aren't related to node_id or geometry for this step. To make sure we preserve link information I also make a A_B column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_links, base_nodes = import_network(base_name,'road',study_area)\n",
    "# join_links, join_nodes = import_network(join_name,'road',study_area)\n",
    "\n",
    "# #initialize the base network\n",
    "# base_links, base_nodes = initialize_base(base_links, base_nodes, join_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d3665c6",
   "metadata": {},
   "source": [
    "### Node Matching\n",
    "This function matches nodes within a set tolerence (in CRS units) that are likely to be the same nodes. This function is intended for matching road intersections or road termini since these are likely to be in both networks. This function can be applied with an iteratively increasing tolerance if you're not sure what's a good tolerance. At some point, the number of matched nodes will not increase by much.\n",
    "\n",
    "The match results will get printed out.\n",
    "\n",
    "#### NOTE: This function handles duplicate matches (i.e. when two or more nodes share a nearest node in the other network) by selecting the one with the shorter match distance. The duplicates won't be rematched unless you run the matching process again.\n",
    "\n",
    "#### When looping match function, feed outputs from previous\n",
    "\n",
    "### Function Inputs\n",
    "- base_nodes, base_name, join_nodes, join_name # self explanatory\n",
    "- tolerance_ft: the match tolerance in units of feet\n",
    "- prev_matched_nodes: geodataframe of the list of currently matched nodes, set to none for first run\n",
    "- remove_duplicates: if set to 'True' (default), then remove duplicate matches. If set to false, duplicate matches will be returned in the matched_nodes gdf.\n",
    "- export_error_lines: if set to 'False', a geojson of linestrings visualizing the matches will be written.\n",
    "- export_unmatched: if you want a geojson of the nodes that didn't match in each network set this to true (False by default).\n",
    "\n",
    "### Function Outputs\n",
    "- matched_nodes: a df of matched nodes, just the node ids.\n",
    "- unmatched_base_nodes: a gdf of the base nodes that weren't matched.\n",
    "- unmatched_join_nodes: a gdf of the join nodes that weren't matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "# tolerance_ft = 25\n",
    "# base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #second iteration example with same tolerance\n",
    "# base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)\n",
    "\n",
    "# #third iteration example wiht larger tolerance\n",
    "# tolerance_ft = 30\n",
    "# base_nodes = match_nodes(base_nodes,base_name,join_nodes,join_name,tolerance_ft)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe76125",
   "metadata": {},
   "source": [
    "### Link Splitting and Add New final and Nodes\n",
    "This function will split final in the base network if there's a node in the join network that is within a certain tolerance. This creates new nodes and final on the base network. The original base final are then replaced with these new final/nodes.\n",
    "\n",
    "#### NOTE: This may create way more final/nodes than neccessary.\n",
    "\n",
    "It may be wise to consider limiting the kind of join nodes that can split a base link. For instance, OSM has lots of additional final and nodes because there are sidewalks. The nodes used to access these sidewalks will split the base link, which creates additional link where there otherwise would be none. These added final/nodes can slow down computational time for shortest path calculation. However, it could be adventageous in the attribute transfer process.\n",
    "\n",
    "#### Looping\n",
    "This function can be looped if unsure what tolerance or nodes to use. \n",
    "\n",
    "### Function Inputs\n",
    "- unmatched_join_nodes: These are the join nodes that weren't matched to base nodes in the previous step\n",
    "- join_name, base_final, base_name: self-explanatory\n",
    "- tolerance_ft: the matching tolerance in feet\n",
    "- export: set to 'True' to get a GeoJSON of new final and nodes that were created\n",
    "\n",
    "### Function Outputs\n",
    "- split_lines: a gdf of just the new base final\n",
    "- split_nodes: a gdf of jsut the new base nodes\n",
    "- unmathced_join_nodes: a gdf of the join nodes that didn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c76ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unmatched_join_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "# tolerance_ft = 25\n",
    "# split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "#                                                                            join_name,\n",
    "#                                                                            base_links,\n",
    "#                                                                            base_name,\n",
    "#                                                                            tolerance_ft,\n",
    "#                                                                            export = False)\n",
    "# split_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "# new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "# new_links.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a931b59f",
   "metadata": {},
   "source": [
    "### Attribute Transfer\n",
    "In the previous steps, we found geometric commonalties between the networks. In this step, we want to transfer attribute information from the join network into the base network. Link attributes are based on a link's reference ids, but the current set of final may not have reference ids that correspond to a join network link.\n",
    "\n",
    "To address this, we buffer the base final and intersect them with the join final. We then measure the length of the resulting linestrings. The attribute information from the join final that have the maximum length (i.e. the maximum amount of overlap with the base link) is tranferred. This ensures that each base link is associated with only one join link's attributes.\n",
    "\n",
    "### NOTE: The buffer here needs to be smaller\n",
    "If it's larger, then a longer join node could be selected as the join link with most overlap.\n",
    "\n",
    "This process will likely change in the future. A different approach might be to look at all the base final with at least one join node in the reference id column, and then look up all the final in the join network associated with that node (there should only be a few). Using other reference node that doesn't have a join node id, the nearest node in that lookup table could be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #match attribute information with greatest overlap from joining links\n",
    "# buffer_ft = 30\n",
    "# new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "# new_base_links_w_attr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b03124",
   "metadata": {},
   "source": [
    "### Add rest of features\n",
    "Now that we've settled the geometric and attribute commonalities between the base and join networks, we can add in the join network features that aren't represented in the base network. This is done using a buffer. If a join link is covered at least 95% by a base link, then it is left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce23175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "# added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "# #create new abmhere column with id and geo\n",
    "# final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)\n",
    "\n",
    "# final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "# final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c9d7fc5",
   "metadata": {},
   "source": [
    "### Save as pickle, this is more of a progress save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9278388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(added_base_final, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))\n",
    "#pickle.dump(added_base_nodes, open(\"processed_shapefiles/conflation/inter/abm_here_road.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a709e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Repeat for OSM\n",
    "#Now that we've resovled ABM and HERE, we can add the second join network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b47e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_name = \"abmhere\"\n",
    "# base_links = final_links\n",
    "# base_nodes = final_nodes\n",
    "\n",
    "# join_name = \"osm\"\n",
    "# join_links = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_links.geojson\")\n",
    "# join_nodes = gpd.read_file(r\"processed_shapefiles/osm/osm_bikewaysim_road_nodes.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean join links (no need to clean base links)\n",
    "#join_links, join_nodes = cleaning_process(join_links,join_nodes,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ffb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first match the nodes, can repeat this by adding in previously matched_nodes\n",
    "# tolerance_ft = 25\n",
    "# matched_nodes, unmatched_base_nodes, unmatched_join_nodes = match_nodes(base_nodes, base_name, join_nodes, join_name, tolerance_ft, prev_matched_nodes=None)\n",
    "\n",
    "# #join the matched nodes to the base nodes once done with matching\n",
    "# matched_nodes_final = pd.merge(base_nodes, matched_nodes, on = f'{base_name}_ID', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create new node and lines from the base links by splitting lines can repeat after the add_new_links_nodes function\n",
    "# tolerance_ft = 25\n",
    "# split_lines, split_nodes, unmatched_join_nodes = split_lines_create_points(unmatched_join_nodes,\n",
    "#                                                                            join_name,\n",
    "#                                                                            base_links,\n",
    "#                                                                            base_name,\n",
    "#                                                                            tolerance_ft,\n",
    "#                                                                            export = False)\n",
    "# split_lines.head()\n",
    "# split_lines.to_file('processed_shapefiles/conflation/split_lines.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add new links and nodes to the base links and nodes created from split_lines_create_points function\n",
    "# new_links, new_nodes = add_new_links_nodes(base_links, matched_nodes_final, split_lines, split_nodes, base_name)\n",
    "# new_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b96068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #match attribute information with greatest overlap from joining links\n",
    "# buffer_ft = 30\n",
    "# new_base_links_w_attr = add_attributes(new_links, base_name, join_links, join_name, buffer_ft)\n",
    "# new_base_links_w_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add unrepresented features from joining by looking at the attributes added in previous step for links and the list of matched nodes\n",
    "# added_base_links, added_base_nodes = add_rest_of_features(new_base_links_w_attr,new_nodes,base_name,join_links,join_nodes,join_name)\n",
    "\n",
    "# #create new abmhere column with id and geo\n",
    "# final_links, final_nodes = fin_subnetwork(added_base_links,added_base_nodes,base_name,join_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_links.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_links.geojson')\n",
    "# final_nodes.to_file(rf'processed_shapefiles/conflation/{base_name+join_name}_nodes.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df29cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike Subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bike layers\n",
    "# bike_links = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_links.geojson')\n",
    "# bike_nodes = gpd.read_file(r'processed_shapefiles/here/here_bikewaysim_bike_nodes.geojson')\n",
    "# bike_name = 'here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clean excess columns\n",
    "# bike_links, bike_nodes = cleaning_process(bike_links,bike_nodes,bike_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e26f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge with other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolerance_ft = 25\n",
    "# merged_links, merged_nodes = merge_diff_networks(added_base_links, added_base_nodes, 'road', bike_links, bike_nodes, 'bike', tolerance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add reference IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # match reference IDs based on all the id in the nodes\n",
    "# refid_base_links = add_reference_ids(merged_links, merged_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refid_base_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97216bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refid_base_links.to_file(r'processed_shapefiles\\conflation\\final_links.geojson', driver = 'GeoJSON')\n",
    "# merged_nodes.to_file(r'processed_shapefiles\\conflation\\final_nodes.geojson', driver = 'GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Convert for use in BikewaySim\n",
    "\n",
    "# This last section focusses on making sure that the conflated network is readable by BikewaySim. After this is completed, you can run the Running BikwaySim notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import pickle\n",
    "\n",
    "# #make directory/pathing more intuitive later\n",
    "# file_dir = r\"C:\\Users\\tpassmore6\\Documents\\BikewaySimData\" #directory of bikewaysim network processing code\n",
    "\n",
    "# #change this to where you stored this folder\n",
    "# os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8139fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filepath for just OSM network\n",
    "# conflated_linksfp\n",
    "# conflated_nodesfp\n",
    "\n",
    "# #filepath for conflated network\n",
    "# #conflated_linksfp = r'processed_shapefiles\\conflation\\final_links.geojson'\n",
    "# #conflated_nodesfp = r'processed_shapefiles\\conflation\\final_nodes.geojson'\n",
    "\n",
    "# #filepaths for network attribute data (doesn't have to be a shapefile)\n",
    "# abm_linksfp = r'processed_shapefiles\\abm\\abm_bikewaysim_base_links.geojson'\n",
    "# here_linksfp = r'processed_shapefiles\\here\\here_bikewaysim_base_links.geojson'\n",
    "# osm_linksfp = r'base_shapefiles\\osm\\osm_links_attr.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Node cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import conflated nodes\n",
    "# conflated_nodes = gpd.read_file(conflated_nodesfp)\n",
    "\n",
    "# #drop the num links columns\n",
    "# conflated_nodes = conflated_nodes.drop(columns=['abm_num_links','here_num_links'])\n",
    "\n",
    "# #create an N column that takes the abm_id if avaiable followed by the here_id\n",
    "# func = lambda row: row['here_ID'] if row['abm_ID'] == None else row['abm_ID']\n",
    "# conflated_nodes['N'] = conflated_nodes.apply(func,axis=1)\n",
    "\n",
    "# #create UTM coords columns\n",
    "# conflated_nodes['X'] = conflated_nodes.geometry.x\n",
    "# conflated_nodes['Y'] = conflated_nodes.geometry.y\n",
    "\n",
    "# #reproject and find latlon\n",
    "# conflated_nodes = conflated_nodes.to_crs(epsg=4326)\n",
    "# conflated_nodes['lon'] = conflated_nodes.geometry.x\n",
    "# conflated_nodes['lat'] = conflated_nodes.geometry.y\n",
    "\n",
    "# #filter\n",
    "# conflated_nodes = conflated_nodes[['N','X','Y','lon','lat','geometry']]\n",
    "\n",
    "# #export\n",
    "# conflated_nodes.to_file(r'processed_shapefiles\\prepared_network\\nodes\\nodes.geojson',driver='GeoJSON')\n",
    "# conlfated_nodes = conflated_nodes.drop(columns=['geometry'])\n",
    "# conflated_nodes.to_csv(r'processed_shapefiles\\prepared_network\\nodes\\nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa581937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conflated network\n",
    "#conflated_links = gpd.read_file(conflated_linksfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e350bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c268eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_network_and_attributes(conflated_links,attr_network,cols_to_keep):\n",
    "#     #find the shared columns between conflated network and attribute network\n",
    "#     shared_cols = list(conflated_links.columns[conflated_links.columns.isin(attr_network.columns)])\n",
    "\n",
    "#     if len(shared_cols) > 2:\n",
    "#         #merge based on shared columns\n",
    "#         conflated_links = pd.merge(conflated_links,attr_network[cols_to_keep + shared_cols],on=shared_cols,how='left')\n",
    "#         print(conflated_links.head(20))\n",
    "#     else:\n",
    "#         print(f'Attr_network columns not in conflated network')\n",
    "#     return conflated_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb472443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import data with attributes, don't bring in geometry\n",
    "# abm_links = gpd.read_file(abm_linksfp,ignore_geometry=True)\n",
    "\n",
    "# #specify which columns you need\n",
    "# cols_to_keep = ['NAME','SPEEDLIMIT','two_way']\n",
    "\n",
    "# #perform the merge\n",
    "# conflated_links = merge_network_and_attributes(conflated_links,abm_links,cols_to_keep)\n",
    "\n",
    "# #delete data with attributes to free up memory\n",
    "# del(abm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here_links = gpd.read_file(here_linksfp,ignore_geometry=True)\n",
    "\n",
    "# cols_to_keep = ['ST_NAME','DIR_TRAVEL']\n",
    "\n",
    "# conflated_links = merge_network_and_attributes(conflated_links,here_links,cols_to_keep)\n",
    "# del(here_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31888f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# osm_links = pickle.load(open(osm_linksfp,\"rb\"))\n",
    "\n",
    "# cols_to_keep = ['name']\n",
    "\n",
    "# conflated_links = merge_network_and_attributes(conflated_links,osm_links,cols_to_keep)\n",
    "# del(osm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conflated_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd48c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff058c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
